<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T22:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">S3Pool: Pooling with Stochastic Spatial Sampling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuangfei</forename><surname>Zhai</surname></persName>
							<email>szhai2@binghamton.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Binghamton Univeristy : IBM Research</orgName>
								<orgName type="institution" key="instit2">UC San Diego §</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Binghamton Univeristy : IBM Research</orgName>
								<orgName type="institution" key="instit2">UC San Diego §</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Binghamton Univeristy : IBM Research</orgName>
								<orgName type="institution" key="instit2">UC San Diego §</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
							<email>chengyu@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Binghamton Univeristy : IBM Research</orgName>
								<orgName type="institution" key="instit2">UC San Diego §</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxi</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Binghamton Univeristy : IBM Research</orgName>
								<orgName type="institution" key="instit2">UC San Diego §</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongfei</forename><surname>Zhang</surname></persName>
							<email>zhongfei@binghamton.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Binghamton Univeristy : IBM Research</orgName>
								<orgName type="institution" key="instit2">UC San Diego §</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
							<email>rsferis@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Binghamton Univeristy : IBM Research</orgName>
								<orgName type="institution" key="instit2">UC San Diego §</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">S3Pool: Pooling with Stochastic Spatial Sampling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Feature pooling layers (e.g., max pooling)   </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The use of pooling layers (max pooling, in particular) in deep convolutional neural networks (CNNs) is critical for their success in modern object recognition systems. In most of the common implementations, each pooling layer downsamples the spatial dimensions of feature maps by a factor of s (e.g., 2). This not only reduces the amount of computation required by the time consuming convolution operation in subsequent layers of the network, it also facilitates the higher layers to learn more abstract representations by looking at larger receptive fields.</p><p>In this paper, we provide new insights into the design of the pooling operation by viewing it as a two-step procedure. In the first step, a pooling window slides over the feature map with stride size 1 producing the pooled output; in the second step, spatial downsampling is performed by extracting the top-left corner element of each disjoint sˆs window, resulting in a feature map with s times smaller spatial dimensions. Our starting point in this work is the observation that although this uniformly spaced spatial downsampling is reasonable from a signal processing perspective which aims for signal reconstruction <ref type="bibr" target="#b18">[19]</ref> and is also computationally friendly, it is not necessarily the optimal design for the purpose of learning which aims for generalization to unseen examples <ref type="bibr" target="#b0">1</ref> .</p><p>Motivated by this observation, we introduce and study a novel pooling scheme, named S3Pool, where the second step (downsampling) is modified to a stochastic version. For a feature map with spatial dimensions hˆw, S3Pool begins with partitioning it into p vertical and q horizontal strips, with p " h g , q " w g and g being a hyperparameter named grid size. It then randomly selects g s rows and g s columns for each horizontal and vertical strip, respectively, with s being the stride, to obtain the final downsampled feature map of size h sˆw s . Compared to the downsampling used in standard pooling layers, S3Pool performs a spatial downsampling that is stochastic and hence is highly likely to be non-uniform. The stochastic nature of S3Pool enables it to produce different feature maps at each pass for the same training examples, which amounts to implicitly performing a sort of data augmentation <ref type="bibr" target="#b19">[20]</ref>, but at intermediate layers. Moreover, the non-uniform characteristics of S3Pool further extends the space of possible downsampled feature maps, which produces spatially distorted downsampled versions at each pass. The grid size g provides a handle for controlling the amount of distortion that S3Pool introduces, which can be used to adapt to CNNs with different designs, and different datasets. Overall, S3Pool acts as a strong regularizer by performing 'virtual' data augmentation at each pooling layer, and greatly enhances a model's generalization ability as observed in our empirical study.</p><p>Practically, S3Pool does not introduce any additional parameters, and can be plugged in place of any existing pooling layers. We have also empirically verified that S3Pool only introduces marginal computational overheads during training time (evaluated by time per epoch). During test time, S3Pool can either be reduced to standard max pooling, or be combined with an additional average pooling layer for a slightly better approximation of the stochastic downsampling step. In our experiments, we show that S3Pool yields excellent results on three standard image classification benchmarks, with two state-of-the-art architectures, namely network in network <ref type="bibr" target="#b16">[17]</ref>, and residual networks <ref type="bibr" target="#b8">[9]</ref>. We also extensively experiment with different data augmentation strategies, and show that under each setting, S3Pool is able to outperform other counterparts such as dropout <ref type="bibr" target="#b21">[22]</ref> and stochastic pooling <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The idea of spatial feature pooling dates back to the seminal work by Hubel and Wiesel <ref type="bibr" target="#b10">[11]</ref> about complex cells in the mammalian visual cortex and the early CNN architectures developed by Yann Lecun et al. <ref type="bibr" target="#b14">[15]</ref>. Prior to the reemergence of deep neural networks in computer vision, different approaches based on bag-of-words and fisher vector coding also had spatial pooling as an essential component of the visual recognition pipeline, e.g., through orderless bag-of-features <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6]</ref>, spatial pyramid aggregation <ref type="bibr" target="#b13">[14]</ref>, or task-driven feature pooling <ref type="bibr" target="#b22">[23]</ref>.</p><p>In modern CNN architectures, spatial pooling plays a fundamental role in achieving invariance (to some extent) to image transformations, and produces more compact representations for efficient processing in subsequent layers. Most existing methods rely on max or average pooling layers. Hybrid pooling <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18]</ref> combines different types of pooling into the same network architecture. Stochastic pooling <ref type="bibr" target="#b25">[26]</ref> randomly picks the activation within each pooling region according to a multinomial distribution. Max-out networks <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b20">21]</ref> perform pooling across different feature maps. Spatial pyramid pooling <ref type="bibr" target="#b7">[8]</ref> aggregates features at multiple scales, and is usually applied to extract fixed-length feature vectors from region proposals for object detection. Fractional pooling <ref type="bibr" target="#b4">[5]</ref> proposes to use pooling strides of less than 2 by applying mixed pooling strides of 1 and 2 at different locations. Learning-based methods for spatial feature pooling have also been proposed <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b0">1]</ref>.</p><p>As discussed previously, we view pooling as two distinct steps and propose stochastic spatial sampling as a novel solution that has not been investigated in previous work, to the best of our knowledge. Our approach is simple to implement, very efficient, and complementary to most of the techniques discussed above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Model Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">A Two-Step View of Max Pooling</head><p>Max pooling is perhaps the most widely adopted pooling option in deep CNNs, which usually follows one or several convolutional layers to reduce the spatial dimensions of the feature maps. Let x P R cˆhˆw be the input feature map before a pooling layer, where c is the number of channels and h and w are the height and width, respectively. A max . Max pooling (a) consists of two steps, selecting the activation inside each pooling region and spatial downsampling, where both steps are deterministic. Stochastic pooling <ref type="bibr" target="#b25">[26]</ref> adapts the first step by choosing the activation with a stochastic procedure (b). While our method modifies the second step by randomly selecting rows and columns from each spatial grid (c).</p><p>pooling layer with pooling window of size kˆk and stride sˆs is defined by the function z " P s k pxq, where z P R cˆh sˆw s , and z n,i,j " max</p><formula xml:id="formula_0">i 1 Prpi´1qs`1,pi´1qs`ks,i 1 ďh j 1 Prpj´1qs`1,pj´1qs`ks,j 1 ďw x n,i 1 ,j 1 , n P r1, cs, i P r1, h s s, j P r1, w s s.<label>(1)</label></formula><p>Specifically, to obtain the value at each spatial location of the output feature map z, P s k p¨q selects the maximum activation within the corresponding local region of size kˆk in x. While performed in a single step, conceptually, max pooling can be considered as two consecutive processes:</p><formula xml:id="formula_1">o " P 1 k pxq, z " D s poq,<label>(2)</label></formula><p>where z n,i,j " o n,pi´1qs`1,pj´1qs`1 . In the first step, max pooling with window size kˆk and stride 1ˆ1 is performed, producing an intermediate output o, which has the same dimension as x. In the second step, a spatial downsampling step is performed, where the value at the top left corner of each disjoint sˆs window is selected to produce the output feature map with the spatial dimension reduced by s times. The two-step view of max pooling allows us to investigate the differences of the effects of each step on learning. The first step P 1 k p¨q provides an additional level of nonlinearity to the CNN, as well as a certain degree of local (up to the scale of kˆk) distortion invariance. The second step D s p¨q, on the other hand, serves the purpose of reducing the amount of computation and weight parameters (given a fixed receptive field size) needed at upper layers of a deep CNN, as well as facilitating the model to learn more abstract representations by providing a more compact view of the input. We exploit this two-step view of the classical max pooling procedure and introduce a pooling algorithm which explicitly improves the downsampling step in order to learn models with better generalization ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pooling with Stochastic Spatial Sampling</head><p>While the typical downsampling step of a max pooling layer intuitively reduces the spatial dimension of a feature map by always selecting the activations at fixed locations, this design choice is somewhat arbitrary and potentially suboptimal. For example, as specified in Equation 2, the downsampling function D s p¨q selects only the activation at the top left corner of each sˆs disjoint window and discards the rest s 2´1 activations, which are equally informative for learning. Considering the total number of pooling layers present in a CNN, denoted by L, this deterministic downsampling approach discards s 2L´1 possible sampling choices. Therefore, although a natural design choice, deterministic uniform spatial sampling may not be optimal for the purpose of learning where the goal is to generalize. On the other hand, if we allow the downsampling step to be performed in a non-uniform and non-deterministic way, where the sampled indices are not restricted to be at evenly distributed locations, we are able to produce many variations of downsampled feature maps. Motivated by this observation, we propose S3Pool, a variant of max pooling with a stochastic spatial downsampling procedure 2 . S3Pool, denoted byP s k,g p¨q, works in a two-step fashion: the first step, P </p><formula xml:id="formula_2">r p " C g s rpp´1qg`1,pgs , c q " C g s rpq´1qg`1,qgs ,<label>(3)</label></formula><p>where C m ra,bs denotes a multinomial sampling function, which samples m sorted integers randomly from the interval ra, bs without replacement. The indices drawn from each vertical/horizontal grid are then concatenated, producing a set of rows, r " rr 1 , r 2 ,¨¨¨, r h g s and a set of columns, c " rc 1 , c 2 ,¨¨¨, c w g s, which leaves us the downsampled feature map being: z "D s g poq, where z n,i,j " o n,ri,cj . To summarize, given the grid size g, the stride s and the pooling window size k, S3Pool is defined as:</p><formula xml:id="formula_3">z "D s g pP 1 k pxqq (4)</formula><p>The grid size, g, is a hyperparameter of S3Pool which controls the level of stochasticity introduced. <ref type="figure">Figure 3</ref> illustrates the effect of changing the grid size for the stochastic spatial downsampling D 2 g p¨q. Larger grid sizes correspond to less uniformly sampled rows and columns. In the extreme case, where the grid size equals to the image size, S3Pool selects h s rows and w s columns from the entire input feature map in a purely random fashion, which yields the maximum amount of randomness in sampling.</p><p>The behavior ofD s g p¨q is intuitively visualized using an image as input <ref type="figure" target="#fig_0">(Figure 1</ref>), which is downsampled by applying uniform sampling, D 2 p¨q, and stochastic downsampling <ref type="bibr" target="#b1">2</ref> Although we work with max pooling as the underlying pooling mechanism since it is widely used, the proposed S3Pool is oblivious to the nature of the first stage pooling and is applicable just as well to other types of pooling schemes, e.g., average pooling, stochastic pooling <ref type="bibr" target="#b25">[26]</ref>, as well as strided convolution.</p><p>with different grid sizes,D w p¨q. It can be seen that all the stochastic spatial sampling variants produce images that are recognizable to human eyes, with certain degrees of distortion, even in the extreme case where the grid size equals to the image size. The benefit of S3Pool is thus obvious in that, each draw from the pooling step will produce different yet plausible downsampled feature maps, which is equivalent to performing data augmentation <ref type="bibr" target="#b19">[20]</ref> at the pooling layer level. However, compared with traditional data augmentation, such as image cropping <ref type="bibr" target="#b12">[13]</ref>, the distortion introduced by S3Pool is more aggressive. As a matter of fact, cropping (which corresponds to horizontal and vertical translation) can be considered as a special case of S3Pool in the input layer, with s " 1 and g " w, with the additional constraint that the sampled rows and columns are spatially contingent.</p><p>To further illustrate the idea of S3Pool and its difference from the standard max pooling, and another nondeterministic variant of max pooling <ref type="bibr" target="#b25">[26]</ref>, we demonstrate the different pooling processes in <ref type="figure" target="#fig_1">Figure 2</ref> using a toy feature map of size 1ˆ4ˆ4. From the two-step view of max pooling, stochastic pooling <ref type="bibr" target="#b25">[26]</ref> modifies the first step: instead of outputing a deterministic maximum in each pooling window of kˆk, it randomly draws a response according to the magnitude of the activation; the second downsampling step, however, remains the same as in max pooling. Different from stochastic pooling <ref type="bibr" target="#b25">[26]</ref> and deterministic max pooling, S3Pool offers the flexibility to control the amount of distortion introduced in each sampling step by varying the grid size g in each layer. This is useful especially for building deep CNNs with multiple pooling layers, which makes it possible to control the trade-off between the regularization strength and the converging speed.</p><p>In terms of implementation concerns, S3Pool does not introduce any additional parameters. It is easy to implement, and fast to compute during training time (in our experiments, we show that S3Pool introduces very little computational overhead compared to max pooling).</p><p>Inference Stage. During testing time, a straightforward but inefficient approach is to take the average classification outputs from many instances of CNN with S3Pool, which can otherwise act as a finite sample estimate of the expectation of S3Pool downsampling. A more efficient approach is to use the expectation of the downsampling procedure during testing. The expected value at a location pi, jq in the feature map (with r si :" ppi´1q mod g{sq`1, q si :" tspi´1q{gu, similarly for sj, and i P rh{ss, j P rw{ss) is given as Erz n,i,j s " where w ab " h a h b with h a "`a´1 r si´1˘`g´a g{s´r si˘{`g g{s˘w ith the convention`0 0˘" 1 (similar for h b with r si replaced with r sj). For g " s, this expectation reduces to average pooling over the sˆs windows in the second downsampling step. For g ą s, computing this expectation is expensive and cannot be easily parallelized in a GPU implementation, we thus still use average pooling with window and stride s in our experiments during testing as an approximation of this expectation. We also experimented with standard uniformly spaced downsampling at testing time (i.e., picking the top-left corner pixel), however this was consistently outperformed by average pooling, with negligible computational overhead. Hence, all the testing results of S3Pool in this paper are computed with average pooling over sˆs windows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We evaluate S3Pool with three popular image classification benchmarks: CIFAR-10, CIFAR-100 and STL-10. Both CIFAR-10 and CIFAR-100 consist of 32ˆ32 color images, each with 50,000 images for training and 10,000 images for testing. STL-10 consists of 96ˆ96 colored images evenly distributed in 10 classes, with 5,000 images for training and 8,000 images for testing. All the three datasets have relatively few examples, which makes proper regularization extremely important. We note that it is not our goal to obtain state-of-the-art results on these datasets, but rather to provide a fair analysis of the effectiveness of S3Pool compared to other pooling and regularization methods. <ref type="table" target="#tab_0">Table 1</ref>: The configurations of NIN and ResNet used on CIFAR-10 and CIFAR-100. Conv-c-d stands for a convolutional layer with c filters of size dˆd. Pool-k-s stands for a pooling layer with pooling window kˆk and stride sˆs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3ˆ"</head><p>Conv-32-3 Conv-32-3</p><p>Pool-2-2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3ˆ"</head><p>Conv-64-3 Conv-64-3</p><p>Pool-2-2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3ˆ"</head><p>Conv-128-3 Conv-128-3</p><p>Conv-10-1</p><p>Global Average Pooling Softmax</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">CIFAR-10 and CIFAR-100</head><p>For CIFAR-10 and CIFAR-100, we experiment with two state-of-the-art architectures, network in network (NIN) <ref type="bibr" target="#b16">[17]</ref> and residual networks (ResNet) <ref type="bibr" target="#b8">[9]</ref>, both of which are well established architectures, but with different designs. We apply identical architectures on CIFAR-10 and CIFAR-100, except for the top convolultional layer for softmax (10 versus 100). The architectures we use in this paper differ slightly from those in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b8">9]</ref>, which we summarize in <ref type="table" target="#tab_0">Table  1</ref>. Here Conv-c-d denotes a convolutional layer with c filters of size dˆd; Pool-k-s denotes a pooling layer implementation with pooling window kˆk and stride sˆs 3 . Batch normalization <ref type="bibr" target="#b11">[12]</ref> is applied to each convolutional layer for each of the two models, with ReLU as the nonlinearity.</p><p>For each of the two models, we experiment with three variants of the pooling layers:</p><p>Standard pooling: for NIN, both of the two Pool-2-2 layers are max pooling with pooling window of size 2ˆ2 and stride 2ˆ2; a dropout layer with rate 0.5 is also inserted after each pooling layer. For ResNet, we follow the original design in <ref type="bibr" target="#b8">[9]</ref> by replacing the Pool-2-2 layer with stride 2 convolution, without dropout.</p><p>Stochastic pooling: proposed by Zeiler et al. <ref type="bibr" target="#b25">[26]</ref> with pooling window of size 2ˆ2 and stride 2ˆ2.</p><p>S3Pool: the proposed pooling method with pooling window of size 2ˆ2 and stride 2ˆ2. Grid size g is set as 16 and 8 for the first and second S3Pool layer, respectively (that is, each feature map is divided into 2 vertical and horizontal strips). We denote this implementation of S3Pool as S3Pool- <ref type="bibr">16-8.</ref> In addition to experimenting with different network structures and pooling methods, we also employ different data augmentation strategies: with or without horizontal flipping and without or without cropping <ref type="bibr" target="#b3">4</ref> . We train all the models with ADADELTA <ref type="bibr" target="#b24">[25]</ref> with an initial learning rate of 1 and a batch size of 128. For all the NIN variants, training takes 200 epochs with the learning rate reduced to 0.1 at the 150-th epoch. All the ResNet variants are trained for a total of 120 epochs with the learning rate reduced to 0.1 at the 80-th epoch.</p><p>The experimental results are summarized in <ref type="table" target="#tab_1">Table 2 and  Table 3</ref> for NIN and Resnet respectively. For each set of the experiments, we show the training and testing error of the final epoch (for S3Pool, an average pooling layer of pooling window and stride 2ˆ2 is added following each S3Pool layer). We also show the average training time of each pooling option when used with different networks, measured by the number of seconds per epoch (that is, the time taken for a full pass of the training data for weight updates, and a full  pass of the testing data). We observe that for every combination of dataset type, network architecture and data augmentation technique (denoted by rows with the same color in <ref type="table" target="#tab_1">Table 2 and Table 3</ref>), S3Pool achieves the lowest testing error, while yielding higher training errors than NIN with dropout, ResNet and their counterparts with stochastic pooling <ref type="bibr" target="#b25">[26]</ref>. More remarkably, S3Pool without any data augmentation can outperform other methods with data augmentation in most of cases. In particular, S3Pool without data augmentation is able to outperform the baselines with cropping on all of the four dataset and architecture combinations. On CIFAR-10, S3Pool is even able to outperform image flipping and cropping augmented dropout version of NIN (9.30 versus 9.34). The high performance of S3Pool even without data augmentation is consistent with our understanding of the stochastic spatial sampling step as an implicit data augmentation strategy. Interestingly, while both flipping and cropping are beneficial to S3Pool, flipping seems to produce more performance gain than cropping. This is reasonable since the stochastic downsampling step in S3Pool does not change the horizontal spatial order of sampled columns.</p><p>As for the computational cost, S3Pool increases the training time by 8% and 4% on NIN and ResNet, respectively. Stochastic pooling, on the other hand, yields a much higher computational overhead of 66% and 27%, respectively <ref type="bibr" target="#b4">5</ref> . This demonstrates that S3Pool is indeed a practical as well as effective implementation choice when used in deep CNNs.</p><p>Effect of grid size To investigate the effect of the grid size of S3Pool, we take the same ResNet architecture used in Section 4.1, replace the S3Pool-16-8 layers with differ- <ref type="figure">Figure 4</ref>: Illustration of the behavior of S3Pool with deconvolutional neural networks on CIFAR-10 (best seen in color). From left to right: 50 images sampled from the test set, reconstructions obtained after the second pooling layer when using deterministic max pooling (center) and S3Pool (right). Note that even after two layers of stochastic spatial sampling, one is able to reconstruct recognizable images with various spatial distortions. ent grid size settings, and report the results on CIFAR-10 in <ref type="table" target="#tab_3">Table 4</ref>. We can observe that, in general, increasing the grid size of S3Pool yields larger training errors, as a result of more stochasticity; the testing error on the other hand, first decreases thanks to stronger regularization, then increases when the training error is too high. This observation suggests a trade-off between the optimization feasibility and the generalization ability, which can be adjusted in different applications by setting the grid sizes of each S3Pool layer.</p><p>Learning with limited training data We further take the same ResNet architecture, and perform experiments with fewer training examples in CIFAR-10, which is shown in <ref type="figure" target="#fig_6">Figure 5</ref>. The results indicate that, by varying the number of training examples from as low as 1000 to 10000, S3Pool achieves consistently lower testing errors compared with the baseline ResNet as well as stochastic pooling <ref type="bibr" target="#b25">[26]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">STL-10</head><p>STL-10 has much fewer training examples and larger image sizes compared with CIFAR-10/CIFAR-100. We adopt the 18-layer ResNet based architecture on this dataset, and test different pooling methods by replacing the stride 2 convolutions by stochastic pooling <ref type="bibr" target="#b25">[26]</ref> and S3Pool with different grid size settings. We follow similar training protocols as in Section 4.1, except that all the models are trained for 200 epochs with the learning rate decreased by a factor of 10 at the 150-th epoch, with no data augmentation applied.</p><p>The results are summarized in <ref type="table" target="#tab_4">Table 5</ref>. All variations of S3Pool significantly improve the performance of the baseline ResNet. In particular, S3Pool with the strongest regularization (S3Pool-96-48-24-12) achieves the state-ofthe-art testing error on STL-10, outperforming supervised learning <ref type="bibr" target="#b23">[24]</ref> as well as semi-supervised learning <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b2">3]</ref> approaches. In terms of computational cost, S3Pool only increases the training time by 16% compared with the basic ResNet, even with four S3Pool layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Visualization</head><p>Despite the convenient visualization of stochastic spatial sampling in the pixel space as shown in <ref type="figure" target="#fig_0">Figure 1</ref>, it is still unclear whether the same intuition holds when S3Pool is used in higher layers, and/or several S3Pool layers are stacked in a deep CNN. To this end, we obtain a trained NIN with two S3Pool layers as specified in Section 4.1, fix all the weights below the second S3Pool layer, turn off the stochasticity (i.e., using the test model of S3Pool) and stack a deconvolutional network <ref type="bibr" target="#b26">[27]</ref> on top. The output of the deconvolutional network is then trained to reconstruct the inputs from the training set of CIFAR-10 in a deterministic way. After training, we can sample reconstructions from the deconvolutional network with stochasticity. The results are shown in <ref type="figure">Figure 4</ref>, where in the left column we show 50 images from the testing set, and each row shows the first 5 images from each of the 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. The second column shows the reconstructions produced by the deconvolutional network with the test mode of S3Pool (no sampling). The third column shows the a single draw of the reconstructions from the network with S3Pool layers. Note that the third column gives different reconstructions at each run of the deconvolutional network, due to its stochastic nature.</p><p>It is noticed that by turning off the stochastic spatial sampling (second column), the deconvolutional network is able to faithfully reconstruct the shape and the location of the objects, subject to reduced image details. The reconstructions from the network with S3Pool are also visually meaningful, even with strong stochasticity (in this case, the grid sizes are set to 16 and 8 for the two S3Pool layers). In particular, most reconstructions correspond to recognizable objects with various spatial distortions: local rescaling, translation, and etc.. Also note that these distortions do not follow a fixed pattern, thus can not be easily obtained by applying a basic geometric transform to the images directly. Therefore, the benefit of S3Pool can be understood as, during training, instead of using samples from the training set directly (first column in <ref type="figure">Figure 4)</ref>, the S3Pool layers sample locally distorted features (third column in <ref type="figure">Figure  4</ref>) which are used implicitly for training. This corresponds to an aggressive data augmentation, which can significantly improve the generalization ability. The observation agrees with the results in <ref type="table" target="#tab_1">Table 2 and Table 3</ref>, where S3Pool outperforms all image cropping augmented baselines, as image cropping can be considered as a much milder data augmentation than S3Pool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We proposed S3Pool, a novel pooling method for CNNs. S3Pool extends the standard max pooling by decomposing pooling into two steps: max pooling with stride 1 and a non-deterministic spatial downsampling step by randomly sampling rows and columns from a feature map. In effect, S3Pool implicitly augments the training data at each pooling stage which enables superior generalization ability of the learned model. Extensive experiments on CIFAR-10 and CIFAR-100 have demonstrated that, S3Pool, either used in conjunction with data augmentation or not, significantly outperforms standard max pooling, dropout, and an existing stochastic pooling approach. In particular, by adjusting the level of stochasticity introduced by S3Pool using a simple mechanism, we obtained state-of-art result on STL-10. Additionally, S3Pool is simple to implement and introduces little computational overhead compared to general max pooling, which makes it a desirable design choice for learning deep CNNs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Illustration of the effect of different downsampling strategies. Left panel: the image before downsampling. Right panel from top left to bottom right: uniform downsampling, stochastic spatial downsampling with the grid size equivalent to a quarter of the image width/height, half of the image width/height, and the image width/height, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of different pooling methods (best seen in color). Max pooling (a) consists of two steps, selecting the activation inside each pooling region and spatial downsampling, where both steps are deterministic. Stochastic pooling [26] adapts the first step by choosing the activation with a stochastic procedure (b). While our method modifies the second step by randomly selecting rows and columns from each spatial grid (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2 Figure 3 :</head><label>23</label><figDesc>Figure 3: Controlling the amount of distortion/stochasticity by changing the grid size g in the stochastic downsampling step (best seen in color).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>w a,b o n,g q si`a,g | sj`b ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Testing error rate on CIFAR-10 with different training data sizes (best seen in color).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>1 k</head><label>1</label><figDesc>p¨q, is identical to max pooling, however, the second step, D s p¨q, is replaced by a stochastic versionD s g p¨q. Prior to the downsampling step of S3Pool, the feature map is divided into h g vertical and w g horizontal disjoint grids, indexed by p P r1, h g s and q P r1, w g s, respectively, with g being the grid size. Within each vertical/horizontal grid, g s rows/columns are randomly chosen:</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Control experiments with NIN [17] on CIFAR-10 and CIFAR-100 (best seen in color).</figDesc><table>Model 
flip crop 
CIFAR-10 
CIFAR-100 
sec/epoch 
train err test err train err test err 

NIN + dropout 
N 
N 
0.63 
10.68 
6.15 
35.24 

131 
NIN + dropout 
N 
Y 
1.62 
10.11 
11.64 
34.08 
NIN + dropout 
Y 
N 
1.28 
9.75 
8.57 
33.48 
NIN + dropout 
Y 
Y 
2.67 
9.34 
14.15 
32.36 

Zeiler et al.[26] N 
N 
0.01 
12.86 
0.1 
39.64 

218 
Zeiler et al.[26] N 
Y 
0.06 
10.97 
0.78 
35.44 
Zeiler et al.[26] Y 
N 
0.02 
10.47 
0.20 
36.82 
Zeiler et al.[26] Y 
Y 
0.22 
9.14 
1.54 
33.47 

S3Pool-16-8 
N 
N 
1.85 
9.30 
9.25 
33.85 

142 
S3Pool-16-8 
N 
Y 
2.86 
8.77 
11.44 
33.24 
S3Pool-16-8 
Y 
N 
3.26 
8.04 
13.19 
31.04 
S3Pool-16-8 
Y 
Y 
4.39 
7.71 
16.66 
30.90 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Control experiments with ResNet [17] on CIFAR-10 and CIFAR-100 (best seen in color). 

Model 
flip crop 
CIFAR-10 
CIFAR-100 
sec/epoch 
train err test err train err test err 

ResNet 
N 
N 
0.00 
14.07 
0.02 
42.32 

120 
ResNet 
N 
Y 
0.01 
9.21 
0.06 
33.88 
ResNet 
Y 
N 
0.00 
11.14 
0.02 
36.05 
ResNet 
Y 
Y 
0.06 
7.72 
0.48 
30.88 

Zeiler et al.[26] N 
N 
0.01 
9.94 
0.04 
34.42 

152 
Zeiler et al.[26] N 
Y 
0.04 
8.60 
0.27 
33.16 
Zeiler et al.[26] Y 
N 
0.05 
8.06 
0.15 
31.76 
Zeiler et al.[26] Y 
Y 
0.23 
8.58 
1.24 
30.09 

S3Pool-16-8 
N 
N 
0.82 
8.86 
3.97 
32.78 

125 
S3Pool-16-8 
N 
Y 
1.47 
8.48 
7.24 
32.21 
S3Pool-16-8 
Y 
N 
1.90 
7.31 
8.28 
30.65 
S3Pool-16-8 
Y 
Y 
3.23 
7.09 
12.47 
29.36 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 4 :</head><label>4</label><figDesc>Performance of different configurations of S3Pool by varying the grid sizes. All results are obtained with ResNet on CIFAR-10, without any data augmentation.</figDesc><table>Configuration train err test err 

S3Pool-32-16 2.58 
9.32 
S3Pool-16-8 
0.82 
8.86 
S3Pool-8-8 
1.29 
10.14 
S3Pool-8-4 
0.92 
11.04 
S3Pool-4-4 
0.72 
11.02 
S3Pool-2-2 
0.26 
13.01 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 5 :</head><label>5</label><figDesc>Results on STL-10. S3Pool-g 1 -g 2 -g 3 -g 4 denotes the configuration of the grid size at each of the four S3Pool layer.</figDesc><table>model 
train err test err sec/epoch 

ResNet 
0.00 
39.84 
30 
Zeiler et al. [26] 
0.00 
25.93 
70 

S3Pool-96-48-24-12 
2.12 
24.06 

35 

S3Pool-48-24-12-6 
1.04 
25.36 
S3Pool-24-12-6-4 
0.12 
29.21 
S3Pool-12-6-4-4 
0.12 
30.01 
S3Pool-4-4-4-4 
0.06 
29.60 
S3Pool-2-2-2-2 
0.02 
35.14 

Zhao et al. [28] 
-
25.47 
-
Dosovitskiy et al. [3] -
27.2 
Yang et al. [24] 
-
26.85 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Uniform sampling has also been examined in the Signal Processing literature, e.g., J. R. Higgins writes [10]: "What is special about equidistantly spaced sample points?"; and then finding that the answer is "Within certain limitations, nothing at all."</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">except for the baseline ResNet, which refers to a simple downsampling of sˆs. 4 4 pixels are padded at each border of the 32ˆ32 images, and random 32ˆ32 crops are selected at each forward pass.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">All models are implemented with Theano, and ran on a single NVIDIA K40 GPU.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Selecting receptive fields in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Visual categorization with bags of keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Willamowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV Workshop</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NIPS</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Maxout networks. ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Graham</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6071</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">Fractional max-pooling. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pyramid match kernels: Discriminative classification with sets of image features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learnednorm pooling for deep feedforward and recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MLKDD</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Spatial pyramid pooling in deep convolutional networks for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Sampling theory in Fourier and signal analysis: foundations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Higgins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Oxford University Press on Demand</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Receptive fields, binocular interaction and functional architecture in the cats visual cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hubel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Physiology</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="106" to="154" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generalizing pooling functions in convolutional neural networks: Mixed, gated, and tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AISTATS</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep multipatch aggregation network for image style, aesthetics, and quality estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Communication in the presence of noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IRE</title>
		<meeting>the IRE</meeting>
		<imprint>
			<date type="published" when="1949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Best practices for convolutional neural networks applied to visual document analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Steinkraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDAR</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Improving deep neural networks with probabilistic maxout units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">ICLR Workshop</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Task-driven feature pooling for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep representation learning with target coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<title level="m">Adadelta: an adaptive learning rate method</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Stochastic pooling for regularization of deep convolutional neural networks. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deconvolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Stacked what-where auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR Workshop</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
