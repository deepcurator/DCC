<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:40+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bayesian GAN</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bayesian</forename><surname>Gan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Uber AI Labs</orgName>
								<orgName type="institution" key="instit2">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunus</forename><surname>Saatchi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Uber AI Labs</orgName>
								<orgName type="institution" key="instit2">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Wilson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Uber AI Labs</orgName>
								<orgName type="institution" key="instit2">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunus</forename><surname>Saatci</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
						</author>
						<title level="a" type="main">Bayesian GAN</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Generative adversarial networks (GANs) can implicitly learn rich distributions over images, audio, and data which are hard to model with an explicit likelihood. We present a practical Bayesian formulation for unsupervised and semi-supervised learning with GANs. Within this framework, we use stochastic gradient Hamiltonian Monte Carlo to marginalize the weights of the generator and discriminator networks. The resulting approach is straightforward and obtains good performance without any standard interventions such as label smoothing or mini-batch discrimination. By exploring an expressive posterior over the parameters of the generator, the Bayesian GAN avoids mode-collapse, produces interpretable and diverse candidate samples, and provides state-of-the-art quantitative results for semi-supervised learning on benchmarks including SVHN, CelebA, and CIFAR-10, outperforming DCGAN, Wasserstein GANs, and DCGAN ensembles.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>over the network weights as a point mass centred on a single mode. Thus even if the generator does not memorize training examples, we would expect samples from the generator to be overly compact relative to samples from the data distribution. Moreover, each mode in the posterior over the network weights could correspond to wildly different generators, each with their own meaningful interpretations. By fully representing the posterior distribution over the parameters of both the generator and discriminator, we can more accurately model the true data distribution. The inferred data distribution can then be used for accurate and highly data-efficient semi-supervised learning.</p><p>In this paper, we propose a simple Bayesian formulation for end-to-end unsupervised and semisupervised learning with generative adversarial networks. Within this framework, we marginalize the posteriors over the weights of the generator and discriminator using stochastic gradient Hamiltonian Monte Carlo. We interpret data samples from the generator, showing exploration across several distinct modes in the generator weights. We also show data and iteration efficient learning of the true distribution. We also demonstrate state of the art semi-supervised learning performance on several benchmarks, including SVHN, MNIST, CIFAR-10, and CelebA. The simplicity of the proposed approach is one of its greatest strengths: inference is straightforward, interpretable, and stable. Indeed all of the experimental results were obtained without many of the ad-hoc techniques often used to train standard GANs.</p><p>We have made code and tutorials available at https://github.com/andrewgordonwilson/bayesgan.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Bayesian GANs</head><p>Given a dataset D = {x (i) } of variables x (i) ∼ p data (x (i) ), we wish to estimate p data (x). We transform white noise z ∼ p(z) through a generator G(z; θ g ), parametrized by θ g , to produce candidate samples from the data distribution. We use a discriminator D(x; θ d ), parametrized by θ d , to output the probability that any x comes from the data distribution. Our considerations hold for general G and D, but in practice G and D are often neural networks with weight vectors θ g and θ d .</p><p>By placing distributions over θ g and θ d , we induce distributions over an uncountably infinite space of generators and discriminators, corresponding to every possible setting of these weight vectors. The generator now represents a distribution over distributions of data. Sampling from the induced prior distribution over data instances proceeds as follows:</p><formula xml:id="formula_0">(1) Sample θ g ∼ p(θ g ); (2) Sample z (1) , . . . , z (n) ∼ p(z); (3)x (j) = G(z (j) ; θ g ) ∼ p generator (x)</formula><p>. For posterior inference, we propose unsupervised and semi-supervised formulations in Sec 2.1 -2.2.</p><p>We note that in an exciting recent work Tran et al. <ref type="bibr" target="#b10">[11]</ref> briefly mention using a variational approach to marginalize weights in a generative model, as part of a general exposition on hierarchical implicit models (see also <ref type="bibr">Karaletsos [5]</ref> for a nice theoretical exploration of related topics in graphical model message passing). While this related work is promising, our approach has several key differences: (1) our GAN representation is quite different, with novel formulations for the conditional posteriors, preserving a clear competition between generator and discriminator; (2) our representation for the posteriors is straightforward, provides novel formulations for unsupervised and semi-supervised learning, and has state of the art results on many benchmarks. Conversely, Tran et al. <ref type="bibr" target="#b10">[11]</ref> is only pursued for fully supervised learning on a few small datasets; (3) we use sampling to explore a full posterior over the weights, whereas Tran et al. <ref type="bibr" target="#b10">[11]</ref> perform a variational approximation centred on one of the modes of the posterior (and due to the properties of the KL divergence is prone to an overly compact representation of even that mode); (4) we marginalize z in addition to θ g , θ d ; and (5) the ratio estimation approach in <ref type="bibr" target="#b10">[11]</ref> limits the size of the neural networks they can use, whereas in our experiments we can use comparably deep networks to maximum likelihood approaches. In the experiments we illustrate the practical value of our formulation.</p><p>Although the high level concept of a Bayesian GAN has been informally mentioned in various contexts, to the best of our knowledge we present the first detailed treatment of Bayesian GANs, including novel formulations, sampling based inference, and rigorous semi-supervised learning experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Unsupervised Learning</head><p>To infer posteriors over θ g , θ d , we propose to iteratively sample from the following conditional posteriors:</p><formula xml:id="formula_1">p(θ g |z, θ d ) ∝ ng i=1 D(G(z (i) ; θ g ); θ d ) p(θ g |α g ) (1) p(θ d |z, X, θ g ) ∝ n d i=1 D(x (i) ; θ d ) × ng i=1 (1 − D(G(z (i) ; θ g ); θ d )) × p(θ d |α d ) .<label>(2)</label></formula><p>p(θ g |α g ) and p(θ d |α d ) are priors over the parameters of the generator and discriminator, with hyperparameters α g and α d , respectively. n d and n g are the numbers of mini-batch samples for the discriminator and generator, respectively. <ref type="bibr" target="#b0">1</ref> We define X = {x</p><formula xml:id="formula_2">(i) } n d i=1</formula><p>. We can intuitively understand this formulation starting from the generative process for data samples. Suppose we were to sample weights θ g from the prior p(θ g |α g ), and then condition on this sample of the weights to form a particular generative neural network. We then sample white noise z from p(z), and transform this noise through the network G(z; θ g ) to generate candidate data samples. The discriminator, conditioned on its weights θ d , outputs a probability that these candidate samples came from the data distribution. Eq. (1) says that if the discriminator outputs high probabilities, then the posterior p(θ g |z, θ d ) will increase in a neighbourhood of the sampled setting of θ g (and hence decrease for other settings). For the posterior over the discriminator weights θ d , the first two terms of Eq. (2) form a discriminative classification likelihood, labelling samples from the actual data versus the generator as belonging to separate classes. And the last term is the prior on θ d .</p><p>Classical GANs as maximum likelihood Moreover, our proposed probabilistic approach is a natural Bayesian generalization of the classical GAN: if one uses uniform priors for θ g and θ d , and performs iterative MAP optimization instead of posterior sampling over Eq. (1) and <ref type="bibr" target="#b1">(2)</ref>, then the local optima will be the same as for Algorithm 1 of Goodfellow et al. <ref type="bibr" target="#b3">[4]</ref>. We thus sometimes refer to the classical GAN as the ML-GAN. Moreover, even with a flat prior, there is a big difference between Bayesian marginalization over the whole posterior versus approximating this (often broad, multimodal) posterior with a point mass as in MAP optimization (see <ref type="figure">Figure 3</ref>, Supplement).</p><formula xml:id="formula_3">1 J d J d j p(θ d |z (j) , X, θ g ), z (j) ∼ p(z).</formula><p>This specific setup has several nice features for Monte Carlo integration. First, p(z) is a white noise distribution from which we can take efficient and exact samples. Secondly, both p(θ g |z, θ d ) and p(θ d |z, X, θ g ), when viewed as a function of z, should be reasonably broad over z by construction, since z is used to produce candidate data samples in the generative procedure. Thus each term in the simple Monte Carlo sum typically makes a reasonable contribution to the total marginal posterior estimates. We do note, however, that the approximation will typically be worse for p(θ d |θ g ) due to the conditioning on a minibatch of data in Equation 2.</p><p>Posterior samples By iteratively sampling from p(θ g |θ d ) and p(θ d |θ g ) at every step of an epoch one can, in the limit, obtain samples from the approximate posteriors over θ g and θ d . Having such samples can be very useful in practice. Indeed, one can use different samples for θ g to alleviate GAN collapse and generate data samples with an appropriate level of entropy, as well as forming a committee of generators to strengthen the discriminator. The samples for θ d in turn form a committee of discriminators which amplifies the overall adversarial signal, thereby further improving the unsupervised learning process. Arguably, the most rigorous method to assess the utility of these posterior samples is to examine their effect on semi-supervised learning, which is a focus of our experiments in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Semi-supervised Learning</head><p>We extend the proposed probabilistic GAN formalism to semi-supervised learning. In the semisupervised setting for K-class classification, we have access to a set of n unlabelled observations, {x (i) }, as well as a (typically much smaller) set of n s observations, {(x</p><formula xml:id="formula_4">(i) s , y (i) s )} Ns i=1</formula><p>, with class labels y (i) s ∈ {1, . . . , K}. Our goal is to jointly learn statistical structure from both the unlabelled and labelled examples, in order to make much better predictions of class labels for new test examples x * than if we only had access to the labelled training inputs.</p><p>In this context, we redefine the discriminator such that D(</p><formula xml:id="formula_5">x (i) = y (i) ; θ d )</formula><p>gives the probability that sample x (i) belongs to class y (i) . We reserve the class label 0 to indicate that a data sample is the output of the generator. We then infer the posterior over the weights as follows:</p><formula xml:id="formula_6">p(θ g |z, θ d ) ∝ ng i=1 K y=1 D(G(z (i) ; θ g ) = y; θ d ) p(θ g |α g ) (3) p(θ d |z, X, y s , θ g ) ∝ n d i=1 K y=1 D(x (i) = y; θ d ) ng i=1 D(G(z (i) ; θ g ) = 0; θ d ) Ns i=1 (D(x (i) s = y (i) s ; θ d ))p(θ d |α d )<label>(4)</label></formula><p>During every iteration we use n g samples from the generator, n d unlabeled samples, and all of the N s labeled samples, where typically N s n. As in Section 2.1, we can approximately marginalize z using simple Monte Carlo sampling.</p><p>Much like in the unsupervised learning case, we can marginalize the posteriors over θ g and θ d . To compute the predictive distribution for a class label y * at a test input x * we use a model average over all collected samples with respect to the posterior over θ d :</p><formula xml:id="formula_7">p(y * |x * , D) = p(y * |x * , θ d )p(θ d |D)dθ d ≈ 1 T T k=1 p(y * |x * , θ (k) d ) , θ (k) d ∼ p(θ d |D) .<label>(5)</label></formula><p>We will see that this model average is effective for boosting semi-supervised learning performance. In Section 3 we present an approach to MCMC sampling from the posteriors over θ g and θ d .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Posterior Sampling with Stochastic Gradient HMC</head><p>In the Bayesian GAN, we wish to marginalize the posterior distributions over the generator and discriminator weights, for unsupervised learning in 2.1 and semi-supervised learning in 2.2. For this purpose, we use Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) <ref type="bibr" target="#b2">[3]</ref> for posterior sampling. The reason for this choice is three-fold: (1) SGHMC is very closely related to momentum-based SGD, which we know empirically works well for GAN training; (2) we can import parameter settings (such as learning rates and momentum terms) from SGD directly into SGHMC; and most importantly, (3) many of the practical benefits of a Bayesian approach to GAN inference come from exploring a rich multimodal distribution over the weights θ g of the generator, which is enabled by SGHMC. Alternatives, such as variational approximations, will typically centre their mass around a single mode, and thus provide a unimodal and otherwise compact representation for the distribution, due to asymmetric biases of the KL-divergence.</p><p>The posteriors in Equations 3 and 4 are both amenable to HMC techniques as we can compute the gradients of the loss with respect to the parameters we are sampling. SGHMC extends HMC to the case where we use noisy estimates of such gradients in a manner which guarantees mixing in the limit of a large number of minibatches. For a detailed review of SGHMC, please see Chen et al. <ref type="bibr" target="#b2">[3]</ref>. Using the update rules from Eq. (15) in Chen et al. <ref type="bibr" target="#b2">[3]</ref>, we propose to sample from the posteriors over the generator and discriminator weights as in Algorithm 1. Note that Algorithm 1 outlines standard momentum-based SGHMC: in practice, we found it helpful to speed up the "burn-in" process by replacing the SGD part of this algorithm with Adam for the first few thousand iterations, after which we revert back to momentum-based SGHMC. As suggested in Appendix G of Chen et al. <ref type="bibr" target="#b2">[3]</ref>, we employed a learning rate schedule which decayed according to γ/d where d is set to the number of unique "real" datapoints seen so far. Thus, our learning rate schedule converges to γ/N in the limit, where we have defined N = |D|.</p><p>Algorithm 1 One iteration of sampling for the Bayesian GAN. α is the friction term for SGHMC, η is the learning rate. We assume that the stochastic gradient discretization noise termβ is dominated by the main friction term (this assumption constrains us to use small step sizes). We take Jg and J d simple MC samples for the generator and discriminator respectively, and M SGHMC samples for each simple MC sample. We rescale to accommodate minibatches as in the supplementary material.</p><p>• Represent posteriors with samples {θ</p><formula xml:id="formula_8">j,m g } Jg,M</formula><p>j=1,m=1 and {θ</p><formula xml:id="formula_9">j,m d } J d ,M</formula><note type="other">j=1,m=1 from previous iteration for number of MC iterations J g do • Sample J g noise samples {z (1) , . . . , z (Jg) } from noise prior p(z). Each z (i) has n g samples. • Update sample set representing p(θ g |θ d ) by running SGHMC updates for M iterations:</note><formula xml:id="formula_10">θ j,m g ← θ j,m g + v; v ← (1 − α)v + η ∂ log i k p(θ g |z (i) , θ k,m d ) ∂θ g + n; n ∼ N (0, 2αηI)</formula><p>•</p><note type="other">Append θ j,m g to sample set. end for for number of MC iterations J d do • Sample minibatch of J d noise samples {z (1) , . . . , z (J d ) } from noise prior p(z). • Sample minibatch of n d data samples x. • Update sample set representing p(θ d |z, θ g ) by running SGHMC updates for M iterations:</note><formula xml:id="formula_11">θ j,m d ← θ j,m d + v; v ← (1 − α)v + η ∂ log i k p(θ d |z (i) , x, θ k,m g ) ∂θ d + n; n ∼ N (0, 2αηI) • Append θ j,m d</formula><p>to sample set. end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate our proposed Bayesian GAN (henceforth titled BayesGAN) on six benchmarks (synthetic, MNIST, CIFAR-10, SVHN, and CelebA) each with four different numbers of labelled examples. We consider multiple alternatives, including: the DCGAN <ref type="bibr" target="#b8">[9]</ref>, the recent Wasserstein GAN (W-DCGAN) <ref type="bibr" target="#b0">[1]</ref>, an ensemble of ten DCGANs (DCGAN-10) which are formed by 10 random subsets 80% the size of the training set, and a fully supervised convolutional neural network. We also compare to the reported MNIST result for the LFVI-GAN, briefly mentioned in a recent work <ref type="bibr" target="#b10">[11]</ref>, where they use fully supervised modelling on the whole dataset with a variational approximation. We interpret many of the results from MNIST in detail in Section 4.2, and find that these observations carry forward to our CIFAR-10, SVHN, and CelebA experiments.</p><p>For all real experiments except MNIST we use a 6-layer Bayesian deconvolutional GAN (BayesGAN) for the generative model G(z|θ g ) (see Radford et al. <ref type="bibr" target="#b8">[9]</ref> for further details about structure). The corresponding discriminator is a 6-layer 2-class DCGAN for the unsupervised GAN and a 6-layer, K + 1 class DCGAN for a semi-supervised GAN performing classification over K classes. The connectivity structure of the unsupervised and semi-supervised DCGANs were the same as for the BayesGAN. As recommended by <ref type="bibr" target="#b9">[10]</ref>, we used feature matching for all models on semi-supervised experiments. For MNIST we found that 4-layers for all networks worked slightly better across the board, due to the added simplicity of the dataset. Note that the structure of the networks in Radford et al. <ref type="bibr" target="#b8">[9]</ref> are slightly different from <ref type="bibr" target="#b9">[10]</ref> (e.g. there are 4 hidden layers and fewer filters per layer), so one cannot directly compare the results here with those in Salimans et al. <ref type="bibr" target="#b9">[10]</ref>. Our exact architecture specification is also given in our codebase. The performance of all methods could be improved through further calibrating architecture design for each individual benchmark. For the Bayesian GAN we place a N (0, 10I) prior on both the generator and discriminator weights and approximately integrate out z using simple Monte Carlo samples. We run Algorithm 1 for 5000 iterations and then collect weight samples every 1000 iterations and record out-of-sample predictive accuracy using Bayesian model averaging (see Eq. 5). For Algorithm 1 we set J g = 10, J d = 1, M = 2, and n d = n g = 64. All experiments were performed on a single TitanX GPU for consistency, but BayesGAN and DCGAN-10 could be sped up to approximately the same runtime as DCGAN through multi-GPU parallelization.</p><p>In <ref type="table" target="#tab_0">Table 1</ref> we summarize the semi-supervised results, where we see consistently improved performance over the alternatives. All runs are averaged over 10 random subsets of labeled examples for estimating error bars on performance <ref type="table" target="#tab_0">(Table 1</ref> shows mean and 2 standard deviations). We also qualitatively illustrate the ability for the Bayesian GAN to produce complementary sets of data samples, corresponding to different representations of the generator produced by sampling from the posterior over the generator weights <ref type="figure" target="#fig_0">(Figures 1, 2, 5</ref>). The supplement also contains additional plots of accuracy per epoch for semi-supervised experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Synthetic Dataset</head><p>We present experiments on a multi-modal synthetic dataset to test the ability to infer a multi-modal posterior p(θ g |D). This ability not only helps avoid the collapse of the generator to a couple training examples, an instance of overfitting in regular GAN training, but also allows one to explore a set of generators with different complementary properties, harmonizing together to encapsulate a rich data distribution. We generate D-dimensional synthetic data as follows:</p><formula xml:id="formula_12">z ∼ N (0, 10 * I d ), A ∼ N (0, I D×d ), x = Az + , ∼ N (0, 0.01 * I D ), d D</formula><p>We then fit both a regular GAN and a Bayesian GAN to such a dataset with D = 100 and d = 2. The generator for both models is a two-layer neural network: 10-1000-100, fully connected, with ReLU activations. We set the dimensionality of z to be 10 in order for the DCGAN to converge (it does not converge when d = 2, despite the inherent dimensionality being 2!). Consistently, the discriminator network has the following structure: 100-1000-1, fully-connected, ReLU activations. For this dataset we place an N (0, I) prior on the weights of the Bayesian GAN and approximately integrate out z using J = 100 Monte-Carlo samples. <ref type="figure" target="#fig_0">Figure 1</ref> shows that the Bayesian GAN does a much better job qualitatively in generating samples (for which we show the first two principal components), and quantitatively in terms of Jensen-Shannon divergence (JSD) to the true distribution (determined through kernel density estimates). In fact, the DCGAN (labelled ML GAN as per Section 2) begins to eventually increase in testing JSD after a certain number of training iterations, which is reminiscent of over-fitting. When D = 500, we still see good performance with the Bayesian GAN. We also see, with multidimensional scaling <ref type="bibr" target="#b1">[2]</ref>, that samples from the posterior over Bayesian generator weights clearly form multiple distinct clusters, indicating that the SGHMC sampling is exploring multiple distinct modes, thus capturing multimodality in weight space as well as in data space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">MNIST</head><p>MNIST is a well-understood benchmark dataset consisting of 60k (50k train, 10k test) labeled images of hand-written digits. Salimans et al. <ref type="bibr" target="#b9">[10]</ref> showed excellent out-of-sample performance using only a small number of labeled inputs, convincingly demonstrating the importance of good generative modelling for semi-supervised learning. Here, we follow their experimental setup for MNIST.</p><p>We evaluate the Bayesian DCGAN for semi-supervised learning using N s = {20, 50, 100, 200} labelled training examples. We see in <ref type="table" target="#tab_0">Table 1</ref> that the Bayesian GAN has improved accuracy over the DCGAN, the Wasserstein GAN, and even an ensemble of 10 DCGANs! Moreover, it is remarkable that the Bayesian GAN with only 100 labelled training examples (0.2% of the training data) is able to achieve 99.3% testing accuracy, which is comparable with a state of the art fully supervised method using all 50, 000 training examples! We show a fully supervised model using n s samples to generally highlight the practical utility of semi-supervised learning.</p><p>Moreover, Tran et al. <ref type="bibr" target="#b10">[11]</ref> showed that a fully supervised LFVI-GAN, on the whole MNIST training set (50, 000 labelled examples) produces 140 classification errors -almost twice the error of our proposed Bayesian GAN approach using only n s = 100 (0.2%) labelled examples! We suspect this difference largely comes from (1) the simple practical formulation of the Bayesian GAN in Section 2, (2) marginalizing z via simple Monte Carlo, and (3) exploring a broad multimodal posterior distribution over the generator weights with SGHMC with our approach versus a variational approximation (prone to over-compact representations) centred on a single mode.</p><p>We can also see qualitative differences in the unsupervised data samples from our Bayesian DCGAN and the standard DCGAN in <ref type="figure" target="#fig_1">Figure 2</ref>. The top row shows sample images produced from six generators produced from six samples over the posterior of the generator weights, and the bottom row shows sample data images from a DCGAN. We can see that each of the six panels in the top row have Samples drawn from pMLGAN(x) and pBGAN(x) visualized in 2D after applying PCA. The data is inherently 2-dimensional so PCA can explain most of the variance using 2 principal components. It is clear that the Bayesian GAN is capturing all the modes in the data whereas the regular GAN is unable to do so. Right: (Top 2) Jensen-Shannon divergence between pdata(x) and p(x; θ) as a function of the number of iterations of GAN training for D = 100 (top) and D = 500 (bottom). The divergence is computed using kernel density estimates of large sample datasets drawn from pdata(x) and p(x; θ), after applying dimensionality reduction to 2-D (the inherent dimensionality of the data). In both cases, the Bayesian GAN is far more effective at minimizing the Jensen-Shannon divergence, reaching convergence towards the true distribution, by exploring a full distribution over generator weights, which is not possible with a maximum likelihood GAN (no matter how many iterations). (Bottom) The sample set {θ k g } after convergence viewed in 2-D using Multidimensional Scaling (using a Euclidean distance metric between weight samples) <ref type="bibr" target="#b1">[2]</ref>. One can clearly see several clusters, meaning that the SGHMC sampling has discovered pronounced modes in the posterior over the weights.</p><p>qualitative differences, almost as if a different person were writing the digits in each panel. Panel 1 (top left), for example, is quite crisp, while panel 3 is fairly thick, and panel 6 (top right) has thin and fainter strokes. In other words, the Bayesian GAN is learning different complementary generative hypotheses to explain the data. By contrast, all of the data samples on the bottom row from the DCGAN are homogenous. In effect, each posterior weight sample in the Bayesian GAN corresponds to a different style, while in the standard DCGAN the style is fixed. This difference is further illustrated for all datasets in <ref type="figure">Figure 5</ref> (supplement). <ref type="figure">Figure 3</ref> (supplement) also further emphasizes the utility of Bayesian marginalization versus optimization, even with vague priors.</p><p>However, we do not necessarily expect high fidelity images from any arbitrary generator sampled from the posterior over generators; in fact, such a generator would probably have less posterior probability than the DCGAN, which we show in Section 2 can be viewed as a maximum likelihood analogue of our approach. The advantage in the Bayesian approach comes from representing a whole space of generators alongside their posterior probabilities.</p><p>Practically speaking, we also stress that for reasonable sample generation from the maximumlikelihood DCGAN we had to resort to using tricks including minibatch discrimination, feature normalization and the addition of Gaussian noise to each layer of the discriminator. The Bayesian DCGAN needed none of these tricks. This robustness arises from a Gaussian prior over the weights which provides a useful inductive bias, and due to the MCMC sampling procedure which alleviates the risk of collapse and helps explore multiple modes (and uncertainty within each mode). To be balanced, we also stress that in practice the risk of collapse is not fully eliminated -indeed, some samples from p(θ g |D) still produce generators that create data samples with too little entropy. In practice, sampling is not immune to becoming trapped in sharply peaked modes. We leave further analysis for future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">CIFAR-10</head><p>CIFAR-10 is also a popular benchmark dataset <ref type="bibr" target="#b6">[7]</ref>, with 50k training and 10k test images, which is harder to model than MNIST since the data are 32x32 RGB images of real objects. <ref type="figure">Figure 5</ref> shows datasets produced from four different generators corresponding to samples from the posterior over the generator weights. As with MNIST, we see meaningful qualitative variation between the panels. In <ref type="table" target="#tab_0">Table 1</ref> we also see again (but on this more challenging dataset) that using Bayesian GANs as a generative model within the semi-supervised learning setup significantly decreases test set error over the alternatives, especially when n s n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">SVHN</head><p>The StreetView House Numbers (SVHN) dataset consists of RGB images of house numbers taken by StreetView vehicles. Unlike MNIST, the digits significantly differ in shape and appearance. The experimental procedure closely followed that for CIFAR-10. There are approximately 75k training and 25k test images. We see in <ref type="table" target="#tab_0">Table 1</ref> a particularly pronounced difference in performance between BayesGAN and the alternatives. Data samples are shown in <ref type="figure">Figure 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">CelebA</head><p>The large CelebA dataset contains 120k celebrity faces amongst a variety of backgrounds (100k training, 20k test images). To reduce background variations we used a standard face detector <ref type="bibr" target="#b11">[12]</ref> to crop the faces into a standard 50 × 50 size. <ref type="figure">Figure 5</ref> shows data samples from the trained Bayesian GAN. In order to assess performance for semi-supervised learning we created a 32-class classification task by predicting a 5-bit vector indicating whether or not the face: is blond, has glasses, is male, is pale and is young. <ref type="table" target="#tab_0">Table 1</ref> shows the same pattern of promising performance for CelebA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>By exploring rich multimodal distributions over the weight parameters of the generator, the Bayesian GAN can capture a diverse set of complementary and interpretable representations of data. We have shown that such representations can enable state of the art performance on semi-supervised problems, using a simple inference procedure.</p><p>Effective semi-supervised learning of natural high dimensional data is crucial for reducing the dependency of deep learning on large labelled datasets. Often labeling data is not an option, or it comes at a high cost -be it through human labour or through expensive instrumentation (such as LIDAR for autonomous driving). Moreover, semi-supervised learning provides a practical and quantifiable mechanism to benchmark the many recent advances in unsupervised learning.</p><p>Although we use MCMC, in recent years variational approximations have been favoured for inference in Bayesian neural networks. However, the likelihood of a deep neural network can be broad with many shallow local optima. This is exactly the type of density which is amenable to a sampling based approach, which can explore a full posterior. Variational methods, by contrast, typically centre their approximation along a single mode and also provide an overly compact representation of that mode. Therefore in the future we may generally see advantages in following a sampling based approach in Bayesian deep learning. Aside from sampling, one could try to better accommodate the likelihood functions common to deep learning using more general divergence measures (for example based on the family of α-divergences) instead of the KL divergence in variational methods, alongside more flexible proposal distributions.</p><p>In the future, one could also estimate the marginal likelihood of a probabilistic GAN, having integrated away distributions over the parameters. The marginal likelihood provides a natural utility function for automatically learning hyperparameters, and for performing principled quantifiable model comparison between different GAN architectures. It would also be interesting to consider the Bayesian GAN in conjunction with a non-parametric Bayesian deep learning framework, such as deep kernel learning <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>. We hope that our work will help inspire continued exploration into Bayesian deep learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Left: Samples drawn from pdata(x) and visualized in 2-D after applying PCA. Right 2 columns:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Top: Data samples from six different generators corresponding to six samples from the posterior over θg. The data samples show that each explored setting of the weights θg produces generators with complementary high-fidelity samples, corresponding to different styles. The amount of variety in the samples emerges naturally using the Bayesian approach. Bottom: Data samples from a standard DCGAN (trained six times). By contrast, these samples are homogenous in style.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Detailed supervised and semi-supervised learning results for all datasets. In almost all experiments BayesGAN outperforms DCGAN and W-DCGAN substantially, and typically even outperforms ensembles of DCGANs. The runtimes, per epoch, in minutes, are provided in rows including the dataset name. While all experiments were performed on a single GPU, note that DCGAN-10 and BayesGAN methods can be sped up straightforwardly using multiple GPUs to obtain a similar runtime to DCGAN. Note also that the BayesGAN is generally much more efficient per epoch than the alternatives, as per Figure 4 (supplement). Results are averaged over 10 random supervised subsets ± 2 stdev. Standard train/test splits are used for MNIST, CIFAR-10 and SVHN. For CelebA we use a test set of size 10k. Test error rates are across the entire test set. Ns No. of misclassifications for MNIST. Test error rate for others.</figDesc><table></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Marginalizing the noise In prior work, GAN updates are implicitly conditioned on a set of noise samples z. We can instead marginalize z from our posterior updates using simple Monte Carlo: p(θ g |θ d ) = p(θ g , z|θ d )dz = p(θ g |z, θ d ) =p(z) p(z|θ d ) dz ≈ 1 J g Jg j=1 p(θ g |z (j) , θ d ) , z (j) ∼ p(z) By following a similar derivation, p(θ d |θ g ) ≈</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For mini-batches, one must make sure the likelihood and prior are scaled appropriately. See Supplement.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements We thank Pavel Izmailov and Ben Athiwaratkun for helping to create a tutorial for the codebase, helpful comments and validation. We also thank Soumith Chintala for helpful advice. We thank NSF IIS-1563887 for support.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">Wasserstein GAN. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Modern multidimensional scaling: Theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Groenen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stochastic gradient Hamiltonian Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning</title>
		<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Adversarial message passing for graphical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karaletsos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.05048</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational Bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Cifar-10</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>Canadian institute for advanced research</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">f-GAN: Training generative neural samplers using variational divergence minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tomioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<title level="m">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Improved techniques for training gans. CoRR, abs/1606.03498</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hierarchical implicit models and likelihood-free variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5529" to="5539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Robust real-time face detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep kernel learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Stochastic variational deep kernel learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2586" to="2594" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
