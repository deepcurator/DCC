<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:20+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Follow the Moving Leader in Deep Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zheng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
						</author>
						<title level="a" type="main">Follow the Moving Leader in Deep Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Deep networks are highly nonlinear and difficult to optimize. During training, the parameter iterate may move from one local basin to another, or the data distribution may even change. Inspired by the close connection between stochastic optimization and online learning, we propose a variant of the follow the regularized leader (FTRL) algorithm called follow the moving leader (FTML). Unlike the FTRL family of algorithms, the recent samples are weighted more heavily in each iteration and so FTML can adapt more quickly to changes. We show that FTML enjoys the nice properties of RMSprop and Adam, while avoiding their pitfalls. Experimental results on a number of deep learning models and tasks demonstrate that FTML converges quickly, and outperforms other state-ofthe-art optimizers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recently, deep learning has emerged as a powerful and popular class of machine learning algorithms. Well-known examples include the convolutional neural network <ref type="bibr" target="#b18">(LeCun et al., 1998)</ref>, long short term memory <ref type="bibr" target="#b14">(Hochreiter &amp; Schmidhuber, 1997)</ref>, memory network <ref type="bibr" target="#b33">(Weston et al., 2014)</ref>, and deep Q-network <ref type="bibr" target="#b24">(Mnih et al., 2015)</ref>. These models have achieved remarkable performance on various difficult tasks such as image classification <ref type="bibr" target="#b12">(He et al., 2016)</ref>, speech recognition <ref type="bibr" target="#b10">(Graves et al., 2013)</ref>, natural language understanding <ref type="bibr" target="#b1">(Bahdanau et al., 2015;</ref><ref type="bibr" target="#b28">Sukhbaatar et al., 2015)</ref>, and game playing .</p><p>Deep network is a highly nonlinear model with typically millions of parameters <ref type="bibr" target="#b13">(Hinton et al., 2006)</ref>. Thus, it is imperative to design scalable and effective solvers. How-ever, training deep networks is difficult as the optimization can suffer from pathological curvature and get stuck in local minima <ref type="bibr" target="#b20">(Martens, 2010)</ref>. Moreover, every critical point that is not a global minimum is a saddle point <ref type="bibr" target="#b16">(Kawaguchi, 2016)</ref>, which can significantly slow down training. Second-order information is useful in that it reflects local curvature of the error surface. However, a direct computation of the Hessian is computationally infeasible. <ref type="bibr" target="#b20">Martens (2010)</ref> introduced Hessian-free optimization, a variant of truncated-Newton methods that relies on using the linear conjugate gradient to avoid computing the Hessian. <ref type="bibr" target="#b6">Dauphin et al. (2014)</ref> proposed to use the absolute Hessian to escape from saddle points. However, these methods still require higher computational costs.</p><p>Recent advances in deep learning optimization focus mainly on stochastic gradient descent (SGD) <ref type="bibr" target="#b2">(Bottou, 1998)</ref> and its variants <ref type="bibr" target="#b29">(Sutskever et al., 2013)</ref>. However, SGD requires careful stepsize tuning, which is difficult as different weights have vastly different gradients (in terms of both magnitude and direction). On the other hand, online learning <ref type="bibr" target="#b37">(Zinkevich, 2003)</ref>, which is closely related to stochastic optimization, has been extensively studied in the past decade. Well-known algorithms include follow the regularized leader (FTRL) <ref type="bibr" target="#b15">(Kalai &amp; Vempala, 2005)</ref>, follow the proximally-regularized leader (FTPRL) <ref type="bibr" target="#b22">(McMahan &amp; Streeter, 2010)</ref> and their variants <ref type="bibr" target="#b8">(Duchi &amp; Singer, 2009;</ref><ref type="bibr" target="#b9">Duchi et al., 2011;</ref><ref type="bibr" target="#b26">Shalev-Shwartz, 2012;</ref><ref type="bibr" target="#b35">Xiao, 2010)</ref>. In particular, adaptive gradient descent (Adagrad) <ref type="bibr" target="#b9">(Duchi et al., 2011)</ref> uses an adaptive per-coordinate stepsize. On convex problems, it has been shown both theoretically and empirically that Adagrad is especially efficient on highdimensional data <ref type="bibr" target="#b9">(Duchi et al., 2011;</ref><ref type="bibr" target="#b23">McMahan et al., 2013)</ref>. When used on deep networks, Adagrad also demonstrates significantly better performance than SGD <ref type="bibr" target="#b7">(Dean et al., 2012)</ref>. However, in Adagrad, the variance estimate underlying the adaptive stepsize is based on accumulating all past (squared) gradients. This becomes infinitesimally small as training proceeds. In more recent algorithms, such as RMSprop <ref type="bibr" target="#b31">(Tieleman &amp; Hinton, 2012)</ref> and Adam <ref type="bibr" target="#b17">(Kingma &amp; Ba, 2015)</ref>, the variance is estimated by an exponentially decaying average of the squared gradients.</p><p>Another problem with the FTRL family of algorithms is that in each round, the learner has to solve an optimization problem that considers the sum of all previous gradients.</p><p>For highly nonconvex models such as the deep network, the parameter iterate may move from one local basin to another. Gradients that are due to samples in the distant past are less informative than those from the recent ones. In applications where the data distribution is changing (as in deep reinforcement learning), this may impede parameter adaptation to the environment.</p><p>To alleviate this problem, we propose a FTPRL variant that reweighs the learning subproblems in each iteration. The proposed algorithm, which will be called follow the moving leader (FTML), shows strong connections with popular deep learning optimizers such as RMSprop and Adam. Experiments on various deep learning models demonstrate that FTML outperforms or at least has comparable convergence performance with state-of-the-art solvers.</p><p>The rest of this paper is organized as follows. Section 2 first gives a brief review on FTRL and other solvers for deep learning. Section 3 presents the proposed FTML. Experimental results are shown in Section 4, and the last section gives some concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notation. For a vector</head><formula xml:id="formula_0">x ∈ R d , x = d i=1 x 2 i , diag(x)</formula><p>is a diagonal matrix with x on its diagonal, √ x is the element-wise square root of x, x 2 denotes the Hadamard (elementwise) product x x, and x 2 Q = x T Qx, where Q is a symmetric matrix. For any two vectors x and y, x/y, and x, y denote the elementwise division and dot product, respectively. For a matrix X, X 2 = XX, and diag(X) is a vector with the diagonal of X as its elements. For t vectors {x 1 , . . . , x t }, x 1:t = t i=1 x i , and x</p><formula xml:id="formula_1">2 1:t = t i=1 x 2 i . For t matrices {X 1 , . . . , X t }, X 1:t = t i=1 X i .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Follow the Regularized Leader and its Variants</head><p>In online learning, the learner observes a sequence of functions f i 's, which can be deterministic, stochastic, or even adversarially chosen. Let Θ ⊆ R d be a convex compact set. At round t, the learner picks a predictor θ t−1 ∈ Θ, and the adversary picks a loss f t . The learner then suffers a loss f t (θ t−1 ). The goal of the learner is to minimize the cumulative loss suffered over the course of T rounds. In online convex learning, f t is assumed to be convex.</p><p>Two popular online learning algorithms are the follow the regularized leader (FTRL) <ref type="bibr" target="#b15">(Kalai &amp; Vempala, 2005;</ref><ref type="bibr" target="#b26">Shalev-Shwartz, 2012)</ref>, and its variant follow the proximally-regularized leader (FTPRL) <ref type="bibr" target="#b22">(McMahan &amp; Streeter, 2010)</ref>. Both achieve the optimal O( √ T ) regret, where T is the number of rounds <ref type="bibr" target="#b26">(Shalev-Shwartz, 2012)</ref>. Other FTRL-like algorithms include regularized dual averaging (RDA) <ref type="bibr" target="#b35">(Xiao, 2010)</ref> as well as its adaptive variant presented in <ref type="bibr" target="#b9">(Duchi et al., 2011)</ref>. Gradient descent style algorithms like online forward and backward splitting (FO-BOS) <ref type="bibr" target="#b8">(Duchi &amp; Singer, 2009</ref>) and adaptive gradient descent (Adagrad) <ref type="bibr" target="#b9">(Duchi et al., 2011)</ref> can also be expressed as special cases of the FTRL family <ref type="bibr" target="#b21">(McMahan, 2011)</ref>.</p><p>At round t, FTRL generates the next iterate θ t by solving the optimization problem:</p><formula xml:id="formula_2">θ t = arg min θ∈Θ t i=1 g i , θ + α t 2 θ 2 ,</formula><p>where g t is a subgradient of f t at θ t−1 (usually, θ 0 = 0), and α t is the regularization parameter at round t. Note that the regularization is centered at the origin. <ref type="bibr" target="#b22">McMahan &amp; Streeter (2010)</ref> generalizes this to FTPRL by centering regularization at each iterate θ i−1 as in online gradient descent and online mirror descent <ref type="bibr" target="#b3">(Cesa-Bianchi &amp; Lugosi, 2006)</ref>,</p><formula xml:id="formula_3">θ t = arg min θ∈Θ t i=1 g i , θ + 1 2 θ − θ i−1 2 Qi ,<label>(1)</label></formula><p>where Q i is a full or diagonal positive semidefinite matrix, and θ − θ i−1 Qi is the corresponding Mahalanobis distance between θ and θ i−1 . When Q i is diagonal, each of its entries controls the learning rate in the corresponding dimension. When Θ = R d , θ t can be obtained in closedform <ref type="bibr" target="#b21">(McMahan, 2011)</ref>:</p><formula xml:id="formula_4">θ t = θ t−1 − Q −1 1:t g t .<label>(2)</label></formula><p>When</p><formula xml:id="formula_5">Q t = 1 η diag g 2 1:t − g 2 1:t−1 ,<label>(3)</label></formula><p>where η &gt; 0 is the stepsize, (2) becomes the update rule of Adagrad <ref type="bibr" target="#b9">(Duchi et al., 2011)</ref> </p><formula xml:id="formula_6">θ t = θ t−1 − diag η g 2 1:t + 1 g t .<label>(4)</label></formula><p>Here, &gt; 0 (usually a very small number) is used to avoid division by zero, and 1 is the vector of all 1's.</p><p>In general, all these algorithms satisfy <ref type="bibr" target="#b22">(McMahan &amp; Streeter, 2010)</ref>:</p><formula xml:id="formula_7">Q 1:t = diag 1 η g 2 1:t + 1 .<label>(5)</label></formula><p>It can be shown that this setting is optimal within a factor of √ 2 of the best possible regret bound for any nonincreasing per-coordinate learning rate schedule <ref type="bibr" target="#b22">(McMahan &amp; Streeter, 2010)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Adaptive Learning Rate in Deep Learning</head><p>In training deep networks, different weights may have vastly different gradients (in terms of both magnitude and direction). Hence, using a per-coordinate learning rate as in Adagrad can significantly improve performance over standard SGD <ref type="bibr" target="#b7">(Dean et al., 2012)</ref>. However, a caveat is that Adagrad suffers from diminishing stepsize. As optimization proceeds, the accumulated squared gradient g 2 1:t in (5) becomes larger and larger, making training difficult.</p><p>To alleviate this problem, a number of algorithms have been proposed <ref type="bibr" target="#b36">(Zeiler, 2012;</ref><ref type="bibr" target="#b31">Tieleman &amp; Hinton, 2012;</ref><ref type="bibr" target="#b17">Kingma &amp; Ba, 2015)</ref>. Typically, they employ an average of the past squared gradients (i.e.,</p><formula xml:id="formula_8">v t = t i=1 α i,t g 2 i , where α i,t ∈ [0, 1])</formula><p>, which is exponentially decaying. For example, RMSprop <ref type="bibr" target="#b31">(Tieleman &amp; Hinton, 2012</ref>) uses</p><formula xml:id="formula_9">v i = βv i−1 + (1 − β)g 2 i ,<label>(6)</label></formula><p>where β is close to 1, and the corresponding α i,t is (1 − β)β t−i . This v t can then be used to replace g 2 1:t , and the update in (4) becomes</p><formula xml:id="formula_10">θ t = θ t−1 − diag η √ v t + 1 g t .<label>(7)</label></formula><p>Zeiler <ref type="formula" target="#formula_3">(2012)</ref> further argues that the parameter and update should have the same unit, and modifies <ref type="formula" target="#formula_10">(7)</ref> to the Adadelta update rule:</p><formula xml:id="formula_11">θ t = θ t−1 − diag √ u t−1 + 1 √ v t + 1 g t , where u t−1 = t−1 i=0 α i,t−1 ( θ i ) 2</formula><p>, and θ t = θ t − θ t−1 with θ 0 = 0.</p><p>As v 0 in (6) is often initialized to 0, the bias has to be corrected. Adam <ref type="bibr" target="#b17">(Kingma &amp; Ba, 2015)</ref> uses the variance estimate v t /(1 − β t ) (which corresponds to</p><formula xml:id="formula_12">α i,t = (1 − β)β t−i /(1 − β t )).</formula><p>Another recent proposal is the equilibrated stochastic gradient descent <ref type="bibr" target="#b5">(Dauphin et al., 2015)</ref>. It uses the variance</p><formula xml:id="formula_13">estimate v t = v t−1 + (H t ζ t ) 2</formula><p>, where H t is the Hessian and</p><formula xml:id="formula_14">ζ t ∼ N (0, 1). It is shown that (H t ζ t )</formula><p>2 is an unbiased estimator of diag(H 2 t ), which serves as the Jacobi preconditioner of the absolute Hessian. Computation of the Hessian can be avoided by using the R-operator <ref type="bibr" target="#b25">(Schraudolph, 2002)</ref>, though it still costs roughly twice that of standard backpropagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Follow the Moving Leader</head><p>Recall that at round t, FTRL generates the next iterate θ t as</p><formula xml:id="formula_15">θ t = arg min θ∈Θ t i=1 P i (θ),<label>(8)</label></formula><p>where</p><formula xml:id="formula_16">P i (θ) = g i , θ + 1 2 θ − θ i−1 2</formula><p>Qi . Note that all P i 's have the same weight. However, for highly nonconvex models such as the deep network, the parameter iterate may move from one local basin to another. P i 's that are due to samples in the distant past are less informative than those from the recent ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Weighting the Components</head><p>To alleviate this problem, one may consider only P i 's in a recent window. However, a large memory is needed for its implementation. A simpler alternative is by using an exponential moving average of the P i 's: S i = β 1 S i−1 + (1 − β 1 )P i , where β 1 ∈ [0, 1) and S 0 = 0. This can be easily rewritten as</p><formula xml:id="formula_17">S t = (1 − β 1 ) t i=1 β t−i 1 P i . Instead of minimizing (8), we have θ t = arg min θ∈Θ t i=1 w i,t P i (θ),<label>(9)</label></formula><p>where the weights</p><formula xml:id="formula_18">w i,t = (1 − β 1 )β t−i 1 1 − β t 1<label>(10)</label></formula><p>are normalized to sum to 1. The denominator 1 − β t 1 plays a similar role as bias correction in Adam. When β 1 = 0, w i,t = 0 for i &lt; t, and w t,t = 1. Thus, (9) reduces to min θ∈Θ P t (θ). When β 1 → 1, the following Lemma shows that all P i 's are weighted equally, and <ref type="formula" target="#formula_15">(8)</ref> is recovered. Lemma 1. lim β1→1 w i,t = 1/t.</p><p>Note that the Hessian of the objective in (8) is Q 1:t . This becomes t i=1 w i,t Q i in (9). Recall that Q 1:t depends on the accumulated past gradients in (5), which is then refined by an exponential moving average in (6). As in Adam, we</p><formula xml:id="formula_19">define v i = β 2 v i−1 + (1 − β 2 )g 2 i ,</formula><p>where β 2 ∈ [0, 1) and v 0 = 0, and then correct its bias by dividing by 1 − β t 2 . Thus, (5) is changed to</p><formula xml:id="formula_20">t i=1 w i,t Q i = diag 1 η t v t 1 − β t 2 + t 1 ,<label>(11)</label></formula><p>where η t and t are the stepsize and value at time t, respectively. When β 2 = 0, (11) reduces to</p><formula xml:id="formula_21">t i=1 w i,t Q i = diag 1 ηt ( g 2 t + t 1) . When β 2 → 1, all g 2 i '</formula><p>s are weighted equally and (11) reduces to</p><formula xml:id="formula_22">t i=1 w i,t Q i = diag 1 ηt g 2 1:t t + t 1 . Using η t = η/ √</formula><p>t and t = / √ t, this is further reduced to (5). The following shows that Q t in (11) has a closed-form expression.</p><formula xml:id="formula_23">Proposition 1. Define d t = 1−β t 1 ηt vt 1−β t 2 + t 1 . Then, Q t = diag d t − β 1 d t−1 1 − β 1 .<label>(12)</label></formula><p>1: Input:</p><formula xml:id="formula_24">η t &gt; 0, β 1 , β 2 ∈ [0, 1), t &gt; 0. 2: initialize θ 0 ∈ Θ; d 0 ← 0; v 0 ← 0; z 0 ← 0; 3: for t = 1, 2, . . . , T do 4:</formula><p>fetch function f t ; 5:</p><formula xml:id="formula_25">g t ← ∂ θ f t (θ t−1 ); 6: v t ← β 2 v t−1 + (1 − β 2 )g 2 t ;</formula><p>7:</p><formula xml:id="formula_26">d t ← 1−β t 1 ηt vt 1−β t 2 + t 1 ; 8: σ t ← d t − β 1 d t−1 ; 9: z t ← β 1 z t−1 + (1 − β 1 )g t − σ t θ t−1 ; 10: θ t ← Π diag(dt/(1−β t 1 )) Θ (−z t /d t ); 11: end for 12: Output: θ T .</formula><p>Substituting this back into (9), θ t is then equal to</p><formula xml:id="formula_27">arg min θ∈Θ t i=1 w i,t g i , θ + 1 2 θ − θ i−1 2 diag σ i 1−β 1 ,<label>(13)</label></formula><formula xml:id="formula_28">where σ i ≡ d i − β 1 d i−1 .</formula><p>Note that some entries of σ i may be negative, and θ − θ i−1 2 diag(σi/(1−β1)) is then not a regularizer in the usual sense. Instead, the negative entries of σ i encourage the corresponding entries of θ to move away from those of θ i−1 . Nevertheless, from the definitions of d t , σ t and (11), we have</p><formula xml:id="formula_29">t i=1 w i,t diag(σ i /(1 − β 1 )) = t i=1 w i,t Q i = diag(d t /(1 − β t 1 ))</formula><p>, and thus the following: Lemma 2.</p><formula xml:id="formula_30">t i=1 w i,t diag(σ i /(1 − β 1 )) 0.</formula><p>Hence, the objective in (13) is still strongly convex. Moreover, the following Proposition shows that θ t in (13) has a simple closed-form solution. Proposition 2. In (13),</p><formula xml:id="formula_31">θ t = Π diag(dt/(1−β t 1 )) Θ (−z t /d t ), where z t = β 1 z t−1 + (1 − β 1 )g t − σ t θ t−1 , and Π A Θ (x) ≡ arg min u∈Θ 1 2 u−x 2</formula><p>A is the projection onto Θ for a given positive semidefinite matrix A.</p><p>The proposed procedure, which will be called follow the moving leader (FTML), is shown in Algorithm 1. Note that though {P 1 , . . . , P t } are considered in each round, the update depends only the current gradient g t and parameter θ t−1 . It can be easily seen that FTML is easy to implement, memory-efficient and has low per-iteration complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Relationships with Adagrad, RMSprop and Adam</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">RELATIONSHIP WITH ADAGRAD</head><p>The following Propositions show that we can recover Adagrad in two extreme cases: (i) β 1 = 0 with decreasing stepsize; and (ii) β 1 → 1 with increasing stepsize. Proposition 3. With β 1 = 0, β 2 → 1, η t = η/ √ t, and t = / √ t, θ t in (13) reduces to:</p><formula xml:id="formula_32">Π diag(( √ g 2 1:t + 1)/η) Θ θ t−1 − diag η g 2 1:t + 1 g t ,</formula><p>which recovers Adagrad in (4). Proposition 4. With β 1 → 1, β 2 → 1, η t = η √ t, and t = / √ t, we recover (1) with Q i in (3). If Θ = R d , it generates identical updates as Adagrad in (4). <ref type="bibr" target="#b21">McMahan (2011)</ref> showed that (1) and (2) generate the same updates. The following Theorem shows that FTML also has a similar gradient descent update. Theorem 1. With Θ = R d , FTML generates the same updates as:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">RELATIONSHIP WITH RMSPROP</head><formula xml:id="formula_33">When Θ = R d ,</formula><formula xml:id="formula_34">θ t = θ t−1 − diag 1 − β 1 1 − β t 1 η t v t /(1 − β t 2 ) + t 1 g t .<label>(14)</label></formula><p>When β 1 = 0 and bias correction for the variance is not used, (14) reduces to RMSprop in (7). However, recall from Section 3.1 that when β 1 = 0, we have w i,t = 0 for i &lt; t, and w t,t = 1. Hence, only the current loss component P t is taken into account, and this may be sensitive to the noise in P t . Moreover, as demonstrated in Adam, bias correction of the variance can be very important. When β 2 → 1, the variance estimate of RMSprop,</p><formula xml:id="formula_35">t i=1 (1 − β 2 )β t−i 2 g 2 i</formula><p>, becomes zero and blows up the stepsize, leading to divergence. In contrast, FTML's Q i in (12) recovers that of Adagrad in this case (Proposition 4). In practice, a smaller β 2 has to be used for RMSprop. However, a larger β 2 enables the algorithm to be more robust to the gradient noise in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">RELATIONSHIP WITH ADAM</head><p>At iteration t, instead of centering regularization at each θ i−1 in (13), consider centering all the proximal regularization terms at the last iterate θ t−1 . θ t then becomes:</p><formula xml:id="formula_36">arg min θ∈Θ t i=1 w i,t g i , θ + 1 2 θ − θ t−1 2 diag σ i 1−β 1 . (15)</formula><p>Compared with (13), the regularization in (15) is more aggressive as it encourages θ t to be close only to the last iterate θ t−1 . The following Proposition shows that (15) generates the same updates as Adam. Proposition 5. In (15),</p><formula xml:id="formula_37">θ t = Π At Θ θ t−1 − A −1 t t i=1 w i,t g i ,<label>(16)</label></formula><p>where</p><formula xml:id="formula_38">A t = diag(( v t /(1 − β t 2 ) + t 1)/η t ).</formula><p>As in Adam, t i=1 w i,t g i in (16) can be obtained as m t /(1−β t 1 ), where m t is computed as an exponential moving average of g t 's: m t = β 1 m t−1 + (1 − β 1 )g t .</p><p>Note that the θ t updates of Adagrad (4), RMSprop (7), and FTML <ref type="formula" target="#formula_3">(14)</ref> depend only on the current gradient g t . On the other hand, the Adam update in (16) involves t i=1 w i,t g i , which contains all the past gradients (evaluated at past parameter estimates θ i−1 's). This is similar to the use of momentum, which is sometimes helpful in escaping from local minimum. However, when the data distribution is changing (as in deep reinforcement learning), the past gradients may not be very informative, and can even impede parameter adaptation to the environment. Recently, it is also reported that the use of momentum can make training unstable when the loss is nonstationary <ref type="bibr" target="#b0">(Arjovsky et al., 2017)</ref>. Indeed, Theorem 4.1 in <ref type="bibr" target="#b17">(Kingma &amp; Ba, 2015)</ref> shows that Adam has low regret only when β 1 is decreasing w.r.t. t. When β 1 → 0, t i=1 w i,t g i → g t and so only the current gradient is used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, experiments are performed on a number of deep learning models, including convolutional neural networks (Section 4.1), deep residual networks (Section 4.2), memory networks (Section 4.3), neural conversational model (Section 4.4), deep Q-network (Section 4.5), and long short-term memory (LSTM) (Section 4.6). A summary of the empirical performance of the various deep learning optimizers is presented in Section 4.7.</p><p>The following state-of-the-art optimizers for deep learning models will be compared: (i) Adam <ref type="bibr" target="#b17">(Kingma &amp; Ba, 2015)</ref>; (ii) RMSprop <ref type="bibr" target="#b31">(Tieleman &amp; Hinton, 2012)</ref>; (iii) Adadelta <ref type="bibr" target="#b36">(Zeiler, 2012)</ref>; and (iv) Nesterov accelerated gradient (NAG) <ref type="bibr" target="#b29">(Sutskever et al., 2013)</ref>. For FTML, we set β 1 = 0.6, β 2 = 0.999, and a constant t = = 10 −8 for all t. For FTML, Adam, RMSprop, and NAG, η is selected by monitoring performance on the training set (note that Adadelta does not need to set η). The learning rate is chosen from {0.5, 0.25, 0.1, . . . , 0.00005, 0.000025, 0.00001}. Significantly underperforming learning rates are removed after running the model for 5 − 20 epochs. We then pick the rate that leads to the smallest final training loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Convolutional Neural Networks</head><p>In the section, we perform experiments with the convolutional neural network (CNN) <ref type="bibr" target="#b18">(LeCun et al., 1998)</ref>. We use the example models on the MNIST and CIFAR-10 data sets from the Keras library 1 . For MNIST, the CNN has two alternating stages of 3 × 3 convolution filters (using ReLU activation), followed by a 2 × 2 max-pooling layer and a dropout layer (with a dropout rate of 0.25). Finally, there is a fully-connected layer with ReLU activation and a dropout rate of 0.5. For CIFAR-10, the CNN has four alternating stages of 3 × 3 convolution filters (using ReLU activation). Every two convolutional layers is followed by a 2 × 2 maxpooling layer and a dropout layer (with a dropout rate of 0.25). The last stage has a fully-connected layer with ReLU activation and a dropout rate of 0.5. Features in both data sets are normalized to [0, 1]. Minibatches of sizes 128 and 32 are used for MNIST and CIFAR-10, respectively.</p><p>As the iteration complexities of the various algorithms are comparable and the total cost is dominated by backpropagation, we report convergence of the training cross entropy loss versus the number of epochs. This setup is also used in <ref type="bibr" target="#b36">(Zeiler, 2012;</ref><ref type="bibr" target="#b17">Kingma &amp; Ba, 2015)</ref>. <ref type="figure" target="#fig_0">Figure 1</ref> shows the convergence results. As can be seen, FTML performs best on both data sets. Adam has comparable performance with FTML on MNIST, but does not perform as well on CIFAR-10. The other methods are much inferior. In particular, RMSprop is slow on both MNIST and CIFAR-10, and Adadelta tends to diverge on CIFAR-10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Deep Residual Networks</head><p>Recently, substantially deeper networks have been popularly used, particularly in computer vision. For example, a 152-layer deep residual network <ref type="bibr" target="#b12">(He et al., 2016)</ref> achieves state-of-the-art performance on ImageNet classification, and won the first place on the ILSVRC 2015 classification task.</p><p>In this section, we perform experiments with a 110-layer deep residual network on the CIFAR-10 and CIFAR-100 data sets. The code is based on its Torch implementation 2 . We leave the architecture and related settings intact, and use the same learning rate schedule. The default optimizer in the Torch code is NAG. Here, we also experiment with Adadelta, RMSprop, Adam and the proposed FTML. A minibatch size of 32 is used.</p><p>Convergence of the training cross entropy loss is shown in <ref type="figure" target="#fig_4">Figure 2</ref>. As can been seen, all optimizers, except Adadelta, are very competitive and have comparable per-  formance on these two data sets. NAG shows slower initial convergence, while FTML converges slightly faster than the others on the CIFAR-10 data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Memory Networks</head><p>Recently, there has been a lot of attention on combining inference, attention and memory for various machine learning tasks. In particular, the memory network <ref type="bibr" target="#b33">(Weston et al., 2014;</ref><ref type="bibr" target="#b28">Sukhbaatar et al., 2015)</ref> has been popularly used for natural language understanding.</p><p>In this section, we use the example model of the end-toend memory network (with LSTM) from the Keras library. We consider the question answering task <ref type="bibr" target="#b28">(Sukhbaatar et al., 2015;</ref><ref type="bibr" target="#b34">Weston et al., 2016)</ref>, and perform experiments on the "single supporting fact" task in the bAbI data set <ref type="bibr" target="#b34">(Weston et al., 2016)</ref>. This task consists of questions in which a previously given single sentence provides the answer. An  example is shown below. We use a single supporting memory, and a minibatch size of 32.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Single Supporting Fact:</head><p>Mary moved to the bathroom. John went to the hallway. Where is Mary? A: bathroom Convergence of the training cross entropy loss is shown in <ref type="figure" target="#fig_5">Figure 3</ref>. As can be seen, FTML and RMSprop perform best on this data set. Adam is slower, while NAG and Adadelta perform poorly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Neural Conversational Model</head><p>The neural conversational model <ref type="bibr" target="#b32">(Vinyals &amp; Le, 2015)</ref> is a sequence-to-sequence model <ref type="bibr" target="#b30">(Sutskever et al., 2014)</ref> that is capable of predicting the next sequence given the last or previous sequences in a conversation. A LSTM layer en- codes the input sentence to a thought vector, and a second LSTM layer decodes the thought vector to the response. It has been shown that this model can often produce fluent and natural conversations.</p><p>In this experiment, we use the publicly available Torch implementation 3 with a constant stepsize, and its default data set Cornell Movie-Dialogs Corpus (with 50, 000 samples) <ref type="bibr" target="#b4">(Danescu-Niculescu-Mizil &amp; Lee, 2011)</ref>. The number of hidden units is set to 1000, and the minibatch size is 10.</p><p>Convergence of the training cross entropy loss is shown in <ref type="figure" target="#fig_6">Figure 4</ref>. Adadelta is not reported here, since it performs poorly (as in previous experiments). As can be seen, FTML outperforms Adam and RMSprop. In particular, RMSprop is much inferior. NAG is slower than FTML and Adam in the first 21 epochs, but becomes faster towards the end of training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Deep Q-Network</head><p>In this section, we use the Deep Q-network (DQN) <ref type="bibr" target="#b24">(Mnih et al., 2015)</ref> for deep reinforcement learning. Experiments are performed on two computer games on the Atari 2600 platform: Breakout and Asterix. We use the publicly available Torch implementation with the default network setup 4 , and a minibatch size of 32. We only compare FTML with RMSprop and Adam for optimization, as NAG and Adadelta are rarely used in training the DQN. As in <ref type="bibr" target="#b24">(Mnih et al., 2015)</ref>, we use = 10 −2 for all methods, and performance evaluation is based on the average score per episode. The higher the score, the better the performance.</p><p>Convergence is shown in <ref type="figure" target="#fig_8">Figure 5</ref>. On Breakout, RM- Sprop and FTML are comparable and yield higher scores than Adam. On Asterix, FTML outperforms all the others. In particular, the DQN trained with RMSprop fails to learn the task, and its score begins to drop after about 100 epochs. A similar problem has also been observed in <ref type="bibr" target="#b11">(Hasselt et al., 2016)</ref>. Experience replay <ref type="bibr" target="#b24">(Mnih et al., 2015)</ref> has been commonly used in deep reinforcement learning to smooth over changes in the data distribution, and avoid oscillations or divergence of the parameters. However, results here show that Adam still has inferior performance because of its use of all past gradients, many of these are not informative when the data distribution has changed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Long Short-Term Memory (LSTM)</head><p>To illustrate the problem of Adam in Section 4.5 more clearly, we perform the following timeseries prediction experiment with the LSTM. We construct a synthetic timeseries of length 1000. This is divided into 20 segments, each of length 50. At each time point, the sample is 10-dimensional. In segment i, samples are generated from a normal distribution with mean ([i, i, . . . , i] + ζ i ) ∈ R 10 and identity covariance matrix, where the components of ζ i are independent standard normal random variables. Noise from the standard normal distribution is added to corrupt the data. The task is to predict the data sample at the next time point t.</p><p>We use a one-layer LSTM implemented in <ref type="bibr" target="#b19">(Léonard et al., 2015)</ref>. 100 hidden units are used. We truncate backpropagation through time (BPTT) to 5 timesteps, and input 5 samples to the LSTM in each iteration. Thus, the data distribution changes every 10 iterations, as a different normal distribution is then used for data generation. Performance evaluation is based on the squared loss f t (θ t−1 ) at time t.</p><p>Convergence of the loss is shown in <ref type="figure">Figure 6</ref>(a). As can be  seen, Adam has difficulty in adapting to the data. In contrast, FTML and RMSprop can adapt more quickly, yielding better and more stable performance.</p><p>As a baseline, we consider the case where the data distribution does not change (the means of all the segments are fixed to the vector of ones) <ref type="figure">Figure 6(b)</ref> shows the results. As can be seen, Adam now performs comparably to FTML and RMSprop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Summary of Results</head><p>The main problem with RMSprop is that its performance is not stable. Sometimes, it performs well, but sometimes it can have significantly inferior performance (e.g., as can be seen from <ref type="figure" target="#fig_0">Figures 1, 4 and 5(b)</ref>). The performance of Adam is more stable, though it often lags behind the best optimizer (e.g., <ref type="figure" target="#fig_0">Figures 1(b)</ref>, 3, and 4). It is particularly problematic when learning in a changing environment <ref type="figure">(Fig-(a)</ref> Changing data distribution.</p><p>(b) Data distribution is stationary. <ref type="figure">Figure 6</ref>. Results on timeseries data using LSTM. ures 5 and 6(a)). In contrast, the proposed FTML shows stable performance on various models and tasks. It converges quickly, and is always the best (or at least among the best) in all our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we proposed a FTPRL variant called FTML, in which the recent samples are weighted more heavily in each iteration. Hence, it is able to adapt more quickly when the parameter moves to another local basin, or when the data distribution changes. FTML is closely related to RMSprop and Adam. In particular, it enjoys their nice properties, but avoids their pitfalls. Experimental results on a number of deep learning models and tasks demonstrate that FTML converges quickly, and is always the best (or among the best) of the various optimizers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Remark 1 .</head><label>1</label><figDesc>(Summary) RMSprop and Adam are improve- ments over Adagrad in training deep networks. However, RMSprop uses β 1 = 0 (and thus relies only on the current sample), does not correct the bias of the variance estimate, but centers the regularization at the current iterates θ i−1 's. On the other hand, Adam uses β 1 &gt; 0, bias-corrected vari- ance, but centers all regularization terms at the last iterate θ t−1 . The proposed FTML combines the nice properties of the two.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Results on convolutional neural network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Results on deep residual network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Results on memory network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Results on neural conversational model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Results on deep Q-network.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/fchollet/keras. 2 https://github.com/facebook/fb.resnet. torch.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/macournoyer/ neuralconvo. 4 https://github.com/Kaixhin/Atari.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported in part by ITF/391/15FX.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wasserstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for Learning Representations</title>
		<meeting>the International Conference for Learning Representations</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Online learning and stochastic approximations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">On-line Learning in Neural Networks</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="9" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lugosi</surname></persName>
		</author>
		<title level="m">Prediction, Learning, and Games</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics</title>
		<meeting>the Workshop on Cognitive Modeling and Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="76" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Equilibrated adaptive learning rates for non-convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1504" to="1512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Identifying and attacking the saddle point problem in high-dimensional non-convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2933" to="2941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Large scale distributed deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1223" to="1231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Efficient online and batch learning using forward backward splitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2899" to="2934" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Acoustics, Speech and Signal Processing</title>
		<meeting>the International Conference on Acoustics, Speech and Signal Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="6645" to="6649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning with double Q-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Hasselt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2094" to="2100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the International Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient algorithms for online decision problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vempala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="291" to="307" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep learning without poor local minima</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kawaguchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="586" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for Learning Representations</title>
		<meeting>the International Conference for Learning Representations</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Léonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Waghmare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rnn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07889</idno>
		<title level="m">Recurrent library for Torch</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning via Hessian-free optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="735" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Follow-the-regularized-leader and mirror descent: Equivalence theorems and L1 regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mcmahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="525" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Adaptive bound optimization for online convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Streeter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Conference on Computational Learning Theory</title>
		<meeting>the Annual Conference on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">244</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ad click prediction: A view from the trenches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Mcmahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Grady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Davydov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Golovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chikkerur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Hrafnkelsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Boulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kubica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1222" to="1230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beattie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page" from="529" to="533" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fast curvature matrix-vector products for second-order gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1723" to="1738" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Online learning and online convex optimization. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="107" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mastering the game of Go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Van</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grewe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Leach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Endto-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fergus</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Lecture 6.5 -RMSProp, COURSERA: Neural networks for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05869</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">A neural conversational model. Preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bordes</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1410.3916</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">A. Memory networks. Preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Towards AI-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference for Learning Representations</title>
		<meeting>the International Conference for Learning Representations</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Dual averaging methods for regularized stochastic learning and online optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2543" to="2596" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">ADADELTA: An adaptive learning rate method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Online convex programming and generalized infinitesimal gradient ascent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zinkevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="928" to="936" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
