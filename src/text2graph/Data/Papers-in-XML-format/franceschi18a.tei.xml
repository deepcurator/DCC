<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bilevel Programming for Hyperparameter Optimization and Meta-Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Franceschi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saverio</forename><surname>Salzo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Grazzi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
						</author>
						<title level="a" type="main">Bilevel Programming for Hyperparameter Optimization and Meta-Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We introduce a framework based on bilevel programming that unifies gradient-based hyperparameter optimization and meta-learning. We show that an approximate version of the bilevel problem can be solved by taking into explicit account the optimization dynamics for the inner objective. Depending on the specific setting, the outer variables take either the meaning of hyperparameters in a supervised learning problem or parameters of a meta-learner. We provide sufficient conditions under which solutions of the approximate problem converge to those of the exact problem. We instantiate our approach for meta-learning in the case of deep learning where representation layers are treated as hyperparameters shared across a set of training episodes. In experiments, we confirm our theoretical findings, present encouraging results for few-shot learning and contrast the bilevel approach against classical approaches for learning-to-learn.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>While in standard supervised learning problems we seek the best hypothesis in a given space and with a given learning algorithm, in hyperparameter optimization (HO) and metalearning (ML) we seek a configuration so that the optimized learning algorithm will produce a model that generalizes well to new data. The search space in ML often incorporates choices associated with the hypothesis space and the features of the learning algorithm itself (e.g., how optimization of the training loss is performed). Under this common perspective, both HO and ML essentially boil down to nesting two search problems: at the inner level we seek a good hypothesis (as in standard supervised learning) while at the outer level we seek a good configuration (including a good hypothesis space) where the inner search takes place. Surprisingly, the literature on ML has little overlap with the literature on HO and in this paper we present a unified framework encompassing both of them.</p><p>Classic approaches to HO (see e.g. <ref type="bibr" target="#b20">Hutter et al., 2015</ref>, for a survey) have been only able to manage a relatively small number of hyperparameters, from a few dozens using random search <ref type="bibr" target="#b5">(Bergstra and Bengio, 2012</ref>) to a few hundreds using Bayesian or model-based approaches <ref type="bibr" target="#b6">(Bergstra et al., 2013;</ref><ref type="bibr" target="#b40">Snoek et al., 2012)</ref>. Recent gradient-based techniques for HO, however, have significantly increased the number of hyperparameters that can be optimized <ref type="bibr" target="#b11">(Domke, 2012;</ref><ref type="bibr" target="#b30">Maclaurin et al., 2015;</ref><ref type="bibr" target="#b35">Pedregosa, 2016;</ref><ref type="bibr" target="#b17">Franceschi et al., 2017)</ref> and it is now possible to tune as hyperparameters entire weight vectors associated with a neural network layer. In this way, it becomes feasible to design models that possibly have more hyperparameters than parameters. Such an approach is well suited for ML, since parameters are learned from a small dataset, whereas hyperparameters leverage multiple available datasets.</p><p>HO and ML only differ substantially in terms of the experimental settings in which they are evaluated. While in HO the available data is associated with a single task and split into a training set (used to tune the parameters) and a validation set (used to tune the hyperparameters), in ML we are often interested in the so-called few-shot learning setting where data comes in the form of short episodes (small datasets with few examples per class) sampled from a common probability distribution over supervised tasks.</p><p>Early work on ML dates back at least to the 1990's <ref type="bibr" target="#b38">(Schmidhuber, 1992;</ref><ref type="bibr" target="#b2">Baxter, 1995;</ref><ref type="bibr" target="#b41">Thrun and Pratt, 1998)</ref> but this research area has received considerable attention in the last few years, mainly driven by the need in real-life and industrial scenarios for learning quickly a vast multitude of tasks. These tasks, or episodes, may appear and evolve continuously over time and may only contain few examples <ref type="bibr" target="#b29">(Lake et al., 2017)</ref>. Different strategies have emerged to tackle ML. Although they do overlap in some aspects, it is possible to identify at least four of them. The metric strategy attempts to use training episodes to construct embeddings such that examples of the same class are mapped into similar repre- sentations. It has been instantiated in several variants that involve non-parametric (or instance-based) predictors <ref type="bibr" target="#b24">(Koch et al., 2015;</ref><ref type="bibr" target="#b43">Vinyals et al., 2016;</ref><ref type="bibr" target="#b39">Snell et al., 2017)</ref>. In the related memorization strategy, the meta-learner learns to store and retrieve data points representations in memory. It can be implemented either using recurrent networks <ref type="bibr" target="#b37">(Santoro et al., 2016)</ref> or temporal convolutions <ref type="bibr" target="#b33">(Mishra et al., 2018)</ref>. The use of an attention mechanism <ref type="bibr" target="#b42">(Vaswani et al., 2017</ref>) is crucial both in <ref type="bibr" target="#b43">(Vinyals et al., 2016)</ref> and in <ref type="bibr" target="#b33">(Mishra et al., 2018)</ref>. The initialization strategy <ref type="bibr" target="#b36">(Ravi and Larochelle, 2017;</ref><ref type="bibr" target="#b15">Finn et al., 2017)</ref> uses training episodes to infer a good initial value for the model's parameters so that new tasks can be learned quickly by fine tuning. The optimization strategy <ref type="bibr" target="#b0">(Andrychowicz et al., 2016;</ref><ref type="bibr" target="#b36">Ravi and Larochelle, 2017;</ref><ref type="bibr" target="#b44">Wichrowska et al., 2017)</ref> forges an optimization algorithm that will find it easier to learn on novel related tasks.</p><p>A main contribution of this paper is a unified view of HO and ML within the natural mathematical framework of bilevel programming, where an outer optimization problem is solved subject to the optimality of an inner optimization problem. In HO the outer problem involves hyperparameters while the inner problem is usually the minimization of an empirical loss. In ML the outer problem could involve a shared representation among tasks while the inner problem could concern classifiers for individual tasks. Bilevel programming <ref type="bibr" target="#b1">(Bard, 2013)</ref> has been suggested before in machine learning in the context of kernel methods and support vector machines <ref type="bibr" target="#b22">(Keerthi et al., 2007;</ref><ref type="bibr" target="#b26">Kunapuli et al., 2008)</ref>, multitask learning <ref type="bibr" target="#b16">(Flamary et al., 2014)</ref>, and more recently HO <ref type="bibr" target="#b35">(Pedregosa, 2016)</ref>, but never in the context of ML. The resulting framework outlined in Sec. 2 encompasses some existing approaches to ML, in particular those based on the initialization and the optimization strategies.</p><p>A technical difficulty arises when the solution to the inner problem cannot be written analytically (for example this happens when using the log-loss for training neural networks) and one needs to resort to iterative optimization approaches.</p><p>As a second contribution, we provide in Sec. 3 sufficient conditions that guarantee good approximation properties. We observe that these conditions are reasonable and apply to concrete problems relevant to applications.</p><p>In Sec. 4, by taking inspiration on early work on representation learning in the context of multi-task and meta-learning <ref type="bibr" target="#b2">(Baxter, 1995;</ref><ref type="bibr" target="#b7">Caruana, 1998)</ref>, we instantiate the framework for ML in a simple way treating the weights of the last layer of a neural network as the inner variables and the remaining weights, which parametrize the representation mapping, as the outer variables. As shown in Sec. 5, the resulting ML algorithm performs well in practice, outperforming most of the existing strategies on MiniImagenet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A bilevel optimization framework</head><p>In this paper, we consider bilevel optimization problems (see e.g. <ref type="bibr" target="#b8">Colson et al., 2007)</ref> of the form</p><formula xml:id="formula_0">min{f (λ) : λ ∈ Λ},<label>(1)</label></formula><p>where function f : Λ → R is defined at λ ∈ Λ as</p><formula xml:id="formula_1">f (λ) = inf{E(w λ , λ) : w λ ∈ arg min u∈R d L λ (u)}.<label>(2)</label></formula><p>We call E : R d × Λ → R the outer objective and, for every λ ∈ Λ, we call L λ : R d → R the inner objective. Note that {L λ : λ ∈ Λ} is a class of objective functions parameterized by λ. Specific instances of this problem include HO and ML, which we discuss next. <ref type="table" target="#tab_0">Table 1</ref> outlines the links among bilevel programming, HO and ML.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Hyperparameter Optimization</head><p>In the context of hyperparameter optimization, we are interested in minimizing the validation error of a model g w : X → Y parameterized by a vector w, with respect to a vector of hyperparameters λ. For example, we may consider representation or regularization hyperparameters that control the hypothesis space or penalties, respectively. In this setting, a prototypical choice for the inner objective is the regularized empirical error</p><formula xml:id="formula_2">L λ (w) = (x,y)∈Dtr (g w (x), y) + Ω λ (w), where D tr = {(x i , y i )} n i=1</formula><p>is a set of input/output points, is a prescribed loss function, and Ω λ a regularizer parameterized by λ. The outer objective represents a proxy for the generalization error of g w , and it may be given by the average loss on a validation set D val</p><formula xml:id="formula_3">E(w, λ) = (x,y)∈D val (g w (x), y).</formula><p>or, in more generality, by a cross-validation error, as detailed in Appendix B. Note that in this setting, the outer objective E does not depend explicitly on the hyperparameters λ, since in HO λ is instrumental in finding a good model g w , which is our final goal. As a more specific example, consider linear models, g w (x) = w, x , let be the square loss and let Ω λ (w) = λ w 2 , in which case the inner objective is ridge regression (Tikhonov regularization) and the bilevel problem optimizes over the regularization parameter the validation error of ridge regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Meta-Learning</head><p>In meta-learning (ML) the inner and outer objectives are computed by averaging a training and a validation error over multiple tasks, respectively. The goal is to produce a learning algorithm that will work well on novel tasks 1 . For this purpose, we have available a meta-training set</p><formula xml:id="formula_4">D = {D j = D j tr ∪ D j val } N j=1</formula><p>, which is a collection of datasets, sampled from a meta-distribution P. Each dataset</p><formula xml:id="formula_5">D j = {(x j i , y j i )} nj i=1 with (x j i , y j i ) ∈ X × Y</formula><p>j is linked to a specific task. Note that the output space is task dependent (e.g. a multi-class classification problem with variable number of classes). The model for each task is a function g w j ,λ : X → Y j , identified by a parameter vectors w j and hyperparameters λ. A key point here is that λ is shared between the tasks. With this notation the inner and outer objectives are</p><formula xml:id="formula_6">L λ (w) = N j=1 L j (w j , λ, D j tr ),<label>(3)</label></formula><formula xml:id="formula_7">E(w, λ) = N j=1 L j (w j , λ, D j val )<label>(4)</label></formula><p>respectively. The loss L j (w j , λ, S) represents the empirical error of the pair (w j , λ) on a set of examples S. Note that the inner and outer losses for task j use different train/validation splits of the corresponding dataset D j . Furthermore, unlike in HO, in ML the final goal is to find a good λ and the w j are now instrumental.</p><p>The cartoon in <ref type="figure" target="#fig_0">Figure 1</ref> illustrates ML as a bilevel problem. The parameter λ indexes an hypothesis space within which the inner objective is minimized. A particular example, detailed in Sec. 4, is to choose the model g w,λ = w, h λ (x) , in which case λ parameterizes a feature mapping. Yet another choice would be to consider g w j ,λ (x) = w + λ, x , in which case λ represents a common model around which task specific models are to be found (see e.g. <ref type="bibr" target="#b14">Evgeniou et al., 2005;</ref><ref type="bibr" target="#b15">Finn et al., 2017;</ref><ref type="bibr" target="#b23">Khosla et al., 2012;</ref><ref type="bibr" target="#b27">Kuzborskij et al., 2013</ref>, and reference therein).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Gradient-Based Approach</head><p>We now discuss a general approach to solve Problem <ref type="formula" target="#formula_0">(1)</ref>- <ref type="formula" target="#formula_1">(2)</ref> when the hyperparameter vector λ is real-valued. To simplify our discussion let us assume that the inner objective has a unique minimizer w λ . Even in this simplified scenario, Problem <ref type="formula" target="#formula_0">(1)</ref>- <ref type="formula" target="#formula_1">(2)</ref> remains challenging to solve. Indeed, in general there is no closed form expression w λ , so it is not possible to directly optimize the outer objective function. While a possible strategy (implicit differentiation) is to apply the implicit function theorem to ∇L λ = 0 <ref type="bibr" target="#b35">(Pedregosa, 2016;</ref><ref type="bibr" target="#b25">Koh and Liang, 2017;</ref><ref type="bibr" target="#b4">Beirami et al., 2017)</ref>, another compelling approach is to replace the inner problem with a dynamical system. This point, discussed in <ref type="bibr" target="#b11">(Domke, 2012;</ref><ref type="bibr" target="#b30">Maclaurin et al., 2015;</ref><ref type="bibr" target="#b17">Franceschi et al., 2017)</ref>, is developed further in this paper.</p><p>Specifically, we let [T ] = {1, . . . , T } where T is a prescribed positive integer and consider the following approximation of Problem <ref type="formula" target="#formula_0">(1)</ref></p><formula xml:id="formula_8">-(2) min λ f T (λ) = E(w T,λ , λ),<label>(5)</label></formula><p>where E is a smooth scalar function, and</p><formula xml:id="formula_9">2 w 0,λ = Φ 0 (λ), w t,λ = Φ t (w t−1,λ , λ), t ∈ [T ],<label>(6)</label></formula><formula xml:id="formula_10">with Φ 0 : R m → R d a smooth initialization mapping and, for every t ∈ [T ], Φ t : R d × R m → R d</formula><p>a smooth mapping that represents the operation performed by the t-th step of an optimization algorithm. For example, the optimization dynamics could be gradient descent:</p><formula xml:id="formula_11">Φ t (w t , λ) = w t − η t ∇L λ (·) where (η t ) t∈[T ]</formula><p>is a sequence of steps sizes.</p><p>The approximation of the bilevel problem (1)-(2) by the procedure (5)-(6) raises the issue of the quality of this approximation and we return to this issue in the next section.</p><p>However, it also suggests to consider the inner dynamics as a form of approximate empirical error minimization (e.g. early stopping) which is valid in its own right. From this perspective -conversely to the implicit differentiation strategy -it is possible to include among the components of λ variables which are associated with the optimization algorithm itself. For example, λ may include the step sizes or momentum factors if the dynamics Φ t in Eq. <ref type="formula" target="#formula_9">(6)</ref> is gradient descent with momentum; in <ref type="bibr" target="#b0">(Andrychowicz et al., 2016;</ref><ref type="bibr" target="#b44">Wichrowska et al., 2017</ref>) the mapping Φ t is implemented as a recurrent neural network, while <ref type="bibr" target="#b15">(Finn et al., 2017)</ref> focus on the initialization mapping by letting Φ 0 (λ) = λ.</p><p>A major advantage of this reformulation is that it makes it possible to compute efficiently the gradient of f T , which we call hypergradient, either in time or in memory <ref type="bibr" target="#b30">(Maclaurin et al., 2015;</ref><ref type="bibr" target="#b17">Franceschi et al., 2017)</ref>, by making use of reverse or forward mode algorithmic differentiation <ref type="bibr" target="#b18">(Griewank and Walther, 2008;</ref><ref type="bibr" target="#b3">Baydin et al., 2017)</ref>. This allows us to optimize a number of hyperparameters of the same order of that of parameters, a situation which arise in ML.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Exact and Approximate Bilevel Programming</head><p>In this section, we provide results about the existence of solutions of Problem <ref type="formula" target="#formula_0">(1)</ref>- <ref type="formula" target="#formula_1">(2)</ref> and the approximation properties of Procedure <ref type="formula" target="#formula_8">(5)</ref>- <ref type="formula" target="#formula_9">(6)</ref> with respect to the original bilevel problem. Proofs of these results are provided in the supplementary material.</p><p>Procedure (5)-(6), though related to the bilevel problem (1)-(2), may not be, in general, a good approximation of it. Indeed, making the assumptions (which sound perfectly reasonable) that, for every λ ∈ Λ, w T,λ → w λ for some w λ ∈ arg max L λ , and that E(·, λ) is continuous, one can only assert that</p><formula xml:id="formula_12">lim T →∞ f T (λ) = E(w λ , λ) ≥ f (λ)</formula><p>. This is because the optimization dynamics converge to some minimizer of the inner objective L λ , but not necessarily to the one that also minimizes the function E. This is illustrated in <ref type="figure">Figure 2</ref>. The situation is, however, different if the inner problem admits a unique minimizer for every λ ∈ Λ. Indeed in this case, it is possible to show that the set of minimizers of the approximate problems converge, as T → +∞ and in an appropriate sense, to the set of minimizers of the bilevel problem. More precisely, we make the following assumptions:</p><formula xml:id="formula_13">(i) Λ is a compact subset of R m ; (ii) E : R d × Λ → R is jointly continuous; (iii) the map (w, λ) → L λ (w)</formula><p>is jointly continuous and such that arg min L λ is a singleton for every λ ∈ Λ;</p><formula xml:id="formula_14">(iv) w λ = arg min L λ remains bounded as λ varies in Λ. w L λ E (·,λ) λ λ (1)<label>(2)</label></formula><p>w w <ref type="figure">Figure 2</ref>. In this cartoon, for a fixed λ, argmin L λ = {w</p><formula xml:id="formula_15">(1) λ , w<label>(2)</label></formula><p>λ }; the iterates of an optimization mapping Φ could converge to w</p><formula xml:id="formula_16">(1) λ with E(w (1) λ , λ) &gt; E(w (2) λ , λ). Then, problem (1)-(2) becomes min λ∈Λ f (λ) = E(w λ , λ), w λ = argmin u L λ (u).<label>(7)</label></formula><p>Under the above assumptions, in the following we give results about the existence of solutions of problem <ref type="formula" target="#formula_16">(7)</ref> and the (variational) convergence of the approximate problems (5)-(6) towards problem (7) -relating the minima as well as the set of minimizers. In this respect we note that, since both f and f T are nonconvex, argmin f T and argmin f are in general nonsingleton, so an appropriate definition of set convergence is required.</p><formula xml:id="formula_17">Theorem 3.1 (Existence). Under Assumptions (i)-(iv) prob- lem (7) admits solutions. Proof See Appendix A.</formula><p>The result below follows from general facts on the stability of minimizers in optimization problems <ref type="bibr" target="#b12">(Dontchev and Zolezzi, 1993)</ref>.</p><p>Theorem 3.2 (Convergence). In addition to Assumptions (i)-(iv), suppose that:</p><formula xml:id="formula_18">(v) E(·, λ) is uniformly Lipschitz continuous; (vi) The iterates (w T,λ ) T ∈N converge uniformly to w λ on Λ as T → +∞. Then (a) inf f T → inf f , (b) argmin f T → argmin f , meaning that, for every (λ T ) T ∈N such that λ T ∈ argmin f T , we have that:</formula><p>-(λ T ) T ∈N admits a convergent subsequence; -for every subsequence</p><formula xml:id="formula_19">(λ K T ) T ∈N such that λ K T →λ, we haveλ ∈ argmin f .</formula><p>Proof See Appendix A.</p><p>We stress that assumptions (i)-(vi) are very natural and satisfied by many problems of practical interests. Thus, the above results provide full theoretical justification to the proposed approximate procedure (5)-(6). The following remark discusses assumption (vi), while the subsequent example will be relevant to the experiments in Sec. 5.</p><p>Input: λ, current values of the hyperparameter, T number of iteration of GD, η ground learning rate, B minibatch of episodes from D Output: Gradient of meta-training error w.r.t. λ on B for j = 1 to |B| do w</p><formula xml:id="formula_20">j 0 = 0 for t = 1 to T do w j t ← w t−1 − η∇ w L j (w j t−1 , λ, D j tr ) α j T ← ∇ w L j (w j T , λ, D val ) p j ← ∇ λ L j (w j T , λ, D val ) for t = T − 1 downto 0 do p j ← p j − α j t+1 η∇ λ ∇ w L j (w j t , λ, D j tr ) α j t ← α j t+1 I − η∇ w ∇ w L j (w j t , λ, D j tr ) return j p j Remark 3.3.</formula><p>If L λ is strongly convex, then many gradientbased algorithms (e.g., standard and accelerated gradient descent) yield linear convergence of the iterates w T,λ 's. Moreover, in such cases, the rate of linear convergence is of type (ν λ − µ λ )/(ν λ + µ λ ), where ν λ and µ λ are the Lipschitz constant of the gradient and the modulus of strong convexity of L λ respectively. So, this rate can be uniformly bounded from above by ρ ∈ ]0, 1[, provided that sup λ∈Λ ν λ &lt; +∞ and inf λ∈Λ µ λ &gt; 0. Thus, in these cases w T,λ converges uniformly to w λ on Λ (at a linear rate).</p><p>Example 3.4. Let us consider the following form of the inner objective:</p><formula xml:id="formula_21">L H (w) = y − XHw 2 + ρ w 2 ,<label>(8)</label></formula><p>where ρ &gt; 0 is a fixed regularization parameter and H ∈ R d×d is the hyperparameter, representing a linear feature map. L H is strongly convex, with modulus µ = ρ &gt; 0 (independent on the hyperparameter H), and Lipschitz smooth with constant ν H = 2 (XH) XH + ρI , which is bounded from above, if H ranges in a bounded set of square matrices. In this case assumptions (i)-(vi) are satisfied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Learning Hyper-Representations</head><p>In this section, we instantiate the bilevel programming approach for ML outlined in Sec. 2.2 in the case of deep learning where representation layers are shared across episodes. Finding good data representations is a centerpiece in machine learning. Classical approaches <ref type="bibr" target="#b2">(Baxter, 1995;</ref><ref type="bibr" target="#b7">Caruana, 1998</ref>) learn both the weights of the representation mapping and those of the ground classifiers jointly on the same data. Here we follow the bilevel approach and split each dataset/episode in training and validation sets.</p><p>Our method involves the learning of a cross-task intermediate representation h λ : X → R k (parametrized by a vector λ) on top of which task specific models g j : R k → Y j (parametrized by vectors w j ) are trained. The final ground model for task j is thus given by g j • h. To find λ, we solve Problem (1)-(2) with inner and outer objectives as in Eqs. (3) and (4), respectively. Since, in general, this problem cannot be solved exactly, we instantiate the approximation scheme in Eqs. <ref type="formula" target="#formula_8">(5)</ref>- <ref type="formula" target="#formula_9">(6)</ref> as follows:</p><formula xml:id="formula_22">min λ f T (λ) = N j=1 L j (w j T , λ, D j val )<label>(9)</label></formula><formula xml:id="formula_23">w j t = w j t−1 −η∇ w L j (w j t−1 , λ, D j tr ), t, j ∈ [T ], [N ]</formula><p>. (10) Starting from an initial value, the weights of the task-specific models are learned by T iterations of gradient descent. The gradient of f T can be computed efficiently in time by making use of an extended reverse-hypergradient procedure <ref type="bibr" target="#b17">(Franceschi et al., 2017</ref>) which we present in Algorithm 1. Since, in general, the number of episodes in a meta-training set is large, we compute a stochastic approximation of the gradient of f T by sampling a mini-batch of episodes. At test time, given a new episodeD, the representation h is kept fixed, and all the examples inD are used to tune the weightsw of the episode-specific modelḡ.</p><p>Like other initialization and optimization strategies for ML, our method does not require lookups in a support set as the memorization and metric strategies do <ref type="bibr" target="#b37">(Santoro et al., 2016;</ref><ref type="bibr" target="#b43">Vinyals et al., 2016;</ref><ref type="bibr" target="#b33">Mishra et al., 2018)</ref>. Unlike <ref type="bibr" target="#b0">(Andrychowicz et al., 2016;</ref><ref type="bibr" target="#b36">Ravi and Larochelle, 2017)</ref> we do not tune the optimization algorithm, which in our case is plain empirical loss minimization by gradient descent, and rather focus on the hypothesis space. Unlike <ref type="bibr" target="#b15">(Finn et al., 2017)</ref>, that aims at maximizing sensitivity of new task losses to the model parameters, we aim at maximizing the generalization to novel examples during training episodes, with respect to λ. Our assumptions about the structure of the model are slightly stronger than in <ref type="bibr" target="#b15">(Finn et al., 2017)</ref> but still mild, namely that some (hyper)parameters define the representation and the remaining parameters define the classification function. In <ref type="bibr" target="#b34">(Munkhdalai and Yu, 2017</ref>) the meta-knowledge is distributed among fast and slow weights and an external memory; our approach is more direct, since the meta-knowledge is solely distilled by λ. A further advantage of our method is that, if the episode-specific models are linear (e.g. logistic regressors) and each loss L j is strongly convex in w, the theoretical guarantees of Theorem 3.2 apply (see Remark 3.3). These assumptions are satisfied in the experiments reported in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>The aim of the following experiments is threefold. First, we investigate the impact of the number of iterations of the optimization dynamics on the quality of the solution on a simple multiclass classification problem. Second, we test our hyper-representation method in the context of few-shot learning on two benchmark datasets. Finally, we constrast the bilevel ML approach against classical approaches to learn shared representations 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">The Effect of T</head><p>Motivated by the theoretical findings of Sec. 3, we empirically investigate how solving the inner problem approximately (i.e. using small T ) affects convergence, generalization performances, and running time. We focus in particular on the linear feature map described in Example 3.4, which allows us to compare the approximated solution against the closed-form analytical solution given by</p><formula xml:id="formula_24">w H = [(XH) T XH + ρI] −1 (XH) T Y.</formula><p>In this setting, the bilevel problem reduces to a (non-convex) optimization problem in H.</p><p>We use a subset of 100 classes extracted from Omniglot dataset <ref type="bibr" target="#b29">(Lake et al., 2017)</ref> to construct a HO problem aimed at tuning H. A training set D tr and a validation set D val , each consisting of three randomly drawn examples per class, were sampled to form the HO problem. A third set D test , consisting of fifteen examples per class, was used for testing. Instead of using raw images as input, we employ feature vectors x ∈ R 256 computed by the convolutional network trained on one-shot five-ways ML setting as described in Sec. 5.2.</p><p>For the approximate problems we compute the hypergradient using Algorithm 1, where it is intended that B = {(D tr , D val )}. <ref type="figure" target="#fig_1">Figure 3</ref> shows the values of functions f and f T (see Eqs. <ref type="formula" target="#formula_0">(1)</ref> and <ref type="formula" target="#formula_8">(5)</ref>, respectively) during the optimization of H. As T increases, the solution of the approximate  problem approaches the true bilevel solution. However, performing a small number of gradient descent steps for solving the inner problem acts as implicit regularizer. As it is evident from <ref type="figure" target="#fig_2">Figure 4</ref>, the generalization error is better when T is smaller than the value yielding the best approximation of the inner solution. This is to be expected since, in this setting, the dimensions of parameters and hyperparameters are of the same order, leading to a concrete possibility of overfitting the outer objective (validation error). An appropriate, problem dependent, choice of T may help avoiding this issue (see also Appendix C). As T increases, the number of hyperiterations required to reach the maximum test accuracy decreases, further suggesting that there is an interplay between the number of iterations used to solve the inner and the outer objective. Finally, the running time of Algorithm 1, is linear in T and the size of w and independent of the size of H (see also <ref type="table" target="#tab_1">Table 2</ref>), making it even more appealing to reduce the number of iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Few-shot Learning</head><p>We now turn our attention to learning-to-learn, precisely to few-shot supervised learning, implementing the ML strategy outlined in Sec. 4 on two different benchmark datasets:</p><p>• OMNIGLOT <ref type="bibr" target="#b28">(Lake et al., 2015)</ref>, a dataset that contains examples of 1623 different handwritten characters from 50 alphabets. We downsample the images to 28 × 28.</p><p>• MINIIMAGENET <ref type="bibr" target="#b43">(Vinyals et al., 2016)</ref>, a subset of ImageNet <ref type="bibr" target="#b10">(Deng et al., 2009)</ref>, that contains 60000 downsampled images from 100 different classes.</p><p>Following the experimental protocol used in a number of recent works, we build a meta-training set D, from which we sample datasets to solve Problem (9)-(10), a meta-validation set V for tuning ML hyperparameters, and finally a metatest set T which is used to estimate accuracy. Operationally, each meta-dataset consists of a pool of samples belonging to different (non-overlapping between separate meta-dataset) classes, which can be combined to form ground classification datasets D j = D  <ref type="formula" target="#formula_22">(9)</ref>) and its (stochastic) gradient if D j ∈ D or to provide a generalization score if D j comes from either V or T . For MiniImagenet we use the same split and images proposed in <ref type="bibr" target="#b36">(Ravi and Larochelle, 2017)</ref>, while for Omniglot we use the protocol defined by <ref type="bibr" target="#b37">(Santoro et al., 2016)</ref>.</p><p>As ground classifiers we use multinomial logistic regressors and as task losses j we employ cross-entropy. The inner problems, being strongly convex, admit unique minimizers, yet require numerical computation of the solutions. We initialize ground models parameters w j to 0 and, according to the observation in Sec. 5.1, we perform T gradient descent steps, where T is treated as a ML hyperparameter that has to be validated. <ref type="figure">Figure 6</ref> shows an example of meta-validation of T for one-shot learning on MiniImagenet. We compute a stochastic approximation of ∇f T (λ) with Algorithm 1 and use Adam with decaying learning rate to optimize λ.</p><p>Regarding the specific implementation of the representation mapping h, we employ for Omniglot a four-layers convolutional neural network with strided convolutions and 64 filters per layer as in <ref type="bibr" target="#b43">(Vinyals et al., 2016)</ref> and other successive works. For MiniImagenet we tried two different architectures:</p><p>• C4L, a four-layers convolutional neural network with maxpooling and 32 filters per layer;</p><p>• RN: a residual network <ref type="bibr" target="#b19">(He et al., 2016)</ref> built of four residual blocks followed by two convolutional layers.</p><p>The first network architecture has been proposed in <ref type="bibr" target="#b36">(Ravi and Larochelle, 2017)</ref> and then used in <ref type="bibr" target="#b15">(Finn et al., 2017)</ref>, while a similar residual network architecture has been employed in a more recent work <ref type="bibr" target="#b33">(Mishra et al., 2018)</ref>. Further details on the architectures of h, as well as other ML hyperparameters, are specified in the supplementary material. We report our results, using RN for MiniImagenet, in <ref type="table" target="#tab_2">Table 3</ref>, alongside scores from various recently proposed methods for comparison.</p><p>The proposed method achieves competitive results highlighting the relative importance of learning a task independent representation, on the top of which logistic classifiers trained with very few samples generalize well. Moreover, utilizing more expressive models such as residual network as representation mappings, is beneficial for our proposed strategy and, unlike other methods, does not result in overfitting of the outer objective, as reported in <ref type="bibr" target="#b33">(Mishra et al., 2018)</ref>. Indeed, compared to C4L, RN achieves a relative improvement of 6.5% on one-shot and 4.2% on five-shot. <ref type="figure">Figure 5</ref> provides a visual example of the goodness of the learned representation, showing that MiniImagenet examples (the first from meta-training, the second from the meta-testing sets) from similar classes (different dog breeds) are mapped near each other by h and, conversely, samples from dissimilar classes are mapped afar. <ref type="figure">Figure 5</ref>. After sampling two datasets D ∈ D and D ∈ T , we show on the top the two images x ∈ D, x ∈ D that minimize ||h λ (x) − h λ (x )|| and on the bottom those that maximize it. In between each of the two couples we compare a random subset of components of h λ(x) (blue) and h λ (x ) (green).  <ref type="figure">Figure 6</ref>. Meta-validation of the number of gradient descent steps (T ) of the ground models for MiniImagenet using the RN representation. Early stopping on the accuracy on meta-validation set during meta-training resulted in halting the optimization of λ after 42k, 40k, 22k, and 15k hyperiterations for T equal to 3, 5, 8 and 12 respectively; in line with our observation in Sec. 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">On Variants of Representation Learning Methods</head><p>In this section, we show the benefits of learning a representation within the proposed bilevel framework compared to other possible approaches that involve an explicit factorization of a classifier as g j • h. The representation mapping h is either pretrained or learned with different meta-learning algorithms. We focus on the problem of one-shot learning on MiniImagenet and we use C4L as architecture for the representation mapping. In all the experiments the ground models g j are multinomial logistic regressor as in Sec. 5.2, tuned with 5 steps of gradient descent. We ran the following experiments:</p><p>• Multiclass: the mapping h : X → R 64 is given by the pretrained on the totality of examples contained in the training meta-dataset (600 examples for each of the 64 classes).</p><p>In this setting, we found that using the second last layer or the output after the softmax yields worst results;</p><p>• Bilevel-train: we use a bilevel approach but, unlike in Sec. 4, we optimize the parameter vector λ of the representation mapping by minimizing the loss on the training sets of each episode. The hypergradient is still computed with Algorithm 1, albeit we set D j val = D j tr for each training episodes; • Approx and Approx-train: we consider an approximation of the hypergradient ∇f T (λ) by disregarding the optimization dynamics of the inner objectives (i.e. we set ∇ λ w j T = 0). In Approx-train we just use the training sets;</p><p>• Classic: as in <ref type="bibr" target="#b2">(Baxter, 1995)</ref>, we learn h by jointly optimizef (λ, w 1 , . . . , w N ) = N j=1 L j (w j , λ, D j tr ) and treat the problem as standard multitask learning, with the exception that we evaluatef on mini-batches of 4 episodes, randomly sampled every 5 gradient descent iterations.</p><p>In settings where we do not use the validation sets, we let the training sets of each episode contain 16 examples per class. Using training episodes with just one example per class resulted in performances just above random chance. While the first experiment constitutes a standard baseline, the others have the specific aim of assessing (i) the importance of splitting episodes of meta-training set into training and validation and (ii) the importance of computing the hypergradient of the approximate bilevel problem with Algorithm 1. The results reported in <ref type="table" target="#tab_3">Table 4</ref> suggest that both the training/validation splitting and the full computation of the hypergradient constitute key factors for learning a good representation in a meta-learning context. On the other side, using pretrained representations, especially in a low-dimensional space, turns out to be a rather effective baseline. One possible explanation is that, in this context, some classes in the training and testing meta-datasets are rather similar (e.g. various dog breeds) and thus ground classifiers can leverage on very specific representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>We have shown that both HO and ML can be formulated in terms of bilevel programming and solved with an iterative approach. When the inner problem has a unique solution (e.g. is strongly convex), our theoretical results show that the iterative approach has convergence guarantees, a result that is interesting in its own right. In the case of ML, by adapting classical strategies <ref type="bibr" target="#b2">(Baxter, 1995)</ref> to the bilevel framework with training/validation splitting, we present a method for learning hyper-representations which is experimentally effective and supported by our theoretical guarantees.</p><p>Our framework encompasses recently proposed methods for meta-learning, such as learning to optimize, but also suggests different design patterns for the inner learning algorithm which could be interesting to explore in future work. The resulting inner problems may not satisfy the assumptions of our convergence analysis, raising the need for further theoretical investigations. An additional future direction of research is the study of the statistical properties of bilevel strategies where outer objectives are based on the generalization ability of the inner model to new (validation) data. Ideas from <ref type="bibr" target="#b32">(Maurer et al., 2016;</ref><ref type="bibr" target="#b9">Denevi et al., 2018)</ref> may be useful in this direction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Each blue line represents the average training error when varying w in g w,λ and the corresponding inner minimizer is shown as a blue dot. The validation error evaluated at each minimizer yields the black curve representing the outer objective f (λ), whose minimizer is shown as a red dot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Optimization of the outer objectives f and fT for exact and approximate problems. The optimization of H is performed with gradient descent with momentum, with same initialization, step size and momentum factor for each run.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Accuracy on Dtest of exact and approximated solutions during optimization of H. Training and validation accuracies reach almost 100% already for T = 4 and after few hundred hyperiterations, and therefore are not reported.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>are used to fit w j (see Eq. 10). The D j val 's, contain- ing 15 examples per class, is used either to compute f T (λ) (see Eq.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>on D test Accuracy on D val</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 .</head><label>1</label><figDesc>Links and naming conventions among different fields.</figDesc><table>Bilevel 
programming 

Hyperparameter 
optimization 

Meta-learning 

Inner variables 
Parameters 
Parameters of 
Ground models 
Outer variables 
Hyperparameters Parameters of 
Meta-learner 
Inner objective 
Training error 
Training errors 
on tasks (Eq. 3) 
Outer objective 
Validation error 
Meta-training 
error (Eq. 4) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 .</head><label>2</label><figDesc>Execution times on a NVidia Tesla M40 GPU.</figDesc><table>T 
1 
4 
16 
64 
256 Exact 
Time (sec) 60 119 356 1344 5532 
320 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 .</head><label>3</label><figDesc>Accuracy scores, computed on episodes from T , of various methods on 1-shot and 5-shot classification problems on Omniglot and MiniImagenet. For MiniImagenet 95% confidence intervals are reported. For Hyper-representation the scores are computed over 600 randomly drawn episodes. For other methods we show results as reported by their respective authors.</figDesc><table>OMNIGLOT 5 classes OMNIGLOT 20 classes 
MINIIMAGENET 5 classes 
Method 
1-shot 
5-shot 
1-shot 
5-shot 
1-shot 
5-shot 

Siamese nets (Koch et al., 2015) 
97.3 
98.4 
88.2 
97.0 
− 
− 
Matching nets (Vinyals et al., 2016) 
98.1 
98.9 
93.8 
98.5 
43.44 ± 0.77 55.31 ± 0.73 
Neural stat. (Edwards and Storkey, 2016) 
98.1 
99.5 
93.2 
98.1 
− 
− 
Memory mod. (Kaiser et al., 2017) 
98.4 
99.6 
95.0 
98.6 
− 
− 
Meta-LSTM (Ravi and Larochelle, 2017) 
− 
− 
− 
− 
43.56 ± 0.84 60.60 ± 0.71 
MAML (Finn et al., 2017) 
98.7 
99.9 
95.8 
98.9 
48.70 ± 1.75 63.11 ± 0.92 
Meta-networks (Munkhdalai and Yu, 2017) 
98.9 
− 
97.0 
− 
49.21 ± 0.96 
− 
Prototypical Net. (Snell et al., 2017) 
98.8 
99.7 
96.0 
98.9 
49.42 ± 0.78 68.20 ± 0.66 
SNAIL (Mishra et al., 2018) 
99.1 
99.8 
97.6 
99.4 
55.71 ± 0.99 68.88 ± 0.92 
Hyper-representation 
98.6 
99.5 
95.5 
98.4 
50.54 ± 0.85 64.53 ± 0.68 

linear outputs before the softmax operation of a network 

4 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 4 .</head><label>4</label><figDesc>Performance of various methods where the representation is either transfered or learned with variants of hyper-representation methods. The last raw reports, for comparison, the score obtained with hyper-representation.</figDesc><table>Method 
# filters Accuracy 1-shot 

Multiclass 
64 
43.02 
Bilevel-train 
32 
29.63 
Approx 
32 
41.12 
Approx-train 
32 
38.80 
Classic-train 
32 
40.46 
Hyper-representation-C4L 
32 
47.51 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The ML problem is also related to multitask learning, however in ML the goal is to extrapolate from the given tasks.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In general, the algorithm used to minimize the inner objective may involve auxiliary variables, e.g., velocities when using gradient descent with momentum, so w should be intended as a larger vector containing both model parameters and auxiliary variables.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The code for reproducing the experiments, based on the package FAR-HO (https://bit.ly/far-ho), is available at https://bit.ly/hyper-repr</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The network is similar to C4L but has 64 filters per layer.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3981" to="3989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Practical bilevel optimization: algorithms and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Bard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">1251</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning internal representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Annual Conference on Computational Learning Theory (COLT)</title>
		<meeting>the 8th Annual Conference on Computational Learning Theory (COLT)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="311" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic differentiation in machine learning: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Baydin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Pearlmutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Radul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Siskind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">43</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On optimal generalizability in parametric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beirami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Razaviyayn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shahrampour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tarokh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3458" to="3468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Random search for hyperparameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yamins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning, (ICML)</title>
		<meeting>the 30th International Conference on Machine Learning, (ICML)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="115" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning to learn</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page">2683</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An overview of bilevel optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Colson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Marcotte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Savard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of operations research</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="235" to="256" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Denevi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ciliberto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.08089</idno>
		<title level="m">Incremental learning-to-learn with statistical guarantees</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>To appear in UAI</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generic Methods for Optimization-Based Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Domke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="318" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Well-posed optimization problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Dontchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zolezzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Mathematics</title>
		<imprint>
			<biblScope unit="volume">1543</biblScope>
			<date type="published" when="1993" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02185[cs,stat].00027</idno>
		<idno>arXiv: 1606.02185</idno>
		<title level="m">Towards a Neural Statistician</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning multiple tasks with kernel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Micchelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="615" to="637" />
			<date type="published" when="2005-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning, (ICML)</title>
		<meeting>the 34th International Conference on Machine Learning, (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning constrained task similarities in graphregularized multi-task learning. Regularization, Optimization, Kernels, and Support Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Flamary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gasso</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">103</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Forward and reverse gradient-based hyperparameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Franceschi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Donini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning, (ICML)</title>
		<meeting>the 34th International Conference on Machine Learning, (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1165" to="1173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Evaluating derivatives: principles and techniques of algorithmic differentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Griewank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Walther</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>SIAM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Beyond Manual Tuning of Hyperparameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="329" to="337" />
		</imprint>
	</monogr>
<note type="report_type">KI -Künstliche Intelligenz</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Learning to remember rare events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Nachum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An efficient method for gradient-based adaptation of hyperparameters in svm models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Keerthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chapelle</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="673" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Undoing the damage of dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="158" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">127</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Understanding black-box predictions via influence functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning (ICML)</title>
		<meeting>the 34th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1885" to="1894" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Classification model selection via bilevel programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kunapuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-S</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optimization Methods and Software</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="475" to="489" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">From n to n+ 1: Multiclass transfer incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kuzborskij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3358" to="3365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Building machines that learn and think like people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<idno>40. 00152</idno>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Gradient-based hyperparameter optimization through reversible learning</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning, (ICML</title>
		<meeting>the 32nd International Conference on Machine Learning, (ICML</meeting>
		<imprint>
			<biblScope unit="page" from="2113" to="2122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The benefit of multitask representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Romera-Paredes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2853" to="2884" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abbeel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Meta networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning, (ICML)</title>
		<meeting>the 34th International Conference on Machine Learning, (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2554" to="2563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Hyperparameter optimization with approximate gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning (ICML)</title>
		<meeting>The 33rd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="737" to="746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Meta-learning with memoryaugmented neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings ofthe 33rd International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno>131-139. 00082</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4080" to="4090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2951" to="2959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Learning to learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learned optimizers that scale and generalize</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Wichrowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohldickstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning (ICML)</title>
		<meeting>the 34th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3751" to="3760" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
