<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Few-Shot Learning Through an Information Retrieval Lens</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Toronto Vector Institute</orgName>
								<orgName type="institution" key="instit2">University of Toronto Vector Institute</orgName>
								<orgName type="institution" key="instit3">University of Toronto Vector Institute Uber ATG</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Toronto Vector Institute</orgName>
								<orgName type="institution" key="instit2">University of Toronto Vector Institute</orgName>
								<orgName type="institution" key="instit3">University of Toronto Vector Institute Uber ATG</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Toronto Vector Institute</orgName>
								<orgName type="institution" key="instit2">University of Toronto Vector Institute</orgName>
								<orgName type="institution" key="instit3">University of Toronto Vector Institute Uber ATG</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Few-Shot Learning Through an Information Retrieval Lens</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Few-shot learning refers to understanding new concepts from only a few examples. We propose an information retrieval-inspired approach for this problem that is motivated by the increased importance of maximally leveraging all the available information in this low-data regime. We define a training objective that aims to extract as much information as possible from each training batch by effectively optimizing over all relative orderings of the batch points simultaneously. In particular, we view each batch point as a 'query' that ranks the remaining ones based on its predicted relevance to them and we define a model within the framework of structured prediction to optimize mean Average Precision over these rankings. Our method achieves impressive results on the standard few-shot classification benchmarks while is also capable of few-shot retrieval.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, the problem of learning new concepts from only a few labelled examples, referred to as few-shot learning, has received considerable attention <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. More concretely, K-shot N-way classification is the task of classifying a data point into one of N classes, when only K examples of each class are available to inform this decision. This is a challenging setting that necessitates different approaches from the ones commonly employed when the labelled data of each new concept is abundant. Indeed, many recent success stories of machine learning methods rely on large datasets and suffer from overfitting in the face of insufficient data. It is however not realistic nor preferred to always expect many examples for learning a new class or concept, rendering few-shot learning an important problem to address. We propose a model for this problem that aims to extract as much information as possible from each training batch, a capability that is of increased importance when the available data for learning each class is scarce. Towards this goal, we formulate few-shot learning in information retrieval terms: each point acts as a 'query' that ranks the remaining ones based on its predicted relevance to them. We are then faced with the choice of a ranking loss function and a computational framework for optimization. We choose to work within the framework of structured prediction and we optimize mean Average Precision (mAP) using a standard Structural SVM (SSVM) <ref type="bibr" target="#b2">[3]</ref>, as well as a Direct Loss Minimization (DLM) <ref type="bibr" target="#b3">[4]</ref> approach. We argue that the objective of mAP is especially suited for the low-data regime of interest since it allows us to fully exploit each batch by simultaneously optimizing over all relative orderings of the batch points. <ref type="figure">Figure 1</ref> provides an illustration of this training objective.</p><p>Our contribution is therefore to adopt an information retrieval perspective on the problem of few-shot learning; we posit that a model is prepared for the sparse-labels setting by being trained in a manner <ref type="figure">Figure 1</ref>: Best viewed in color. Illustration of our training objective. Assume a batch of 6 points: G1, G2 and G3 of class "green", Y1 and Y2 of "yellow", and another point. We show in columns 1-5 the predicted rankings for queries G1, G2, G3, Y1 and Y2, respectively. Our learning objective is to move the 6 points in positions that simultaneously maximize the Average Precision (AP) of the 5 rankings. For example, the AP of G1's ranking would be optimal if G2 and G3 had received the two highest ranks, and so on.</p><p>that fully exploits the information in each batch. We also introduce a new form of a few-shot learning task, 'few-shot retrieval', where given a 'query' image and a pool of candidates all coming from previously-unseen classes, the task is to 'retrieve' all relevant (identically labelled) candidates for the query. We achieve competitive with the state-of-the-art results on the standard few-shot classification benchmarks and show superiority over a strong baseline in the proposed few-shot retrieval problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our approach to few-shot learning heavily relies on learning an informative similarity metric, a goal that has been extensively studied in the area of metric learning. This can be thought of as learning a mapping of objects into a space where their relative positions are indicative of their similarity relationships. We refer the reader to a survey of metric learning <ref type="bibr" target="#b4">[5]</ref> and merely touch upon a few representative methods here.</p><p>Neighborhood Component Analysis (NCA) <ref type="bibr" target="#b5">[6]</ref> learns a metric aiming at high performance in nearest neirhbour classification. Large Margin Nearest Neighbor (LMNN) <ref type="bibr" target="#b6">[7]</ref> refers to another approach for nearest neighbor classification which constructs triplets and employs a contrastive loss to move the 'anchor' of each triplet closer to the similarly-labelled point and farther from the dissimilar one by at least a predefined margin.</p><p>More recently, various methods have emerged that harness the power of neural networks for metric learning. These methods vary in terms of loss functions but have in common a mechanism for the parallel and identically-parameterized embedding of the points that will inform the loss function. Siamese and triplet networks are commonly-used variants of this family that operate on pairs and triplets, respectively. Example applications include signature verification <ref type="bibr" target="#b7">[8]</ref> and face verification <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. NCA and LMNN have also been extended to their deep variants <ref type="bibr" target="#b10">[11]</ref> and <ref type="bibr" target="#b11">[12]</ref>, respectively. These methods often employ hard-negative mining strategies for selecting informative constraints for training <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13]</ref>. A drawback of siamese and triplet networks is that they are local, in the sense that their loss function concerns pairs or triplets of training examples, guiding the learning process to optimize the desired relative positions of only two or three examples at a time. The myopia of these local methods introduces drawbacks that are reflected in their embedding spaces. <ref type="bibr" target="#b13">[14]</ref> propose a method to address this by using higher-order information.</p><p>We also learn a similarity metric in this work, but our approach is specifically tailored for few-shot learning. Other metric learning approaches for few-shot learning include <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>. <ref type="bibr" target="#b14">[15]</ref> employs a deep convolutional neural network that is trained to correctly predict pairwise similarities. Attentive Recurrent Comparators <ref type="bibr" target="#b15">[16]</ref> also perform pairwise comparisons but form the representation of the pair through a sequence of glimpses at the two points that comprise it via a recurrent neural network. We note that these pairwise approaches do not offer a natural mechanism to solve K-shot N-way tasks for K &gt; 1 and focus on one-shot learning, whereas our method tackles the more general few-shot learning problem. Matching Networks <ref type="bibr" target="#b0">[1]</ref> aim to 'match' the training setup to the evaluation trials of K-shot N-way classification: they divide each sampled training 'episode' into disjoint support and query sets and backpropagate the classification error of each query point conditioned on the support set. Prototypical Networks <ref type="bibr" target="#b16">[17]</ref> also perform episodic training, and use the simple yet effective mechanism of representing each class by the mean of its examples in the support set, constructing a 'prototype' in this way that each query example will be compared with. Our approach can be thought of as constructing all such query/support sets within each batch in order to fully exploit it.</p><p>Another family of methods for few-shot learning is based on meta-learning. Some representative work in this category includes <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b17">18]</ref>. These approaches present models that learn how to use the support set in order to update the parameters of a learner model in such a way that it can generalize to the query set. Meta-Learner LSTM <ref type="bibr" target="#b1">[2]</ref> learns an initialization for learners that can solve new tasks, whereas Model-Agnostic Meta-Learner (MAML) <ref type="bibr" target="#b17">[18]</ref> learns an update step that a learner can take to be successfully adapted to a new task. Finally, <ref type="bibr" target="#b18">[19]</ref> presents a method that uses an external memory module that can be integrated into models for remembering rarely occurring events in a life-long learning setting. They also demonstrate competitive results on few-shot classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Mean Average Precision (mAP)</head><p>Consider a batch B of points: X = {x 1 , x 2 , . . . , x N } and denote by c j the class label of the point x j . Let Rel x1 = {x j ∈ B : c 1 == c j } be the set of points that are relevant to x 1 , determined in a binary fashion according to class membership. Let O x1 denote the ranking based on the predicted similarity between x 1 and the remaining points in B so that O x1 [j] stores x 1 's j th most similar point. Precision at j in the ranking O x1 , denoted by P rec@j x1 is the proportion of points that are relevant to x 1 within the j highest-ranked ones. The Average Precision (AP) of this ranking is then computed by averaging the precisions at j over all positions j in O x1 that store relevant points.</p><formula xml:id="formula_0">AP x1 = j∈{1,...,|B−1|: O x 1 [j]∈Rel x 1 } P rec@j x1 |Rel x1 | where P rec@j x1 = |{k ≤ j : O x1 [k] ∈ Rel x1 }| j</formula><p>Finally, mean Average Precision (mAP) calculates the mean AP across batch points.</p><formula xml:id="formula_1">mAP = 1 |B| i∈{1,...B} AP xi</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Structural Support Vector Machine (SSVM)</head><p>Structured prediction refers to a family of tasks with inter-dependent structured output variables such as trees, graphs, and sequences, to name just a few <ref type="bibr" target="#b2">[3]</ref>. Our proposed learning objective that involves producing a ranking over a set of candidates also falls into this category so we adopt structured prediction as our computational framework. SSVM <ref type="bibr" target="#b2">[3]</ref> is an efficient method for these tasks with the advantage of being tunable to custom task loss functions. More concretely, let X and Y denote the spaces of inputs and structured outputs, respectively. Assume a scoring function F (x, y; w) depending on some weights w, and a task loss L(y GT ,ŷ) incurred when predictingŷ when the groundtruth is y GT . The margin-rescaled SSVM optimizes an upper bound of the task loss formulated as: min</p><formula xml:id="formula_2">w E[max y∈Y {L(y GT ,ŷ) − F (x, y GT ; w) + F (x,ŷ; w)}]</formula><p>The loss gradient can then be computed as:</p><formula xml:id="formula_3">∇ w L(y) = ∇ w F (X , y hinge , w) − ∇ w F (X , y GT , w)</formula><p>with y hinge = arg max</p><formula xml:id="formula_4">y∈Y {F (X ,ŷ, w) + L(y GT ,ŷ)} (1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Direct Loss Minimization (DLM)</head><p>[4] proposed a method that directly optimizes the task loss of interest instead of an upper bound of it.</p><p>In particular, they provide a perceptron-like weight update rule that they prove corresponds to the gradient of the task loss. <ref type="bibr" target="#b19">[20]</ref> present a theorem that equips us with the corresponding weight update rule for the task loss in the case of nonlinear models, where the scoring function is parameterized by a neural network. Since we make use of their theorem, we include it below for completeness.</p><p>Let D = {(x, y)} be a dataset composed of input x ∈ X and output y ∈ Y pairs. Let F (X , y, w) be a scoring function which depends on the input, the output and some parameters w ∈ R A .</p><p>Theorem 1 (General Loss Gradient Theorem from <ref type="bibr" target="#b19">[20]</ref>). When given a finite set Y, a scoring function F (X , y, w), a data distribution, as well as a task-loss L(y,ŷ), then, under some mild regularity conditions, the direct loss gradient has the following form:</p><formula xml:id="formula_5">∇ w L(y, y w ) = ± lim →0 1 (∇ w F (X , y direct , w) − ∇ w F (X , y w , w))<label>(2)</label></formula><p>with:</p><formula xml:id="formula_6">y w = arg max y∈Y F (X ,ŷ, w) and y direct = arg max y∈Y {F (X ,ŷ, w) ± L(y,ŷ)}</formula><p>This theorem presents us with two options for the gradient update, henceforth the positive and negative update, obtained by choosing the + or − of the ± respectively. <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b19">[20]</ref> provide an intuitive view for each one. In the case of the positive update, y direct can be thought of as the 'worst' solution since it corresponds to the output value that achieves high score while producing high task loss. In this case, the positive update encourages the model to move away from the bad solution y direct . On the other hand, when performing the negative update, y direct represents the 'best' solution: one that does well both in terms of the scoring function and the task loss. The model is hence encouraged in this case to adjust its weights towards the direction of the gradient of this best solution's score.</p><p>In a nutshell, this theorem provides us with the weight update rule for the optimization of a custom task loss, provided that we define a scoring function and procedures for performing standard and loss-augmented inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Relationship between DLM and SSVM</head><p>As also noted in <ref type="bibr" target="#b3">[4]</ref>, the positive update of direct loss minimization strongly resembles that of the margin-rescaled structural SVM <ref type="bibr" target="#b2">[3]</ref> which also yields a loss-informed weight update rule. This gradient computation differs from that of the direct loss minimization approach only in that, while SSVM considers the score of the ground-truth F (X , y GT , w), direct loss minimization considers the score of the current prediction F (X , y w , w). The computation of y hinge strongly resembles that of y direct in the positive update. Indeed SSVM's training procedure also encourages the model to move away from weights that produce the 'worst' solution y hinge .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Optimizing for Average Precision (AP)</head><p>In the following section we adapt and extend a method for optimizing AP <ref type="bibr" target="#b19">[20]</ref>.</p><p>Given a query point, the task is to rank N points x = (x 1 , . . . , x N ) with respect to their relevance to the query, where a point is relevant if it belongs to the same class as the query and irrelevant otherwise. Let P and N be the sets of 'positive' (i.e. relevant) and 'negative' (i.e. irrelevant) points respectively. The output ranking is represented as y ij pairs where ∀i, j, y ij = 1 if i is ranked higher than j and y ij = −1 otherwise, and ∀i, y ii = 0. Define y = (. . . , y ij , . . . ) to be the collection of all such pairwise rankings.</p><p>The scoring function that <ref type="bibr" target="#b19">[20]</ref> used is borrowed from <ref type="bibr" target="#b20">[21]</ref> and <ref type="bibr" target="#b21">[22]</ref>:</p><formula xml:id="formula_7">F (x, y, w) = 1 |P||N | i∈P,j∈N y ij (ϕ(x i , w) − ϕ(x j , w))</formula><p>where ϕ(x i , w) can be interpreted as the learned similarity between x i and the query.</p><p>[20] devise a dynamic programming algorithm to perform loss-augmented inference in this setting which we make use of but we omit for brevity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Few-Shot Learning by Optimizing mAP</head><p>In this section, we present our approach for few-shot learning that optimizes mAP. We extend the work of <ref type="bibr" target="#b19">[20]</ref> that optimizes for AP in order to account for all possible choices of query among the batch points. This is not a straightforward extension as it requires ensuring that optimizing the AP of one query's ranking does not harm the AP of another query's ranking.</p><p>In what follows we define a mathematical framework for this problem and we show that we can treat each query independently without sacrificing correctness, therefore allowing to efficiently in parallel learn to optimize all relative orderings within each batch. We then demonstrate how we can use the frameworks of SSVM and DLM for optimization of mAP, producing two variants of our method henceforth referred to as mAP-SSVM and mAP-DLM, respectively.</p><p>Setup: Let B be a batch of points: B = {x 1 , x 2 , . . . , x N } belonging to C different classes. Each class c ∈ {1, 2, . . . , C} defines the positive set P c containing the points that belong to c and the negative set N c containing the rest of the points. We denote by c i the class label of the i th point.</p><p>We</p><note type="other">represent the output rankings as a collection of y i kj variables where y i kj = 1 if k is ranked higher than j in i's ranking, y i kk = 0 and y i kj = −1 if j is ranked higher than k in i's ranking. For convenience we combine these comparisons for each query i in y i = (. . . , y i kj , . . . ). Let f (x, w) be the embedding function, parameterized by a neural network and ϕ(x 1 , x 2 , w) the cosine similarity of points x 1 and x 2 in the embedding space given by w:</note><formula xml:id="formula_8">ϕ(x 1 , x 2 , w) = f (x 1 , w) · f (x 2 , w) |f (x 1 , w)||f (x 2 , w)| ϕ(x i , x j , w)</formula><p>is typically referred in the literature as the score of a siamese network.</p><p>We consider for each query i, the function F i (X , y i , w):</p><formula xml:id="formula_9">F i (X , y i , w) = 1 |P ci ||N ci | k∈P c i \i j∈N c i y i kj (ϕ(x i , x k , w) − ϕ(x i , x j , w))</formula><p>We then compose the scoring function by summing over all queries:</p><formula xml:id="formula_10">F (X , y, w) = i∈B F i (X , y i , w)</formula><p>Further, for each query i ∈ B, we let </p><formula xml:id="formula_11">p i = rank(y i ) ∈ {0, 1}</formula><formula xml:id="formula_12">L i AP (p i ,p i ) = 1 − 1 |P ci | j:p i j =1 P rec@j</formula><p>where P rec@j is the percentage of relevant points among the top-ranked j and p i andp i denote the ground-truth and predicted binary relevance vectors for query i, respectively. We define the mAP loss to be the average AP loss over all query points.</p><p>Inference: We proof-sketch in the supplementary material that inference can be performed efficiently in parallel as we can decompose the problem of optimizing the orderings induced by the different queries to optimizing each ordering separately. Specifically, for a query i of class c the computation of the y i kj 's, ∀k ∈ P c \ i, j ∈ N c can happen independently of the computation of the y i k j 's for some other query i = i. We are thus able to optimize the ordering induced by each query point independently of those induced by the other queries. For query i, positive point k and negative point j, the solution of standard inference is y i w kj = arg max y i F i (X , y i , w) and can be computed as follows</p><formula xml:id="formula_13">y i w kj = 1, if ϕ(x i , x k , w) − ϕ(x i , x j , w) &gt; 0 −1, otherwise<label>(3)</label></formula><p>Loss-augmented inference for query i is defined as y i direct = arg max</p><formula xml:id="formula_14">y i F i (X ,ŷ i , w) ± L i (y i ,ŷ i )<label>(4)</label></formula><p>and can be performed via a run of the dynamic programming algorithm of <ref type="bibr" target="#b19">[20]</ref>. We can then combine the results of all the independent inferences to compute the overall scoring function</p><formula xml:id="formula_15">F (X , y w , w) = i∈B F i (X , y i w , w) and F (X , y direct , w) = i∈B F i (X , y i direct , w)<label>(5)</label></formula><p>Finally, we define the ground-truth output value y GT . For any query i and distinct points m, n = i we set y i GTmn = 1 if m ∈ P ci and n ∈ N ci , y i GTmn = −1 if n ∈ P ci and m ∈ N ci and y i GTmn = 0 otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Few-Shot Learning by Optimizing mAP</head><p>Input: A batch of points X = {x1, . . . , xN } of C different classes and ∀c ∈ {1, . . . , C} the sets P c and N c . Compute the gradient ∇wL(y, yw) as in Equation 1 (using y direct in the place of y hinge ) end if Perform the weight update rule with stepsize η: w ← w − η∇wL(y, yw) until stopping criteria</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initialize w if using mAP-SSVM then</head><p>We note that by construction of our scoring function defined above, we will only have to compute y i kj 's where k and i belong to the same class c i and j is a point from another class. Because of this, we set the y i GT for each query i to be an appropriately-sized matrix of ones:</p><formula xml:id="formula_16">y i GT = ones(|P ci |, |N ci |).</formula><p>The overall score of the ground truth is then</p><formula xml:id="formula_17">F (X , y GT , w) = i∈B F i (X , y i GT , w)<label>(6)</label></formula><p>Optimizing mAP via SSVM and DLM We have now defined all the necessary components to compute the gradient update as specified by the General Loss Gradient Theorem of <ref type="bibr" target="#b19">[20]</ref> in equation 2 or as defined by the Structural SVM in equation 1. For clarity, Algorithm 1 describes this process, outlining the two variants of our approach for few-shot learning, namely mAP-DLM and mAP-SSVM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>In what follows, we describe our training setup, the few-shot learning tasks of interest, the datasets we use, and our experimental results. Through our experiments, we aim to evaluate the few-shot retrieval ability of our method and additionally to compare our model to competing approaches for few-shot classification. For this, we have updated our tables to include very recent work that is published concurrently with ours in order to provide the reader with a complete view of the state-of-the-art on few-shot learning. Finally, we also aim to investigate experimentally our model's aptness for learning from little data via its training objective that is designed to fully exploit each training batch.</p><p>Controlling the influence of loss-augmented inference on the loss gradient We found empirically that for the positive update of mAP-DLM and for mAP-SSVM, it is beneficial to introduce a hyperparamter α that controls the contribution of the loss-augmented F (X , y direct , w) relative to that of F (X , y w , w) in the case of mAP-DLM, or F (X , y GT , w) in the case of mAP-SSVM. The updated rules that we use in practice for training mAP-DLM and mAP-SSVM, respectively, are shown below, where α is a hyperparamter. Few-shot Classification and Retrieval Tasks Each K-shot N-way classification 'episode' is constructed as follows: N evaluation classes and 20 images from each one are selected uniformly at random from the test set. For each class, K out of the 20 images are randomly chosen to act as the 'representatives' of that class. The remaining 20 − K images of each class are then to be classified among the N classes. This poses a total of (20 − K)N classification problems. Following the standard procedure, we repeat this process 1000 times when testing on Omniglot and 600 times for mini-ImageNet in order to compute the results reported in tables 1 and 2.</p><formula xml:id="formula_18">∇ w L(y, y w ) = ± lim →0 1 (α∇ w F (X , y direct , w) − ∇ w F (X , y w , w)) and ∇ w L(y) = α∇ w F (X , y direct , w) − ∇ w F (X ,</formula><p>We also designed a similar one-shot N-way retrieval task, where to form each episode we select N classes at random and 10 images per class, yielding a pool of 10N images. Each of these 10N images acts as a query and ranks all remaining (10N -1) images. The goal is to retrieve all 9 relevant images before any of the (10N -10) irrelevant ones. We measure the performance on this task using mAP. Note that since this is a new task, there are no publicly available results for the competing few-shot learning methods.</p><p>Our Algorithm for K-shot N-way classification Our model classifies image x into class c = arg max i AP i (x), where AP i (x) denotes the average precision of the ordering that image x assigns to the pool of all KN representatives assuming that the ground truth class for image x is i. This means that when computing AP i (x), the K representatives of class i will have a binary relevance of 1 while the K(N − 1) representatives of the other classes will have a binary relevance of 0. Note that in the one-shot learning case where K = 1 this amounts to classifying x into the class whose (single) representative is most similar to x according to the model's learned similarity metric.</p><p>We note that the siamese model does not naturally offer a procedure for exploiting all K representatives of each class when making the classification decision for some reference. Therefore we omit few-shot learning results for siamese when K &gt; 1 and examine this model only in the one-shot case.</p><p>Training details We use the same embedding architecture for all of our models for both Omniglot and mini-ImageNet. This architecture mimics that of <ref type="bibr" target="#b0">[1]</ref> and consists of 4 identical blocks stacked upon each other. Each of these blocks consists of a 3x3 convolution with 64 filters, batch normalization <ref type="bibr" target="#b22">[23]</ref>, a ReLU activation, and 2x2 max-pooling. We resize the Omniglot images to 28x28, and the mini-ImageNet images to 3x84x84, therefore producing a 64-dimensional feature vector for each Omniglot image and a 1600-dimensional one for each mini-ImageNet image. We use ADAM <ref type="bibr" target="#b23">[24]</ref> for training all models. We refer the reader to the supplementary for more details.</p><p>Omniglot The Omniglot dataset <ref type="bibr" target="#b24">[25]</ref> is designed for testing few-shot learning methods. This dataset consists of 1623 characters from 50 different alphabets, with each character drawn by 20 different drawers. Following <ref type="bibr" target="#b0">[1]</ref>, we use 1200 characters as training classes and the remaining 423 for evaluation while we also augment the dataset with random rotations by multiples of 90 degrees. The results for this dataset are shown in <ref type="table">Table 1</ref>. Both mAP-SSVM and mAP-DLM are trained with α = 10, and for mAP-DLM the positive update was used. We used |B| = 128 and N = 16 for our models and the siamese. Overall, we observe that many methods perform very similarly on few-shot classification on this dataset, ours being among the top-performing ones. Further, we perform equally well or better than the siamese network in few-shot retrieval. We'd like to emphasize that the siamese network is a tough baseline to beat, as can be seen from its performance in the classification tasks where it outperforms recent few-shot learning methods.</p><p>mini-ImageNet mini-ImageNet refers to a subset of the ILSVRC-12 dataset <ref type="bibr" target="#b25">[26]</ref> that was used as a benchmark for testing few-shot learning approaches in <ref type="bibr" target="#b0">[1]</ref>. This dataset contains 60,000 84x84 color images and constitutes a significantly more challenging benchmark than Omniglot. In order to 43.44 ± 0.77 % 60.60 ± 0.71 % --Prototypical Networks <ref type="bibr" target="#b16">[17]</ref> 49.42 ± 0.78% 68.20 ± 0.66 % --MAML <ref type="bibr" target="#b17">[18]</ref> 48  confidence intervals). We report accuracy for the classification and mAP for the retrieval tasks. *Results reported by <ref type="bibr" target="#b1">[2]</ref>.</p><p>compare our method with the state-of-the-art on this benchmark, we adapt the splits introduced in <ref type="bibr" target="#b1">[2]</ref> which contain a total of 100 classes out of which 64 are used for training, 16 for validation and 20 for testing. We train our models on the training set and use the validation set for monitoring performance. <ref type="table" target="#tab_3">Table 2</ref> reports the performance of our method and recent competing approaches on this benchmark. As for Omniglot, the results of both versions of our method are obtained with α = 10, and with the positive update in the case of mAP-DLM. We used |B| = 128 and N = 8 for our models and the siamese. We also borrow the baseline reported in <ref type="bibr" target="#b1">[2]</ref> for this task which corresponds to performing nearest-neighbors on top of the learned embeddings. Our method yields impressive results here, outperforming recent approaches tailored for few-shot learning either via deep-metric learning such as Matching Networks <ref type="bibr" target="#b0">[1]</ref> or via meta-learning such as Meta-Learner LSTM <ref type="bibr" target="#b1">[2]</ref> and MAML <ref type="bibr" target="#b17">[18]</ref> in few-shot classification. We set the new state-of-the-art for 1-shot 5-way classification. Further, our models are superior than the strong baseline of the siamese network in the few-shot retrieval tasks.</p><p>CUB We also experimented on the Caltech-UCSD Birds (CUB) 200-2011 dataset <ref type="bibr" target="#b26">[27]</ref>, where we outperform the siamese network as well. More details can be found in the supplementary.</p><p>Learning Efficiency We examine our method's learning efficiency via comparison with a siamese network. For fair comparison of these models, we create the training batches in a way that enforces that they have the same amount of information available for each update: each training batch B is formed by sampling N classes uniformly at random and |B| examples from these classes. The siamese network is then trained on all possible pairs from these sampled points. <ref type="figure" target="#fig_2">Figure 2</ref> displays the performance of our model and the siamese on different metrics on Omniglot and mini-ImageNet. The first two rows show the performance of our two variants and the siamese in the few-shot classification (left) and few-shot retrieval (right) tasks, for various levels of difficulty as regulated by the different values of N. The first row corresponds to Omniglot and the second to mini-ImageNet. We observe that even when both methods converge to comparable accuracy or mAP values, our method learns faster, especially when the 'way' of the evaluation task is larger, making the problem harder.</p><p>In the third row in <ref type="figure" target="#fig_2">Figure 2</ref>, we examine the few-shot learning performance of our model and the all-pairs siamese that were trained with N = 8 but with different |B|. We note that for a given N , larger batch size implies larger 'shot'. For example, for N = 8, |B| = 64 results to on average 8 examples of each class in each batch (8-shot) whereas |B| = 16 results to on average 2-shot. We observe that especially when the 'shot' is smaller, there is a clear advantage in using our method over the all-pairs siamese. Therefore it indeed appears to be the case that the fewer examples we are given per class, the more we can benefit from our structured objective that simultaneously optimizes all relative orderings. Further, mAP-DLM can reach higher performance overall with smaller batch sizes (thus smaller 'shot') than the siamese, indicating that our method's training objective is indeed efficiently exploiting the batch examples and showing promise in learning from less data.</p><p>Discussion It is interesting to compare experimentally methods that have pursued different paths in addressing the challenge of few-shot learning. In particular, the methods we compare against each other in our tables include deep metric learning approaches such as ours, the siamese network, Prototypical Networks and Matching Networks, as well as meta-learning methods such as MetaLearner LSTM <ref type="bibr" target="#b1">[2]</ref> and MAML <ref type="bibr" target="#b17">[18]</ref>. Further, <ref type="bibr" target="#b18">[19]</ref> has a metric-learning flavor but employs external memory as a vehicle for remembering representations of rarely-observed classes. The experimental results suggest that there is no clear winner category and all these directions are worth exploring further.</p><p>Overall, our model performs on par with the state-of-the-art results on the classification benchmarks, while also offering the capability of few-shot retrieval where it exhibits superiority over a strong baseline. Regarding the comparison between mAP-DLM and mAP-SSVM, we remark that they mostly perform similarly to each other on the benchmarks considered. We have not observed in this case a significant win for directly optimizing the loss of interest, offered by mAP-DLM, as opposed to minimizing an upper bound of it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have presented an approach for few-shot learning that strives to fully exploit the available information of the training batches, a skill that is utterly important in the low-data regime of few-shot learning. We have proposed to achieve this via defining an information-retrieval based training objective that simultaneously optimizes all relative orderings of the points in each training batch. We experimentally support our claims for learning efficiency and present promising results on two standard few-shot learning datasets. An interesting future direction is to not only reason about how to best exploit the information within each batch, but additionally about how to create training batches in order to best leverage the information in the training set. Furthermore, we leave it as future work to explore alternative information retrieval metrics, instead of mAP, as training objectives for few-shot learning (e.g. ROC curve, discounted cumulative gain etc).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>| be a vector obtained by sorting the y i kj 's ∀k ∈ P ci \ i, j ∈ N ci , such that for a point g = i, p i g = 1 if g is relevant for query i and p i g = −1 otherwise. Then the AP loss for the ranking induced by some query i is defined as:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>ONES(|P c i |, |N c i |), ∀i = 1, . . . , N end if repeat if using mAP-DLM then Standard inference: Compute y i w , ∀i = 1, . . . , N as in Equation 3 end if Loss-augmented inference: Compute y i direct , ∀i = 1, . . . , N via the DP algorithm of [20] as in Equation 4. In the case of mAP-SSVM, always use the positive update option and set = 1 Compute F (X , y direct , w) as in Equation 5 if using mAP-DLM then Compute F (X , yw, w) as in Equation 5 Compute the gradient ∇wL(y, yw) as in Equation 2 else if using mAP-SSVM then Compute F (X , yGT , w) as in Equation 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Few-shot learning performance (on unseen validation classes). Each point represents the average performance across 100 sampled episodes. Top row: Omniglot. Second and third rows: mini-ImageNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>y y GT , w) We refer the reader to the supplementary material for more details concerning this hyperparameter.</figDesc><table>Classification 

Retrieval 
1-shot 
5-shot 
1-shot 
5-way 20-way 5-way 20-way 5-way 20-way 

Siamese 
98.8 
95.5 
-
-
98.6 
95.7 
Matching Networks [1] 
98.1 
93.8 
98.9 
98.5 
-
-
Prototypical Networks [17] 
98.8 
96.0 
99.7 
98.9 
-
-
MAML [18] 
98.7 
95.8 
99.9 
98.9 
-
-
ConvNet w/ Memory [19] 
98.4 
95.0 
99.6 
98.6 
-
-
mAP-SSVM (ours) 
98.6 
95.2 
99.6 
98.6 
98.6 
95.7 
mAP-DLM (ours) 
98.8 
95.4 
99.6 
98.6 
98.7 
95.8 

Table 1: Few-shot learning results on Omniglot (averaged over 1000 test episodes). We report accuracy for the 

classification and mAP for the retrieval tasks. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Few-shot learning results on miniImageNet (averaged over 600 test episodes and reported with 95%</figDesc><table></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Large margin methods for structured and interdependent output variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasemin</forename><surname>Altun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1453" to="1484" />
			<date type="published" when="2005-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Direct loss minimization for structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamir</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Keshet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Mcallester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1594" to="1602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A survey on metric learning for feature vectors and structured data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurélien</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amaury</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Sebban</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.6709</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neighbourhood components analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence K</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1473" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Signature verification using a &quot;siamese&quot; time delay neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bentz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roopak</forename><surname>Säckinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Pattern Recognition and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page" from="669" to="688" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning a nonlinear embedding by preserving class neighbourhood structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A deep non-linear feature mapping for large-margin knn classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqiang</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zineng</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaolei</forename><surname>Bonner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining, 2009. ICDM&apos;09. Ninth IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="357" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4004" to="4012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learnable structured clustering framework for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.01213</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubham</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambedkar</forename><surname>Dukkipati</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00767</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">Attentive recurrent comparators. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.05175</idno>
		<title level="m">Prototypical networks for few-shot learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03400</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofir</forename><surname>Nachum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurko</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03129</idno>
		<title level="m">Learning to remember rare events</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Training deep neural networks via direct loss minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<meeting>The 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2169" to="2177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A support vector method for optimizing average precision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisong</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 30th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficient optimization for average precision svm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pritish</forename><surname>Mohapatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M Pawan</forename><surname>Jawahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2312" to="2320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">One shot learning of simple visual concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Brenden M Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CogSci</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">172</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The caltech-ucsd birds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
