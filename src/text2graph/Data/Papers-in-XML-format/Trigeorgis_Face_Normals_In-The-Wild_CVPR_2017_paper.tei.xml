<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T22:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Face Normals &quot;in-the-wild&quot; using Fully Convolutional Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Trigeorgis</surname></persName>
							<email>g.trigeorgis@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Imperial College London</orgName>
								<orgName type="institution" key="instit2">Imperial College London</orgName>
								<orgName type="institution" key="instit3">Iasonas Kokkinos University College London</orgName>
								<orgName type="institution" key="instit4">Imperial College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Snape</surname></persName>
							<email>p.snape@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Imperial College London</orgName>
								<orgName type="institution" key="instit2">Imperial College London</orgName>
								<orgName type="institution" key="instit3">Iasonas Kokkinos University College London</orgName>
								<orgName type="institution" key="instit4">Imperial College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
							<email>s.zafeiriou@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Imperial College London</orgName>
								<orgName type="institution" key="instit2">Imperial College London</orgName>
								<orgName type="institution" key="instit3">Iasonas Kokkinos University College London</orgName>
								<orgName type="institution" key="instit4">Imperial College London</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Face Normals &quot;in-the-wild&quot; using Fully Convolutional Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Facial surface reconstruction from a single image is a problem that has attracted considerable attention over the past 25 years. This is in part due to both the multitude of applications related to face recognition and facial expression analysis, as well as its tractability due to the desirable properties of the physical structure of the human face. In contrast to the difficulty of the general case, the recovery of 3D facial shape has been highly successful. Human faces have a number of qualities that are desirable for shape recovery: they are extremely homogeneous in configuration (all healthy human faces have two eyes, a nose and mouth in the same approximate location), convex, exhibit approximately Lambertian reflectance <ref type="bibr" target="#b54">[54,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b61">61,</ref><ref type="bibr" target="#b43">43]</ref>, are largely captured from a single direction (frontal) and are deformable and mostly not self occluding. Furthermore, there exists a large amount of publicly available imagery of faces and human faces are of significant interest to a number of fields including entertainment, medicine, and psychology. The two main lines of research consist of (a) Shape from Shading (SfS) methods, which can also potentially employ a statistical face prior <ref type="bibr" target="#b71">[71,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b65">65,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b55">55,</ref><ref type="bibr" target="#b59">59,</ref><ref type="bibr" target="#b56">56]</ref>, or (b) building and fitting a 3D Morphable Model (3DMM) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b0">1]</ref>. A convnet normals face shape <ref type="figure">Figure 1</ref>: Depiction of our pipeline for 3D face shape estimation. Using a number of images of facial normals we train a fully convolutional network for normal estimation.</p><p>Using the estimated normals we can retrieve the 3D face shape by classical normal integration techniques.</p><p>3DMM consists of a linear statistical model of the facial texture and surface which is learnt from a set of captured and well-aligned 3D facial scans. For many years, the only publicly available 3DMM was the Basel model <ref type="bibr" target="#b40">[40]</ref>, which was constructed from 200 Caucasian people displaying a neutral expression. Now, large-scale 3DMMs of neutral faces are available in LSFM <ref type="bibr" target="#b7">[8]</ref> and expressive 3DMMs can be constructed by combining the statistical model of neutral faces with blendshapes <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b8">9]</ref>. Nevertheless, fitting a 3DMM to single images requires solving a high-dimensional nonlinear optimisation problem which is not only computationally demanding but also requires a near-optimal initialisation. Due to the difficulty of solving the original optimisation problem for 3DMMs, recent methods do not attempt to optimise the texture consistency term, but instead only fit the facial surface part of the 3DMM to a set of 2D facial landmarks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26]</ref>. SfS <ref type="bibr" target="#b23">[24]</ref>, is the process of recovering surface by assuming that shading (i.e., the intensity of a pixel in the image) is generated as a function of the surface geometry and its interaction with light which is reflected/absorbed by the surface and captured by an imaging device. This function is generally modelled by the image irradiance equation:</p><formula xml:id="formula_0">I(x, y) ∝ R(s x (x, y), s y (x, y)),<label>(1)</label></formula><p>which states that the measured brightness of the image I(x, y) is proportional to the radiance R at the corresponding point on the surface s x (x, y), s y (x, y). The most commonly employed radiance function is the Lambertian function, which describes the measured brightness as being proportional to the cosine of the angle between the direction of the incident light and the surface normal. Explicitly, the Lambertian function describes the observed intensity at a single pixel as I = ρ d n ⊤ s, where ρ d is the albedo, n is the unit normal of the surface for the given pixel and s is a single unit point light placed at infinity. Although this is a relatively simple explanation for the potentially complex interaction between a surface and the light sources within an environment, it has been shown to describe up to 90% <ref type="bibr" target="#b68">[68]</ref> of the low-frequency component of the lighting for images of a human face <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b68">68]</ref>. However, it is well known that shading alone is insufficient to disambiguate shape (e.g., the well known bas-relief ambiguity <ref type="bibr" target="#b5">[6]</ref>), hence generic SfS methods such as <ref type="bibr" target="#b2">[3]</ref> are often suboptimal for more structured objects such as faces. Thus, statistical priors of facial surface normals have been utilised to constrain generic SfS methods in order to improve results. For example, generic methods such as that of Worthington et al. <ref type="bibr" target="#b65">[65]</ref> have been extended by performing a linear projection of the recovered surface normals onto a constructed basis of facial normals <ref type="bibr" target="#b55">[55,</ref><ref type="bibr" target="#b56">56,</ref><ref type="bibr" target="#b59">59]</ref>. Similarly, the work of Barron et al. <ref type="bibr" target="#b2">[3]</ref> was extended to incorporate face specific priors by <ref type="bibr" target="#b34">[35]</ref>. However, both of these methods required pre-built models in order to constrain their solutions. The current state-of-the-art SfS methods that do not require models <ref type="bibr" target="#b57">[57,</ref><ref type="bibr" target="#b27">28]</ref> combine ideas from uncalibrated photometric stereo <ref type="bibr" target="#b3">[4]</ref> and low-rank tensor decompositions to robustly recover a combined model of shape and identity. Other methods have also explored the adaptation of fitted 3D templates with surface normals for more plausible surface recovery <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b28">29]</ref>. However, the majority of these methods require an explicit alignment step in order to bring the facial model into correspondence with the facial image. Despite impressive advances in the area of facial alignment, this remains to be a challenging problem. Furthermore, dense alignment, as is required for the recovery of dense facial shape, is often achieved through highly expensive operations such as optical flow <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b58">58]</ref>. Both 3DMMs and SfS are generative methods. In this paper, we take a different direction for estimation of the facial normals in unconstrained images and propose the first, to the best of our knowledge, discriminative deep learning methodology for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ours</head><p>Marr Revisited  <ref type="bibr" target="#b57">[57]</ref>, and generic state-of-the-art network <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IMM</head><p>the task of facial normal estimation. In particular, motivated by the success of deep learning to various tasks including object detection, dense semantic segmentation, and normal estimation of scenes <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b62">62]</ref> etc., we propose to exploit the available large scale facial databases captured both in controlled, as well as in unconstrained conditions <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b47">47]</ref> to train a fully convolutional deep network that maps image pixels to normals. More precisely, to acquire accurate ground truth of facial normals we synthesise images of faces created with the use of recently released Large-Scale 3D Facial Models (LSFM) <ref type="bibr" target="#b7">[8]</ref> which contains facial shapes of individuals with diverse ethnicities and characteristics. To retrieve the 3D facial shape of the subject, we integrate the recovered normals using standard methods <ref type="bibr" target="#b13">[14]</ref>.</p><p>We provide experiments with multiple deep architectures using various loss functions appropriate for the task. We show that the proposed networks achieve state-of-the-art performance in estimation of facial normals in controlled conditions, as well as impressive reconstruction for very challenging "in-the-wild" facial images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Prior work on Discriminative Surface Normal Estimation</head><p>Discriminative estimation of normals has recently received increased attention <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b62">62,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b14">15]</ref>. One of the first methods was proposed in <ref type="bibr" target="#b70">[70]</ref>. The training images were segmented using multiple unsupervised segmentation methods and then several dense features were extracted (e.g., texton <ref type="bibr" target="#b38">[38]</ref>, SIFT <ref type="bibr" target="#b37">[37]</ref>, etc) and discriminative feature representations combining contextual and segment-based features were built. The ground truth normals were approximated by applying local feature coding by a weighted sum of representative normals and a discrim-inative regressor (based on boosting) for these coefficients is trained. In the test phase, the likelihood of each representative normal was predicted by the classifier and the output normals were recovered as a weighted sum of representative normals. Richter and Roth <ref type="bibr" target="#b44">[44]</ref> relax the requirement for external training data and instead use synthetic training data. The object silhouette is used to approximate an initial normal map, which is then used to approximate the object reflectance map in order to relight synthetic training data for the training the regressor.</p><p>One of the first methods that exploited the power of Deep Convolutional Neural Networks (DCNNs) for estimating the normals were proposed in <ref type="bibr" target="#b62">[62]</ref>. The method in <ref type="bibr" target="#b62">[62]</ref> used DCNNs to combine normal estimates from local and global scales, incorporating cues from room layout, edge labels and vanishing points. The method posed the surface normal regression problem as a classification one by applying the surface normal triangular coding technique from Ladicky et al. <ref type="bibr" target="#b70">[70]</ref>. In particular, a codebook using k-means and a Delaunay triangulation was constructed over the words. Given this codebook and triangulation, a normal can be re-written as a weighted combination of the codewords in whose triangle it lies. At training-time, a softmax classifier is trained on the codewords. Recently, <ref type="bibr" target="#b14">[15]</ref> used reliable surface normals reconstructed from multiview stereo as training data for a DCNN, which then predicts continuous normals from image intensity patches. This allows for object specific training and was shown to improve viewpoint specific reconstruction.</p><p>The first method that directly regresses to the surface normals was proposed in <ref type="bibr" target="#b12">[13]</ref>, which simultaneously trained a course-to-fine multi-scale DCNN for three tasks: depth prediction, surface normal estimation, and semantic labelling. The convolutional layers of the first scale (coarse level) were initialised by training on the object classification task over ImageNet <ref type="bibr" target="#b10">[11]</ref>. The remaining network parameters for the mid-and fine levels were trained from scratch on the surface normal prediction task using NYU depth <ref type="bibr" target="#b50">[50,</ref><ref type="bibr" target="#b49">49]</ref>. The element-wise loss function used for surface estimation was the dot product between the groundtruth and the estimated surface normals.</p><p>Another regression based DCNN for normal estimation was proposed in <ref type="bibr" target="#b1">[2]</ref>. Similar to <ref type="bibr" target="#b12">[13]</ref>, this method leverages the rich feature representation learnt by a DCNN trained on large-scale data tasks, such as object classification over ImageNet. The architecture combined a fully-convolutional architecture adapted from VGG-16 <ref type="bibr" target="#b52">[52]</ref> with structures inspired by the hypercolumn representation <ref type="bibr" target="#b21">[22]</ref>. The network was optimised using the ℓ 2 -norm between groundtruth and estimated surface normals.</p><p>Most recently, another regression DCNN trained for surface estimation was proposed in <ref type="bibr" target="#b31">[32]</ref>. This DCNN is a part of the so-called UberNet architecture which was proposed for jointly solving multiple image labelling tasks: such as detection of boundaries, saliency, semantic segmentation, human-parts prediction, surface normals recovery etc. The building block of Ubernet is VGG-16 <ref type="bibr" target="#b53">[53]</ref>. For surface normal estimation, the ℓ 1 -norm between ground-truth and the estimated surface normals was used.</p><p>All the above networks for surface normal estimation were trained on data samples displaying various indoor scenes <ref type="bibr" target="#b49">[49,</ref><ref type="bibr" target="#b50">50]</ref>, hence, are likely sub-optimal for estimating the normals of human faces (please see <ref type="figure" target="#fig_0">Fig. 2</ref>). In this paper, we explore various DCNN architectures trained on facial databases for the task of facial surface normal estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Databases of facial normals</head><p>Over the past two decades, the computer vision community has made considerable efforts to collect facial images for varying applications. Notable examples of early attempts include the FERET database <ref type="bibr" target="#b42">[42]</ref> for face recognition and Cohn-Kadade database <ref type="bibr" target="#b26">[27]</ref> for facial expression recognition. The interested reader may refer to <ref type="bibr" target="#b18">[19]</ref> for a survey on face databases.</p><p>In this paper, we are interested in databases that can be used for training a DCNN for surface normal estimation. Ideally, we would use datasets that contain samples whose texture is captured in unconstrained conditions or whose texture is as close as possible to "in-the-wild" textures. Unfortunately, even with modern 3D capturing devices it is very difficult to acquire the 3D or 2.5D surface information from "in-the-wild" images. To mitigate this, we propose a learning strategy where we mix synthetic and real data for training the proposed network.</p><p>The databases appropriate for training our network are those that provide 3D surface scans, as well as databases captured under varying illuminations where the normals can be recovered using Photometric Stereo (PS) <ref type="bibr" target="#b64">[64]</ref>. Currently, there are many databases that provide 3D facial scans, including FRGC <ref type="bibr" target="#b41">[41]</ref>, BU-3D <ref type="bibr" target="#b67">[67]</ref>, BU-4D <ref type="bibr" target="#b66">[66]</ref> and BP4D-Spontaneous <ref type="bibr" target="#b72">[72]</ref>. Nevertheless, collectively they do not contain more than 620 unique identities. Fortunately, a recent effort was made to collect a large database of faces and to build a large scale 3D Morphable Model (3DMM) <ref type="bibr" target="#b7">[8]</ref>. In this paper, we use this database to generate a large amount of synthetic data.</p><p>The databases that contain samples captured under different illuminations include YALE-B <ref type="bibr" target="#b15">[16]</ref>, PIE <ref type="bibr" target="#b51">[51]</ref> and MULTI-PIE <ref type="bibr" target="#b19">[20]</ref>, as well as the recently collected Photoface database <ref type="bibr" target="#b69">[69]</ref>. The Photoface database <ref type="bibr" target="#b69">[69]</ref> was collected using a custom-made four-source PS device designed to enable data capture with minimal interaction with people. The device was placed at the entrance to a busy workplace and captured many sessions from more than 450 people displaying various expressions. Each session comprises four different images, under four different illuminants, from which the surface normal can be calculated using PS <ref type="bibr" target="#b64">[64]</ref>.</p><p>We also used the 3D Relightable Facial Expression database (ICT-3DRFE) <ref type="bibr" target="#b60">[60]</ref> which contains 23 subjects and 15 expressions for a total of 345 images. The ICT-3DRFE dataset was acquired using a face scanning system that employs a spherical light stage with 156 white LED lights. This database can be used to synthesise high quality facial samples under different illuminations due to the separation of both specular and diffuse normals for each individual.</p><p>Finally, in order to incorporate the statistics of "in-thewild" facial textures, we used the facial landmarks of the 300W data <ref type="bibr" target="#b48">[48]</ref> to fit a 3DMM, following <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b73">73]</ref>. We visually inspected the fittings and we kept those images for which the fitting was deemed acceptable.</p><p>In the remainder of this section we provide more details regarding how the data have been prepared with some visualisations of these data can be seen in <ref type="figure" target="#fig_1">Fig. 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Synthetic data generation from ICT-3DRFE</head><p>We generated synthetic data using the ICT-3DRFE database. The ICT-3DRFE dataset was captured using a high resolution face scanning system that employs a spherical light stage with 156 white LED lights. The lights are individually controllable in intensity and are used to light the face with a series of controlled spherical lighting conditions which reveal detailed shape and reflectance information. Linear polariser filters on the LED lights and an active polariser on the cameras allow specular and diffuse reflection to be recorded independently, yielding the diffuse and specular reflectance maps needed for photorealistic rendering under new lighting. We relit each sample under different random illuminations using the diffuse normals, as shown in <ref type="figure" target="#fig_2">Fig. 4.</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Synthetic data generation using the LSFM 3DMM</head><p>As discussed above, the largest obstacle in solving the normal estimation problem for in-the-wild images is the lack of ground truth accurate normals in unconstrained scenarios. Although there are many databases suitable for normal recovery using Photometric Stereo (PS) <ref type="bibr" target="#b64">[64]</ref>, these lighting conditions are highly unrealistic. Also, the nature of PS capture set-ups is highly constrained and thus the variety in both identity and expression are low for these databases. For this reason, we constructed a large amount of synthetic data using rendered images. Specifically, we performed the following two steps (1) use a generative model of shape and texture to create a 3D instance of a face; <ref type="bibr" target="#b1">(2)</ref> given this shape and a texture instance render it in a pseudophotorealistic way on top of a randomly chosen scene.</p><p>The solution to (1) can be obtained by the use of threedimensional statistical models of human facial shape and texture, known as 3D morphable models (3DMMs). A 3DMM is constructed by performing some form of dimensionality reduction, typically Principal Component Analysis (PCA), on a training set of 3D scans of faces that are in correspondence. Given this model, one can generate an infinite amount of realistic normals by synthesising a new instance x of the model. Specifically, choosing parameters from a normal distribution c I ∼ N (0, I) and using the mean shape µ ∈ R 3N and weights of the model W ∈ R 3N ×k we can synthesise a new instance x ∈ R 3N ×p ,</p><formula xml:id="formula_1">x = µ + W I c<label>(2)</label></formula><p>Booth et al. <ref type="bibr" target="#b7">[8]</ref>, provide a powerful 3DMM constructed with 9, 663 distinct subjects from a diverse set of demographics. Although this dataset is very diverse in terms of identity variation, it does not contain any diversity with respect to facial expression as all the subjects were captured in a neutral expression. To circumvent this, we use the expression bases created from the FaceWarehouse Database <ref type="bibr" target="#b8">[9]</ref> to create a dual basis model of expression and identity, similar to <ref type="bibr" target="#b73">[73]</ref>,</p><formula xml:id="formula_2">x = µ + W I c I + W E c E .</formula><p>This process is further depicted in <ref type="figure">Fig. 5</ref> where we detail the process that we used to generated the synthetic images of this dataset. As the true 3D facial structure is known, we obtain high quality ground truth normals for every synthesised image. From the newly constructed mesh, we can retrieve the surface normals n at a vertex location v ∈ R 3 by the vector cross product of two edges of that the vertex's triangle,</p><formula xml:id="formula_3">n = (v u − v) × (v v − v) (v u − v) × (v v − v) 2</formula><p>where v u and v v are vertices adjacent to v in the mesh structure along the positive horizontal and vertical directions.</p><p>A caveat with these generated samples is that a powerful regressor, as is the case with a large convolutional network, is that it can 'cheat' by taking into account various peculiarities of the synthesised samples such as the discontinuities between the face and the background or inaccurate lighting to learn to more easily recognise the pose and shape of the face. To account for this, we align these generated images to existing large-scale 2D datasets of "in-the-wild" images <ref type="bibr" target="#b47">[47]</ref> in order to provide more realistic backgrounds. Each of these facial images contains a set of sparse annotations s 2d ∈ R 68×2 . Thus, we manually annotate the 3D mesh in the same manner in order to provide a set of 68 corresponding points s 3d ∈ R 68×3 with the 2D images. Once we establish this correspondence, we can align the 3D shape to the image plane by employing a Perspective-n-Point (Pn-P) problem:  where</p><formula xml:id="formula_4">s 2d = KRs 3d + t<label>(3)</label></formula><formula xml:id="formula_5">K =   f x 0 c x 0 f y c y 0 0 1  </formula><p>is the matrix of intrinsic camera parameters, containing the focal length f ∈ R 2 and the principle point location c ∈ R 2 . In this way we generate a supplementary 100 000 images of synthetic faces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Synthetic data generation fitting a 3DMM</head><p>As has been previously mentioned, the constructed data using the 3DMM may not contain the desired facial texture of the "in-the-wild" images. To this end, we also fit the 3DMM to the "in-the-wild" images by employing the available sparse landmarks, similar to <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b73">73]</ref>. Specifically, to fit the 3DMM to the available images we employ the fol- </p><formula xml:id="formula_6">P(R(s + U c) + t)) − s 2d 2 F ,<label>(4)</label></formula><p>where the goal is to recover the rotation R, translation t and parameters c of the morphable model, under a weakperspective projection P. Beginning with just the mean 3D shapes, we optimise in an alternating manner first the pose parameters R, t and then the shape model parameters c. Unfortunately, as shown in <ref type="figure" target="#fig_1">Fig. 3</ref>, the fittings do not accurately capture the identity of the person. However, these fittings can still be employed to regularise the optimisation problem. They ensure that the normals correctly capture the pose and expression of the subject.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Data from the Photoface Database</head><p>The last database we used was the Photoface database <ref type="bibr" target="#b69">[69]</ref>. In the Photoface database, each ses-sion contains four images captured under a different illumination.</p><p>Examples of the Photoface are shown in <ref type="figure" target="#fig_1">Fig. 3</ref>. In order to estimate the normals from the images, we used the standard 4 source PS <ref type="bibr" target="#b64">[64]</ref>. The standard PS assumes three or more grayscale images of a Lambertian object and constructs the following matrix equation:</p><formula xml:id="formula_7">I = ρ ⊙ N L<label>(5)</label></formula><p>where I = [I 1 , I 2 , . . . , I N ] is a P ×N matrix containing irradiance values from all images, and P and N are the number of pixels and images respectively. Each row of I corresponds to a pixel position in an image, and each column corresponds to a different image. The albedo ρ ∈ R P combined with the normals matrix N ∈ R P ×3 represents the surface properties. The lighting matrix L = [l 1 , . . . , l N ] ∈ R 3×F represents the lighting directions and intensities, i.e., the j-th column of the matrix L corresponds to the lighting direction in the j-th image scaled by its intensity. Assuming that the light source vectors are known, we can solve a least squares version of the system in Eq. 5 for the albedo and the surface normal components at each pixel. Having available the albedo and normal information of a face, we can generate synthesised examples of the same subject by varying the light direction. We synthesised 3148 images by sampling random illuminations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Model</head><p>As in <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b36">36]</ref>, we use a 'fully convolutional' network to extract an increasingly sophisticated hierarchy of features. Since the normal estimation task can benefit from both low and high level features, we use skip layers <ref type="bibr" target="#b20">[21]</ref> that take intermediate layer activations as inputs and perform simple linear operations on them. In particular, we pool features from layers conv1, block2/unit 4 , block3/unit 6 , block4/unit 3 of the Resnet-50 <ref type="bibr" target="#b22">[23]</ref> network. At each layer we learn linear mappings from the high-dimensional intermediate neuron activation space to the three-dimensional output space required for normal estimation.</p><p>We process these intermediate layers with batch normalisation <ref type="bibr" target="#b24">[25]</ref> so as to bring the intermediate activations into a common scaling. As in <ref type="bibr" target="#b31">[32]</ref> we keep the task-specific memory and computation budget low by applying linear operations within these skip layers, and fuse skip-layer results through additive fusion with learnt weights.</p><p>We appropriately place interpolation layers to ensure that results from different skip layers have commensurate dimensions, while, as in <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b9">10]</ref>, we use atrous convolution to increase the spatial resolution of high-level neurons. Finally, to account for the varying face sizes in the images we employ a 3-scale pyramid of our proposed network where at scales 2 &amp; 3 we down-sample the image by half and a quarter times respectively by using a 2D average pooling operation, similar to <ref type="bibr" target="#b31">[32]</ref>. The outputs of the different resolutions are combined through an additional fusion scheme that delivers the final normal estimates.</p><p>We consider two possible objective functions for the problem of surface normal regression. As our evaluation criterion is to minimise the angular distance between the network predictions f (I) and the available ground truth normals n * it is preferable to use the same loss function to train our fully convolutional network. To ensure that the resulting predictions are valid unit normal vectors we add a further ℓ 2 constraint, after of which we arrive at,</p><formula xml:id="formula_8">L cosine = 1 − i∈M f (I) ⊤ i n * i s.t. f (I) 2 2 = n * 2 2 = 1,</formula><p>where M is a mask containing the image indices corresponding to the visible face region. In addition to the cosine distance, we consider the smooth ℓ 1 -loss <ref type="bibr" target="#b17">[18]</ref> which was used in dense estimation tasks such as surface normal retrieval, segmentation <ref type="bibr" target="#b31">[32]</ref> and object detection <ref type="bibr" target="#b17">[18]</ref>. The ℓ 1 -loss is regarded generally as a robust penaliser which helps to avoid the effect over over-smoothing the dense reconstructions <ref type="bibr" target="#b63">[63]</ref>. To incorporate the smooth ℓ 1 -loss we add again the ℓ 2 constrain for the network predictions,</p><formula xml:id="formula_9">L ℓ1 = i∈M smooth L1 (f (I) i − n * i ) s.t. f (I) 2 2 = n * 2 2 = 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We conducted two sets of experiments. The first set is quantitative experiments on the Photoface database <ref type="bibr" target="#b69">[69]</ref> where we consider as ground-truth the normals produced by the calibrated 4-source Photometric Stereo. For the purposes of this experiment we have withheld 100 subjects from the training set of all algorithms. Due to the lack of "in-the-wild" databases of normals, our second experiment is purely qualitative and includes images obtained from the Helen <ref type="bibr" target="#b32">[33]</ref> and 300W <ref type="bibr" target="#b47">[47]</ref> databases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Setup</head><p>For learning the weights of the network we employ stochastic optimisation with Adam <ref type="bibr" target="#b30">[31]</ref> with the default hyperparameters and one image per mini-batch. We use an initial learning rate of 0.001 with a polynomial decay rule, decreasing the learning rate by a factor of 10 every 10 000 iterations. To initialise the weights of the network we use the ImageNet-pretrained Resnet-50 model and initialise the weights of the new layers with random weights drawn from a Normal distribution. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IMM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Marr Revisited Ours</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Experiments in Photoface</head><p>We compare with an array of state-of-the-art techniques for estimation of normals. Although we are concerned about the problem of surface normal estimation from a single image, we also provide experimental results for two well established techniques for SfS which require many images of the same subject under different illuminations as input <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b57">57,</ref><ref type="bibr" target="#b3">4]</ref>. First is Photometric Stereo with Unknown lighting (PS w/o Light), as porposed by <ref type="bibr" target="#b3">[4]</ref> where we used the images from all four available illuinations to estimate the normals. Second, we applied the SfS method of <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b57">57]</ref> (IMM). The method in <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b57">57]</ref> reconstructs the facial normals from a collection of images of the same object. Hence, they have been applied on all the available data of Photoface to perform normal estimation. We applied the robust version of <ref type="bibr" target="#b27">[28]</ref>, proposed in <ref type="bibr" target="#b57">[57]</ref>, though the database does not contain occlusions and thus the results are expected to be very similar to <ref type="bibr" target="#b27">[28]</ref>. We also compare against a landmark-driven fitting of the state-of-the art large scale 3DMM that we used for synthetic data generation in Section 3.2 (the model can describe both identity and expression variations). Finally, regarding state-of-theart generic networks, we compare against the publicly available pre-trained networks <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b1">2]</ref>. For all methods, we computed the angular error between the ground-truth and the estimated surface normals.</p><p>The results are summarised in Tab. 1. The proposed network has the best performance and achieves the lowest angular error. It is worth noting that the average performance of 3DMM fitting is good because it can capture general facial characteristics, but there are far fewer pixels with errors below 20</p><p>• as 3DMMs lack the ability to capture highfrequency details of the facial surface. It is also worth noting that our method does not require an explicit alignment step, in comparison to both <ref type="bibr" target="#b27">[28]</ref> and the landmark driven 3DMM estimation.   Finally, we performed a series of experiments in order to evaluate the effect (a) of the loss function for the task (i.e., ℓ 1 vs cosine distance) and (b) of the network architecture (i.e., Resnet vs the PixelNet, which is based on VGG <ref type="bibr" target="#b1">[2]</ref>). The experiments are summarised in <ref type="table" target="#tab_1">Tables 2 and 3</ref>. As can be seen there is small difference between the performance of the two losses but the cosine distance is slightly better. Furthermore, the proposed architecture produces better results than PixelNet trained on exactly the same data and using the same loss function. The network generalises well to a diverse set of individuals and expressions. On the left is the original image from the 300W dataset. Next is the 3D shape reconstruction and the sampled texture from the image onto the shape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experiments "in-the-wild" databases</head><p>Since, there is no ground-truth for "in-the-wild" images, we can show only qualitative examples. For these experiments, we used the data provided by the 300W facial landmark localisation challenge <ref type="bibr" target="#b47">[47,</ref><ref type="bibr" target="#b48">48]</ref>. The methods we compare against are the robust version of the Internet Morphable Model (IMM) <ref type="bibr" target="#b27">[28]</ref> proposed in <ref type="bibr" target="#b57">[57]</ref> and, as before, a landmark-based fitting of the large scale 3DMM. The IMM reconstructs a collection of images, hence we have used 3000 "in-the-wild" facial images (the reconstruction process takes around 20 minutes). <ref type="figure" target="#fig_4">Fig. 6</ref> shows some representative reconstruction cases of the proposed network versus IMM and the surface normal estimation network in <ref type="bibr" target="#b1">[2]</ref>. For all surface reconstructions from normals we used the standard Frankot-Chellappa method <ref type="bibr" target="#b13">[14]</ref>.</p><p>It is evident that the proposed network provides very high-quality facial normals, even in images captured in very challenging recording conditions. Visual comparison versus the 3DMM are provided in the supplementary materials, since although the 3DMM can recover the pose and the expression, up to a certain extent, it cannot capture the finegrained details. Finally, <ref type="figure" target="#fig_5">Fig. 7</ref> shows more facial surfaces reconstructed by the proposed network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>We have presented the first, to the best of our knowledge, discriminative methodology tailored to facial surface estimation "in-the-wild". To this end, we capitalised on both the available facial database, as well as on the power of deep convolutional neural networks (DCNNs). We proposed methodologies for preparing training data for the task. We show that the proposed DCNN outperforms both the state-of-the-art facial surface normal estimation techniques, as well as the state-of-the-art pre-trained networks for normal estimation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledgements</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Facial surface normal estimation results from state-of-the-art techniques on the "in-the-wild" image of Fig. 1. Left to right: Proposed, IMM: state-of-the-art SfS technique [57], and generic state-of-the-art network [2].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: From left to right: Photoface, ICT-3DRFE, 3D Morphable Models fitting, Synthesised image using a 3D Morphable model. Below are the associated ground truth normals for each dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Relitting of the of the ICT-3DRFE dataset using the diffuse normals. On the left is the albedo texture, and on the right three examples of the relit texture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 : 1 .</head><label>51</label><figDesc>Figure 5: 1. The generated shape and texture instance using the LSFM morphable model; 2. Addition of expression using the FaceWarehouse expression basis; 3. An image from the series Breaking Bad; 4. The rendered aligned model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Example facial normal estimation and surface reconstruction from the Helen Dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Representative surface reconstruction results from the challenging 300W dataset of "in-the-wild" facial images. The network generalises well to a diverse set of individuals and expressions. On the left is the original image from the 300W dataset. Next is the 3D shape reconstruction and the sampled texture from the image onto the shape.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>G. Trigeorgis was supported by EPSRC DTA award at Im- perial College London. The work of P. Snape was par- tially funded by an EPSRC DTA and by the European Community Horizon 2020 [H2020/2014-2020] under grant agreement no. 688520 (TeSLA). S. Zafeiriou was partially funded by EPSRC Project EP/N007743/1 (FACER2VM). I. Kokkinos was supported by EU Horizon 2020 Project 643666 I-Support. We thank the NVIDIA Corporation for donating a Tesla K40 GPU used in this work.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Angular error for all the tested surface normal es- timation methods. We show the results of the proposed net- work trained using the ℓ 1 loss.</figDesc><table>Name 
Mean ± Std &lt; 20 

• 

&lt; 25 

• 

&lt; 30 

• 

PS w/o Light 42.9 ± 15.2 
1.1% 
13.1% 
35.8% 
IMM [28, 57] 24.2 ± 5.4 
23.5 
64.6% 
88.3% 

3DMM 
26.3 ± 10.2 
4.3% 
56.05% 89.4% 
Marr Rev. [2] 28.3 ± 10.1 
31.8% 
36.5% 
44.4% 
UberNet [32] 29.1 ± 11.5 
30.8% 
35.5% 
55.2% 

Proposed 
22.0 ± 6.3 
36.63% 59.8% 
79.6% 

Loss 
Mean ± Std &lt; 20 

• 

&lt; 25 

• 

&lt; 30 

• 

Cosine Loss 
21.5 ± 6.9 
29.9% 
55.9% 81.5% 

Smooth ℓ 1 Loss 22.0 ± 6.3 
36.63% 59.8% 79.6% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>Angular error for the different loss functions.</figDesc><table>Architecture 
Mean ± Std &lt; 20 

• 

&lt; 25 

• 

&lt; 30 

• 

Resnet + Cosine 
21.5 ± 6.9 
29.9% 
55.9% 81.5% 

Pixelnet + Cosine 23.5 ± 6.3 
35.17% 58.0% 78.2% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Angular error for the different architectures.</figDesc><table></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A linear approach of 3d face shape and texture recovery using a 3d morphable model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Aldrian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Marr Revisited: 2D-3D Alignment Via Surface Normal Prediction. CVPR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Shape, illumination, and reflectance from shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1670" to="1687" />
		</imprint>
	</monogr>
<note type="report_type">T-PAMI</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Photometric stereo with general, unknown lighting. IJCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<title level="m">Lambertian reflectance and linear subspaces. T-PAMI</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="218" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The basrelief ambiguity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="1060" to="1066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A morphable model for the synthesis of 3d faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Blanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<publisher>ACM Press/Addison-Wesley Publishing Co</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="187" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A 3d morphable model learnt from 10,000 faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Booth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roussos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ponniah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dunaway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Facewarehouse: A 3d facial expression database for visual computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">T-VCG</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<idno>abs/1606.00915</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feifei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Numerical methods for shape-from-shading: A new survey with benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Durou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Falcone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sagona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVIU</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="43" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A method for enforcing integrability in shape from shading algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Frankot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="439" to="451" />
		</imprint>
	</monogr>
<note type="report_type">T-PAMI</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Just look at the image: viewpoint-specific surface normal prediction for improved multi-view reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Galliani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">From few to many: Illumination cone models for face recognition under variable lighting and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Georghiades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>T-PAMI</publisher>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="643" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">From few to many: Illumination cone models for face recognition under variable lighting and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Georghiades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>T-PAMI</publisher>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="643" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Face databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of face recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="301" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multi-pie</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Hypercolumns for object segmentation and fine-grained localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.5752</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hypercolumns for object segmentation and fine-grained localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="447" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Shape from shading: A method for obtaining the shape of a smooth opaque object from one view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Horn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970" />
		</imprint>
		<respStmt>
			<orgName>MIT Artificial Intelligence Laboratory</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Large-pose face alignment via CNN-based dense 3D model fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jourabloo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Comprehensive database for facial expression analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FG</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="46" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<title level="m">Internet-based morphable model. ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">3D face reconstruction from a single image using a single reference face shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>T-PAMI</publisher>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="394" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Face reconstruction in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1746" to="1753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Ubernet : Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<idno>abs/1609.02132</idno>
		<imprint>
			<date type="published" when="2007" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Interactive facial feature localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="679" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Intrinsic face image decomposition with human face priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="page" from="218" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Contour and texture analysis for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="27" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Modeling local and global deformations in deep learning: Epitomic convolution, multiple instance learning, and sliding window detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Savalle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="390" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A 3D face model for pose and illumination invariant face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paysan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Knothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Amberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Romdhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AVSS</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="296" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Overview of the face recognition grand challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Scruggs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Worek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="947" to="954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The feret database and evaluation procedure for face-recognition algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wechsler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Rauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="295" to="306" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Analytic pca construction for theoretical analysis of lighting variability in images of a lambertian object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">T-PAMI</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1322" to="1333" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Discriminative shape from shading in uncalibrated illumination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unconstrained 3D face reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2606" to="2615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Adaptive 3D face reconstruction from unconstrained photo collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">300 faces in-the-wild challenge: Database and results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3" to="18" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">300 faces in-the-wild challenge: The first facial landmark Localization Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="397" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Indoor scene segmentation using a structured light sensor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV-W</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="601" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Indoor segmentation and support inference from rgbd images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="746" to="760" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The cmu pose, illumination, and expression (pie) database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bsat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FG</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="46" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Low-dimensional procedure for the characterization of human faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sirovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kirby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOPT</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="519" to="524" />
			<date type="published" when="1987-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Recovering facial shape using a statistical model of surface normal direction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1914" />
			<publisher>T-PAMI</publisher>
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Facial shape-from-shading and recognition using principal geodesic analysis and robust statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="91" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Automatic construction of robust spherical harmonic subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Panagakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="91" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Face flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roussos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Panagakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2993" to="3001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Kernel-pca analysis of surface normals for shape from shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Snape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1059" to="1066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Effect of illumination on automatic expression recognition: a novel 3d relightable facial database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Stratou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Debevec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FG</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="611" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Eigenfaces for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">COGNEURO</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="86" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Designing deep networks for surface normal estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fouhey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Anisotropic huber-l1 optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Werlberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Trobin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Photometric method for determining surface orientation from multiple images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Woodham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">New constraints on data-closeness and needle map consistency for shape-fromshading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Worthington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Hancock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>T-PAMI</publisher>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1250" to="1267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A highresolution 3d dynamic facial expression database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Worm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FG</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">A 3d facial expression database for facial behavior research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Rosato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FG</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="211" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Determining generative models of objects under varying illumination: Shape and albedo from multiple images using svd and integrability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="222" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The photoface database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Atkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Argyriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Petrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Discriminatively trained dense surface normal estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zeisl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-S</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Cryer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<title level="m">Shape-fromshading: a survey. T-PAMI</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="690" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">BP4D-Spontaneous: a high-resolution spontaneous 3D dynamic facial expression database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Canavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IMAVIS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="692" to="706" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Face alignment across large poses: A 3d solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
