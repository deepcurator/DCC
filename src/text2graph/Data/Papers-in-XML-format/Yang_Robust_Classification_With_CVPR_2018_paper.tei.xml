<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T23:15+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust Classification with Convolutional Prototype Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong-Ming</forename><surname>Yang</surname></persName>
							<email>hongming.yang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">NLPR</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu-Yao</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">NLPR</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Yin</surname></persName>
							<email>fyin@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">NLPR</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Lin</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">NLPR</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">CAS Center for Excellence of Brain Science and Intelligence Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Robust Classification with Convolutional Prototype Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Convolutional neural networks (CNNs) have been widely used for image classification. Despite its high accuracies, CNN has been shown to be easily fooled by some adversarial examples, indicating that CNN is not robust enough for pattern classification. In this paper, we argue that the lack of robustness for CNN is caused by the softmax layer, which is a totally discriminative model and based on the assumption of closed world (i.e., with a fixed number of categories). To improve the robustness, we propose a novel learning framework called convolutional prototype learning (CPL). The advantage of using prototypes is that it can well handle the open world recognition problem and therefore improve the robustness. Under the framework of C-PL, we design multiple classification criteria to train the network. Moreover, a prototype loss (PL) is proposed as a regularization to improve the intra-class compactness of the feature representation, which can be viewed as a generative model based on the Gaussian assumption of different classes. Experiments on several datasets demonstrate that CPL can achieve comparable or even better results than traditional CNN, and from the robustness perspective, C-PL shows great advantages for both the rejection and incremental category learning tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, convolutional neural networks <ref type="bibr" target="#b15">[16]</ref> (CNNs) have achieved great success for pattern recognition and computer vision, leading to important progress in a variety of tasks, like image classification <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b33">34]</ref>, object detection <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b8">9]</ref>, instance segmentation <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b5">6]</ref> and so on.</p><p>Despite the success of CNN, it still suffer from some serious problems. One example is the existence of adversarial samples <ref type="bibr" target="#b36">[37]</ref>, when we add small noises or make some small changes to the initial samples, CNN will give different predictions for these samples with high confidence, al- though visually we can hardly find any significant changes in the images. Another example is the rejection ability of CNN, when feed a sample from an unseen class to CN-N, it will still allocate the sample to a known class with high confidence. These two phenomena indicate that CNN is not robust, though it can achieve human-level or even better accuracy on some specific datasets, its performance will degenerate obviously in the complex scenes of the reality. This greatly limits the application of CNN in real worlds. The main reasons for these problems include two aspects: First, CNN is a purely discriminative model, it essentially learns a partition of the "whole" feature space, therefore, the samples from unseen classes are still predicted to some specific regions under the partition, and CNN still views these samples as some known classes with high confidence. This explains why the rejection ability of CNN is poor; Second, from the perspective of representation learning, the learned representation of CNN is linear separable, see <ref type="figure" target="#fig_0">Fig. 1</ref> for an illustration, and under this kind of representation, the interclass distance is sometimes even smaller than the intra-class distance, this significantly reduces the robustness of CNN in real and complicated environments.</p><p>Several methods have been proposed to improve the ro-bustness of CNN and most of them concentrate on designing better loss functions. <ref type="bibr" target="#b35">[36]</ref> and <ref type="bibr" target="#b32">[33]</ref> proposed the contrastive loss and triplet loss to learn a more robust feature representation, in which the input pairs and triplets need to be carefully selected from the training data to ensure the convergence and stability. <ref type="bibr" target="#b37">[38]</ref> proposed the center loss to improve the performance of softmax-based CNN, however, the centers can not be learned jointly with the CNN and are only updated according to some pre-defined rules rather than learned directly from data. Our CPL is more general than the center loss, since we totally abandon softmax layer and all the prototypes are learned automatically from data. Moreover, previous work of <ref type="bibr" target="#b25">[26]</ref> and <ref type="bibr" target="#b24">[25]</ref> also made improvements and extensions for the softmax based loss but they still kept the softmax layer with the traditional framework of CNN for classification.</p><p>In this paper, we propose a novel framework called convolutional prototype learning (CPL) for image classification. In the bottom of CPL, the convolutional layers are used to extract discriminative features just like traditional CNN, but in the top of CPL we assign multiple prototypes to represent different classes. The classification is simply implemented by finding the nearest prototype (using Euclidean distance) in the feature space. We design multiple loss functions for this framework, making the CNN feature extractor and the prototypes being learned jointly from the raw data. Therefore, the whole framework can be trained efficiently and effectively. Experiments on several datasets demonstrate that the CPL framework can achieve comparable or even better classification accuracies compared with traditional CNN models.</p><p>Benefited from the prototype-based decision function, a natural prototype loss (PL) can be added to our CPL framework, to pull the feature vector closer to their corresponding prototypes (genuine class representation). The PL is akin to the maximum likelihood (ML) regularization proposed in <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b21">22]</ref>. On one hand, it acts like a regularizer, which can prevents the model form over-fitting and improves the performance of CPL. On the other hand, it can also improves the intra-class compactness in feature representation. Therefore, the final learned representation is intra-class compact and inter-class separable, which makes the representation more discriminative and robust. From the perspective of probability, our CPL and PL framework essentially extract, transform, and model the data of each class as a Gaussian mixture distribution and the prototypes act as the means of Gaussian components for each class, this enables integrating probabilistic methods such as Bayesian models into our framework. Compared with the traditional CNN framework, we do not make partition for the "whole" feature space, but project the samples to some specific regions of the feature space (near the prototypes), thus our model is more robust to samples from unseen classes and more suitable for rejection. CPL can also be viewed as a hybrid discriminative and generative model (like the discriminative density model in <ref type="bibr" target="#b22">[23]</ref>) which will lead to better generalization performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related works</head><p>In this section, we describe related works from two aspects: robust representation learning and prototype learning. Most recent methods concentrate on modifying or proposing new loss functions to learn discriminative and robust representations. Among these methods, <ref type="bibr" target="#b35">[36]</ref> combined the cross entropy loss and contrastive loss <ref type="bibr" target="#b4">[5]</ref> to train the CNN, the cross entropy loss can increase the inter-personal variations while the contrastive loss can reduce the intrapersonal variations, and both losses guide the CNN to learn more discriminative representations. <ref type="bibr" target="#b32">[33]</ref> designed a triplet loss for CNN to learn representations in a compact Euclidean space where distances directly correspond to a measure of similarity, and the learned representation performs well on several tasks including recognition, verification, and clustering. <ref type="bibr" target="#b37">[38]</ref> proposed a center loss and combine it with cross entropy loss to train the CNN for learning more discriminative features, and they also propose a mini-batch based update method for the centers, which was proved to be useful for face recognition and verification. <ref type="bibr" target="#b25">[26]</ref> proposed a generalized large-margin softmax loss which explicitly encourages intra-class compactness and inter-class separability between learned representations, making the representation more discriminative and robust. <ref type="bibr" target="#b24">[25]</ref> further proposed a angular soft-max loss, which can ensure the learned representations more angularly discriminative, and this method was proved to be efficient under open-set protocols.</p><p>Prototype learning is a classical and representative method in patter recognition society. The earliest prototype learning method is k-nearest-neighbor (K-NN). In order to reduce the heavy burden of storages space and computation requirement of K-NN, an improvement called learning vector quantization (LVQ) is proposed <ref type="bibr" target="#b11">[12]</ref>. The LVQ has been studied in many works and it has a lot of variations. According to the updating methods of the prototypes, we can classify the LVQ methods into two main categories. The first category concentrates on designing suitable updating conditions and rules to learn the prototypes, and the representing works include <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20]</ref>. The other category learns the prototypes in a parameter optimization way, by defining loss functions with regard to the prototypes and learning the prototypes through optimizing the loss functions. The representative methods include <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b1">2]</ref>. A detailed review and evaluation of the prototype based learning methods can be found in <ref type="bibr" target="#b20">[21]</ref>. Previous prototype learning methods are mainly based on hand-designed features and they were widely used in different pattern recognition tasks be- fore the arrival of CNN. To the best of our knowledge, this is the first work on combining the prototype based classifiers with deep convolutional neural networks for both high accuracy and robust pattern classification.</p><p>3. Convolutional prototype learning</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Architecture of the framework</head><p>Compared with hand-designed features, the features automatically learned from data usually perform better for classification. Thus, we use a CNN as feature extractor in our framework, which is denoted as f (x; θ), x and θ denote the raw input and parameters of the CNN respectively. Different from the traditional CNN which use softmax layer for linear classification on the learned features, we maintain and learn several prototypes on the features for each class and use prototype matching for classification. The prototypes are denoted as m ij where i ∈ {1, 2, ..., C} represents the index of the classes and j ∈ {1, 2, ..., K} represents the index of the prototypes in each class. Here we assume each class having equal number of K prototypes and this assumption can be easily relaxed in real application.</p><p>The CNN feature extractor f (x; θ) and the prototypes {m ij } are jointly trained from data. In the classification stage, we classify the objects by prototype matching, i.e., we find the nearest prototype according the Euclidean distance and assign the class of this prototype to the particular object. A graphic description of our framework can be seen in <ref type="figure" target="#fig_1">Fig. 2.</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Feedforward for prediction</head><p>Given an input pattern x, we first get its abstract representation by the CNN feature extractor, then we compare the abstract feature with all prototypes and classify it to the category where the nearest prototype belongs to:</p><formula xml:id="formula_0">x ∈ class arg C max i=1 g i (x)<label>(1)</label></formula><p>where g i (x) is the discriminant function for class i:</p><formula xml:id="formula_1">g i (x) = − K min j=1 f (x; θ) − m ij 2 2<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Backward for training</head><p>The trainable parameters in our framework are composed by two parts. One is the parameters of the CNN extractor, which is denoted as θ; the other is the prototypes in each class, which is denoted as M = {m ij |i = 1, ..., C; j = 1, ..., K}. The parameters of θ and M should be trained jointly in an end-to-end manner, and this can make them cooperate better with each other, which is beneficial for the performance of classification. To train the framework, we should first define the corresponding loss function. Besides, the loss function should be derivable with respect to θ and M as well. The loss function should also be closely related to the classification accuracy. In following subsections, we introduce multiple loss functions designed to train CPL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Minimum classification error loss (MCE)</head><p>Minimum classification error (MCE) loss is firstly proposed by <ref type="bibr" target="#b29">[30]</ref>. We modify this loss function and make it applicable in our framework. In prototype learning, the discriminant function is defined as Eq. 2. Then the misclassification measure of a sample from class y is given by:</p><formula xml:id="formula_2">µ y (x) = −g y (x) +   1 C − 1 j =y g j (x) η   1/η (3)</formula><p>when η approaches infinity, the misclassification measure becomes:</p><formula xml:id="formula_3">µ y (x) = −g y (x) + g r (x)<label>(4)</label></formula><p>where g r (x) is the most competitive class, i.e.,</p><formula xml:id="formula_4">g r (x) = max k =y g k (x)<label>(5)</label></formula><p>then we can rewritten the misclassification measure as</p><formula xml:id="formula_5">µ y (x) = f (x) − m yi 2 2 − f (x) − m rj 2 2<label>(6)</label></formula><p>where m yi is the closest prototype from the genuine class while m rj is the closest prototype from incorrect classes. Then, the loss function is defined as:</p><formula xml:id="formula_6">l((x, y); θ, M ) = 1 1 + e −ξµy .<label>(7)</label></formula><p>From the definition of the loss function, we can see that during minimizing the loss function, the µ y is also minimized. This means f (x) − m yi 2 2 is decreased and f (x) − m rj 2 2 is increased, which acts like pull the feature closer to its class but push it away from the other classes. Thus, the training can help the framework to achieve better classification performance on the training samples.</p><p>The MCE loss is derivable with regard to M and f , the derivatives can be calculated as:</p><formula xml:id="formula_7">∂l ∂f = 2ξl(1 − l)(m rj − m yi ). (8) ∂l ∂m yi = 2ξl(1 − l)(m yi − f (x)) (9) ∂l ∂m rj = 2ξl(1 − l)(f (x) − m rj )<label>(10)</label></formula><p>and for the remainder prototypes, we have:</p><formula xml:id="formula_8">∂l ∂m = 0.<label>(11)</label></formula><p>Note that f is the output of the CNN feature extractor, according to the error back propagation algorithm, the derivatives with regard to the parameters of CNN can be calculated start from ∂l/∂f . Given the gradients of the loss function, the gradient based optimization methods can be used to update the whole framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Margin based classification loss (MCL)</head><p>For a training sample (x, y), let m yi and m rj denote the closest prototypes from the correct class and the most competitive class respectively. If the sample is classified cor-</p><formula xml:id="formula_9">rectly, then d(f (x), m yi ) &lt; d(f (x)</formula><p>, m rj ) and we think the loss should be 0. If the sample is misclassified, then</p><formula xml:id="formula_10">d(f (x), m yi ) &gt; d(f (x)</formula><p>, m rj ) and we think the loss exists in this situation. Naturally, the loss now can be defined</p><formula xml:id="formula_11">as d(f (x), m yi ) − d(f (x), m rj ).</formula><p>Putting the two situations together, we can define the loss function as:</p><formula xml:id="formula_12">l((x, y); θ, M ) = [d(f (x), m yi ) − d(f (x), m rj )] + (12)</formula><p>To increase the classification ability of the framework, a margin is added to the loss function 12, leading to the new margin based classification loss (MCL) function, which is denoted as:</p><formula xml:id="formula_13">l((x, y); θ, M ) = [d(f (x), m yi ) − d(f (x), m rj ) + m] +<label>(13)</label></formula><p>where m is a positive number and acts as the margin. Compared with Eq. 12, MCL is stricter, it penalize the framework even though it classifies some sample correctly (within the margin). Thus, it can increase the discriminative ability of the framework.</p><p>In order to apply MCL successfully, the margin m should be carefully selected and it should have same scale</p><formula xml:id="formula_14">with d(f (x), m yi ) − d(f (x), m rj ). However, the scale of d(f (x), m yi ) − d(f (x)</formula><p>, m rj ) is unknown and we have to compute and estimate it from the training data. To avoid this problem, a generalized margin based classification loss (GMCL) function is proposed and defined as:</p><formula xml:id="formula_15">l((x, y); θ, M ) = d(f (x), m yi ) − d(f (x), m rj ) d(f (x), m yi ) + d(f (x), m rj ) + m +<label>(14)</label></formula><p>In Eq. 14,</p><formula xml:id="formula_16">−1 &lt; d(f (x),myi)−d(f (x),mrj ) d(f (x)</formula><p>,myi)+d(f (x),mrj ) &lt; 1, thus we can simply choose margin m from (0, 1).</p><p>Both MCL and GMCL are derivable with regard to M and f , for MCL, the gradients can be computed by:</p><formula xml:id="formula_17">∂l ∂f = 2(m rj − m yi ) l &gt; 0 0 l ≤ 0 (15) ∂l ∂m yi = 2(m yi − f ) l &gt; 0 0 l ≤ 0 (16) ∂l ∂m rj = 2(f − m rj ) l &gt; 0 0 l ≤ 0<label>(17)</label></formula><p>for other prototypes, we have</p><formula xml:id="formula_18">∂l/∂m ij = 0<label>(18)</label></formula><p>Similarly, the gradients of GMCL can also be computed directly and we do not list the equations any more. Equally, the gradients of the loss function with regard to θ can also be computed by the error back propagation algorithm beginning from ∂l/∂f . In MCL and GMCL, the framework is updated only when the loss exists and during the updating, only two prototypes are trained but the other prototypes are kept unchanged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Distance based cross entropy loss (DCE)</head><p>In our CPL framework, the distance can be used to measure the similarity between the samples and the prototypes. Thus, the probability of a sample (x, y) belonging to the prototype m ij can be measured by the distance between them:</p><formula xml:id="formula_19">p(x ∈ m ij |x) ∝ − f (x) − m ij 2 2 .<label>(19)</label></formula><p>To satisfy the non-negative and sum-to-one properties of the probability, we further define the probability p(x ∈ m ij |x) as:</p><formula xml:id="formula_20">p(x ∈ m ij |x) = e −γd(f (x),mij ) C k=1 K l=1 e −γd(f (x),m kl )<label>(20)</label></formula><p>where</p><formula xml:id="formula_21">d(f (x), m ij ) = f (x) − m ij 2 2</formula><p>represents the distance between f (x) and m ij . γ is a hyper-parameter that control the hardness of probability assignment. Given the definition of p(x ∈ m ij |x), we can further define the probability of p(y|x) as:</p><formula xml:id="formula_22">p(y|x) = K j=1 p(x ∈ m yj |x).<label>(21)</label></formula><p>Based on the probability of p(y|x), we can define the cross entropy (CE) loss under our framework as:</p><formula xml:id="formula_23">l((x, y); θ, M ) = −logp(y|x).<label>(22)</label></formula><p>This loss function is defined based on the distance, to distinguish it from the traditional cross entropy loss, we call it distance based cross entropy (DCE) loss. From Eq. 20, 21 and 22, we can see that minimizing the loss function essentially means decreasing the distance between the samples with the prototypes which come from the genuine class of the samples. Obviously, the DCE is also derivable with regard to M and f , here we don't list the equation of the corresponding gradients any more. Similarly, the derivatives with regard to the parameters of CNN can also be calculated starting from ∂l/∂f by the chain rule. Compared with MCL and GM-CL, DCE updates all the prototypes every time during the training, thus it converges faster than the MCL and GMCL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Generalized CPL with prototype loss</head><p>The loss functions defined in section 3.3 are used as measurements of classification accuracy, and by minimizing these losses, we can train the model to classify the data correctly. However, directly minimizing the classification loss may lead to over-fitting. In light of this, we propose a new prototype loss (PL) as a regularization, which acts like a generative model to improve the generalization performance of CPL.</p><p>From the prediction function defined in Eq. 1, we can derive the decision boundary of the CPL:</p><formula xml:id="formula_24">f − m ij 2 2 = f − m kl 2 2 (23) 2f · (m kl − m ij ) + m ij 2 2 − m kl 2 2 = 0.<label>(24)</label></formula><p>We can see that the resulted decision boundary is still linear. Like traditional CNN framework for classification, the CPL still separates the whole feature space and the learned representation is still linearly separable. As stated before, this kind of framework is not robust, it can not reject the samples from unseen classes and can not be extended to new classes conveniently. To overcome this problem, a new loss function called prototype loss (PL) is added in our framework, which is defined as:</p><formula xml:id="formula_25">pl((x, y); θ, M ) = f (x) − m yj 2 2<label>(25)</label></formula><p>where m yj is the closest prototype with f (x) from the corresponding class y. The prototype loss can be combined with the classification loss defined in section 3.3 to train the model. Then the total loss can be defined as:</p><p>loss((x, y); θ, M ) = l((x, y); θ, M ) + λpl((x, y); θ, M ) (26) where λ is a hyper-parameter which control the weight of prototype loss. The PL can also be viewed as the maximumlikelihood (ML) regularization <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b21">22]</ref> which is widely used in pattern recognition <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19]</ref>. PL can further boost the performance of CPL, because: (1) PL pull the features of samples close to their corresponding prototypes, making the features within the same class more compact, this can implicitly increase the distance between the classes, which is beneficial for classification; (2) the classification loss stresses the separation property of the representation and the prototype loss stresses the compactness property of the representation, by combining them together, we can learn intra-class compact and inter-class separable representations, which are more robust and more appropriate for rejection and open set problems. We denote CPL equipped with PL as generalized convolutional prototype learning (GCPL).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Application of GCPL</head><p>Besides classification, GCPL can also be used for rejection and class-incremental learning. In this paper, we did not invent new rejection and class-incremental learning methods, but only show that our framework is suitable for these two tasks. Most rejection strategies are based on the probabilities (confidences) produced by the softmax layer of CNN model. In our framework, we can also obtain classification probabilities by Eq. 21, so the same strategies can also be used in our framework. The distance is also a meaningful measurement for the classification confidence in our framework, thus the same strategies can also be implemented based on the distance outputted by GCPL.</p><p>For class-incremental learning, we only consider the most general case. That is, given a trained framework and some samples from a new class, we should extend the framework to recognize the new class correctly and keep the accuracy on the old classes. In GCPL framework, the learned representations have better clustering property, for samples of the new class, the resulted features are also compact. Thus we can cluster the features of new class or use the mean of these features as the prototypes for the new class. Therefore, the framework can be expanded to the new class easily. In the following experimental section, we will show that this approach is very effective for classincremental learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experiments and analysis on MNIST [17]</head><p>In this experiment, the architecture of CNN feature extractor is the same as the network used in <ref type="bibr" target="#b37">[38]</ref> with the ReLU activation function. The output of the CNN feature vector is set to be two, thus we can directly plot the features on the 2-D surface for visualization. We maintain one prototype in each class and train the framework under the DCE loss and DCE+PL loss respectively. Meanwhile, we also give the accuracy of the traditional softmax based CN-N framework under the same architecture as <ref type="bibr" target="#b37">[38]</ref>  The final results can be seen in table 1 and <ref type="figure" target="#fig_2">Fig. 3</ref>. From table 1, we can see that our new proposed CPL framework can achieve comparable performance with traditional softmax based CNN under the same structure. Moreover, by cooperating with PL, our GCPL can achieve even better results. This demonstrates that the PL, which acts as an implicit regularization, is beneficial for classification as well. Meanwhile, we can also see that the test accuracy is not sensitive to the parameter λ, the change of λ did not greatly impact the results. From <ref type="figure" target="#fig_2">Fig. 3 (a)</ref>, we can see that when only use the classification loss, the resulted representations are still linear separable, this demonstrates that our analysis in section 3.4 is correct. <ref type="figure" target="#fig_2">From Fig. 3 (b)</ref> to (d), we can see the learned representations under GCPL framework are really inter-class separable and intra-class compact. With the increasing of the weight λ on PL loss, the learned representations within the same class become more and more compact. This demonstrate our GCPL framework can really learn robust and discriminative representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Experiments and analysis on CIFAR-10</head><p>We realized several CNN structures on CIFAR-10 <ref type="bibr" target="#b13">[14]</ref>, including the model C appeared in <ref type="bibr" target="#b34">[35]</ref>, a modified version of model C that adds batch normalization layers after each convolutional and fully connected layers in model C, residual net <ref type="bibr" target="#b19">20</ref> and residual net 32 in <ref type="bibr" target="#b7">[8]</ref>. Then we compare the CNN structure soft-max CPL GCPL model C <ref type="bibr" target="#b34">[35]</ref> 90.26 <ref type="bibr" target="#b34">[35]</ref>   <ref type="table">Table 3</ref>. The accuracy of GCPL on OLHWDB dataset performance of the traditional softmax based classification, CPL, and GCPL methods under these CNN structures. In all experiments, we maintain one prototype for each class and the prototypes are initialized as zero vectors. The images data are whitened and contrast normalized following <ref type="bibr" target="#b3">[4]</ref>. The experimental results are shown in table 2.</p><p>From table 2, we can see that the proposed CPL framework can achieve comparable or even better results than the traditional softmax based classification method under different network structures. This further demonstrates the efficiency and generality of the proposed framework. Besides, the GCPL framework, which has an additional prototype loss during training, performs best in all experiments on CIFAR-10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experiments and analysis on OLHWDB</head><p>Online handwriting database (OLHWDB <ref type="bibr" target="#b23">[24]</ref>) is a large scale Chinese handwriting dataset. Following the settings in <ref type="bibr" target="#b39">[40]</ref> and <ref type="bibr" target="#b38">[39]</ref>, the training and test datasets include 2,697,673 and 224,590 samples respectively, which are come from 3755 classes. We use the same CNN structure as <ref type="bibr" target="#b39">[40]</ref> and make little modifications with batch normalization and ReLU to improve training process. We mainly test the GCPL framework on this dataset and adopt different classification loss functions to study their influence on the performance. We maintain only one prototype for each class and the prototypes are initialized as the mean of training features in the corresponding classes. We use the same data pre-processing method as <ref type="bibr" target="#b39">[40]</ref>. The experimental results are listed in table 3. From table 3, we can see that our framework also performs well or even better on large scale classification problems, which again demonstrate its efficiency and generality.</p><p>Note that our purpose is not to achieve significantly better accuracy than previous softmax-based CNN model, we only want to show that, from the accuracy perspective, our framework can match or work slightly better than tradition-  <ref type="table">Table 4</ref>. The tradeoff between acceptance rate AR (%) and rejection rate RR (%) for different methods.</p><p>al CNN model. The advantage of our model in another perspective is that it can significantly improve the robustness of pattern recognition. In following subsections, we will show this from the viewpoints of rejection and class-incremental learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Experiments for rejection</head><p>To test the robustness of our GCPL framework, we further conduct experiments for rejection. We firstly train a network on MNIST training set. To evaluate its robustness, we use two test sets (MNIST and CIFAR-10 test sets) for this network. The CIFAR-10 test samples are not digits, and therefore, they should be viewed as outliers and then be rejected by this network. At the same time, the samples from the MNIST test set should still be accepted since they are from the same domain as the training data. Actually, the rejection and acceptance performance are closely coupled, we can only get a tradeoff between them.</p><p>To fairly evaluate the performance, we use two measurements of acceptance rate (AR) and rejection rate (RR). AR denotes the percentage of accepted samples in MNIST test set (how many MNIST samples have been accepted), while RR denotes the percentage of rejected samples in CIFAR-10 test set (how many CIFAR-10 samples have been rejected). The higher of these two measurements, the better of the model in robustness. We adopt the most frequently used threshold-based rejection strategy, i.e., if the output confidence for a sample is larger than the pre-defined threshold, then it will be accepted, otherwise it will be rejected. The confidence can be obtained by the output probability or distance in GCPL (section 4). Different from the probability, the smaller distance represents larger confidence. We use the same structure of CNN feature extractor as section 5.1. For comparison, we also test the rejection performance of traditional softmax based framework under the same CN-N structure. The results are showed in table 4. Note these results are obtained by using different (smoothly changed) thresholds to give the AR-RR tradeoffs.</p><p>From table 4, we can see that the softmax-based model is confused by the MNIST and CIFAR-10 samples, the high AR and high RR is not able to coexist. This explains that the softmax-based model is not robust in outlier detection. Differently, our GCPL model can achieve better rejection performance and meantime keep satisfactory acceptance rate. For example, while over 99% CIFAR-10 samples being rejected, we can still keep over 99% MNIST samples accepted. This is a significant advantage compared with softmax based approach, which demonstrates the robustness of the GCPL framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Experiments for class-incremental learning</head><p>We conduct experiments on MNIST and CIFAR dataset to demonstrate the superiority of GCPL framework for class-incremental learning. We treat all MNIST samples (from class 0 to 9) as the known class data and choose one class from CIFAR-10 as the new class (which should be learned incrementally). We use the same network structure as described in section 5.1 and train the GCPL on the MNIST training set, then we feed the test data from both known and unknown classes to the trained GCPL and obtain their representations, the results are shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. From <ref type="figure" target="#fig_3">Fig. 4</ref>, we can find that the learned representations for both known and unknown (new) classes are intra-class compact and inter-class separable, this again demonstrates the robustness of the GCPL framework. Based on such representations, we can simply use the mean of the training data from the new class as the prototype for the new class, then we can directly extend the GCPL to make predictions for both the new class and the previous classes. To evaluate the accuracy of GCPL for class-incremental learning, we further give the accuracy of the extended GCPL on the test new class ID (CIFAR) test accuracy <ref type="bibr">(11-</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.">Experiments with small sample size</head><p>Another aspect of robust classification is the ability to deal with small sample size (SSS). To further demonstrate the robustness of GCPL, we conduct experiments under the condition of SSS. We use different number (percentages) of samples in MNIST training set to train the models and then observe their accuracy on the MNIST test set. For GC-PL, We use the same net structure and training settings as described in section 5.1, the weight λ for prototype loss is 0.001. For comparison, we also give the test accuracy of the traditional softmax-based CNN framework under the same architecture and training data. We repeat the experiments for five times and show the statistical results in  From table 6, we can find that the decreasing of training samples has less impact on the performance of GCPL. Compared with the softmax-based framework, the performance of GCPL declines much slower when the sample size is reduced. In particular, when training with very small number of training samples (e.g., with only 5% or 3% training samples), the test accuracies for softmax-based framework are very low (with large variance), which demonstrates that the softmax-based model is not robust for SSS problem. On the contrary, under the same situation, the GCPL is still very effective for different sizes of training samples. GCPL not only achieves much higher accuracy but also shows more stable results with smaller variances. This again demonstrates the robustness of GCPL in dealing with SSS problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7.">Experiments with multiple prototypes</head><p>In all previous experiments, we set the number of prototypes K in each class as 1. In this section, we adopt different values for K and investigate its effect on the classification performance. We use model C (described in section 5.2) with DCE loss, and conduct the experiment on CIFAR-10 dataset. For different K, we use the same settings for the hyper-parameters during the training, the results are shown in From table 7, we can see that more prototypes didn't lead to better results. Actually, CNN is very powerful for feature extraction, even though the initial intra-class distribution may be very complex, after CNN transformation, it can still be well modeled with a single Gaussian distribution (a single prototype). However, in more complicated scenarios, where the data distributions are difficult to model, more prototypes may be beneficial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper proposed a convolutional prototype learning (CPL) framework for pattern recognition. Different from the softmax-based models, CPL directly learn multiple prototypes (in convolutional feature space) for each class and then use prototype matching for decision making. CPL can achieve comparable or even better classification accuracy than softmax-based CNN models. To further improve the robustness, we propose a prototype loss (PL) to increase the intra-class compactness, resulting in a generalized CPL (GCPL) model. The GCPL has great advantage compared with traditional CNN models in the perspectives of outlier rejection and class-incremental learning. In future, we will try to conduct more detailed experiments to evaluate other properties of GCPL such as the adaptation ability in changing environment, dealing with weakly labeled data, and so on.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Feature representation learned by traditional CNN model on MNIST. Different colors represent different classes. It is shown that the inter-class variation is even smaller than the intra-class variation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. An illustration of convolutional prototype learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The learned representations of CPL and GCPL on M-NIST. Different colors represent different classes the initial learning rate as 0.001, the batch size as 50, and the hyper-parameter γ in DCE as 1.0 during the training. The final results can be seen in table 1 and Fig. 3. From table 1, we can see that our new proposed CPL framework can achieve comparable performance with traditional softmax based CNN under the same structure. Moreover, by cooperating with PL, our GCPL can achieve even better results. This demonstrates that the PL, which acts as an implicit regularization, is beneficial for classification as well. Meanwhile, we can also see that the test accuracy is not sensitive to the parameter λ, the change of λ did not greatly impact the results. From Fig. 3 (a), we can see that when only use the classification loss, the resulted representations are still linear separable, this demonstrates that our analysis in section 3.4 is correct. From Fig. 3 (b) to (d), we can see the learned representations under GCPL framework are really inter-class separable and intra-class compact. With the increasing of the weight λ on PL loss, the learned representations within the same class become more and more compact. This demonstrate our GCPL framework can really learn robust and discriminative representations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The learned representations for both known and unknown (new) classes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>Table 5. Accuracy (%) of GCPL on test samples from both known and new classes samples from both known and new classes (total 11 classes) in table 5. From table 5, we can see the GCPL still keep- s high performance when extended to the new class. Note that in this class-incremental learning process, we did not re-train any part of the model, and due to the advantage of prototype-based decision making, we can directly add a new prototype to represent the new class. This demonstrates the advantage of GCLP for class-incremental learning.</figDesc><table>class) 
0 
99.23 
1 
99.23 
3 
99.24 
5 
99.23 
6 
99.24 
7 
99.22 
8 
99.20 
9 
99.23 
without new class 
99.27 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>table 6 .</head><label>6</label><figDesc></figDesc><table>sample size (%) 
soft-max 
GCPL 
100 
99.08 ± 0.10 99.33 ± 0.10 
50 
98.07 ± 0.39 99.12 ± 0.10 
30 
92.68 ± 4.52 98.89 ± 0.10 
10 
86.12 ± 6.00 97.80 ± 0.22 
5 
73.95 ± 6.10 96.44 ± 0.40 
3 
50.79 ± 17.44 94.90 ± 0.58 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 6 .</head><label>6</label><figDesc>Test accuracy (%) under different percentages of training samples.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>table 7 .</head><label>7</label><figDesc>%) 90.70 90.40 90.37 90.67 90.46 Table 7. Test accuracy (%) under different values of K.</figDesc><table>K 
1 
2 
3 
4 
5 
accuracy (</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been supported by the National Natural Science Foundation of China (NSFC) Grants 61721004 and 61633021, and NVIDIA NVAIL program.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">R-FCN: Object detection via region-based fully convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="379" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Finding prototypes for nearest neighbour classification by means of gradient descent and deterministic annealing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Decaestecker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="281" to="288" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Adaptive nearest neighbor pattern classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sitte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="318" to="340" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wardefarley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Maxout networks. In ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<title level="m">Mask R-CNN. In ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep direct regression for multi-oriented scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="745" to="753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A simulated annealing approach to construct optimized prototypes for nearestneighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Shie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">I</forename><surname>Shyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Y</forename><surname>Tsay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page">483</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Regularized margin-based conditional log-likelihood loss for prototype learning. Pattern Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-B</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="2428" to="2438" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The self-organizing map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1C3</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improved versions of learning vector quantization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kohonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNN</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="545" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Handwritten digit recognition with a back-propagation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Habbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="396" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Optimal design of reference models for large-set handwritten character recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1267" to="1274" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">One-vs-all training of prototype classifier for pattern classification and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3328" to="3331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">High accuracy handwritten Chinese character recognition by improved feature matching method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDAR</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1033" to="1037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Evaluation of prototype learning algorithms for nearest-neighbor classifier in application to handwritten character recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="601" to="615" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Discriminative learning quadratic discriminant function for handwriting recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sako</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fujisawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="430" to="444" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Effects of classifier structures and training regimes on integrated segmentation and recognition of handwritten numeral strings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sako</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fujisawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1395" to="1407" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">CASIA online and offline Chinese handwriting databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDAR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="37" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sphereface: Deep hypersphere embedding for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page" from="6738" to="6746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Large-margin softmax loss for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A global optimization technique for statistical classifier design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gersho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Processing</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3108" to="3122" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to segment object candidates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Discriminative learning for minimization error classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-H</forename><forename type="middle">J S</forename><surname>Katagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3043" to="3054" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generalized learning vector quantization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">8227</biblScope>
			<biblScope unit="page" from="19" to="26" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A formulation of learning vector quantization using a new misclassification measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yamada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="322" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Striving for simplicity: The all convolutional net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep learning face representation by joint identification-verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A discriminative feature learning approach for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="499" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Icdar 2013 Chinese handwriting recognition competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDAR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1464" to="1470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Online and offline handwritten Chinese character recognition: A comprehensive study and new benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="issue">61</biblScope>
			<biblScope unit="page" from="348" to="360" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
