<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:18+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Spread-out Local Feature Descriptors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Zhang</surname></persName>
							<email>xu.zhang@columbia.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
							<email>felixyu@google.com</email>
							<affiliation key="aff1">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
							<email>sanjivk@google.com</email>
							<affiliation key="aff1">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Fu</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Spread-out Local Feature Descriptors</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Computing image patch correspondences based on local descriptor matching is important in many computer vision problems such as image retrieval, wide baseline stereo matching and panorama building. The main challenge of finding correct correspondences is that the appearance of the image patches varies due to changes of scaling, view angle, illumination and imaging condition etc. Designing local feature descriptors that are invariant to such changes is therefore essential. Efforts of local descriptor fall into two categories: hand-crafted and learning-based. Handcrafted descriptors try to achieve the invariance by manually selected rules. One of the most popular hand-crafted descriptors is SIFT <ref type="bibr" target="#b9">[10]</ref> and its variants <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b23">24]</ref>, which are widely used in the computer vision community. The main issue of the hand-crafted descriptors is that they can only consider a limited predefined set of variations.</p><p>One approach to take all variations into consideration is learning local descriptors from a large patch correspondence dataset <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b19">20]</ref>. The state-of-the-art descriptor learning methods are based on neural networks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b25">26]</ref>. In addition to the model itself, the most important aspect of learning-based method is the loss function which defines the goal of descriptor learning: matching patches should be close in the descriptor space, while the non-matching patches should be far-away <ref type="bibr" target="#b0">1</ref> . The pairwise loss and triplet loss (Section 2) are the commonly used loss functions to achieve the desired properties. Recently, there are a lot of works such as smart sampling strategies <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b11">12]</ref> and structured loss <ref type="bibr" target="#b22">[23]</ref> that improve the triplet loss. In particular, Kumar et al. <ref type="bibr" target="#b7">[8]</ref> propose to use a global loss to separate the distance distributions of the matching pairs and nonmatching pairs. This approach avoids the design of complicated sampling strategies and is also shown to provide results that are robust to training with outliers.</p><p>The success of global loss motivates us to further explore the desired properties of the descriptor space and design a robust regularization term based on these properties. Our main idea is that the good local feature descriptors should be sufficiently "spread-out" in the descriptor space in order to fully utilize the expressive power of the space. Specifically, we introduce a regularization term that induces the spread-out condition, inspired by the properties of the uniform distribution on unit sphere (Section 3). The regularization can be easily used to improve all methods where pairwise or triplet loss is used. We show that the proposed regularization with triplet loss, without hard sample mining, outperforms all the Euclidean distance based descriptors by a large margin (Section 5). In particular, it outperforms the global loss <ref type="bibr" target="#b7">[8]</ref> in the patch pair classification task. As an extension of descriptor learning, we show that the proposed regularization can also be used in improving image-level deep feature embedding (Section 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head><p>We begin by reviewing some commonly used loss functions in learning local feature descriptors. Let X = {x 1 , . . . , x N }, x i ∈ R m×n denote a set of N training patches with m × n pixels. {y ij , 1 ≤ i, j ≤ N } is a set of pairwise labels for X indicating whether x i and x j belong to the same class (y ij = 1) or not (y ij = 0). In this paper, we call the pairs with y ij = 1 the matching pairs, and the pairs with y ij = 0 the non-matching pairs. The goal of descriptor learning is to learn a feature embedding f (·) : R m×n → R d that maps raw patch pixels to a d dimensional vector, such that ∥ f (x i ) − f (x j ) ∥ 2 is small when y ij = 1 and ∥ f (x i )−f (x j ) ∥ 2 is large when y ij = 0. In this paper, we assume that f (·) lives on the unit sphere, i.e., ∥ f (x) ∥ 2 = 1, ∀x ∈ R m×n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Pairwise loss</head><p>The pairwise loss tries to directly induce small distance for matching pairs and large distance for non-matching pairs. An input for pairwise loss is of the form (x i , x j , y ij ), consisting of a pair of samples and their corresponding label. The most widely used pairwise loss is the contrastive loss:</p><formula xml:id="formula_0">ℓ con = y ij max(0, ∥ f (x i ) − f (x j ) ∥ 2 −ϵ + ) + (1 − y ij ) max(0, ϵ − − ∥ f (x i ) − f (x j ) ∥ 2 ),<label>(1)</label></formula><p>where f (·) is the feature embedding. ϵ + and ϵ − control the margins of the matching and non-matching pairs respectively. Contrastive loss was originally proposed in <ref type="bibr" target="#b3">[4]</ref> with ϵ + = 0. As shown in <ref type="bibr" target="#b8">[9]</ref>, this often leads to overfitting. And a proper relaxed margin (ϵ + &gt; 0) can achieve better performance. The main problem with the pairwise loss is that the margin parameters are often difficult to choose <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Triplet loss</head><p>Triplet loss takes a triplet of samples as input. One triplet consists of three samples: (x i , x j , x k ), with y ij = 1 and y ik = 0. To simplify the notation, we denote one triplet as</p><formula xml:id="formula_1">(x i , x + i , x − i ), where x + i = x j and x − i = x k .</formula><p>One commonly used triplet loss is the ranking loss <ref type="bibr" target="#b17">[18]</ref>:</p><formula xml:id="formula_2">ℓ tri = max ( 0, ϵ − (∥ f (x i ) − f (x − i ) ∥ 2 − ∥ f (x i ) − f (x + i ) ∥ 2 ) )<label>(2)</label></formula><p>where ϵ is a margin. The idea of ranking loss is to separate the matching sample and the non-matching sample by at least a margin ϵ. The main difference between pairwise loss and triplet loss is that pairwise loss considers the absolute distances of the matching pairs and non-matching pairs, while triplet loss considers the relative difference of the distances between matching and non-matching pairs. Since the quality of the embeddings largely depends on the relative ordering of the matching pairs and non-matching pairs, triplet loss shows better performance than pairwise loss in local descriptor learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Improvements</head><p>The main issue of triplet loss and pairwise loss is that as the number of training samples grows, sampling all the possible triplets/pairs becomes infeasible, and only a relatively small portion of triplets/pairs can be used in training. As observed in practice, the training is often ineffective since many of the sampled triplets/pairs will satisfy the constraint within just a few training steps. One possible solution is to remove the "easy samples" and add new "hard samples" to the training set. However, determining which samples to remove or add is a challenging task <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b18">19]</ref>. Additionally, focusing only on the samples that violate the training constraints the most will lead to overfitting <ref type="bibr" target="#b16">[17]</ref>.</p><p>Balntas et al. <ref type="bibr" target="#b0">[1]</ref> propose an improved version of triplet loss by applying in-triplet hard negative mining. The idea is that one triplet contains two non-matching pairs (</p><formula xml:id="formula_3">x i , x − i ) and (x + i , x − i )</formula><p>, and choosing the one that violates the triplet constraint more will make training more effective. They call this technique "anchor swap".</p><p>Kumar et al. <ref type="bibr" target="#b7">[8]</ref> propose a global loss and combine it with the traditional triplet loss to address the sampling issue in pairwise and triplet loss. Instead of considering sample pair or triplet, the global loss considers all matching and non-matching pairs in one training batch, and calculate the empirical mean and variance of the distance of the matching and non-matching pairs. The main idea of the global loss is to separate two empirical means by a margin and minimize the variances. There are two drawbacks of this method. First, the distribution of the distance of the matching pairs can vary greatly across different classes, and using a batch of randomly sampled matching pairs to estimate that distribution is unstable. Second, the extra margin in global loss adds extra complexity for training.</p><p>Structured loss <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23]</ref> considers all the possible matching and non-matching pairs in one batch of samples. By carefully designing the loss functions, structured loss has the ability to focus on the "hard" pairs in training. Song et al. <ref type="bibr" target="#b13">[14]</ref> propose the lifted structured similarity softmax loss (LSSS). N-pair loss <ref type="bibr" target="#b20">[21]</ref> further develops the idea by using a more effective batch construction method.</p><p>The motivation of this paper is that good descriptors should fully utilize the expressive power of the whole space ("spread-out" in the descriptor space). We also propose a simple regularization term, global orthogonal regularization, to encourage the "spread-out" property. The global orthogonal regularization can be easily incorporated into other losses. Experiments show that the proposed regularization can improve the performance of different types of losses, especially those originally without the "spread-out" property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">"Spread-out" local descriptors</head><p>The main idea of this paper is that in order for the descriptors to fully utilize the descriptor space, it should be sufficiently "spread-out" in the descriptor space. On the contrary, suppose there is part of the space where no fea- One intuitive way to characterize "spread-out" is that: Given a dataset, we say that the learned descriptors are spread-out if two randomly sampled non-matching descriptors are close to orthogonal with a high probability. As an obvious example, we notice that uniform distribution has such property.</p><formula xml:id="formula_4">Proposition 1. Let p 1 , p 2 ∈ S d−1 be</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>two points independently and uniformly sampled from the unit sphere in</head><formula xml:id="formula_5">d-dimensional space. Each point is represented by a d- dimensional ℓ 2 normalized vector. The probability density of p T 1 p 2 satisfies p(p T 1 p 2 = s) =      (1 − s 2 ) d−1 2 −1 B( d−1 2 , 1 2 ) − 1 ≤ s ≤ 1 0 otherwise,</formula><p>where B(a, b) is the beta function.</p><formula xml:id="formula_6">Proof. Since −1 ≤ p T 1 p 2 ≤ 1, the second equation is ob- vious.</formula><p>To show the first equation, we calculate the cumulative distribution first. Here we only consider the case when −1 ≤ s &lt; 0, and 0 ≤ s &lt; 1 can be shown similarly. Without loss of generality, we fix p 1 and also assume that s = cos θ, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Since cos(·) is a monotone function in [0, π], p T 1 p 2 ≤ s if and only if p 2 is located on the blue spherical cap. Since p 2 is uniformly sampled from the sphere, the probability of p T 1 p 2 ≤ s is equal to the area of the blue spherical cap divided by the area of the whole sphere. The area of the d − 1 dimensional spherical cap is</p><formula xml:id="formula_7">S = 1 2 S 0 r d−1 I (2rh−h 2 )/r 2 ( d − 1 2 , 1 2 ),</formula><p>where S 0 is the area of the whole sphere. r = 1 is the radius of the sphere. h is the height of the spherical cap: h = r + rcos(θ) = r + sr. I x (a, b) is the regularized incomplete beta function. Therefore, the cumulative distribution can be written as,</p><formula xml:id="formula_8">P (p T 1 p 2 ≤ s) = 1 2 I 1−s 2 ( d − 1 2 , 1 2 ), −1 ≤ s &lt; 0.</formula><p>The probability density is the derivative of the cumulative distribution. <ref type="figure" target="#fig_1">Figure 2</ref> shows the probability distribution of the inner product (cosine similarity) of two points independently and uniformly sampled from the unit sphere <ref type="bibr" target="#b1">2</ref> . It shows that with high probability, the two independently and uniformly sampled points are close to orthogonal.</p><p>Based on the above observation, one might hope to make the distribution of the learned descriptors matches that of the uniform distribution. This is not practical in two ways. 1) How the learned descriptors distribute depends not only on the learned model, but also on the natural distribution of the image patches (not controllable). 2) It is technically difficult to match two distributions in practice. Instead, in this paper, we propose a regularization technique inspired by the theoretic properties of the uniform distribution on unit sphere. The regularization encourages the inner product of two randomly sampled non-matching descriptors matches that of two points independently and uniformly sampled from the unit sphere in its mean and second moment.</p><p>The following proposition shows that for two points that are independently and uniformly sampled on the unit sphere, the mean and the second moment of their inner product are 0 and 1/d, respectively. </p><formula xml:id="formula_9">E(p T 1 p 2 ) = 0 and E((p T 1 p 2 ) 2 ) = 1 d .</formula><p>Proof. Due to symmetry, it's easy to show that E(p 1 ) = E(p 2 ) = 0, since p 1 and p 2 are independent,</p><formula xml:id="formula_10">E(p T 1 p 2 ) = E(p T 1 )E(p 2 ) = 0 T 0 = 0.</formula><p>Since both p 1 and p 2 are uniformly sampled from the unit sphere, when considering the second moment of the innerproduct, we can fix one point and let the other point to be uniformly sampled. Without loss of generality, we choose</p><formula xml:id="formula_11">p 1 = [1, 0, . . . , 0] T and denote p 2 as [p 21 , . . . , p 2d ] T , thus, (p T 1 p 2 ) 2 = p 21 and E((p T 1 p 2 ) 2 ) = E(p 2 21 ).</formula><p>Due to the symmetry of the sphere, we can have E(p</p><formula xml:id="formula_12">2 21 ) = E(p 2 22 ) = . . . = E(p 2 2d ). Since p 2 is on the unit sphere, ∑ d i=1 p 2 2i = 1. Thus, E(p 2 21 ) = 1/d.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Global orthogonal regularization</head><p>We propose a regularization which tries to match the mean and second moment shown in Proposition 2. It encourages that the descriptors of random sampled nonmatching pairs have similar statistical property as two points independently and uniformly sampled from the unit sphere. We call this regularization Global Orthogonal Regularization (GOR). Following the notations in Section 2, given a set of N random sampled non-matching patches</p><formula xml:id="formula_13">{(x i , x − i )} N i=1</formula><p>, denote the descriptor function as f (·). The sample mean of the inner product of the descriptors of nonmatching pairs is,</p><formula xml:id="formula_14">M 1 = 1 N N ∑ i=1 f (x i ) T f (x − i ).<label>(3)</label></formula><p>The sample second moment of the inner product is,</p><formula xml:id="formula_15">M 2 (f (x) T f (x − )) = 1 N N ∑ i=1 (f (x i ) T f (x − i )) 2 . (4)</formula><p>The Global Orthogonal Regularization (GOR) is defined as</p><formula xml:id="formula_16">ℓ gor = M 2 1 + max(0, M 2 − 1 d ),<label>(5)</label></formula><p>where d is the dimension of the final output descriptor. In (5), the first term tries to match the mean of the distributions and the second term tries to make the second moment close to 1/d. In order to calculate the regularization term, one needs to consider all the non-matching pairs in the training set -this is impractical. In practice we use a sampled batch to estimate its value. The reason for using the hinge loss for the second term is that, in many batches, all the non-matching pairs are already very close to being orthogonal (M 2 &lt; 1/d), and there is no need to force M 2 to be 1/d. We have tried other loss functions for the second term. ℓ 1 loss results in a similar performance, while ℓ 2 leads to slight degradation.</p><p>The proposed regularization term can be used with any loss function. Denote the original training loss as ℓ (·) , the final loss can be written as,</p><formula xml:id="formula_17">ℓ (·) gor = ℓ (·) + αℓ gor ,<label>(6)</label></formula><p>where α is a tunable parameter. In the experiment section, we test combining the global orthogonal regularization with contractive loss <ref type="bibr" target="#b2">3</ref> (1) <ref type="bibr" target="#b18">[19]</ref>, triplet loss (2) <ref type="bibr" target="#b0">[1]</ref>, lifted structured similarity softmax loss (LSSS) <ref type="bibr" target="#b13">[14]</ref> and N-pair loss <ref type="bibr" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Non-Euclidean distance</head><p>So far, we assumed that the distance of the descriptors is based on the Euclidean distance. There are several recent works that use a decision network instead of the Euclidean distance to calculate the similarity. Han et al. <ref type="bibr" target="#b5">[6]</ref> propose to use a Siamese network followed by a decision net. Zagoruyko and Komodakis <ref type="bibr" target="#b26">[27]</ref> develop a 2-stream networks, in which one stream focuses on the central area of the patch and the other focuses on the surrounding area of the patch. Kumar et al. <ref type="bibr" target="#b7">[8]</ref> propose a global loss and combine it with the 2-stream networks to achieve the stateof-the-art performance. The drawback of using a new type of distance rather than Euclidean distance is that efficient large-scale nearest neighbor search method such as locality sensitive hashing (LSH) <ref type="bibr" target="#b14">[15]</ref> can no longer be used. In this paper, we focus on training local descriptor in the Euclidean space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Implementation</head><p>In this section, we show our training framework based on triplet loss and the proposed global orthogonal regularization. The framework has three branches (as shown in <ref type="figure" target="#fig_4">Figure 3</ref>). The proposed global orthogonal regularization only considers two branches which process the nonmatching pairs. Training pipeline of other losses can be achieved accordingly. For example, for the pairwise loss, we use a network with two branches (known as the Siamese network) instead of three.</p><p>Though our method is flexible in terms of the patch sizes, here we follow <ref type="bibr" target="#b5">[6]</ref> to use patch size 64 × 64. Each branch in the triplet/Siamese network has the following structure: {Conv <ref type="bibr">(7,7,</ref>  is a max pooling layer with size n×n and stride m. FC(d) is a fully connected layer with output dimension d. ℓ 2 Norm is ℓ 2 normalization layer to guarantee each descriptor has unit norm. All the convolution layers are followed by batch normalization <ref type="bibr" target="#b6">[7]</ref> and ReLU. Based on our implementation, when trained without the proposed global regularization, the above network structure achieves similar performance as the one proposed in <ref type="bibr" target="#b0">[1]</ref>. The motivation of the use of the above shallow network is for efficiency and avoiding overfitting <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19]</ref>. We show the experiment of the proposed method over the large-scale patch descriptor benchmark in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Local Descriptor Result</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Dataset</head><p>We first conduct experiments on the standard local patch descriptor benchmark, UBC patch dataset <ref type="bibr" target="#b2">[3]</ref>. The dataset contains three subsets, Yosemite, Notre Dame and Liberty. Each subset consists of more than 100k classes which include different image patches corresponding to the same 3D location obtained through a 3D reconstruction from different multi-view images. The total number of local image patches within each subset is more than 450k. Each patch has a size of 64 × 64 and is sampled around the output of difference of Gaussian (DOG) <ref type="bibr" target="#b9">[10]</ref> detector. The scale and orientation of the patch is normalized by the detector. Though with normalized scale and orientation, the patch dataset still contains great variations in view points, lighting, camera conditions etc. We follow the evaluation protocol proposed in <ref type="bibr" target="#b2">[3]</ref> to separate the whole dataset into six training-test combinations in which one subset is for training and the other for test.</p><p>The metric used to evaluate different methods is false positive rate at 95% true positive rate (FPR95), which is the standard metric in previous works <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27]</ref>. The test split of each subset contains 100k patch pairs in which 50% are matching pairs and the other 50% are non-matching pairs. The test pairs are predefined in <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Training setting and evaluation method</head><p>For training, we randomly sample 1M triplets (for triplet network), or 1M matching pairs and 1M non-matching pairs (for Siamese network), for each training subset. No data augmentation or specially designed sampling is used. The training batch size is set to 128. We use SGD with momentum in the optimization. The learning rate starts at 0.1, with momentum 0.9. The learning rate is reduced after each epoch by a factor of 0.96. The trade-off parameter α in <ref type="formula" target="#formula_17">(6)</ref> is set to 1 (we discuss the choice of α in Section 5.3). The loss function in <ref type="formula" target="#formula_16">(5)</ref> is hinge loss. The margin for matching pair in Siamese network (ϵ + in <ref type="formula" target="#formula_0">(1)</ref>) is set to 0.7 and the margin of triplet network (ϵ in <ref type="formula" target="#formula_2">(2)</ref>) is set to 0.5. All are estimated via empirical cross validation. Our implementation is based on TensorFlow <ref type="bibr" target="#b4">[5]</ref>. The training of each epoch takes about 10 minutes on a Titan X GPU. All the networks are trained with 20 epochs, and they all converge before the end of training.</p><p>We compare our method with a large set of local feature descriptors which use Euclidean distance as similarity metric. The methods include: 1) hand-crafted descriptor (SIFT <ref type="bibr" target="#b9">[10]</ref>), conventional machine learning based descriptor (VGG-Opt <ref type="bibr" target="#b19">[20]</ref>  DeepCampare 2str 4 <ref type="bibr" target="#b26">[27]</ref> and DeepDesc <ref type="bibr" target="#b18">[19]</ref>), 3) descriptors learned with triplet loss with and without anchor swap (TFeat+AS <ref type="bibr" target="#b0">[1]</ref> and TFeat <ref type="bibr" target="#b0">[1]</ref>), 4) descriptors learned with global loss (TGLoss <ref type="bibr" target="#b7">[8]</ref>), and 5) descriptors learned with structured loss (N-pair <ref type="bibr" target="#b20">[21]</ref>).</p><p>We combine the proposed Global Orthogonal Regularization with four commonly used losses mentioned in Section 2, namely, contractive loss, triplet loss, triplet loss with anchor swap and N-pair loss <ref type="bibr" target="#b20">[21]</ref>. Thus four variants of our method are used in evaluation: contractive loss with global orthogonal regularization (CL+GOR), triplet loss with GOR (TL+GOR), triplet loss with anchor swap <ref type="bibr" target="#b0">[1]</ref> and GOR (TL+AS+GOR) and N-pair loss with GOR (N-pair+GOR).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Patch pair classification result</head><p>Classification error. <ref type="table">Table 1</ref> summarizes the performance of all the evaluated Euclidean embedding methods on UBC patch dataset. We show FPR95 on each of the six training- <ref type="bibr" target="#b3">4</ref> Subscript "2str" means central-surround network proposed in <ref type="bibr" target="#b26">[27]</ref>. test combinations and also the mean over all of them.</p><p>By simply applying the proposed global orthogonal regularization, almost all the baseline methods show performance gains. Specifically, among all the pairwise loss based methods, contractive loss with the proposed GOR (CL+GOR) reduces the error of the previous best pairwise loss model (DeepCampare 2str ) from 9.67 to 5.97 with a relative deduction of 38.3%. Among all the triplet loss based methods, triplet loss with the proposed GOR (TL+GOR) reduces the error of its triplet loss baseline (TFeat) from 6.79 to 4.69. For the anchor swap version (TL+AS+GOR vs. TFeat+AS), the error reduces from 6.47 to 4.36. The relative deductions are 30.9% and 32.6%, respectively. For the structured loss, the error was reduced from 5.29 to 4.98. The improvement is not as significant because the N-pair loss already has the ability to force the random non-matching pairs to be orthogonal. The second moment of the non-matching pairs trained with N-pair loss is close to 2/d, while that of the triplet loss is close to 50/d. Overall, TL+AS+GOR achieves the lowest FPR95 rate.</p><p>The improvement of our method can also be shown using other metrics such as the ROC curves. The ROC curves of TL+AS+GOR and TL+AS both are shown in <ref type="figure" target="#fig_5">Figure 4</ref>. Here, the training subset is Notre Dame, and the test subsets are Liberty <ref type="figure" target="#fig_5">(Figure 4(a)</ref>) and Yosemite <ref type="figure" target="#fig_5">(Figure 4(b)</ref>. The result shows that the performance gain of the proposed regularization is universal at different false positive rates.</p><p>Similarity histogram. To understand how the proposed GOR affects the distribution of the similarity, the histograms of cosine similarity of the matching pairs and nonmatching pairs of the models trained with/without the proposed GOR on test set are shown in <ref type="figure" target="#fig_6">Figure 5</ref>. We use the same baseline method defined above. This figure shows the setting in which the training subset is Notre Dame and the test subset is Liberty, but the observation is also general for   other training/test combinations. The histogram of the similarity of the matching and nonmatching pairs of the baseline method is shown in <ref type="figure" target="#fig_6">Figure 5(a)</ref>, while those of model trained with the proposed regularization is shown in <ref type="figure" target="#fig_6">Figure 5</ref>(b). The histogram in blue is for matching pairs, while the histogram in orange is for non-matching pairs. The histogram of the similarity of non-matching pairs trained with GOR has a much sharper shape than that without the proposed regularization, which means when trained with GOR, non-matching pairs are more likely to be close to orthogonal. With the proposed GOR, the empirical error (overlapped area in <ref type="figure" target="#fig_6">Figure 5(b)</ref>) decreases by 15% relatively in comparison with the baseline ( <ref type="figure" target="#fig_6">Figure 5(a)</ref>).</p><p>Trade-off parameter. α in (6) controls the trade-off between the triplet loss and GOR. We use Notre Dame as training set and Liberty as test set and show the FPR95 of different models trained with different α values (from 0.01 to 10) in <ref type="figure" target="#fig_8">Figure 6</ref>(a). When α = 0, (6) becomes standard triplet loss. When α is large, the network will enforce the descriptor of all the non-matching pairs (including "hard negatives") to be close to orthogonal.</p><p>Embedding dimension. We investigate how the proposed GOR affects the training of descriptors of different dimensionalities. We change the output node number in final fully-connected layer from <ref type="bibr">[32,</ref><ref type="bibr">64,</ref><ref type="bibr">128,</ref><ref type="bibr">256,</ref><ref type="bibr">512,</ref><ref type="bibr">1024]</ref>. The result is shown in <ref type="figure" target="#fig_8">Figure 6</ref>(b). The proposed GOR achieves significant performance gain when training a highdimensional descriptor (d ≥ 64). The low dimensional case (d = 32) does not work as well. One possible reason is that the descriptors of two non-matching patches are harder to be spread-out, and forcing non-matching patches to be orthogonal may lead to error. Finally, both our method and the baseline degrade for very high dimensions. We conjecture this is due to over-fitting. One may think that when d is large, the network may not be able to force the second moment to a very small 1/d. However, the proposed GOR is only a regularization not a hard constraint. And we can always make a trade-off by changing the value of α in (6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Descriptor extraction efficiency</head><p>Since there are hundreds of patches in one image, the speed of descriptor extraction is also very important. The proposed GOR only affects the training stage, adding no additional cost in extraction pipeline. Based on our implementation on TensorFlow, when running a Titan X GPU, the extraction speed is about 10K patches per second, which is comparable to the conventional local descriptor extraction method like SIFT <ref type="bibr" target="#b9">[10]</ref> and descriptor learning techniques using "shallow" structure such as TFeat and DeepDesc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Extension to image-level embedding</head><p>Although GOR is proposed to learn local descriptors, the method can also be used in other applications where a feature embedding is learned. As an example, we show that it can also be used to improve the performance of image-level embedding. We compare our method to LSSS <ref type="bibr" target="#b13">[14]</ref>, which, as reviewed in Section 2.3, outperforms triplet and pairwise losses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Dataset and evaluation metric</head><p>The image level feature embedding experiment is conducted on Stanford Online Products dataset <ref type="bibr" target="#b13">[14]</ref>. Stanford Online Products dataset contains 120,053 product images crawled from eBay.com. There are a total of 22,634 products belonging to 12 categories. Each product is an individual class and has an average of 5.3 images. We strictly follow the same experiment setting in <ref type="bibr" target="#b13">[14]</ref>, that using 11,318 classes with a total of 59,551 images for training and another 11,316 classes with 60,502 images for test. The training and test splits have no overlap and are predefined in the dataset. We choose this dataset due to its realistic setting and rich variations within classes.</p><p>As in <ref type="bibr" target="#b13">[14]</ref>, we perform both clustering and retrieval tasks. For the clustering task, the F1 and NMI scores are used as the evaluation metrics <ref type="bibr" target="#b10">[11]</ref>. F1 metric computes the harmonic mean of precision and recall. NMI metric equals to the mutual information divided by the average value of the entropy of clusters and the entropy of labels. For retreival task, the performance is evaluated by Recall@K score as in <ref type="bibr" target="#b13">[14]</ref>. For each query image, we first remove the query from the test set and then retrieve its K nearest neighbors from the test set. The recall of the test image is set to 1 if any image in the same class with the query is retrieved and 0 otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Implementation details</head><p>The proposed GOR is embedded with the lifted structured similarity softmax loss (LSSS), which is one of the best performing losses used in learning feature embedding. The network structure follows GoogLeNet <ref type="bibr" target="#b21">[22]</ref> up to the "pool5" layer. The final descriptor is generated by a fully connected layer. All the convolutional layers are initialized from the network pre-trained on ImageNet ILSVRC dataset <ref type="bibr" target="#b15">[16]</ref>. All convolutional layers are fine-tuned with a learning rate that is 10 times smaller than that of the fullyconnected layer. The batch size is set to 128 and the training iteration is set to 20,000. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Result</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We proposed a regularization technique named Global Orthogonal Regularization (GOR) that makes the local feature descriptor more spread-out in the descriptor space. Inspired by the properties of uniform distribution, the regularization achieves the desired property by making the nonmatching pairs close to orthogonal. We showed the proposed regularization can be easily used to improve the performance of various feature embedding losses such as the pairwise and triplet losses.</p><p>In the future, we plan to extend the proposed regularization technique to non-Euclidean distance. We also plan to apply our method to more general metric learning settings. Our prototype implementation can be downloaded from https://github.com/ColumbiaDVMM/ Spread-out_Local_Feature_Descriptor.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Valid area for p T 1 p2 ≤ s = cos θ. If p2 is on the blue spherical cap, p T 1 p2 ≤ cos θ, otherwise, p T 1 p2 &gt; cos θ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Probability density of inner product of two points which are independently and uniformly sampled from the unit sphere in d-dimensional space. We can see that, in high dimensional space, most pairs are close to orthogonal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Proposition 2 .</head><label>2</label><figDesc>Let p 1 , p 2 ∈ S d−1 be two points indepen- dently and uniformly sampled from the unit sphere. The mean and the second moment of p T 1 p 2 are</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Norm}. Conv(n, m, c) means convolutional layer with ker- nel size (n, m) and output channel number c. MaxP(n, m)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Local feature descriptor training pipeline with triplet loss and the proposed global orthogonal regularization (GOR). GOR can also be used with the pairwise loss. In that case, there will be two branches of the network (known as the Siamese network) instead of three.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. ROC curves for our method and baseline method trained on the Notre Dame subset and tested on the Liberty and Yosemite subsets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Histogram of cosine similarity of matching pairs and non-matching pairs on "Liberty". The model is trained on "Notre Dame". When trained with GOR, the non-matching pairs are more close to being orthogonal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. FPR95(%) with different α and embedding dimensions. α trades off the regularization term and the triplet loss. Training set: Notre Dame, Test set: Liberty.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. F1, NMI (for clustering) and Recall@K (for retrieval) scores for image-level descriptor learning using Stanford Online Product dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 (</head><label>7</label><figDesc>Figure 7(a) and Figure 7(b) further show the F1 score and NMI score for the clustering task with different embedding sizes. By combining the proposed GOR with LSSS, our method shows better performance especially in highdimensional cases (d ≥ 128). The reason is discussed in Section 5.3. Figure 7(c) shows the Recall@K score for 512 dimensional descriptor. We also test the proposed regularization on small metric learning datasets such as Car196 and CUB-200-2011. The proposed regularization does not show clear improvement. One possible explanation is that the numbers of the classes in Car196 (196) and CUB-200-2011 (200) are</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>), 2) deep learning based descrip- tors learned with pairwise loss (DeepCampare siam [27],</figDesc><table>Loss 
Type 

Training 
NotreDame Liberty NotreDame Yosemite Yosemite Liberty 
Mean 
Test 
Yosemite 
Liberty 
NotreDame 
Descriptor 
Dim 

N/A 
SIFT [10] 
128 
27.29 
29.84 
22.53 
26.55 
VGG-Opt [20] 
80 
10.08 
11.63 
11.42 
14.58 
7.22 
6.17 
10.28 

Pairwise 

DeepComparesiam[27] 256 
15.89 
19.91 
13.24 
17.25 
8.38 
6.01 
13.45 
DeepCompare2str[27] 
512 
13.02 
13.24 
8.79 
12.84 
5.58 
4.54 
9.67 
DeepDesc[19] 
128 
16.19 
8.82 
4.54 
9.85 
CL+GOR (Ours) 
128 
6.88 
6.99 
6.46 
8.33 
3.73 
3.40 
5.97 
Global 
TGLoss[8] 
256 
9.47 
10.65 
9.91 
13.45 
5.43 
3.91 
8.80 

Triplet 

TFeat[1] 
128 
7.95 
8.10 
7.64 
9.88 
3.83 
3.39 
6.79 
TFeat+AS[1] 
128 
7.08 
7.82 
7.22 
9.79 
3.85 
3.12 
6.47 
TL+GOR (Ours) 
128 
4.94 
5.74 
5.47 
7.13 
2.58 
2.28 
4.69 
TL+AS+GOR (Ours) 
128 
5.15 
5.40 
4.80 
6.45 
2.38 
1.95 
4.36 

Structured 
N-pair[21] 
128 
5.53 
8.29 
4.80 
7.51 
3.01 
2.60 
5.29 
N-pair+GOR (Ours) 
128 
5.16 
7.43 
5.03 
7.10 
2.81 
2.34 
4.98 

Table 1. FPR95 (%) of different methods on UBC patch dataset. TL+AS+GOR achieves the lowest FPR95 rate. 

False Positive Rate 

0.05 0.1 0.15 0.2 0.25 0.3 

True Positive Rate 

0.9 

0.92 

0.94 

0.96 

0.98 

1 

TL+AS+GOR (Ours) 
TL+AS 

(a) Train: Notre Dame, 
Test: Liberty. 

False Positive Rate 

0.05 0.1 0.15 0.2 0.25 0.3 

True Positive Rate 

0.9 

0.92 

0.94 

0.96 

0.98 

1 

TL+AS+GOR (Ours) 
TL+AS 

(b) Train: Notre Dame, 
Test: Yosemite. 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We use Euclidean distance in this paper. See Section 2 for more details, and Section 3 for the discussion on alternatives.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Note that since we assume the descriptors stay on the unit sphere (ℓ 2 normalized), there is only a sign and constant difference between ℓ 2 distance and cosine similarity, and the cosine similarity equals to the inner product.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">For contractive loss (1), we substitute the second term in (1) with the proposed regularization, since both terms try to separate the non-matching pairs.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning local feature descriptors with triplets and shallow convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Balntas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ponsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>BMVC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Surf: Speeded up robust features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Discriminative Learning of Local Image Descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Winder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">MatchNet: Unifying Feature and Metric Learning for PatchBased Matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<title level="m">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning local image descriptors with deep siamese and triplet convolutional networks by minimising global loss functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Morere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Goh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1501.04711</idno>
		<title level="m">Deephash: Getting regularization, depth and finetuning right</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
		<title level="m">Distinctive Image Features from Scale-Invariant Keypoints. IJCV</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Introduction to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Working hard to know your neighbor&apos;s margins: Local descriptor learning loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mishchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Radenovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Movshovitz-Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07464</idno>
		<title level="m">No Fuss Distance Metric Learning using Proxies</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Locality sensitive hashing: A comparison of hash function types and querying mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Paulevé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Amsaleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Imagenet large scale visual recognition challenge. IJCV</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning a distance metric from relative comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Discriminative Learning of Deep Convolutional Feature Point Descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Simo-Serra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Trulls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ferraz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Moreno-Noguer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Learning Local Feature Descriptors Using Convex Optimisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Improved Deep Metric Learning with Multi-class N-pair Loss Objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<editor>D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">L2-net: Deep learning of discriminative patch descriptor in euclidean space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Daisy: An efficient dense descriptor applied to wide-baseline stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning Deep Embeddings with Histogram Loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">LIFT: Learned Invariant Feature Transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Trulls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to compare image patches via convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
