<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Assessing Generative Models via Precision and Recall</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><forename type="middle">S M</forename><surname>Sajjadi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><forename type="middle">Bachem</forename><surname>Google</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brain</forename><surname>Mario</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucic</forename><surname>Google</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brain</forename><surname>Olivier</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bousquet</forename><surname>Google</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brain</forename><surname>Sylvain</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gelly</forename><surname>Google Brain</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Assessing Generative Models via Precision and Recall</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Recent advances in generative modeling have led to an increased interest in the study of statistical divergences as means of model comparison. Commonly used evaluation methods, such as Fréchet Inception Distance (FID), correlate well with the perceived quality of samples and are sensitive to mode dropping. However, these metrics are unable to distinguish between different failure cases since they yield one-dimensional scores. We propose a novel definition of precision and recall for distributions which disentangles the divergence into two separate dimensions. The proposed notion is intuitive, retains desirable properties, and naturally leads to an efficient algorithm that can be used to evaluate generative models. We relate this notion to total variation as well as to recent evaluation metrics such as Inception Score and FID. To demonstrate the practical utility of the proposed approach we perform an empirical study on several variants of Generative Adversarial Networks and the Variational Autoencoder. In an extensive set of experiments we show that the proposed metric is able to disentangle the quality of generated samples from the coverage of the target distribution.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep generative models, such as Variational Autoencoders (VAE) <ref type="bibr" target="#b11">[12]</ref> and Generative Adversarial Networks (GAN) <ref type="bibr" target="#b7">[8]</ref>, have received a great deal of attention due to their ability to learn complex, high-dimensional distributions. One of the biggest impediments for future research is the lack of quantitative evaluation methods to accurately assess the quality of trained models. Without a proper evaluation metric researchers often need to visually inspect generated samples or resort to qualitative techniques which can be subjective. One of the main difficulties for quantitative assessment lies in the fact that the distribution is only specified implicitly -one can learn to sample from a predefined distribution, but cannot evaluate the likelihood efficiently. In fact, even if likelihood computation were computationally tractable, it would be inadequate for this task as it can be highly misleading <ref type="bibr" target="#b20">[21]</ref>.</p><p>As a result, surrogate metrics are often used to assess the quality of the trained models. Some of the proposed measures, such as Inception Score (IS) <ref type="bibr" target="#b18">[19]</ref> and Fréchet Inception Distance (FID) <ref type="bibr" target="#b8">[9]</ref>, have shown promising results in practice. In particular, FID has been shown to be robust to image corruption, it correlates well with the visual fidelity of the samples, and it can be computed on unlabeled data.</p><p>However, all of the metrics commonly applied to evaluating generative models share a crucial weakness: Since they yield a one-dimensional score, they are unable to distinguish between different failure cases. For example, the generative models shown in <ref type="figure" target="#fig_0">Figure 1</ref> obtain similar FIDs but exhibit different sample characteristics: the model on the left trained on MNIST produces realistic samples, For example, the model on the left produces reasonably looking faces on CelebA, but too many dark images. In contrast, the model on the right produces more artifacts, but more varied images. By the proposed metric (middle), the models on the left achieve higher precision and lower recall than the models on the right, which suffices to successfully distinguishing between the failure cases.</p><p>but only generates a subset of the digits. On the other hand, the model on the right produces lowquality samples which appear to cover all digits. A similar effect can be observed for the CelebA <ref type="bibr" target="#b14">[15]</ref> data set. Hence, we argue that a single-value summary is not adequate to compare generative models.</p><p>Motivated by this shortcoming, we present a novel approach which disentangles the divergence between distributions into two components: precision and recall. Given a reference distribution P and a learned distribution Q, precision intuitively measures the quality of the samples in Q, while recall measures the proportion of P that is covered by Q. Furthermore, we propose an elegant algorithm which can compute these quantities based on samples from P and Q. In particular, using this approach we are able to quantify the degree of mode dropping and mode inventing based on samples from the true and the learned distribution.</p><p>Our contributions: (1) We introduce a novel definition of precision and recall for distributions and prove that the notion is theoretically sound and has desirable properties, (2) we propose an efficient algorithm to compute these quantities, (3) we relate these notions to total variation, IS and FID, (4) we demonstrate that in practice one can quantify the degree of mode dropping and mode inventing on real world data sets (image and text data), and (5) we compare several types of generative models based on the proposed approach -to our knowledge, this is the first metric that experimentally confirms the folklore that GANs often produce "sharper" images, but can suffer from mode collapse (high precision, low recall), while VAEs produce "blurry" images, but cover the whole distribution (low precision, high recall).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>The task of evaluating generative models is an active research area. Here we focus on recent work in the context of deep generative models for image and text data. The classic approaches relying on comparing log-likelihood have received some criticism due the fact that one can achieve high likelihood, but low image quality, and conversely, high-quality images but low likelihood <ref type="bibr" target="#b20">[21]</ref>. While the likelihood can be approximated in some simple settings, kernel density estimation in high-dimensional spaces is challenging and can be misleading <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b22">23]</ref>. Other failure modes related to density estimation in high-dimensional spaces have been elaborated in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b20">21]</ref>. A recent review of popular approaches is presented in <ref type="bibr" target="#b4">[5]</ref>.</p><p>The IS <ref type="bibr" target="#b18">[19]</ref> offers a way to quantitatively evaluate the quality of generated samples in the context of image data. Intuitively, the conditional label distribution p(y|x) of samples containing meaningful objects should have low entropy, while the label distribution over the whole data set p(y) should have high entropy. Formally, IS(G) = exp(E x∼G [d KL (p(y|x), p(y)]). The score is computed based on a classifier (Inception network trained on ImageNet). However, it necessitates a labeled data set and has been found to be weak at providing guidance for comparing models <ref type="bibr" target="#b2">[3]</ref>.</p><p>The FID <ref type="bibr" target="#b8">[9]</ref> provides an alternative approach which requires no labeled data. The samples are first embedded in some feature space (a specific layer of Inception for images). Then, a continuous multivariate Gaussian is fit to the data and the distance computed as</p><formula xml:id="formula_0">P (a) Q (b) (c) (d) (e)<label>(f</label></formula><formula xml:id="formula_1">FID(x, g) = ||µ x − µ g || 2 2 + Tr(Σ x + Σ g − 2(Σ x Σ g ) 1 2</formula><p>), where µ and Σ denote the mean and covariance of the corresponding samples. FID is sensitive to both the addition of spurious modes as well as to mode dropping (see <ref type="figure" target="#fig_4">Figure 5</ref> and results in <ref type="bibr" target="#b16">[17]</ref>). As an unbiased alternative, the Kernel Inception Distance <ref type="bibr" target="#b3">[4]</ref> has been proposed. The drawback of the latter is high computational cost.</p><p>Another approach is to train a classifier between the real and fake distribution and to use its accuracy on a test set as a proxy for the quality of the samples <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16]</ref>. This approach necessitates training of a classifier for each model which is seldom practical. Furthermore, the classifier might detect a single dimension where the true and generated samples differ (e.g., barely visible artifacts in generated images) and enjoy high accuracy, which runs the risk of assigning higher quality to a worse model.</p><p>To the best of our knowledge, all commonly used metrics for evaluating generative models are one-dimensional in that they only yield a single score or distance. A notion of precision and recall has previously been introduced in <ref type="bibr" target="#b16">[17]</ref> where the authors compute the distance to the manifold of the true data and use it as a proxy for precision and recall on a synthetic data set. Unfortunately, it is not possible to compute this quantity for more complex data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRD: Precision and Recall for Distributions</head><p>In this section, we derive a novel notion of precision and recall to compare a distribution Q to a reference distribution P. The key intuition is that precision should measure how much of Q can be generated by a "part" of P while recall should measure how much of P can be generated by a "part" of Q. <ref type="figure">Figure 2</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Derivation</head><p>Let S = supp(P) ∩ supp(Q) be the (non-empty) intersection of the supports 2 of P and Q. Then, P may be viewed as a two-component mixture where the first component P S is a probability distribution on S and the second component P S is defined on the complement of S. Similarly, Q may be rewritten as a mixture of Q S and Q S . More formally, for someᾱ,β ∈ (0, 1], we define</p><formula xml:id="formula_2">P =βP S + (1 −β)P S and Q =ᾱQ S + (1 −ᾱ)Q S .<label>(1)</label></formula><p>This decomposition allows for a natural interpretation: P S is the part of P that cannot be generated by Q, so its mixture weight 1 −β may be viewed as a loss in recall. Similarly, Q S is the part of Q that cannot be generated by P, so 1 −ᾱ may be regarded as a loss in precision. In the case where P S = Q S , i.e., the distributions P and Q agree on S up to scaling,ᾱ andβ provide us with a simple two-number precision and recall summary satisfying the examples in <ref type="figure">Figure 2</ref> (a)-(d).</p><p>If P S = Q S , we are faced with a conundrum: Should the differences in P S and Q S be attributed to losses in precision or recall? Is Q S inadequately "covering" P S or is it generating "unnecessary" noise? Inspired by PR curves for binary classification, we propose to resolve this predicament by providing a trade-off between precision and recall instead of a two-number summary for any two distributions P and Q. To parametrize this trade-off, we consider a distribution µ on S that signifies a "true" common component of P S and Q S and similarly to (1), we decompose both P S and Q S as</p><formula xml:id="formula_3">P S = β µ + (1 − β )P µ and Q S = α µ + (1 − α )Q µ .<label>(2)</label></formula><p>The distribution P S is viewed as a two-component mixture where the first component is µ and the second component P µ signifies the part of P S that is "missed" by Q S and should thus be considered a recall loss. Similarly, Q S is decomposed into µ and the part Q µ that signifies noise and should thus be considered a precision loss. As µ is varied, this leads to a trade-off between precision and recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Formal definition</head><p>For simplicity, we consider distributions P and Q that are defined on a finite state space, though the notion of precision and recall can be extended to arbitrary distributions. By combining <ref type="formula" target="#formula_2">(1)</ref> and <ref type="formula" target="#formula_3">(2)</ref>, we obtain the following formal definition of precision and recall. Definition 1. For α, β ∈ (0, 1], the probability distribution Q has precision α at recall β w.r.t. P if there exist distributions µ, ν P and ν Q such that</p><formula xml:id="formula_4">P = βµ + (1 − β)ν P and Q = αµ + (1 − α)ν Q .<label>(3)</label></formula><p>The component ν P denotes the part of P that is "missed" by Q and encompasses both P S in (1) and P µ in <ref type="bibr" target="#b1">(2)</ref>. Similarly, ν Q denotes the noise part of Q and includes both Q S in (1) and Q µ in (2). Definition 2. The set of attainable pairs of precision and recall of a distribution Q w.r.t. a distribution P is denoted by PRD(Q, P) and it consists of all (α, β) satisfying Definition 1 and the pair (0, 0).</p><p>The set PRD(Q, P) characterizes the above-mentioned trade-off between precision and recall and can be visualized similar to PR curves in binary classification: <ref type="figure">Figure 2</ref>. Note how the plot distinguishes between (a) and (b): Any symmetric evaluation method (such as FID) assigns these cases the same score although they are highly different. The interpretation of the set PRD(Q, P) is further aided by the following set of basic properties which we prove in Section A.1 in the appendix. Theorem 1. Let P and Q be probability distributions defined on a finite state space Ω. The set PRD(Q, P) satisfies the following properties:</p><formula xml:id="formula_5">Figure 3 (a)-(d) show the set PRD(Q, P) on a 2D-plot for the examples (a)-(d) in</formula><formula xml:id="formula_6">(i) (1, 1) ∈ PRD(Q, P) ⇔ Q = P (equality) (ii) PRD(Q, P) = {(0, 0)} ⇔ supp(Q) ∩ supp(P) = ∅ (disjoint supports) (iii) Q(supp(P)) =ᾱ = max (α,β)∈PRD(Q,P) α (max precision) (iv) P(supp(Q)) =β = max (α,β)∈PRD(Q,P) β (max recall) (v) (α , β ) ∈ PRD(Q, P) if α ∈ (0, α], β ∈ (0, β], (α, β) ∈ PRD(Q, P) (monotonicity) (vi) (α, β) ∈ PRD(Q, P) ⇔ (β, α) ∈ PRD(P, Q) (duality)</formula><p>Property (i) in combination with Property (v) guarantees that Q = P if the set PRD(Q, P) contains the interior of the unit square, see case (c) in <ref type="figure">Figures 2 and 3</ref>. Similarly, Property (ii) assures that whenever there is no overlap between P and Q, PRD(Q, P) only contains the origin, see case (d) of Figures 2 and 3. Properties (iii) and (iv) provide a connection to the decomposition in <ref type="formula" target="#formula_2">(1)</ref> and allow an analysis of the cases (a) and (b) in Figures 2 and 3: As expected, Q in (a) achieves a maximum precision of 1 but only a maximum recall of 0.5 while in (b), maximum recall is 1 but maximum precision is 0.5. Finally, Property (vi) provides a natural interpretation of precision and recall: The precision of Q w.r.t. P is equal to the recall of P w.r.t. Q and vice versa.</p><p>Clearly, not all cases are as simple as the examples (a)-(d) in <ref type="figure">Figures 2 and 3</ref>, in particular if P and Q are different on the intersection S of their support. The examples (e) and (f) in <ref type="figure">Figure 2</ref> and the resulting sets PRD(Q, P) in <ref type="figure">Figure 3</ref> illustrate the importance of the trade-off between precision and recall as well as the utility of the set PRD(Q, P). In both cases, P and Q have the same support while Q has high precision and low recall in case (e) and low precision and high recall in case (f). This is clearly captured by the sets PRD(Q, P). Intuitively, the examples (e) and (f) may be viewed as noisy versions of the cases (a) and (b) in <ref type="figure">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Algorithm</head><p>Computing the set PRD(Q, P) based on Definitions 1 and 2 is non-trivial as one has to check whether there exist suitable distributions µ, ν P and ν Q for all possible values of α and β. We introduce an equivalent definition of PRD(Q, P) in Theorem 2 that does not depend on the distributions µ, ν P and ν Q and that leads to an elegant algorithm to compute practical PRD curves. Theorem 2. Let P and Q be two probability distributions defined on a finite state space Ω. For λ &gt; 0 define the functions</p><formula xml:id="formula_7">α(λ) = ω∈Ω min (λP(ω), Q(ω)) and β(λ) = ω∈Ω min P(ω), Q(ω) λ .<label>(4)</label></formula><p>Then, it holds that</p><formula xml:id="formula_8">PRD(Q, P) = {(θα(λ), θβ(λ)) | λ ∈ (0, ∞), θ ∈ [0, 1]} .</formula><p>We prove the theorem in Section A.2 in the appendix. The key idea of Theorem 2 is illustrated in <ref type="figure">Figure 4</ref>: The set of PRD(Q, P) may be viewed as a union of segments of the lines α = λβ over all λ ∈ (0, ∞). Each segment starts at the origin (0, 0) and ends at the maximal achievable value (α(λ), β(λ)). This provides a surprisingly simple algorithm to compute PRD(Q, P) in practice: Simply compute pairs of α(λ) and β(λ) as defined in <ref type="formula" target="#formula_7">(4)</ref> for an equiangular grid of values of λ. For a given angular resolution m ∈ N, we compute</p><formula xml:id="formula_9">PRD(Q, P) = {(α(λ), β(λ)) | λ ∈ Λ} where Λ = tan i m+1 π 2 | i = 1, 2, . . . , m .</formula><p>To compare different distributions Q, one may simply plot their respective PRD curves PRD(Q, P). To approximate the full set PRD(Q, P), one may interpolate between PRD(Q, P) and the origin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Connection to total variation distance</head><p>Theorem 2 provides a natural interpretation of the proposed approach. For λ = 1, we have</p><formula xml:id="formula_10">α(1) = β(1) = ω∈Ω min (P(ω), Q(ω)) = ω∈Ω P(ω) − (P(ω) − Q(ω)) + = 1 − δ(P, Q)</formula><p>where δ(P, Q) denotes the total variation distance between P and Q. As such, our notion of precision and recall may be viewed as a generalization of total variation distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Application to Deep Generative Models</head><p>In this section, we show that the algorithm introduced in Section 3.3 can be readily applied to evaluate the precision and recall of deep generative models. In practice, access to P and Q is given via empirical samplesP ∼ P andQ ∼ Q. Given that both P and Q are continuous distributions, the probability of generating a point sampled from Q is 0. Furthermore, there is strong empirical evidence that comparing samples in image space runs the risk of assigning higher quality to a worse model <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21]</ref>. A common remedy is to apply a pre-trained classifier trained on natural images and compareP andQ at a feature level. Intuitively, in this feature space the samples should be compared based on statistical regularities in the images, rather than random artifacts resulting from the generative process <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18]</ref>.</p><p>Following this line of work, we first use a pre-trained Inception network to embed the samples into the Pool3 layer <ref type="bibr" target="#b8">[9]</ref>. We then cluster the union ofP andQ in this feature space using mini-batch k-means with k = 20 <ref type="bibr" target="#b19">[20]</ref>. Intuitively, we reduce the problem to a one dimensional problem where the histogram over the cluster assignments can be meaningfully compared. Hence, failing to produce samples from a cluster with many samples from the true distribution will hurt recall, and producing samples in clusters without many real samples will hurt precision. As the clustering algorithm is randomized, we run the procedure several times and average over the PRD curves. We note that such a clustering is meaningful as shown in <ref type="figure">Figure 9</ref> in the appendix and could be scaled to larger sample sizes using approaches such as <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>.</p><p>We stress that from the point of view of our algorithm, only a meaningful embedding is required. As such, the algorithm can be applied to various data modalities. In particular, in Section 4.1 we show that besides image data the algorithm can be applied to a text generation task.  <ref type="figure" target="#fig_4">Figure 5</ref>: Left: IS and FID as we remove and add classes of CIFAR-10. IS generally only increases, while FID is sensitive to both the addition and removal of classes. However, it cannot distinguish between the two failure cases (inventing a mode and dropping a mode). Middle: Resulting PRD curves for the same experiment. As expected, adding modes (Q6-Q10) leads to a loss in precision, while dropping modes (Q1-Q4) leads to a loss in recall. As an example consider Q4 and Q6 which have similar FID, but strikingly different precision and recall curves. The same behavior can be observed for the task of text generation, as displayed on the plot on the right. For this experiment, we set P to contain samples from all classes so the PRD curves demonstrate the increase in recall as we increase the number of classes in Q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Adding and dropping modes from the target distribution</head><p>Mode collapse or mode dropping is a major challenge in GANs <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b18">19]</ref>. Due to the symmetry of commonly used metrics with respect to precision and recall, the only way to assess whether the model is producing low-quality images or dropping modes is by visual inspection. In stark contrast, the proposed metric can quantitatively disentangle these effects which we empirically demonstrate.</p><p>We consider three data sets commonly used in the GAN literature: MNIST <ref type="bibr" target="#b13">[14]</ref>, Fashion-MNIST <ref type="bibr" target="#b23">[24]</ref>, and CIFAR-10 <ref type="bibr" target="#b12">[13]</ref>. These data sets are labeled and consist of 10 balanced classes. To show the sensitivity of the proposed measure to mode dropping and mode inventing, we first fixP to contain samples from the first 5 classes in the respective test set. Then, for a fixed i = 1, 2, . . . , 10, we generate a setQ i , which consists of samples from the first i classes from the train set. As i increases, Q i covers an increasing number of classes fromP which should result in a higher As we increase i beyond 5,Q i includes samples from an increasing number of classes that are not present inP which should result in a loss in precision, but not in recall as the other classes are already covered. Finally, the setQ 5 covers the same classes asP, so it should have high precision and high recall.  <ref type="figure" target="#fig_0">Figure 11</ref> in the appendix). As we add classes toQ i , the IS increases. Since the IS is not computed w.r.t. a reference distribution, it is invariant to the choice ofP. The FID decreases as we add more classes untilQ 5 before it starts to increase as we add spurious modes. Critically, FID fails to distinguish the cases of mode dropping and mode inventing -Q 4 andQ 6 share similar FIDs. In contrast, <ref type="figure" target="#fig_4">Figure 5</ref> (middle) shows our PRD curves as we vary the number of classes inQ i . Adding correct modes leads to an increase in recall, while adding fake modes leads to a loss of precision.</p><p>We also apply the proposed approach on text data as shown in <ref type="figure" target="#fig_4">Figure 5</ref> (right). In particular, we use the MultiNLI corpus of crowd-sourced sentence pairs annotated with topic and textual entailment information <ref type="bibr" target="#b21">[22]</ref>. After discarding the entailment label, we collect all unique sentences for the same topic. Following <ref type="bibr" target="#b5">[6]</ref>, we embed these sentences using a BiLSTM with 2048 cells in each direction and max pooling, leading to a 4096-dimensional embedding <ref type="bibr" target="#b6">[7]</ref>. We consider 5 classes from this data set and setP to contain samples from all classes and to measure the loss in recall for different Q i . <ref type="figure" target="#fig_4">Figure 5 (right)</ref> shows that PRD curves demonstrate the sensitivity to mode dropping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Assessing class imbalances for GANs</head><p>In this section we analyze the effect of class imbalance on the PRD curves. <ref type="figure">Figure 6</ref> shows a pair of GANs trained on MNIST which have virtually the same FID, but very different PRD curves. The model on the left generates a subset of the digits of high quality, while the model on the right seems to generate all digits, but each has low quality. We can naturally interpret this difference via the PRD curves: For a desired recall level of less than ∼0.6, the model on the left enjoys higher precision  <ref type="figure">Figure 6</ref>: Comparing two GANs trained on MNIST which both achieve an FID of 49. The model on the left seems to produce high-quality samples of only a subset of digits. On the other hand, the model on the right generates low-quality samples of all digits. The histograms showing the corresponding class distributions based on a trained MNIST classifier confirm this observation. At the same time, the classifier is more confident which indicates different levels of precision (96.7% for the model on the left compared to 88.6% for the model on the right). Finally, we note that the proposed PRD algorithm does not require labeled data, as opposed to the IS which further needs a classifier that was trained on the respective data set.</p><p>-it generates several digits of high quality. If, however, one desires a recall higher than ∼0.6, the model on the right enjoys higher precision -it covers all digits, but generates low-quality samples. To confirm this, we train an MNIST classifier on the embedding ofP with the ground truth labels and plot the distribution of the predicted classes for both models. The histograms clearly show that the model on the left failed to generate all classes (loss of recall), while the model on the right is producing a more balanced distribution over all classes (high recall). At the same time, the classifier has an average confidence 3 of 96.7% on the model on the left compared to 88.6% on the model on the right, indicating that the sample quality of the former is higher. This aligns very well with the PRD plots: samples on the left have high quality but are not diverse in contrast to the samples on the right which are diverse but have low quality. This analysis reveals a connection to IS which is based on the premise that the conditional label distribution p(y|x) should have low entropy, while the marginal p(y) = p(y|x = G(z))dz should have high entropy. To further analyze the relationship between the proposed approach and PRD curves, we plot p(y|x) against precision and p(y) against recall metric in <ref type="figure" target="#fig_0">Figure 10</ref> in the appendix. The results over a large number of GANs and VAEs show a large Spearman correlation of -0.83 for precision and 0.89 for recall. We stress two key differences: Firstly, to compute the quantities in IS one needs a classifier and a labeled data set in contrast to our metric which can be applied on unlabeled data. Secondly, IS only captures losses in recall w.r.t. classes, while our metric measures more fine-grained recall losses (e.g. the lack of tilted digits, see <ref type="figure" target="#fig_8">Figure 8</ref> in the appendix).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Application to GANs and VAEs</head><p>We evaluate the precision and recall of 7 GAN types and the VAE with 100 hyperparameter settings each as provided by <ref type="bibr" target="#b16">[17]</ref>. In order to visualize this vast quantity of models, one needs to summarize the PRD curves. A natural idea is to compute the maximum F 1 score, which corresponds to the harmonic mean between precision and recall, as a single-number summary. However, F 1 has a critical drawback as is symmetric. Its generalization, defined as</p><formula xml:id="formula_11">F β = (1 + β 2 )</formula><p>p·r (β 2 p)+r , provides a way to quantify the relative importance of precision and recall: β &gt; 1 weighs recall higher than precision, whereas β &lt; 1 weighs precision higher than recall. As a result, we propose to distill each PRD curve into a pair of values: F β and F 1/β . <ref type="figure" target="#fig_6">Figure 7</ref> compares the maximum F 8 with the maximum F 1/8 for these models on the Fashion-MNIST data set. We chose β = 8 as it offers a good insight into the bias towards precision versus recall. Since F 8 weighs recall higher than precision and F 1/8 does the opposite, models with higher recall than precision will lie below the diagonal F 8 = F 1/8 and models with higher precision than recall and F8 scores to show the tradeoff between precision and recall. VAEs generally achieve lower precision and/or higher recall than GANs which matches the folklore that VAEs often produce samples of lower quality while being less prone to mode collapse. On the right we show samples from four models which correspond to various success/failure modes: (A) high precision, low recall, (B) high precision, high recall, (C) low precision, low recall, and (D) low precision, high recall.</p><p>will lie above. According to folklore, VAEs should achieve high recall, but suffer from precision issues (e.g. due to blurring effects). To our knowledge this is the first metric which clearly shows that this is indeed the case for the considered data set. On the right, we show samples from four models on the extreme ends of the plot for all combinations of high and low precision and recall. We have included similar plots on the MNIST, CIFAR-10 and CelebA data sets in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Quantitatively evaluating generative models is a challenging task of paramount importance. Classic evaluation methods, such as comparing the log-likelihood, can be misleading and run the risk of assigning a higher score to a worse model <ref type="bibr" target="#b20">[21]</ref>. As a remedy, several recently introduced scores, such as IS and FID, can be used as proxy measures which are well correlated with the perceptual quality of the generated samples.</p><p>In this work we show that one-dimensional scores are not sufficient to capture different failure cases of current state-of-the-art generative models. As an alternative, we propose a novel notion of precision and recall for distributions and prove that both notions are theoretically sound and have desirable properties. We then connect these notions to total variation distance as well as FID and IS. We then develop an efficient algorithm that can be readily applied to evaluate deep generative models based on samples. We investigate the properties of the proposed algorithm on real-world data sets, including image and text generation, and show that it captures the precision and recall of generative models. Finally, we find some empirical evidence which is well aligned with the folklore that VAEs produce samples of lower quality, while being less prone to mode collapse than GANs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Proofs</head><p>We first show the following auxiliary result and then prove Theorems 1 and 2. Lemma 1. Let P and Q be probability distributions defined on a finite state space Ω. Let α ∈ (0, 1] and β ∈ (0, 1]. Then, (α, β) ∈ PRD(Q, P) if and only if there exists a distribution µ such that for all ω ∈ Ω P(ω) ≥ βµ(ω) and Q(ω) ≥ αµ(ω).</p><p>Proof. If (α, β) ∈ PRD(Q, P), then (3) and the non-negativity of ν P and ν Q directly imply <ref type="formula" target="#formula_12">(5)</ref> for the same choice of µ. Conversely, if (5) holds for a distribution µ, we may define the distributions</p><formula xml:id="formula_13">ν P (ω) = P(ω) − βµ(ω) 1 − β and ν Q (ω) = Q(ω) − αµ(ω) 1 − α .</formula><p>By definition α, β, µ, ν P and ν Q satisfy (3) in Definition 1 which implies (α, β) ∈ PRD(Q, P).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Proof of Theorem 1</head><p>Proof. We show each of the properties independently:</p><p>(i) Equality: If (1, 1) ∈ PRD(Q, P), then we have by Definition 1 that P = µ and Q = µ which implies P = Q as claimed. Conversely, if P = Q, Definition 1 is satisfied for α = β = 1 by choosing µ = ν P = ν Q = P. Hence, (1, 1) ∈ PRD(Q, P) as claimed.</p><p>(ii) Disjoint support: We show both directions of the claim by contraposition, i.e., we show supp(P) ∩ supp(Q) = ∅ ⇔ PRD(Q, P) ⊃ {(0, 0)}. Consider an arbitrary ω ∈ supp(P) ∩ supp(Q). Then, by definition we have P(ω) &gt; 0 and Q(ω) &gt; 0. Let µ be defined as the distribution with µ(ω) = 1 and µ(ω ) = 0 for all ω ∈ Ω \ {ω}. Clearly, it holds that P(ω) ≥ P(ω)µ(ω) and Q(ω) ≥ Q(ω)µ(ω) for all ω ∈ Ω. Hence, by Lemma 1, we have (Q(ω), P(ω)) ∈ PRD(Q, P) which implies that PRD(Q, P) ⊃ {(0, 0)} as claimed. Conversely, PRD(Q, P) ⊃ {(0, 0)} implies by Lemma 1 that there exist α ∈ (0, 1] and β ∈ (0, 1] as well as a distribution µ satisfying (5). Let ω ∈ supp(µ) which implies µ(ω) &gt; 0 and thus by (5) also P(ω) &gt; 0 and Q(ω) &gt; 0. Hence, ω is both in the support of P and Q which implies supp(P) ∩ supp(Q) = ∅ as claimed.</p><p>(iii) Maximum precision: If (α, β) ∈ PRD(Q, P), then by Lemma 1 there exists a distribution µ such that for all ω ∈ Ω we have P(ω) ≥ βµ(ω) and Q(ω) ≥ αµ(ω). P(ω) ≥ βµ(ω) implies supp(µ) ⊆ supp(P) and hence ω∈supp(P) µ(ω) = 1. Together with Q(ω) ≥ αµ(ω), this yields Q(supp(P)) = ω∈supp(P) Q(ω) ≥ α ω∈supp(P) µ(ω) = α which implies α ≤ Q(supp(P)) for all (α, β) ∈ PRD(Q, P).</p><p>To prove the claim, we next show that there exists (α, β) ∈ PRD(Q, P) with α = Q(supp(P)). Let S = supp(P) ∩ supp(Q). If S = ∅, then α = Q(supp(P)) = 0 and (0, 0) ∈ PRD(Q, P) by Definition 2 as claimed. For the case S = ∅, let β = min ω∈S</p><formula xml:id="formula_14">P(ω)Q(S) Q(ω)</formula><p>. By definition of S, we have β &gt; 0. Furthermore, β ≤ P(S) ≤ 1 since</p><formula xml:id="formula_15">P(ω) P(S) ≤ Q(ω)</formula><p>Q(S) for at least one ω ∈ S. Consider the distribution µ where µ(ω) = Q(ω) Q(S) for all ω ∈ S and µ(ω) = 0 for ω ∈ Ω \ S. By construction, µ satisfies (5) in Lemma 1 and hence (α, β) ∈ PRD(Q, P) as claimed.</p><p>(iv) Maximum recall: This follows directly from applying Property (vi) to Property (iii).</p><p>(v) Monotonicity: If (α, β) ∈ PRD(Q, P), then by Lemma 1 there exists a distribution µ such that for all ω ∈ Ω we have that P(ω) ≥ βµ(ω) and Q(ω) ≥ αµ(ω). For α ∈ (0, α] and β ∈ (0, β], it follows that P(ω) ≥ β µ(ω) and Q(ω) ≥ α µ(ω) for all ω ∈ Ω. By Lemma 1 this implies (α , β ) ∈ PRD(Q, P) as claimed. (vi) Duality: This follows directly from switching α with β, P with Q and ν P with ν Q in Definition 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Proof of Theorem 2</head><p>Proof. We first show that PRD(Q, P) ⊆ {(θα(λ), θβ(λ)) | λ ∈ (0, ∞), θ ∈ [0, 1]}. We consider an arbitrary element (α , β ) ∈ PRD(Q, P) and show that (α , β ) = (θα(λ), θβ(λ)) for some λ ∈ (0, ∞) and θ ∈ [0, 1]. For the case (α , β ) = (0, 0), the result holds trivially for the choice of λ = 1 and θ = 0. For the case (α , β ) = (0, 0), we choose λ = and thus β µ(ω) ≤ min P(ω),</p><formula xml:id="formula_16">Q(ω) λ for all ω ∈ Ω.</formula><p>Summing over all ω ∈ Ω, we obtain β ≤ ω∈Ω min P(ω),</p><formula xml:id="formula_17">Q(ω) λ = β(λ) which implies θ ∈ [0, 1]. Finally, we show that PRD(Q, P) ⊇ {(θα(λ), θβ(λ)) | λ ∈ (0, ∞), θ ∈ [0, 1]}. Consider arbitrary λ ∈ (0, ∞) and θ ∈ [0, 1].</formula><p>If β(λ) = 0, the claim holds trivially since (0, 0) ∈ PRD(Q, P). Otherwise, define the distribution µ by µ(ω) = min P(ω),</p><formula xml:id="formula_18">Q(ω) λ /β(λ) for all ω ∈ Ω. By definition, β(λ)µ(ω) ≤ min P(ω), Q(ω) λ ≤ P(ω) for all ω ∈ Ω. Similarly, α(λ)µ(ω) ≤ min (λP(ω), Q(ω)) ≤ Q(ω) for all ω ∈ Ω since α(λ) = λβ(λ)</formula><p>. Because θ ∈ [0, 1], this implies θβ(λ)µ(ω) ≤ P(ω) and θα(λ)µ(ω) ≤ Q(ω) for all ω ∈ Ω. Hence, by Lemma 1, (θα(λ), θβ(λ)) ∈ PRD(Q, P) for all λ ∈ (0, ∞) and θ ∈ [0, 1] as claimed. s. An analysis with a trained classifier as in Section 4.2 comes to the same conclusion for both models, namely, that they have collapsed to producing 1's only. However, the PRD curve shows that the model on the right has a higher recall. This is indeed correct: while the model on the left is producing straight 1's only, the model on the right is producing some more varied shapes such as tilted 1's.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Further figures</head><p>Real images Generated images <ref type="figure">Figure 9</ref>: Clustering the real and generated samples from a GAN in feature space (10 cluster centers for visualization) yields the clusters above for the data sets MNIST, Fashion-MNIST, CIFAR-10 and CelebA. Although the GAN samples are not perfect, they are clustered in a meaningful way.  Figure 11: Corresponding plots as in <ref type="figure" target="#fig_4">Figure 5</ref> for the data sets MNIST (top) and Fashion-MNIST (bottom).  <ref type="figure" target="#fig_6">Figure 7</ref> for the data sets MNIST (top), CIFAR-10 (middle) and CelebA (bottom).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Comparison of GANs trained on MNIST and CelebA. Although the models obtain a similar FID on each data set (32/29 for MNIST and 65/62 for CelebA), their samples look very different. For example, the model on the left produces reasonably looking faces on CelebA, but too many dark images. In contrast, the model on the right produces more artifacts, but more varied images. By the proposed metric (middle), the models on the left achieve higher precision and lower recall than the models on the right, which suffices to successfully distinguishing between the failure cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>) Figure 2 :Figure 3 :Figure 4 :</head><label>)234</label><figDesc>Figure 2: Intuitive examples of P and Q.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a)-(d) shows four toy examples for P and Q to visualize this idea: (a) If P is bimodal and Q only captures one of the modes, we should have perfect precision but only limited recall. (b) In the opposite case, we should have perfect recall but only limited precision. (c) If Q = P, we should have perfect precision and recall. (d) If the supports of P and Q are disjoint, we should have zero precision and recall.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 (</head><label>5</label><figDesc>Figure 5 (left) shows the IS and FID for the CIFAR-10 data set (results on the other data sets are shown in Figure 11 in the appendix). As we add classes toQ i , the IS increases. Since the IS is not computed w.r.t. a reference distribution, it is invariant to the choice ofP. The FID decreases as we add more classes untilQ 5 before it starts to increase as we add spurious modes. Critically, FID fails to distinguish the cases of mode dropping and mode inventing -Q 4 andQ 6 share similar FIDs. In contrast, Figure 5 (middle) shows our PRD curves as we vary the number of classes inQ i . Adding correct modes leads to an increase in recall, while adding fake modes leads to a loss of precision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: F 1/8 vs F8 scores for a large number of GANs and VAEs on the Fashion-MNIST data set. For each model, we plot the maximum F 1/8 and F8 scores to show the tradeoff between precision and recall. VAEs generally achieve lower precision and/or higher recall than GANs which matches the folklore that VAEs often produce samples of lower quality while being less prone to mode collapse. On the right we show samples from four models which correspond to various success/failure modes: (A) high precision, low recall, (B) high precision, high recall, (C) low precision, low recall, and (D) low precision, high recall.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>λ) . Since α(λ) = λβ(λ) by definition, this implies (α , β ) = (θα(λ), θβ(λ)) as required. Furthermore, λ ∈ (0, ∞) since by Definitions 1 and 2 α &gt; 0 if and only if β &gt; 0. Similarly, we show that θ ∈ [0, 1]: By Lemma 1 there exists a distribution µ such that β µ(ω) ≤ P(ω) and α µ(ω) ≤ Q(ω) for all ω ∈ Ω. This implies that β µ(ω) ≤ Q(ω) λ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Comparing a pair of GANs on MNIST which have both collapsed to producing 1's. An analysis with a trained classifier as in Section 4.2 comes to the same conclusion for both models, namely, that they have collapsed to producing 1's only. However, the PRD curve shows that the model on the right has a higher recall. This is indeed correct: while the model on the left is producing straight 1's only, the model on the right is producing some more varied shapes such as tilted 1's.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Comparing our unsupervised F 1/8 and F8 measures with the supervised measures P (y|x) and P (y) similar to the IS (for a definition of F β , see Section 4.3). Each circle represents a trained generative model (GAN or VAE) on the MNIST data set. The values show a fairly high correlation with a Spearman rank correlation coefficient of -0.83 on the left and 0.89 on the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>Figure 12: Corresponding plots as in Figure 7 for the data sets MNIST (top), CIFAR-10 (middle) and CelebA (bottom).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">For a distribution P defined on a finite state space Ω, we define supp(P) = {ω ∈ Ω | P(ω) &gt; 0}.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We denote the output of the classifier for its highest value at the softmax layer as confidence. The intuition is that higher values signify higher confidence of the model for the given label.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast and provably good seedings for k-means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bachem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Hassani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Approximate k-means++ in sublinear time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bachem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Hamed Hassani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krause</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A Note on the Inception Score</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Barratt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishi</forename><surname>Sharma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.01973</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikołaj</forename><surname>Bińkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Arbel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Demystifying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gans</surname></persName>
		</author>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Pros and Cons of GAN Evaluation Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Borji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03446</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Eval all, trust a few, do wrong to none: Comparing sentence generation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Cífka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Filippova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07972</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.02364</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generative Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">GANs trained by a two time-scale update rule converge to a Nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günter</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<idno type="arXiv">arXiv:1511.05101</idno>
		<title level="m">Ferenc Huszár. How (not) to Train your Generative Model: Scheduled Sampling, Likelihood, Adversary? arXiv preprint</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Quantitatively evaluating GANs with divergences proposed for training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Daniel Jiwoong Im</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Branson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Auto-encoding Variational Bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Revisiting Classifier Two-Sample Tests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Oquab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Are GANs Created Equal? A Large-Scale Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.10337</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Deconvolution and checkerboard artifacts. Distill</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improved Techniques for Training GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Web-scale k-means clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web (WWW)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Aäron van den Oord, and Matthias Bethge. A note on the evaluation of generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05426</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the quantitative analysis of decoder-based generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<title level="m">Fashion-MNIST: A Novel Image Dataset for Benchmarking Machine Learning Algorithms</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
