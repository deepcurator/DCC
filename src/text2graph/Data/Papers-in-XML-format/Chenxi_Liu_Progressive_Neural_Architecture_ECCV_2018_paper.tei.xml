<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T23:17+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Progressive Neural Architecture Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Neumann</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google AI</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Google AI</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Progressive Neural Architecture Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract. We propose a new method for learning the structure of convolutional neural networks (CNNs) that is more efficient than recent state-of-the-art methods based on reinforcement learning and evolutionary algorithms. Our approach uses a sequential model-based optimization (SMBO) strategy, in which we search for structures in order of increasing complexity, while simultaneously learning a surrogate model to guide the search through structure space. Direct comparison under the same search space shows that our method is up to 5 times more efficient than the RL method of <ref type="bibr" target="#b40">Zoph et al. (2018)</ref> in terms of number of models evaluated, and 8 times faster in terms of total compute. The structures we discover in this way achieve state of the art classification accuracies on CIFAR-10 and ImageNet.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There has been a lot of recent interest in automatically learning good neural net architectures. Some of this work is summarized in Section 2, but at a high level, current techniques usually fall into one of two categories: evolutionary algorithms (see e.g. <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b34">35]</ref>) or reinforcement learning (see e.g., <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b1">2]</ref>). When using evolutionary algorithms (EA), each neural network structure is encoded as a string, and random mutations and recombinations of the strings are performed during the search process; each string (model) is then trained and evaluated on a validation set, and the top performing models generate "children". When using reinforcement learning (RL), the agent performs a sequence of actions, which specifies the structure of the model; this model is then trained and its validation performance is returned as the reward, which is used to update the RNN controller. Although both EA and RL methods have been able to learn network structures that outperform manually designed architectures, they require significant computational resources. For example, the RL method in <ref type="bibr" target="#b40">[41]</ref> trains and evaluates 20,000 neural networks across 500 P100 GPUs over 4 days.</p><p>In this paper, we describe a method that is able to learn a CNN which matches previous state of the art in terms of accuracy, while requiring 5 times fewer model evaluations during the architecture search. Our starting point is the structured search space proposed by <ref type="bibr" target="#b40">[41]</ref>, in which the search algorithm is tasked with searching for a good convolutional "cell", as opposed to a full CNN. A cell contains B "blocks", where a block is a combination operator (such as addition) applied to two inputs (tensors), each of which can be transformed (e.g., using convolution) before being combined. This cell structure is then stacked a certain number of times, depending on the size of the training set, and the desired running time of the final CNN (see Section 3 for details). This modular design also allows easy architecture transfer from one dataset to another, as we will show in experimental results.</p><p>We propose to use heuristic search to search the space of cell structures, starting with simple (shallow) models and progressing to complex ones, pruning out unpromising structures as we go. At iteration b of the algorithm, we have a set of K candidate cells (each of size b blocks), which we train and evaluate on a dataset of interest. Since this process is expensive, we also learn a model or surrogate function which can predict the performance of a structure without needing to training it. We expand the K candidates of size b into K ′ ≫ K children, each of size b + 1. We apply our surrogate function to rank all of the K ′ children, pick the top K, and then train and evaluate them. We continue in this way until b = B, which is the maximum number of blocks we want to use in our cell. See Section 4 for details.</p><p>Our progressive (simple to complex) approach has several advantages over other techniques that directly search in the space of fully-specified structures. First, the simple structures train faster, so we get some initial results to train the surrogate quickly. Second, we only ask the surrogate to predict the quality of structures that are slightly different (larger) from the ones it has seen (c.f., trust-region methods). Third, we factorize the search space into a product of smaller search spaces, allowing us to potentially search models with many more blocks. In Section 5 we show that our approach is 5 times more efficient than the RL method of <ref type="bibr" target="#b40">[41]</ref> in terms of number of models evaluated, and 8 times faster in terms of total compute. We also show that the structures we discover achieve state of the art classification accuracies on CIFAR-10 and ImageNet. <ref type="bibr" target="#b3">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our paper is based on the "neural architecture search" (NAS) method proposed in <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41]</ref>. In the original paper <ref type="bibr" target="#b39">[40]</ref>, they use the REINFORCE algorithm <ref type="bibr" target="#b33">[34]</ref> to estimate the parameters of a recurrent neural network (RNN), which represents a policy to generate a sequence of symbols (actions) specifying the structure of the CNN; the reward function is the classification accuracy on the validation set of a CNN generated from this sequence. <ref type="bibr" target="#b40">[41]</ref> extended this by using a more structured search space, in which the CNN was defined in terms of a series of stacked "cells". (They also replaced REINFORCE with proximal policy optimization (PPO) <ref type="bibr" target="#b28">[29]</ref>.) This method was able to learn CNNs which outperformed almost all previous methods in terms of accuracy vs speed on image classification (using CIFAR-10 <ref type="bibr" target="#b18">[19]</ref> and ImageNet <ref type="bibr" target="#b7">[8]</ref>) and object detection (using COCO <ref type="bibr" target="#b19">[20]</ref>).</p><p>There are several other papers that use RL to learn network structures. <ref type="bibr" target="#b38">[39]</ref> use the same model search space as NAS, but replace policy gradient with Qlearning. <ref type="bibr" target="#b1">[2]</ref> also use Q-learning, but without exploiting cell structure. <ref type="bibr" target="#b4">[5]</ref> use policy gradient to train an RNN, but the actions are now to widen an existing layer, or to deepen the network by adding an extra layer. This requires specifying an initial model and then gradually learning how to transform it. The same approach, of applying "network morphisms" to modify a network, was used in <ref type="bibr" target="#b11">[12]</ref>, but in the context of hill climbing search, rather than RL. <ref type="bibr" target="#b25">[26]</ref> use parameter sharing among child models to substantially accelerate the search process.</p><p>An alternative to RL is to use evolutionary algorithms (EA; "neuro-evolution" <ref type="bibr" target="#b31">[32]</ref>). Early work (e.g., <ref type="bibr" target="#b32">[33]</ref>) used EA to learn both the structure and the parameters of the network, but more recent methods, such as <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27]</ref>, just use EA to search the structures, and use SGD to estimate the parameters.</p><p>RL and EA are local search methods that search through the space of fullyspecified graph structures. An alternative approach, which we adopt, is to use heuristic search, in which we search through the space of structures in a progressive way, from simple to complex. There are several pieces of prior work that explore this approach. <ref type="bibr" target="#b24">[25]</ref> use Monte Carlo Tree Search (MCTS), but at each node in the search tree, it uses random selection to choose which branch to expand, which is very inefficient. Sequential Model Based Optimization (SMBO) <ref type="bibr" target="#b16">[17]</ref> improves on MCTS by learning a predictive model, which can be used to decide which nodes to expand. This technique has been applied to neural net structure search in <ref type="bibr" target="#b24">[25]</ref>, but they used a flat CNN search space, rather than our hierarchical cell-based space. Consequently, their resulting CNNs do not perform very well. Other related works include <ref type="bibr" target="#b22">[23]</ref>, who focus on MLP rather than CNNs; <ref type="bibr" target="#b32">[33]</ref>, who used an incremental approach in the context of evolutionary algorithms; <ref type="bibr" target="#b39">[40]</ref> who used a schedule of increasing number of layers; and <ref type="bibr" target="#b12">[13]</ref> who search through the space of latent factor models specified by a grammar. Finally, <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16]</ref> grow CNNs sequentially using boosting.</p><p>Several other papers learn a surrogate function to predict the performance of a candidate structure, either "zero shot" (without training it) (see e.g., <ref type="bibr" target="#b3">[4]</ref>), or after training it for a small number of epochs and extrapolating the learning curve (see e.g., <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b2">3]</ref>). However, most of these methods have been applied to fixed sized structures, and would not work with our progressive search approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Architecture Search Space</head><p>In this section we describe the neural network architecture search space used in our work. We build on the hierarchical approach proposed in <ref type="bibr" target="#b40">[41]</ref>, in which we first learn a cell structure, and then stack this cell a desired number of times, in order to create the final CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Cell Topologies</head><p>A cell is a fully convolutional network that maps an H ×W ×F tensor to another H ′ ×W ′ ×F ′ tensor. If we use stride 1 convolution, then H ′ = H and W ′ = W ; if we use stride 2, then H ′ = H/2 and W ′ = W/2. We employ a common heuristic to double the number of filters (feature maps) whenever the spatial activation is halved, so F ′ = F for stride 1, and F ′ = 2F for stride 2. The cell can be represented by a DAG consisting of B blocks. Each block is a mapping from 2 input tensors to 1 output tensor. We can specify a block b in a cell c as a 5-tuple, (I 1 , I 2 , O 1 , O 2 , C), where I 1 , I 2 ∈ I b specifies the inputs to the block, O 1 , O 2 ∈ O specifies the operation to apply to input I i , and C ∈ C specifies how to combine O 1 and O 2 to generate the feature map (tensor) corresponding to the output of this block, which we denote by H • 3x3 depthwise-separable convolution • 5x5 depthwise-separable convolution • 7x7 depthwise-separable convolution • 1x7 followed by 7x1 convolution</p><formula xml:id="formula_0">• identity • 3x3 average pooling • 3x3 max pooling • 3x3 dilated convolution</formula><p>This is less than the 13 operators used in <ref type="bibr" target="#b40">[41]</ref>, since we removed the ones that their RL method discovered were never used. For the space of possible combination operators C, <ref type="bibr" target="#b40">[41]</ref> considerd both elementwise addition and concatenation. However, they discovered that the RL method never chose to use concatenation, so to reduce our search space, we always use addition as the combination operator. Thus in our work, a block can be specified by a 4-tuple.</p><p>We now quantify the size of the search space to highlight the magnitude of the search problem. Let the space of possible structures for the b'th block be B b ; this has size If we allow cells of up to B = 5 blocks, the total number of cell structures is given by |B 1:</p><formula xml:id="formula_1">|B b | = |I b | 2 × |O| 2 × |C|,</formula><formula xml:id="formula_2">5 | = 2 2 × 8 2 × 3 2 × 8 2 × 4 2 × 8 2 × 5 2 × 8 2 × 6 2 × 8 2 = 5.6 × 10</formula><p>14 . However, there are certain symmetries in this space that allow us to prune it to a more reasonable size. For example, there are only 136 unique cells composed of 1 block. The total number of unique cells is ∼ 10</p><p>12 . This is much smaller than the search space used in <ref type="bibr" target="#b40">[41]</ref>, which has size 10 28 , but it is still an extremely large space to search, and requires efficient optimization methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">From Cell to CNN</head><p>To evaluate a cell, we have to convert it into a CNN. To do this, we stack a predefined number of copies of the basic cell (with the same structure, but untied weights), using either stride 1 or stride 2, as shown in <ref type="figure" target="#fig_2">Figure 1</ref> (right). The number of stride-1 cells between stride-2 cells is then adjusted accordingly with up to N number of repeats. At the top of the network, we use global average pooling, followed by a softmax classification layer. We then train the stacked model on the relevant dataset.</p><p>In the case of CIFAR-10, we use 32 × 32 images. In the case of ImageNet, we consider two settings, one with high resolution images of size 331 × 331, and one with smaller images of size 224 × 224. The latter results in less accurate models, but they are faster. For ImageNet, we also add an initial 3 × 3 convolutional filter layer with stride 2 at the start of the network, to further reduce the cost.</p><p>The overall CNN construction process is identical to <ref type="bibr" target="#b40">[41]</ref>, except we only use one cell type (we do not distinguish between Normal and Reduction cells, but instead emulate a Reduction cell by using a Normal cell with stride 2), and the cell search space is slightly smaller (since we use fewer operators and combiners).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Progressive Neural Architecture Search</head><p>Many previous approaches directly search in the space of full cells, or worse, full CNNs. For example, NAS uses a 50-step RNN 6 as a controller to generate cell specifications. In <ref type="bibr" target="#b34">[35]</ref> a fixed-length binary string encoding of CNN architecture</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Progressive Neural Architecture Search (PNAS).</head><p>Inputs: B (max num blocks), E (max num epochs), F (num filters in first layer), K (beam size), N (num times to unroll cell), trainSet, valSet. S1 = B1 // Set of candidate structures with one block M1 = cell-to-CNN(S1, N , F ) // Construct CNNs from cell specifications C1 = train-CNN(M1, E, trainSet) // Train proxy CNNs A1 = eval-CNN(C1, valSet) // Validation accuracies π = fit(S1, A1) // Train the reward predictor from scratch</p><formula xml:id="formula_3">for b = 2 : B do S ′ b = expand-cell(S b−1 ) // Expand current candidate cells by one more block A ′ b = predict(S ′ b , π) // Predict accuracies using reward predictor S b = top-K(S ′ b ,Â ′ b , K) // Most promising cells according to prediction M b = cell-to-CNN(S b , N , F ) C b = train-CNN(M b , E, trainSet) A b = eval-CNN(C b , valSet) π = update-predictor(S b , A b , π) // Finetune reward predictor with new data end for Return top-K(SB, AB, 1)</formula><p>is defined and used in model evolution/mutation. While this is a more direct approach, we argue that it is difficult to directly navigate in an exponentially large search space, especially at the beginning where there is no knowledge of what makes a good model.</p><p>As an alternative, we propose to search the space in a progressive order, simplest models first. In particular, we start by constructing all possible cell structures from B 1 (i.e., composed of 1 block), and add them to a queue. We train and evaluate all the models in the queue (in parallel), and then expand each one by adding all of the possible block structures from B 2 ; this gives us a set of |B 1 | × |B 2 | = 256 × 576 = 147, 456 candidate cells of depth 2. Since we cannot afford to train and evaluate all of these child networks, we refer to a learned predictor function (described in Section 4.2); it is trained based on the measured performance of the cells we have visited so far. (Our predictor takes negligible time to train and apply.) We then use the predictor to evaluate all the candidate cells, and pick the K most promising ones. We add these to the queue, and repeat the process, until we find cells with a sufficient number B of blocks. See Algorithm 1 for the pseudocode, and <ref type="figure" target="#fig_3">Figure 2</ref> for an illustration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Performance Prediction with Surrogate Model</head><p>As explained above, we need a mechanism to predict the final performance of a cell before we actually train it. There are at least three desired properties of such a predictor:</p><p>-Handle variable-sized inputs: We need the predictor to work for variablelength input strings. In particular, it should be able to predict the performance of any cell with b + 1 blocks, even if it has only been trained on cells with up to b blocks. </p><note type="other">procedure when the maximum number of blocks is B = 3. Here S b represents the set of candidate cells with b blocks. We start by considering all cells with 1 block, S1 = B1; we train and evaluate all of these cells, and update the predictor. At iteration 2, we expand each of the cells in S1 to get all cells with 2 blocks, S ′ 2 = B1:2; we predict their scores, pick the top K to get S2, train and evaluate them, and update the predictor. At iteration 3, we expand each of the cells in S2, to get a subset of cells with 3 blocks, S ′ 3 ⊆ B1:3; we predict their scores, pick the top K to get S3, train and evaluate them, and return the winner. B b = |B b | is the number of possible blocks at level b and K is the beam size (number of models we train and evaluate per level of the search tree).</note><p>-Correlated with true performance: we do not necessarily need to achieve low mean squared error, but we do want the predictor to rank models in roughly the same order as their true performance values. -Sample efficiency: We want to train and evaluate as few cells as possible, which means the training data for the predictor will be scarce.</p><p>The requirement that the predictor be able to handle variable-sized strings immediately suggests the use of an RNN, and indeed this is one of the methods we try. In particular, we use an LSTM that reads a sequence of length 4b (representing I 1 , I 2 , O 1 and O 2 for each block), and the input at each step is a one-hot vector of size |I b | or |O|, followed by embedding lookup. We use a shared embedding of dimension D for the tokens I 1 , I 2 ∈ I, and another shared embedding for O 1 , O 2 ∈ O. The final LSTM hidden state goes through a fully-connected layer and sigmoid to regress the validation accuracy. We also try a simpler MLP baseline in which we convert the cell to a fixed length vector as follows: we embed each token into an D-dimensional vector, concatenate the embeddings for each block to get an 4D-dimensional vector, and then average over blocks. Both models are trained using L 1 loss.</p><p>When training the predictor, one approach is to update the parameters of the predictor using the new data using a few steps of SGD. However, since the sample size is very small, we fit an ensemble of 5 predictors, each fit (from scratch) to 4/5 of all the data available at each step of the search process. We observed empirically that this reduced the variance of the predictions.</p><p>In the future, we plan to investigate other kinds of predictors, such as Gaussian processes with string kernels (see e.g., <ref type="bibr" target="#b0">[1]</ref>), which may be more sample efficient to train and produce predictions with uncertainty estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Details</head><p>Our experimental setting follows <ref type="bibr" target="#b40">[41]</ref>. In particular, we conduct most of our experiments on CIFAR-10 <ref type="bibr" target="#b18">[19]</ref>. CIFAR-10 has 50,000 training images and 10,000 test images. We use 5000 images from the training set as a validation set. All images are whitened, and 32 × 32 patches are cropped from images upsampled to 40 × 40. Random horizontal flip is also used. After finding a good model on CIFAR-10, we evaluate its quality on ImageNet classification in Section 5.5.</p><p>For the MLP accuracy predictor, the embedding size is 100, and we use 2 fully connected layers, each with 100 hidden units. For the RNN accuracy predictor, we use an LSTM, and the hidden state size and embedding size are both 100. The embeddings use uniform initialization in range [-0.1, 0.1]. The bias term in the final fully connected layer is initialized to 1.8 (0.86 after sigmoid) to account for the mean observed accuracy of all b = 1 models. We use the Adam optimizer <ref type="bibr" target="#b17">[18]</ref> with learning rate 0.01 for the b = 1 level and 0.002 for all following levels.</p><p>Our training procedure for the CNNs follows the one used in <ref type="bibr" target="#b40">[41]</ref>. During the search we evaluate K = 256 networks at each stage (136 for stage 1, since there are only 136 unique cells with 1 block), we use a maximum cell depth of B = 5 blocks, we use F = 24 filters in the first convolutional cell, we unroll the cells for N = 2 times, and each child network is trained for 20 epochs using initial learning rate of 0.01 with cosine decay <ref type="bibr" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance of the Surrogate Predictors</head><p>In this section, we compare the performance of different surrogate predictors. Note that at step b of PNAS, we train the predictor on the observed performance of cells with up to b blocks, but we apply it to cells with b+1 blocks. We therefore consider predictive accuracy both for cells with sizes that have been seen before (but which have not been trained on), and for cells which are one block larger than the training data.</p><p>More precisely, let U b,1:R be a set of randomly chosen cells with b blocks, where R = 10, 000. (For b = 1, there are only 136 unique cells.) We convert each of these to CNNs, and train them for E = 20 epochs. (Thus in total we train Algorithm 2 Evaluating performance of a predictor on a random dataset. ∼ (B − 1) × R = 40, 000 models for 20 epochs each.) We now use this random dataset to evaluate the performance of the predictors using the pseudocode in Algorithm 2, where A(H) returns the true validation set accuracies of the models in some set H. In particular, for each size b = 1 : B, and for each trial t = 1 : T (we use T = 20), we do the following: randomly select K = 256 models (each of size b) from U b,1:R to generate a training set S b,t,1:K ; fit the predictor on the training set; evaluate the predictor on the training set; and finally evaluate the predictor on the set of all unseen random models of size b + 1.</p><p>The top row of <ref type="figure">Figure 3</ref> shows a scatterplot of the true accuracies of the models in the training sets, A(S b,1:T,1:K ), vs the predicted accuracies,Â b,1:T,1:K (so there are T ×K = 20×256 = 5120 points in each plot, at least for b &gt; 1). The bottom row plots the true accuracies on the set of larger models, A(U b+1,1:R ), vs the predicted accuraciesÃ b+1,1:R (so there are R = 10K points in each plot). We see that the predictor performs well on models from the training set, but not so well when predicting larger models. However, performance does increase as the predictor is trained on more (and larger) cells. <ref type="figure">Figure 3</ref> shows the results using an ensemble of MLPs. The scatter plots for the other predictors look similar. We can summarize each scatterplot using the Spearman rank correlation coefficient. Letρ b = rank-correlation(Â b,1:T,1:K , A(S b,1:T,1:K )) andρ b+1 = rank-correlation(Ã b+1,1:R , A(U b+1,1:R )). <ref type="table">Table 1</ref> summarizes these statistics across different levels. We see that for predicting the training set, the RNN does better than the MLP, but for predicting the performance on unseen larger models (which is the setting we care about in practice), the MLP seems to do slightly better. This will be corroborated by our end-toend test in Section 5.3, and is likely due to overfitting. We also see that for the extrapolation task, ensembling seems to help.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Search Efficiency</head><p>In this section, we compare the efficiency of PNAS to two other methods: random search and the NAS method. To perform the comparison, we run PNAS for B = 5, and at each iteration b, we record the set S b of K = 256 models of size b that it picks, and evaluate them on the CIFAR-10 validation set (after training for 20 epochs each). We then compute the validation accuracy of the top M models for M ∈ {1, 5, 25}. To capture the variance in performance of a given model due to randomness of the parameter initialization and optimization procedure, we repeat this process 5 times. We plot the mean and standard error of this statistic in <ref type="figure" target="#fig_5">Figure 4</ref>. We see that the mean performance of the top M ∈ {1, 5, 25} models steadily increases, as we search for larger models. Furthermore, performance is  <ref type="table">Table 2</ref>. Relative efficiency of PNAS (using MLP-ensemble predictor) and NAS under the same search space. B is the size of the cell, "Top" is the number of top models we pick, "Accuracy" is their average validation accuracy, "# PNAS" is the number of models evaluated by PNAS, "# NAS" is the number of models evaluated by NAS to achieve the desired accuracy. Speedup measured by number of examples is greater than speedup in terms of number of models, because NAS has an additional reranking stage, that trains the top 250 models for 300 epochs each before picking the best one.</p><p>better when using an MLP-ensemble (shown in <ref type="figure" target="#fig_5">Figure 4</ref>) instead of an RNNensemble (see supplementary material), which is consistent with <ref type="table">Table 1</ref>. For our random search baseline, we uniformly sample 6000 cells of size B = 5 blocks from the random set of models U 5,1:R described in Section 5.2. <ref type="figure" target="#fig_5">Figure 4</ref> shows that PNAS significantly outperforms this baseline.</p><p>Finally, we compare to NAS. Each trial sequentially searches 6000 cells of size B = 5 blocks. At each iteration t, we define H t to be the set of all cells visited so far by the RL agent. We compute the validation accuracy of the top M models in H t , and plot the mean and standard error of this statistic in <ref type="figure" target="#fig_5">Figure 4</ref>. We see that the mean performance steadily increases, but at a slower rate than PNAS.</p><p>To quantify the speedup factor compared to NAS, we compute the number of models that are trained and evaluated until the mean performance of PNAS and NAS are equal (note that PNAS produces models of size B after evaluating |B 1 | + (B − 1) × K models, which is 1160 for B = 5). The results are shown in <ref type="table">Table 2</ref>. We see that PNAS is up to 5 times faster in terms of the number of models it trains and evaluates.</p><p>Comparing the number of models explored during architecture search is one measure of efficiency. However, some methods, such as NAS, employ a secondary reranking stage to determine the best model; PNAS does not perform a reranking stage but uses the top model from the search directly. A more fair comparison is therefore to count the total number of examples processed through SGD throughout the search. Let M 1 be the number of models trained during search, and let E 1 be the number of examples used to train each model. <ref type="bibr" target="#b6">7</ref> The total number of examples is therefore M 1 E 1 . However, for methods with the additional reranking stage, the top M 2 models from the search procedure are trained using E 2 examples each, before returning the best. This results in a total cost of  <ref type="table">Table 3</ref>. Performance of different CNNs on CIFAR test set. All model comparisons employ a comparable number of parameters and exclude cutout data augmentation <ref type="bibr" target="#b8">[9]</ref>. "Error" is the top-1 misclassification rate on the CIFAR-10 test set. (Error rates have the form µ ± σ, where µ is the average over multiple trials and σ is the standard deviation. In PNAS we use 15 trials.) "Params" is the number of model parameters. "Cost" is the total number of examples processed through SGD (M1E1 + M2E2) before the architecture search terminates. The number of filters F for NASNet-{B, C} cannot be determined (hence N/A), and the actual E1, E2 may be larger than the values in this table (hence the range in cost), according to the original authors.</p><formula xml:id="formula_4">M 1 E 1 + M 2 E 2 .</formula><p>For NAS and PNAS, E 1 = 900K for NAS and PNAS since they use 20 epochs on a training set of size 45K. The number of models searched to achieve equal top-1 accuracy is M 1 = 1160 for PNAS and M 1 = 5808 for NAS. For the second stage, NAS trains the top M 2 = 250 models for E 2 = 300 epochs before picking the best. <ref type="bibr" target="#b7">8</ref> Thus we see that PNAS is about 8 times faster than NAS when taking into account the total cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results on CIFAR-10 Image Classification</head><p>We now discuss the performance of our final model, and compare it to the results of other methods in the literature. Let PNASNet-5 denote the best CNN we discovered on CIFAR using PNAS, also visualized in <ref type="figure" target="#fig_2">Figure 1</ref> (left). After 8 This additional stage is quite important for NAS, as the NASNet-A cell was originally ranked 70th among the top 250. <ref type="bibr" target="#b8">9</ref> In Hierarchical EA, the search phase trains 7K models (each for 4 times to reduce variance) for 5000 steps of batch size 256. Thus, the total computational cost is 7K × 5000 × 256 × 4 = 35.8B. <ref type="bibr" target="#b9">10</ref> The total computational cost for AmoebaNet consists of an architecture search and a reranking phase. The architecture search phase trains over 27K models each for 50 epochs. Each epoch consists of 45K examples. The reranking phase searches over 100 models each trained for 600 epochs. Thus, the architecture search is 27K × 50 × 45K = 60.8B examples. The reranking phase consists of 100 × 600 × 45K = 2.7B examples. The total computational cost is 60.8B + 2.7B = 63.5B. <ref type="bibr" target="#b10">11</ref> The search phase trains 20K models each for 25 epochs. The rest of the computation is the same as AmoebaNet-B.</p><p>we have selected the cell structure, we try various N and F values such that the number of model parameters is around 3M, train them each for 300 epochs using initial learning rate of 0.025 with cosine decay, and pick the best combination based on the validation set. Using this best combination of N and F , we train it for 600 epochs on the union of training set and validation set. During training we also used auxiliary classifier located at 2/3 of the maximum depth weighted by 0.4, and drop each path with probability 0.4 for regularization.</p><p>The results are shown in <ref type="table">Table 3</ref>. We see that PNAS can find a model with the same accuracy as NAS, but using 21 times less compute. PNAS also outperforms the Hierarchical EA method of <ref type="bibr" target="#b20">[21]</ref>, while using 36 times less compute. Though the the EA method called "AmoebaNets" <ref type="bibr" target="#b26">[27]</ref> currently give the highest accuracies (at the time of writing), it also requires the most compute, taking 63 times more resources than PNAS. However, these comparisons must be taken with a grain of salt, since the methods are searching through different spaces. By contrast, in Section 5.3, we fix the search space for NAS and PNAS, to make the speedup comparison fair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Results on ImageNet Image Classification</head><p>We further demonstrate the usefulness of our learned cell by applying it to ImageNet classification. Our experiments reveal that CIFAR accuracy and ImageNet accuracy are strongly correlated (ρ = 0.727; see supplementary material).</p><p>To compare the performance of PNASNet-5 to the results in other papers, we conduct experiments under two settings:</p><p>-Mobile: Here we restrain the representation power of the CNN. Input image size is 224 × 224, and the number of multiply-add operations is under 600M. -Large: Here we compare PNASNet-5 against the state-of-the-art models on ImageNet. Input image size is 331 × 331.</p><p>In both experiments we use RMSProp optimizer, label smoothing of 0.1, auxiliary classifier located at 2/3 of the maximum depth weighted by 0.4, weight decay of 4e-5, and dropout of 0.5 in the final softmax layer. In the Mobile setting, we use distributed synchronous SGD with 50 P100 workers. On each worker, batch size is 32, initial learning rate is 0.04, and is decayed every 2.2 epochs with rate 0.97. In the Large setting, we use 100 P100 workers. On each worker, batch size is 16, initial learning rate is 0.015, and is decayed every 2.4 epochs with rate 0.97. During training, we drop each path with probability 0.4.</p><p>The results of the Mobile setting are summarized in <ref type="table" target="#tab_1">Table 4</ref>. PNASNet-5 achieves slightly better performance than NASNet-A (74.2% top-1 accuracy for PNAS vs 74.0% for NASNet-A). Both methods significantly surpass the previous state-of-the-art, which includes the manually designed MobileNet <ref type="bibr" target="#b13">[14]</ref> (70.6%) and ShuffleNet <ref type="bibr" target="#b36">[37]</ref> (70.9%). AmoebaNet-C performs the best, but note that this is a different model than their best-performing CIFAR-10 model. <ref type="table">Table 5</ref> shows that under the Large setting, PNASNet-5 achieves higher performance (82.9% top-1; 96.2% top-5) than previous state-of-the-art approaches, including SENet <ref type="bibr" target="#b14">[15]</ref>, NASNet-A, and AmoebaNets under the same model capacity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Params Mult-Adds Top-1 Top-5</p><p>MobileNet-224 <ref type="bibr" target="#b13">[14]</ref> 4.2M 569M 70.6 89.5 ShuffleNet (2x) <ref type="bibr" target="#b36">[37]</ref> 5M 524M 70.9 89.   <ref type="table">Table 5</ref>. ImageNet classification results in the Large setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion and Future Work</head><p>The main contribution of this work is to show how we can accelerate the search for good CNN structures by using progressive search through the space of increasingly complex graphs, combined with a learned prediction function to efficiently identify the most promising models to explore. The resulting models achieve the same level of performance as previous work but with a fraction of the computational cost. There are many possible directions for future work, including: the use of better surrogate predictors, such as Gaussian processes with string kernels; the use of model-based early stopping, such as <ref type="bibr" target="#b2">[3]</ref>, so we can stop the training of "unpromising" models before reaching E 1 epochs; the use of "warm starting", to initialize the training of a larger b + 1-sized model from its smaller parent; the use of Bayesian optimization, in which we use an acquisition function, such as expected improvement or upper confidence bound, to rank the candidate models, rather than greedily picking the top K (see e.g., <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b29">30]</ref>); adaptively varying the number of models K evaluated at each step (e.g., reducing it over time); the automatic exploration of speed-accuracy tradeoffs (cf., <ref type="bibr" target="#b10">[11]</ref>), etc.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>of possible inputs, I b , is the set of all previous blocks in this cell,space O is the following set of 8 functions, each of which oper- ates on a single tensor 5 :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>B</head><label></label><figDesc>where |I b | = (2 + b − 1), |O| = 8 and |C| = 1. For b = 1, we have I 1 = {H}, which are the final outputs of the previous two cells, so there are |B 1 | = 256 possible block structures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Left: The best cell structure found by our Progressive Neural Architecture Search, consisting of 5 blocks. Right: We employ a similar strategy as [41] when constructing CNNs from cells on CIFAR-10 and ImageNet. Note that we learn a single cell type instead of distinguishing between Normal and Reduction cell.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of the PNAS search procedure when the maximum number of blocks is B = 3. Here S b represents the set of candidate cells with b blocks. We start by considering all cells with 1 block, S1 = B1; we train and evaluate all of these cells, and update the predictor. At iteration 2, we expand each of the cells in S1 to get all cells with 2 blocks, S</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>for b = 1 :Fig. 3 .</head><label>13</label><figDesc>Fig. 3. Accuracy of MLP-ensemble predictor. Top row: true vs predicted accuracies on models from the training set over different trials. Bottom row: true vs predicted accuracies on models from the set of all unseen larger models. Denoted is the mean rank correlation from individual trials.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Comparing the relative efficiency of NAS, PNAS and random search under the same search space. We plot mean accuracy (across 5 trials) on CIFAR-10 validation set of the top M models, for M ∈ {1, 5, 25}, found by each method vs number of models which are trained and evaluated. Each model is trained for 20 epochs. Error bars and the colored regions denote standard deviation of the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 4 .</head><label>4</label><figDesc>ImageNet classification results in the Mobile setting.AmoebaNet-B (N = 6, F = 190) [27] 331 × 331 84.0M 22.3B 82.3 96.1 AmoebaNet-A (N = 6, F = 190) [27] 331 × 331 86.7M 23.1B 82.8 96.1 AmoebaNet-C (N = 6, F = 228) [27] 331 × 331 155.3M 41.1B 83.1 96.3</figDesc><table>Model 
Image Size Params Mult-Adds Top-1 Top-5 

ResNeXt-101 (64x4d) [36] 
320 × 320 83.6M 
31.5B 
80.9 95.6 
PolyNet [38] 
331 × 331 92M 
34.7B 
81.3 95.8 
Dual-Path-Net-131 [6] 
320 × 320 79.5M 
32.0B 
81.5 95.8 
Squeeze-Excite-Net [15] 
320 × 320 145.8M 
42.3B 
82.7 96.2 

NASNet-A (N = 6, F = 168) [41] 
331 × 331 88.9M 
23.8B 
82.7 96.2 
PNASNet-5 (N = 4, F = 216) 
331 × 331 86.1M 
25.0B 
82.9 96.2 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">⋆ Work done while an intern at Google.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The code and checkpoint for the PNAS model trained on ImageNet can be downloaded from the TensorFlow models repository at http://github.com/tensorflow/ models/. Also see https://github.com/chenxi116/PNASNet.TF and https:// github.com/chenxi116/PNASNet.pytorch for author's reimplementation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">The depthwise-separable convolutions are in fact two repetitions of ReLU-SepConvBatchNorm; 1x1 convolutions are also inserted when tensor sizes mismatch.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">5 symbols per block, times 5 blocks, times 2 for Normal and Reduction cells.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">The number of examples is equal to the number of SGD steps times the batch size. Alternatively, it can be measured in terms of number of epoch (passes through the data), but since different papers use different sized training sets, we avoid this measure. In either case, we assume the number of examples is the same for every model, since none of the methods we evaluate use early stopping.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Quoc Le for inspiration, discussion and support; George Dahl for many fruitful discussions; Gabriel Bender, Vijay Vasudevan for the development of much of the critical infrastructure and the larger Google Brain team for the support and discussions. CL also thanks Lingxi Xie for support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">On a family of decomposable kernels on sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baisero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>Pokorny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Ek</surname></persName>
		</author>
		<idno>abs/1501.06284</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Designing neural network architectures using reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">ICLR</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Accelerating neural architecture search using performance prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<idno>CoRR abs/1705.10823</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">SMASH: one-shot model architecture search through hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Weston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Efficient architecture search by network transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Dual path networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gonzalvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kuznetsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">Adanet: Adaptive structural learning of artificial neural networks. In: ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno>CoRR abs/1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Domhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">PPP-Net: Platform-aware progressive search for pareto-optimal neural architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Simple and efficient architecture search for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno>CoRR abs/1711.04528</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Exploiting compositionality to explore a large space of model structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>UAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno>CoRR abs/1704.04861</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<idno>CoRR abs/1709.01507</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning deep resnet blocks sequentially using boosting theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Ash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<idno>CoRR abs/1706.04964</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sequential Model-Based optimization for general algorithm configuration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Learning and Intelligent Optimization</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="507" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<title level="m">Microsoft COCO: common objects in context</title>
		<imprint>
			<publisher>ECCV</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Hierarchical representations for efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">SGDR: stochastic gradient descent with restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<title level="m">Towards Automatically-Tuned neural networks. In: ICML Workshop on AutoML</title>
		<imprint>
			<date type="published" when="2016-12" />
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Evolving deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Francon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shahrzad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Navruzyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Duffy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hodjat</surname></persName>
		</author>
		<idno>CoRR abs/1703.00548</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Deeparchitect: Automatically designing and training deep architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Negrinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
		<idno>CoRR abs/1704.08792</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Efficient neural architecture search via parameter sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno>CoRR abs/1802.03268</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno>CoRR abs/1802.01548</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Large-scale evolution of image classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">L</forename><surname>Suematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">ICML</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Proximal policy optimization algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Klimov</surname></persName>
		</author>
		<idno>CoRR abs/1707.06347</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Taking the human out of the loop: A review of bayesian optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shahriari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="148" to="175" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Neuroevolution: A different kind of deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Evolving neural networks through augmenting topologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evol. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="127" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<title level="m">Genetic CNN. In: ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Shufflenet: An extremely efficient convolutional neural network for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno>CoRR abs/1707.01083</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Polynet: A pursuit of structural diversity in very deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Practical network blocks design with Q-Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
