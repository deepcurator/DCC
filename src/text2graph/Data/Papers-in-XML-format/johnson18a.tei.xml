<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Composite Functional Gradient Learning of Generative Adversarial Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rie</forename><surname>Johnson</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
						</author>
						<title level="a" type="main">Composite Functional Gradient Learning of Generative Adversarial Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>This paper first presents a theory for generative adversarial methods that does not rely on the traditional minimax formulation. It shows that with a strong discriminator, a good generator can be learned so that the KL divergence between the distributions of real data and generated data improves after each functional gradient step until it converges to zero. Based on the theory, we propose a new stable generative adversarial method. A theoretical insight into the original GAN from this new viewpoint is also provided. The experiments on image generation show the effectiveness of our new method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>We consider observed real data x * 1 , . . . , x * n ∈ R r from an unknown distribution p * on R r . Moreover, assume that we are given a random variable Z with a known distribution such as a Gaussian. We are interested in learning a random variable transformation G(Z) so that the generated data G(Z) has a probability density function that is close to the real distribution p * . This is the setting considered in generative adversarial networks (GAN) <ref type="bibr" target="#b5">(Goodfellow et al., 2014)</ref>, and the transformation G(Z) is often referred to as a generator. While GAN has been widely used, it is also known that GAN is difficult to train due to its instability, which has led to numerous studies, e.g., Wasserstein GAN (WGAN) and its extensions to pursue a different minimax objective <ref type="bibr" target="#b6">Gulrajani et al., 2017;</ref><ref type="bibr" target="#b14">Mroueh &amp; Sercu, 2017)</ref>, mode-regularized GAN to tackle the issue of mode collapse <ref type="bibr" target="#b3">(Che et al., 2017)</ref>, unrolled GAN , AdaGAN <ref type="bibr" target="#b21">(Tolstikhin et al., 2017)</ref>, MMD GAN , and references therein. inate real data from generated data. Mathematically, GAN solves the following minimax optimization problem:</p><formula xml:id="formula_0">max d min G   x * ∈real data lnd(x * )+ G(z)∈fake data ln(1−d(G(z)))   .</formula><p>(1) Parameterizing d and G, (1) can be viewed as a saddle point problem in optimization, which can be solved using a stochastic gradient method, where one takes a gradient step with respect to the parameters in d and G (see Algorithm 4 below). However, the practical procedure, suggested by the original work <ref type="bibr" target="#b5">(Goodfellow et al., 2014)</ref>, replaces minimization of log(1 − d(G(z))) with respect to G in (1) with maximization of log(d(G(z))) with respect to G, called the logd trick. Thus, GAN with the logd trick, though often more effective, can not directly be explained by the theory based on the minimax formulation (1). This paper presents a new theory for generative adversarial methods which does not rely on the minimax formulation (1). Our theory shows that one can learn a good generator G(Z) where 'goodness' is measured by the KL-divergence between the distributions of real data and generated data, by using functional gradient learning greedily, similar to gradient boosting <ref type="bibr" target="#b4">(Friedman, 2001)</ref>. However, unlike the standard gradient boosting, which uses additive models, we consider functional compositions in the following form G t (Z) = G t−1 (Z)+η t g t (G t−1 (Z)), (t = 1, . . . , T ) (2) to obtain G(Z) = G T (Z). Here η t is a small learning rate, and each g t is a function to be estimated from data. An initial generator G 0 (Z) ∈ R r is assumed to be given. We learn from data g t greedily from t = 1 to t = T so that improvement (in terms of the KL-divergence) is guaranteed.</p><p>Our theory leads to a new stable generative adversarial method. It also provides a new theoretical insight into the original GAN both with and without the logd trick. The experiments show the effectiveness of our new method on image generation in comparison with GAN variants.</p><p>Notation Throughout the paper, we use x to denote data in R r , and in particular, we use x * to denote real data. The probability density function of real data is denoted by p * . We use · to denote the vector 2-norm and ∇h(x) to denote the gradient w.r.t. x of a scalar function h(x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Theory</head><p>To present our theory, we start with stating assumptions. We then analyze one step of random variable transformation in (2) (i.e., transforming G t−1 (Z) to G t (Z)) and examine an algorithm suggested by this analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Assumptions and definitions</head><p>A strong discriminator Given a set S * of real data and a set S of generated data, assume that we can obtain a strong discriminator D using logistic regression so that D ≈</p><formula xml:id="formula_1">argmin D 1 |S * | x∈S * ln(1+e −D (x) )+ 1 |S| x∈S ln(1+e D (x) ) .</formula><p>D tries to discriminate the real data from the generated data.</p><p>Here we use the logistic model, and so d in (1) corresponds to</p><formula xml:id="formula_2">1 1+exp(−D(x)) . Define a quantity D(x) by D(x) := ln p * (x) p(x)</formula><p>where p * and p are the probability density functions of real data and generated data, respectively, and assume that |D(x)|&lt;∞. p * and p are thus assumed to be nonzero everywhere. When the number of given examples is sufficiently large, the standard statistical consistency theory of logistic regression (see e.g., <ref type="bibr" target="#b24">(Zhang, 2004)</ref>) implies that D(x) ≈ D(x) . Therefore, assume that the followingapproximation condition is satisfied for a small &gt; 0:</p><formula xml:id="formula_3">q * (x) |D(x) − D(x)| + e D(x) − e D(x) dx ≤ , q * (x) = p * (x) max(1, ∇ ln p * (x) ) .</formula><p>Note that the assumption of the optimal discriminator has been commonly used, and we slightly relax it to a strong discriminator by quantifying the deviation from the optimum by .</p><p>Smooth and light-tailed p * Assume that p * , the density of real data, is smooth with light tails; we use a constant h 0 &gt; 0 that depends on the shape of p * . Due to the space limit, the precise statements are deferred to the Appendix. Common exponential distributions such as Gaussian distributions and mixtures of Gaussians all satisfy the assumption, and an arbitrary distribution can always be approximated to an arbitrary precision by a mixture of Gaussians.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Analyzing one step of random variable transformation</head><p>The goal is to approximate the true density p * on R r through (2). Our analysis here focuses on one step of (2) at time t, namely, random variable transformation of G t−1 (Z) to G t (Z). To simplify notation, we assume that we are given a random variable X with a probability density p on R r . We are interested in finding a function g : R r → R r , so that the transformed variable X = X + ηg(X) for small η &gt; 0 has a distribution closer to p * . We show that this can be achieved with a gradient-like step in the function space.</p><p>To measure the distance of a density p from the true density p * , we will keep track of the KL-divergence</p><formula xml:id="formula_4">L(p) = p * (x) ln p * (x) p(x) dx<label>(3)</label></formula><p>before and after the transformation. We know that L(p) ≥ 0 for all p, and L(p) = 0 if and only if p = p * .</p><p>The following theorem consequently shows that with an appropriately chosen g(·), the transformation X → X + ηg(X) can always reduce the KL-divergence L(·). This means that transformation X + ηg(X) is an improvement from X. The proof is given in the Appendix.</p><p>Theorem 2.1 Under the assumptions in Section 2.1, let g : R r → R r be a continuously differentiable transformation such that g(·) ≤ a and ∇g(·) ≤ b. Let p be the probability density of a random variable X, and let p be the probability density of the random variable X such that X = X + ηg(X) where 0 &lt; η &lt; min(1/b, h 0 /a). Then there exists a positive constant c such that for all &gt; 0:</p><formula xml:id="formula_5">L(p ) ≤ L(p) − η p * (x) g(x) ∇D(x) dx + cη 2 + cη .</formula><p>The consequences of the theorem become clear when we choose g(x) = s(x)∇D(x) (where s(x) &gt; 0 is an arbitrary scaling factor). By doing so and letting = η, we have:</p><formula xml:id="formula_6">L(p ) ≤ L(p) − η p * (x)s(x) ∇D(x) 2 2 dx + O(η 2 ).</formula><p>(4) This means that by letting g(x) = s(x)∇D(x), the objective value L(·) will be reduced for a sufficiently small η unless p * (x)s(x) ∇D(x) 2 2 dx vanishes. The vanishing condition implies that D(x) is approximately a constant when p * has full support on R r . In this case, the discriminator is unable to differentiate the real data from the generated data. Thus, it is implied that letting g(x) = s(x)∇D(x) makes the probability density of generated data closer to that of real data until the discriminator becomes unable to distinguish the real data and generated data.</p><p>We note that taking g(x) = s(x)∇D(x) is analogous to a gradient descent step of L(p) in the function space so that a step is taken to modify the function instead of the model parameters. Therefore, our theory leads to a functional gradient view of variable transformation that can always improve the quality of the generator -when the quality is measured by the KL-divergence between the true data and the generated data.</p><p>If we repeat the process described above, Algorithm 1 is ob-Algorithm 1 CFG: Composite Functional Gradient Learning of GAN Input: real data x * 1 , . . . , x * n , initial generator G 0 (z) with generated data {G 0 (z 1 ), . . . , G 0 (z m )}. Meta-parameter: T . 1: for t = 1, 2, . . . , T do 2:</p><formula xml:id="formula_7">D t (x) ← arg min D 1 n n i=1 ln(1 + exp(−D(x * i ))) + 1 m m i=1 ln(1 + exp(D(G t−1 (z i )))) 3: g t (x) ← s t (x)∇D t (x) (s t (x)</formula><p>is for scaling, e.g., most simply s t (x) = 1) 4: tained. We call it composite functional gradient learning of GAN (CFG-GAN), or simply CFG. CFG forms g t by directly using the functional gradient ∇D t (x), as suggested by our theory. If (4) holds, and if we choose η t =η= =O(1/ √ T ), then by cascading (4) from t=1 to T we obtain the following bound:</p><formula xml:id="formula_8">G t (z) ← G t−1 (z) + η t g t (G t−1 (z)), for some η t &gt; 0. 5: end for 6: return generator G T (z) G 0 g 1 g 2 + g 3 + Input z G 1 G 2 G 3 + Output</formula><formula xml:id="formula_9">1 T T t=1 p * (x)s t (x) ∇D t (x) 2 dx = 1 T O(T η) + η −1 L(p 0 ) = O(T −1/2 )</formula><p>, where p 0 is the density of G 0 (z). This means that as t increases, ∇D t (x) → 0 and thus D t (x) approaches a constant, assuming p * has full support on R r . That is, in the limit, the discriminator is unable to differentiate the real data from the generated data.</p><p>We note that <ref type="bibr" target="#b10">(Lazarow et al., 2017)</ref> describes a related but different cascading process motivated by Langevin dynamics sampling. The Langevin theory requires repeated noise addition in the generation process. Our generation is simpler as there is no need for noise addition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Composite Functional Gradient Algorithms</head><p>Starting from the CFG algorithm above, we empirically explored algorithms on image generation. In this section we parameterize D and denote the model parameters by θ D .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">ICFG: Incremental CFG</head><p>The first change made to CFG is to make it incremental similar to GAN, resulting in incremental CFG (ICFG, Algorithm 2). CFG (Algorithm 1) optimizes the discriminator to convergence in every iteration. On image generation, this tends to cause the discriminator to overfit, which turned out to be much more harmful than underfitting as an overfit discriminator grossly violates the -approximation condition</p><formula xml:id="formula_10">Algorithm 2 ICFG: Incremental CFG Input: a set of training examples S * , prior p z , initial gen- erator G 0 , discriminator D. Meta-parameters: T , mini- batch size b, discriminator update frequency U . 1: for t = 1, 2, . . . , T do 2:</formula><p>for U steps do 3:</p><formula xml:id="formula_11">Sample x * 1 , . . . , x * b from S * . 4:</formula><p>Sample z 1 , . . . , z b according to p z .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Update D by descending the stochastic gradient:</p><formula xml:id="formula_12">∇ θ D 1 b b i=1 ln(1+e −D(x * i ) )+ln(1+e D(G t−1 (z i )) ) 6:</formula><p>end for 7:</p><formula xml:id="formula_13">g t (x) ← s t (x)∇D(x) (e.g., s t (x) = 1) 8: G t (z) ← G t−1 (z) + η t g t (G t−1 (z))</formula><p>, for η t &gt; 0. 9: end for 10: return generator G T (and the updated D if so desired).</p><p>(Section 2.1) thus grossly pushing the generator in a wrong direction. Also, updating the discriminator to convergence is computationally impractical apart from whether or not doing so is helpful/harmful. ICFG incrementally updates a discriminator little by little interleaved with the generator updates, so that the generator can keep providing new and more challenging examples to prevent the discriminator from overfitting.</p><p>Note that here we broadly use the term "overfit" for failure to generalize to unseen data (after fitting to observed data). This includes cases on unseen data in the low-density region according to our assumption, which is outside of manifolds according to the view of disjoint low-dim data manifolds of , and so our observation is in line with  in that the shape of distributions could be problematic. However, we handle the issue differently. Instead of changing loss (leading to WGAN), we deal with it by early stopping of discriminator training (like GAN) and functional gradient learning in generator update (unlike GAN). The latter ensures improvement of generator so that it keeps challenging the discriminator, and we will later revisit this point.</p><p>ICFG shares nice properties with CFG. The generator is guaranteed to improve with each update to the extent that the assumptions hold; therefore, it is expected to be sta- S z ← an input pool sampled according to p z .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3:</head><p>q z ← the uniform distribution over S z .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>G,D ← output of ICFG using S * , q z , G, D as input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>if exit criteria are met then return generator G fi 6:</p><formula xml:id="formula_14">Update G to minimize z∈Sz 1 2 G(z) − G(z) 2 7: end loop ble.</formula><p>There is no need to design a complex generator model. The generator model is automatically and implicitly derived from the discriminator and grows as training proceeds (see <ref type="figure" target="#fig_1">Figure 1)</ref>. A shortcoming, however, is that the implicit generator network can become very large. At time t, computation of G t (z) starting from scratch is in O(t); therefore, performing T iterations of training could be in O(</p><formula xml:id="formula_15">T t=1 t) = O(T 2 )</formula><p>. We found that image generation requires a large T to the extent that it is computationally problematic, causing slow training and slow generation. <ref type="bibr" target="#b16">(Nitanda &amp; Suzuki, 2018)</ref> recently proposed a related method for fine-tuning WGAN based on different motivations. We note that their method would also suffer from the same issue if used for image generation from scratch.</p><p>A partial remedy, which speeds up training (but not generation), is to have an input pool of a fixed size. That is, we restrict the input distribution to be on a finite set S z and for every input z ∈ S z , maintain G t (z) for the latest t for which G t (z) was computed. By doing so, when G t (z) needs to be computed, one can start from G t (z) instead of starting over from G 0 (z), which saves computation time. However, this remedy solves only a part of the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">xICFG: Approximate incremental CFG</head><p>As a complete solution to the issue of large generators, we propose Approximate ICFG (xICFG, Algorithm 3). xICFG periodically compresses the generator obtained by ICFG, by training an approximator of a fixed size that approximates the behavior of the generator obtained by ICFG. That is, given a definition of an approximator G and its initial state, xICFG repeatedly alternates the following.</p><p>• Using the approximator G as the initial generator, perform T iterations of ICFG to obtain generator G.</p><p>• Update the approximator G to achieve G(z) ≈ G(z).</p><p>The generator size is again in O(T ), but unlike ICFG, T for xICFG can be small (e.g., T = 10), thus xICFG is efficient. We use the idea of an input pool above for speeding up training, and instead of keeping the same pool to the end, we refresh the pool S z in every iteration of xICFG (Lines 2&amp;3 of Algorithm 3). For speed, the values G t (z) for z ∈ S z for the latest t should be kept not only for use in ICFG but also for preparing the training data {(z, G(z)) | z ∈ S z } for the training of the approximator G (Line 6).</p><p>A small pool size |S z | and a small T would reduce the runtime of one iteration, but they would increase the number of required iterations, as they reduce the amount of the improvement achieved by one iteration of xICFG, and so a trade-off should be found empirically. In particular, approximation typically causes some degradation, and so it is important to set T and |S z | to sufficiently large values so that the amount of the generator improvement exceeds the amount of degradation caused by approximation. In our experiments, however, tuning of meta-parameters turned out to be relatively easy; essentially one set of meta-parameters achieved stable training in all the tested settings across datasets and network architectures, as described later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Relation to GAN</head><p>We show that GAN (Algorithm 4) with the logistic model (as is typically done) is closely related to a special case of xICFG that uses an extreme setting. This viewpoint leads to a new insight into GAN's instability.</p><p>We start with the fact that GAN with the logistic model for U steps do Sample z 1 , . . . , z b according to p z .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Update d by ascending the stochastic gradient:</p><formula xml:id="formula_16">∇ θ d 1 b b i=1 [ln d(x * i ) + ln(1 − d(G(z i )))] 6:</formula><p>end for 7:</p><p>Sample z 1 , . . . , z b according to p z .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>Update G by descending the stochastic gradient:</p><formula xml:id="formula_17">∇ θ G 1 b b i=1 ln(1 − d(G(z i ))) 9:</formula><p>until exit criteria are met 10: return generator G</p><p>[v] i for the i-th component of vector v, the k-th component of this gradient can be written as:</p><formula xml:id="formula_18">[∇ θ G ln(1 − d(G(z)))] k = ∇ θ G ln exp(−D(G(z))) 1+exp(−D(G(z))) k = −s 0 (G(z)) j [∇D(G(z))] j ∂[G(z)]j ∂[θ G ] k (5) where s 0 (x) = 1 1+exp(−D(x)) , resulting from differentiat- ing f (y) = − ln exp(−y)</formula><p>1+exp(−y) at y = D(x). Now suppose that we apply ICFG with T = 1 to a generator G to obtain a new generator G (z) = G(z) + ηg(G(z)) = G(z) + ηs(G(z))∇D(G(z)), and then we update G to approximate</p><formula xml:id="formula_19">G so that z 1 2 G (z) − G(z)</formula><p>2 is minimized as in Line 6 of xICFG. To take one step of gradient descent for this approximation, we need the gradient</p><formula xml:id="formula_20">∇ θ G 1 2 G (z) − G(z) 2 ,</formula><p>and its k-th component is</p><formula xml:id="formula_21">− j [G (z) − G(z)] j ∂[G(z)] j ∂[θ G ] k = −ηs(G(z)) j [∇D(G(z))] j ∂[G(z)] j ∂[θ G ] k</formula><p>. By setting the scaling factor s(x) = s 0 (x)/η, this is exactly the same as (5), required for the GAN generator update. (Recall that our theory and algorithms accommodate an arbitrary data-dependent scaling factor s(x) &gt; 0.) Thus, algorithmically GAN is closely related to a special case of xICFG that does the following:</p><p>• Set T =1 so that ICFG updates the generator just once.</p><p>• To update the approximator, take only one gradient descent step with only one mini-batch, instead of optimizing to the convergence with many examples. Therefore, the degree of approximation could be poor.</p><p>The same argument applies also to the logd-trick variant of GAN by replacing s 0 (x) = 1 1+exp(−D(x)) with s 1 (x) = 1 1+exp(D(x)) . When generated data x is very far from the real data and so D(x) 0, we have s 0 (x) ≈ 0 (without the logd trick), which would make the gradient (required for updating the GAN generator) vanish, as noted in <ref type="bibr" target="#b5">(Goodfellow et al., 2014)</ref>, even though the generator is poor and so requires updating. In contrast, we have s 1 (x) ≈ 1 (with the logd trick) in this poor generator situation, which is more sensible as well as more similar to our choice (s(x) = 1) for the xICFG experiments.</p><p>Why is GAN unstable? In spite of their connection, GAN is unstable, and xICFG with appropriate meta-parameters is stable (shown later). Thus, we figure that GAN's instability derives from what is unique to GAN, the two bullets abovean extremely small T and coarse approximation. Either can cause degradation of the generator, leading to instability.</p><p>We have contrasted GAN's generator update with xICFG's approximator update. Now we compare it with ICFG's generator update to consider the algorithmic merits of our functional gradient approach. The short-term goal of generator update can be regarded as the increase of the discriminator output on generated data, i.e., to have D(G t+1 (z)) &gt; D(G t (z)) for any z∼p z . ICFG updates the generator by G t+1 (z) = G t (z)+η∇D(G t (z)), and so with small η, D(G(z)) is guaranteed to increase for any z. This is because by definition ∇D(G t (z)) is the direction that increases the discriminator output for z, and it is precisely obtained on the fly for every z at the time of generation. By contrast, GAN stochastically and approximately updates θ G using a small sample (one mini-batch SGD step backpropagating ∇D), and so GAN's update can be noisy, which can lead to instability through generator degradation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We tested xICFG on the image generation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental setup</head><p>Baseline methods For comparison, we also tested the following three methods: the original GAN without the logd trick (GAN0 in short), GAN with the logd trick (GAN1), and WGAN with the gradient penalty (WGANgp) <ref type="bibr" target="#b6">(Gulrajani et al., 2017)</ref>. The choice of GAN0 and GAN1 is due to its relation to xICFG as analyzed above. WGANgp was chosen as a representative of state-of-the-art methods, as it was shown to rival or outperform a number of previous methods such as the original WGAN with weight clipping , Least Squares GAN <ref type="bibr" target="#b12">(Mao et al., 2017)</ref>, Boundary Equilibrium GAN <ref type="bibr" target="#b2">(Berthelot et al., 2017)</ref>, GAN with denoising feature matching <ref type="bibr" target="#b22">(Warde-Farley &amp; Bengio, 2017)</ref>, and Fisher GAN <ref type="bibr" target="#b14">(Mroueh &amp; Sercu, 2017)</ref>.</p><p>Evaluation metrics Making reliable likelihood estimates with generative adversarial models is known to be challenging <ref type="bibr" target="#b19">(Theis et al., 2016)</ref>, and we instead focused on evaluating the visual quality of generated images, using datasets that come with labels for classification. We measured the inception score <ref type="bibr" target="#b18">(Salimans et al., 2016)</ref>. The intuition behind this score is that high-quality images should lead to high confidence in classification. It is defined as exp(E x KL(p(y|x)||p(y))) where p(y|x) is the label distribution conditioned on generated data x and p(y) is the label distribution over the generated data. Following previous work, e.g., <ref type="bibr" target="#b3">Che et al., 2017)</ref>, the probabilities were estimated by a classifier trained with the labels provided with the datasets (instead of the ImageNet-trained inception model used in <ref type="bibr" target="#b18">(Salimans et al., 2016)</ref>) so that the image classes of interest were well represented in the classifier. We, however, call this score the 'inception score', following custom. We also compared the label distributions over generated data and real data, but we found that in our settings this measure roughly correlates to the inception score (generally, a very good match when the methods produce decent inception scores), and so we do not report it to avoid redundancy. We note that these metrics are limited, e.g., they would not detect mode collapse or missing modes within a class. Apart from that, we found the inception score to generally correspond to human perception well.</p><p>Data We used MNIST, the Street View House Numbers dataset (SVHN) <ref type="bibr" target="#b15">(Netzer et al., 2011)</ref>, and the large-scale scene understanding (LSUN) dataset. These datasets are provided with class labels (digits '0' -'9' for MNIST and SVHN and 10 scene types for LSUN). A number of studies have used only one LSUN class ('bedroom'). Since a singleclass dataset would preclude evaluation using class labels, we instead generated a balanced two-class dataset using the same number of images from the 'bedroom' class and the 'living room' class (LSUN BR+LR). Similarly, we generated a balanced dataset from 'tower' and 'bridge' (LSUN T+B). The number of real images used for training was 60K (MNIST), 521K (SVHN), 2.6 million (LSUN BR+LR), and 1.4 million (LSUN T+B). The LSUN images were shrunk and cropped into 64×64 as in previous studies. The pixel values were scaled into [−1, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network architectures</head><p>The tested methods require as input a network architecture of a discriminator and that of an approximator or a generator. Among the numerous network architectures we could experiment with, we focused on two types with two distinct merits -good results and simplicity.</p><p>The first type (convolutional; stronger) aims at complexity appropriate for the dataset so that good results can be obtained. On MNIST and SVHN, we used an extension of DCGAN <ref type="bibr" target="#b17">(Radford et al., 2015)</ref>, adding 1×1 convolution layers. Larger (64×64) images of LSUN were found to benefit from more complex networks, and so we used a residual net (ResNet) <ref type="bibr" target="#b7">(He et al., 2015)</ref> of four residual blocks, which is a simplification from the WGANgp code release, for both the discriminator and the approximator/generator. Details are given in the Appendix.</p><p>These networks include batch normalization layers <ref type="bibr" target="#b8">(Ioffe &amp; Szegedy, 2015)</ref>. The original study states that WGANgp does not work well with a discriminator with batch normalization. Although it would be ideal to use exactly the same networks for all the methods, it would be rather unfair for the other methods if we always remove batch normalization. Therefore, in each setting, we tested WGANgp with the options of either removing batch normalization only from D or from both D and G, and picked the best. (We also tried other normalizations such as layer normalization but did not see any merit.) In addition, we tested some cases without batch normalization anywhere for all the methods.</p><p>The second type (fully-connected G or G; weaker) uses a minimally simple approximator/generator, consisting of two 512-dim fully-connected layers with ReLU, followed by the output layer with tanh, which has a merit of simplicity, requiring less design effort. We combined it with a convolutional discriminator, the DCGAN extension above. xICFG implementation details To speed up training, we limited the number of epochs of the approximator training in xICFG to 10 while reducing the learning rate by multiplying by 0.1 whenever the training loss stops going down. The scaling function s(x) in ICFG was set to s(x) = 1. To initialize the approximator G for xICFG, we first created a simple generator G rand (z) consisting of a projection layer with random weights (Gaussian with 0 mean and 0.01 stddev) to produce the desired dimensionality, and then trained G to approximate G rand . The training time reported below includes the time spent for this initialization.</p><p>Other details In all cases, the prior p z was set to generate 100-dimensional Gaussian vectors with zero mean and standard deviation 1. All the experiments were done using a single NVIDIA Tesla P100.</p><p>The meta-parameter values for xICFG were fixed to those in <ref type="table">Table 1</ref> except when we pursued smaller values for T for practical advantages (described below). For GAN, we used the same mini-batch size as xICFG, and we set the discriminator update frequency U to 1 as other values led to poorer results. The SGD update was done with rmsprop <ref type="bibr" target="#b20">(Tieleman &amp; Hinton, 2012)</ref> for xICFG and GAN. The learning rate for rmsprop was fixed for xICFG, but we tried several values for GAN as it turned out to be critical. Similarly, for xICFG, we found it important to set the step size η for the generator update in ICFG to an appropriate value. The SGD update for WGANgp was done with Adam <ref type="bibr" target="#b9">(Kingma &amp; Ba, 2015)</ref> as in the original study. We set the meta-parameters for WGANgp to the suggested values, except that we tried several values for the learning rate. Thus, the amount of tuning effort was about the same for all but WGANgp, which required additional search for the normalization options. Tuning was done based on the inception score on the validation set of 10K input vectors (i.e., 10K 100-dim Gaussian vectors), and we report inception scores on the test set of 10K input vectors, disjoint from the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head><p>First, we report the inception score results. The scores of the real data (a held-out set of 10K images) are 9.91 (MNIST), 9.13 (SVHN), 1.84 (LSUN BR+LR), and 1.90 (LSUN T+B), respectively, which roughly set the upper bounds that can be achieved by generated images. <ref type="figure">Figure 2</ref> shows the score of generated images (in relation to training time) with the convolutional networks, including the two cases without batch normalization anywhere for all the methods (upper- Best baseline (7.81) Worst baseline (3.37) <ref type="figure">Figure 7</ref>. SVHN. Using fully-connected G or G as in <ref type="figure">Fig 3.</ref> right and lower-right). Recall that a smaller T has practical advantages of a smaller generator resulting in faster generation and smaller footprints while a larger T stabilizes xICFG training by ensuring that training makes progress by overcoming the degradation caused by approximation. With convolutional approximators, we explored values for T by a decrement of 5 starting from T =25 (which works well for all) and found that T can be reduced to 5 (SVHN), 10 (MNIST), and 15 (both LSUN) without negative consequences. The results in <ref type="figure">Figure 2</ref> were obtained by using these smaller T . xICFG generally outperforms the others. Although on LSUN datasets GAN1 occasionally exceeds xICFG, inspection of generated images reveals that it suffers from severe mode collapse. The results with the simple but weak fully-connected approximator/generator are shown in <ref type="figure">Figure 3</ref>. Among the baseline methods, only WGANgp succeeded in this setting, but its score fell behind xICFG. These results show that xICFG is effective and efficient.</p><p>Examples of generated images are shown in <ref type="figure" target="#fig_7">Figures 4-9</ref>. Note however that a small set of images may not represent the entire population well due to variability. Looking through larger sets of generated images, we found that roughly, when the inception score is higher, the images are sharper and/or there are fewer images that are harder to tell what they are, and that when the score fluctuates violently (as GAN1 does on LSUN), severe mode collapse is observed. Overall, we feel that the images generated by xICFG are better than or at least as good as those of the bestperforming baseline, WGANgp, one of the state-of-the-art methods. Discriminator output values Successful training should make it harder and harder for the discriminator to distinguish real images and generated images, which would man-   ifest as the discriminator output values for real images and generated images becoming closer and closer. In <ref type="figure" target="#fig_1">Figure  11</ref>, the y-axis is the inception score, and the x-axis is '|D(real)−D(gen)|' (∆ D in short), which is the difference between the discriminator output values for real images and generated images averaged over time intervals of a fixed length, obtained as a by-product of the forward propagation for updating the discriminator. The arrows indicate the direction of time flow. When training is going well (indicated by blue solid arrows), ∆ D decreases and the inception score improves as training proceeds. When it is failing, ∆ D goes up rapidly and the inception scores degrades rapidly (red dotted arrows in <ref type="figure" target="#fig_1">Fig 11 right)</ref>. Here, the discriminator is overfitting to the small set of real data (1000 MNIST examples), violating the -approximation assumption. That slows down and eventually stops the progress of the generator, resulting in the increase of ∆ D . In practice, training should be stopped before the rapid growth of ∆ D . Thus, the decrease/increase of ∆ D values (which can be obtained at almost no cost during training) can be used as an indicator of the status of xICFG training, similar to WGAN and in contrast to GAN.</p><p>Use of the approximator as a generator As noted above, a smaller generator resulting from a smaller T has practical advantages, but a larger T stabilizes training. One way to reduce generator size without reducing T is to use the final approximator G (after completing regular xICFG training) as a generator, at the expense of performance degradation. We show below the inception scores of the final approximator (G 0 in the final call of ICFG) in comparison with the final generator (G T in the final call of ICFG) in the settings of <ref type="figure">Figure 2</ref> (convolutional). Although the final approximator underperforms the final generator as expected, it rivals and sometimes exceeds the best baseline method, whose generator has the same size as the approximator. Thus, use of the final approximator may be a viable option. The results also indicate that the good performance of xICFG is due to not only having a larger (and therefore more complex) generator but also stable and efficient training, which makes it possible to refine the approximator network to the degree that it can outperform the baseline methods.</p><p>Not memorization Finally, in <ref type="figure" target="#fig_1">Fig 10 we</ref> show examples indicating xICFG does something more than memorization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In the generative adversarial learning setting, we considered a generator that can be obtained using composite functional gradient learning. Our theoretical results led to the new stable algorithm xICFG. The experimental results showed that xICFG generated equally good or better images than GAN and WGAN variants in a stable manner.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>An important concept introduced by GAN is the idea of ad- versarial learner, denoted here by d, which tries to discrim-Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Generator network automatically derived by CFG or ICFG at t = 3. '⊕' indicates addition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>−D(x)) ) and ICFG share the dis- criminator update procedure as both minimize the logis- tic loss. This fact becomes more obvious when we plug d(x) = 1 1+exp(−D(x)) into Line 5 of Algorithm 4. Next, we show that the generator update of GAN is equiv- alent to coarsely approximating a generator produced by ICFG with T =1. First note that GAN's generator update (Line 8 of Algorithm 4) requires the gradient ∇ θ G ln(1 − d(G(z))). Using d(x) = 1 1+exp(−D(x)) again, and writing Algorithm 4 GAN (Goodfellow et al., 2014) Input: S * , p z , discriminator d, G. Meta-parameters b, U . 1: repeat 2:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Figure 2. Image quality (measured by the inception score) in relation to training time. Convolutional networks. The legends are sorted from the best to the worst. The two graphs on the right are without batch normalization anywhere for all the methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Image quality (y-axis) vs. ∆D(=|D(real)−D(gen)|, x-axis). xICFG. The arrows indicate the direction of time flow. A correlation is observed both when training is succeeding (blue solid arrows) and failing (red dotted arrows).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 .</head><label>8</label><figDesc>LSUN bedrooms and living rooms (64×64). (a-c) 4-block ResNets as in Fig 2. (d-f) Fully-connected G/G as in Fig 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 .</head><label>9</label><figDesc>LSUN towers and bridges (64×64). (a-c) 4-block ResNets as in Fig 2. (d-f) Fully-connected G/G as in Fig 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 .</head><label>10</label><figDesc>(a) Real Golden Gate Bridge images in LSUN T+B; the red tower has 4 grids. (b) Images generated by xICFG that look like Golden Gate Bridge though not perfect. (c) Images generated by xICFG that look like modifications of Golden Gate Bridge with more grids or connected with an object that is not there in reality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>Algorithm 3 xICFG: Approximate ICFG Input: a set of training examples S * , prior p z , approxima- tor G at its initial state, discriminator D. Meta-parameters: input pool size, (T, b, U ) for ICFG. 1: loop</figDesc><table>2: 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards principled methods for training generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR</title>
		<meeting>International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schumm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Began</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10717</idno>
		<title level="m">Boundary equilibrium generative adversarial networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mode regularized generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR</title>
		<meeting>International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Greedy function approximation: a gradient boosting machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="90" to="5364" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27 (NIPS 2014)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improved training of Wasserstein GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<title level="m">Deep residual learning for image recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning (ICML)</title>
		<meeting>International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Introspective neural networks for generative modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lazarow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Towards deeper understanding of moment matching network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Póczos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Y</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Smolley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04076</idno>
		<title level="m">Least squares generative adversarial networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unrolled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR</title>
		<meeting>International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mroueh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sercu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gan</forename><surname>Fisher</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<meeting>NIPS Workshop on Deep Learning and Unsupervised Feature Learning</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Gradient layer: Enhancing the convergence of adversarial training for generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nitanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Suzuki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.02227</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improved techniques for training GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29 (NIPS 2016)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A note on the evaluation of generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COURSERA: Neural Networks for Machine Learning</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">AdaGAN: Boosting generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tolstikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Simon-Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Improving generative adversarial networks with denoising feature matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR</title>
		<meeting>International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Layered recursive generative adversarial networks for image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lr-Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations (ICLR</title>
		<meeting>International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Statistical behavior and consistency of classification methods based on convex risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="56" to="85" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
