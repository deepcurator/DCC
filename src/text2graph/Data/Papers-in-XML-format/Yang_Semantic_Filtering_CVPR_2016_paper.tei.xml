<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T22:25+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semantic Filtering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingxiong</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Technology</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Semantic Filtering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Edge-preserving filtering has found widespread use in many computer vision and graphics tasks. It is an image smoothing technique that removes low-contrast details/textures while maintaining sharp edges/image structures.</p><p>A large category of edge-preserving filters are designed with a specific filter kernel to measure the distance between two pixels in a local region. The distance measurement is then converted to the confidence of an edge between the two pixels for edge-aware filtering. This category is very sensitive to noise/textures. Examples are anisotropic diffusion <ref type="bibr" target="#b33">[34]</ref>, bilateral filter <ref type="bibr" target="#b41">[42]</ref>, guided image filter <ref type="bibr" target="#b22">[23]</ref> and do- * This work was partially supported by the Early Career Scheme through the Research Grants Council of Hong Kong (Project Number: CityU 21201914) and a grant from Qualcomm Technologies, Inc. main transform filter <ref type="bibr" target="#b19">[20]</ref>. The main challenge in this category is accurately including scale measurement for filter design to distinguish textures/noise from image structure. Designing a robust edge-aware filter kernel is surprisingly difficult. There is not an "optimal" solution as the detection of image edges can only be evaluated in a subjective manner. Meanwhile, numerical experiments like the Berkeley Segmentation Dataset and Benchmark (BSDS500) <ref type="bibr" target="#b2">[3]</ref> demonstrate that human subjects have various perceptions of edges in a same image.</p><p>On the other hand, significant progress has been achieved in machine learning over the past few years. Unlike standard image processing techniques that use strictly static program instructions, it normally builds a model based on example inputs and then uses it to generate predictions or decisions. The performance of a learning-based edge-preserving image filter is thus likely to be closer to human visual system when the example inputs are obtained based on average agreement between sufficient human subjects. The svm-based filter presented in <ref type="bibr" target="#b50">[51]</ref> is the first learning-based bilateral filter. As Taylor series expansion of the Gaussian function can be used to approximate the bilateral filters <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b50">[51]</ref> learns a function that maps feature vector comprising of the exponentiation of the pixel intensity, the corresponding Gaussian filtered response, and their products to the corresponding exact bilateral filtered values from the training image.</p><p>This paper aims at developing image smoothing techniques that can preserve edges between different-size objects/structures. It is a much more challenging problem. Unlike the bilateral filter, it cannot be approximated using Taylor series expansion and there is not any ground-truth filtered image for training. Nevertheless, there are sufficient hand-labelled segmentation data sets. For instance, BSDS500 <ref type="bibr" target="#b2">[3]</ref> contains 12,000 hand-labelled segmentations of 1,000 Corel dataset images from 30 human subjects. Image segmentation and edge detection is closely related to image smoothing technique. They normally pre-smooth the image with a specific low-pass filter for noise reduction.</p><p>Because human visual system is capable to understand semantically meaningful structures blended with or formed (a)Input (b)GuidedFilter <ref type="bibr" target="#b22">[23]</ref>(c)D.T. Filter <ref type="bibr" target="#b19">[20]</ref>(d)L0smooth <ref type="bibr" target="#b43">[44]</ref>(e)RelativeTV <ref type="bibr" target="#b44">[45]</ref>(f)RollingGF <ref type="bibr" target="#b53">[54]</ref> (g)Proposed <ref type="figure">Figure 1</ref>. Natural scenes like (a) contain objects of different sizes and structures of various scales. As a result, the state-of-the-art edgepreserving filters are unlikely to obtain "optimal" smoothing result without parameter adjustment as shown in (b)-(f). The default parameters included in the implementations published by the authors were used in this experiment. This paper aims at an efficient scale-aware filtering solution by integrating fast edge-preserving filtering technique with prior knowledge learned from human segmentation results. Unlike previous filters, it can sufficiently suppress image variance/textures inside large objects while maintaining the structures of small objects as shown in (g).</p><p>by texture elements <ref type="bibr" target="#b3">[4]</ref>, a "perfect" segmentation result (which agrees with human subjects) is obviously an excellent guidance for scale-invariant edge-preserving filtering. However, it is very difficult to obtain ideal edges from real life images of moderate complexity. Traditional edge detectors rely on image gradients (followed by non-maximal suppression). Unfortunately, many visually salient edges like texture edges do not correspond to image gradients. As a result, most of the state-of-the-art edge-preserving filters ignore the potential contribution from an edge detector. On the other hand, it has been demonstrated recently that the performance of learning-based edge detectors is approaching human subjects <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. This paper proposes a simple seamless combination of the recursive filtering technique and the learning-based edge classification technique for fast scale-aware edgepreserving filtering. We observed that a number of fast edge-preserving filtering techniques including anisotropic diffusion <ref type="bibr" target="#b33">[34]</ref>, recursive bilateral filter <ref type="bibr" target="#b46">[47]</ref> and domain transform filter <ref type="bibr" target="#b19">[20]</ref> operate on the differential structure of the input image. They recursively smoothen an image based on the similarity between every two neighboring pixels and are referred to as Anisotropic Filters in this paper. These filters are naturally more sensitive to noise than the others like the bilateral filter <ref type="bibr" target="#b41">[42]</ref> or guided image filter <ref type="bibr" target="#b22">[23]</ref>. They cannot separate meaningful structures from textures either. However, their computational complexity is lower as they can be implemented recursively. Another great advantage is that they can be naturally combined with a stateof-the-art learning-based edge classifier <ref type="bibr" target="#b12">[13]</ref> to encourage smoothing within regions until reaching strong edges. Such an edge classifier is trained using human-labelled contours. According to <ref type="bibr" target="#b3">[4]</ref>, "the overall structural features are the primary data of human perception, not the individual details". Learning-based edge detectors can thus robustly distinguish the contours of different-size objects from image noise and textures. When integrating with an anisotropic filter, it enables robust structure extraction from natural scenes containing objects of various scales as demonstrated in <ref type="figure">Fig. 1</ref>. <ref type="figure">Fig. 1</ref> (a) contains two images with both large scale objects (e.g., sky and meadow) and small scale objects (e.g., animals). Current state-of-the-art edge-preserving filters cannot successfully separate large scale objects from the small ones without parameter tuning as shown in <ref type="figure">Fig. 1 (b)</ref>-(f). The proposed filtering technique does not have this limitation as demonstrate in <ref type="figure">Fig. 1 (g)</ref>. Its computational complexity is also low due to the efficiency of the adopted edge classifier and the recursive filters.</p><p>Compared with the other edge-preserving filters, the proposed filtering technique has the following advantages:</p><p>• It is robust to natural scenes containing objects of different sizes and structures of various scales, and thus can successfully extract subjectively-meaningful structures from images containing multiple-scale objects.</p><p>• Its computational complexity is low and real-time performance can be achieved. The major computation cost of the proposed filtering technique resides in the adopted edge classifier <ref type="bibr" target="#b12">[13]</ref> and recursive filter, and both can obtain real-time performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Edge-Preserving Filtering</head><p>The most popular edge-preserving filter is likely to be the bilateral filter introduced by Tomasi and Manduchi <ref type="bibr" target="#b41">[42]</ref>. It has been used in many computer vision and computer graphics tasks, and a general overview of the applications can be found in <ref type="bibr" target="#b29">[30]</ref>. Let x i denote the color of an image x at pixel i and y i denote the corresponding filtered value,</p><formula xml:id="formula_0">y i = j∈Ωi G σs (|i − j|)G σr (|x i − x j |)x j j∈Ωi G σs (|i − j|)G σr (|x i − x j |) ,<label>(1)</label></formula><p>where j is a pixel in the neighborhood Ω i of pixel i, and G σs and G σr are the spatial and range filter kernels measuring the spatial and range/color similarities. The parameter σ s defines the size of the spatial neighborhood used to filter a pixel, and σ r controls how much an adjacent pixel is down-weighted because of the color difference. A joint (or cross) bilateral filter <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b15">16]</ref> is the same as the bilateral filter except that its range filter kernel G σr is computed from another image named guidance image. The brute-force implementation of the bilateral filter is slow when the kernel is large. A number of techniques have been proposed for fast bilateral filtering based on quantization on the spatial domain and/or range domain <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b20">21]</ref>. Other techniques reduce the computational complexity with additional constraints on the spatial filter kernel <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b37">38]</ref> or the range filter kernel <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>Besides accelerating bilateral filter, there are efficient bilateral-filter-like techniques derived from the anisotropic diffusion <ref type="bibr" target="#b33">[34]</ref>, weighted least square (WLS) measure <ref type="bibr" target="#b17">[18]</ref>, wavelets <ref type="bibr" target="#b18">[19]</ref>, linear regression <ref type="bibr" target="#b22">[23]</ref>, local Laplacian pyramid <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b31">32]</ref>, domain transform <ref type="bibr" target="#b19">[20]</ref> and L 0 gradient minimization <ref type="bibr" target="#b43">[44]</ref>.</p><p>These edge-preserving filters have found widespread computer graphics applications. However, they all focus on relatively small variance suppression and vulnerable to textures. The proposed filtering technique is different in that it can distinguish meaningful structures from textures and image noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Structure-Preserving Filtering</head><p>Traditional edge-preserving filtering techniques cannot distinguish textured regions/patterns from the major structures of an image. Popular structure-preserving techniques are based on the total variation (TV) model <ref type="bibr" target="#b39">[40]</ref>. It uses L1-norm based regularization constraints to enforce large-scale edges, and has demonstrated good separations of structure from texture <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b5">[6]</ref>. Xu et al. <ref type="bibr" target="#b44">[45]</ref> proposes relative total variation measures to better capture the difference between texture and structure, and develops an optimization system to extract main structures. Another model was proposed by <ref type="bibr" target="#b40">[41]</ref>. It separates oscillations from the structure layer through extrema extraction and extrapolation. Alternatively, better similarity metrics like geodesic <ref type="bibr" target="#b9">[10]</ref> or diffusion <ref type="bibr" target="#b16">[17]</ref> distances instead of traditional Euclidean distances can enhance the ability of texture-structure separation. Recently, <ref type="bibr" target="#b23">[24]</ref> uses second order statistics as a patch descriptor to capture the difference between structure and texture.</p><p>Structure-preserving filtering is normally slow before the availability of the rolling guidance filter <ref type="bibr" target="#b53">[54]</ref>. Besides the efficiency, <ref type="bibr" target="#b53">[54]</ref> also proposes a unique scale measure to control the level of details during filtering. This scale measure is very useful when manual adjustment is required/allowed. Unlike <ref type="bibr" target="#b53">[54]</ref> and most of the available structure-preserving filters, this paper aims at extracting meaning structures regardless of the sizes/scales of the objects/structures. This type of technique is desired in computer vision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Edge Detection</head><p>Edge detection is a fundamental task in computer vision and image processing. Traditional approaches like the Sobel operator <ref type="bibr" target="#b13">[14]</ref> detects edges by convolving the input image with local derivative filters. The most popular edge detector -Canny detector <ref type="bibr" target="#b6">[7]</ref> makes extensions by adding nonmaximum suppression and hysteresis thresholding steps. These approaches use low-level interpolation of the image structures, and an overview can be found in <ref type="bibr" target="#b56">[57]</ref>. Recent works focusing on utilizing machine learning techniques. They either train an edge classifier based on local image patches <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b12">13]</ref> or make use of learning techniques for cue combination <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b58">59]</ref>. Deep neural networks were also applied to edge detection recently <ref type="bibr" target="#b24">[25]</ref>.</p><p>Traditional edge detectors rely on image gradients while many visually salient edges like texture edges do not correspond to image gradients. As a result, they are not suitable for structure-preserving filtering. However, the state-of-theart detectors <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> are learned from human-labelled segmentation results including sufficient texture edges. As a result, they contain useful and accurate structural information that can be adopted for robust structure-preserving filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Scale-Aware Structure-Preserving Filtering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Anisotropic Filtering</head><p>Anisotropic diffusion is a popular edge-aware filtering technique <ref type="bibr" target="#b33">[34]</ref>. It is modeled using partial differential equations and implemented as an iterative process. The recent domain transform filter (DTF) <ref type="bibr" target="#b19">[20]</ref> and the recursive bilateral filter <ref type="bibr" target="#b46">[47]</ref> are closely related to anisotropic diffusion and can achieve real-time performance. Due to page limit, only a brief introduction of DTF is presented in this section. The proposed filtering technique is identical to DT-F except that the distance measurement in DTF (Eq.3) will be adjusted using edge confidence computed from an edge classifier and the proposed filter need to repeat iteratively until converge. As a result, a fully understand DTF is indeed not required.</p><p>Given a one-dimensional (1D) signal, DTF applies a distance-preserving transformation to the signal. A perfect distance-preserving transformation does not exist, but a simple approximation is the sum of the spatial distance (e.g., one pixel distance) and color/intensity difference between every two pixels. Let x denote the 1D input signal, and t denote the transformed signal,</p><formula xml:id="formula_1">t i = x 0 + i j=1 (1 + |x j − x j−1 |).<label>(2)</label></formula><p>Similar to the bilateral filter, two additional parameters σ s and σ r will be included in Eq. <ref type="formula" target="#formula_1">(2)</ref> to adjust the amount of smoothness in practice:</p><formula xml:id="formula_2">t i = x 0 + i j=1 (1 + σ s σ r |x j − x j−1 |).<label>(3)</label></formula><p>As can be seen from Eq. (3), this transform operates on the differential structure of the input signal, which is the same as the anisotropic diffusion. The recursive implementation of a standard low-pass filter like the Gaussian filter with kernel defined by σ s will be used to smooth the transformed signal (Eq.3) without blurring the edges, and the smoothed image is the output of DTF. DTF filters 2D signals using the 1D operations by performing separate passes along each dimension of the signal. <ref type="bibr" target="#b19">[20]</ref> demonstrates that artifact-free filtered images can be obtained by performing filtering iteratively and the filter kernel size (defined by σ s and σ r ) should be reduced iteratively to guarantee convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Structure-Preserving Anisotropic Filtering</head><p>The anisotropic filters can be implemented recursively and thus the computational complexity is relatively low. However, they are sensitive to image noise and cannot distinguish textures from structures. Available solutions either manually design low-level vision model(s) and descriptor(s) <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b23">24]</ref> to capture the difference between structure and texture or simply adopt a texture scale parameter <ref type="bibr" target="#b53">[54]</ref>. The performance of these filters is excellent when perfect parameters are used. Nevertheless, natural photos contain objects of different sizes and structures of various scales which are hard to describe using a unified low-level feature. In contrast, it has already been demonstrated on closely related research (like edge detection) that high-level features learned from human-labelled data can significantly outperform manually-designed features. This section makes use of the state-of-the-art structured learning based edge classifier <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> for structure-preserving filtering while maintain its efficiency. The sufficient human-labelled training examples from BSDS500 benchmark <ref type="bibr" target="#b2">[3]</ref> enable the proposed filtering technique to be robust to various texture scales.</p><p>DTF accumulates the image gradients to measure the distance between two pixels as can be seen from Eq. (3). However, it is clear that texture edges do not correspond to image gradients. A straightforward learning-based solution is training a deep learning architecture to map a local patch to a "perfect" image gradient value so that it is low inside a region and high around texture edges. However, it will be slow. A simpler but much faster solution is thus adopted in this paper. By taking the advantage of the inherent structure in edges in a local patch, <ref type="bibr" target="#b12">[13]</ref> proposes a generalized structured learning approach for edge classification. It has been demonstrated to be very robust to textures and very efficient.</p><p>A straight-forward solution to structure-preserving smoothing is using the edge confidence computed from <ref type="bibr" target="#b12">[13]</ref> as the guidance in DTF to smooth the input image. This type of filter is named cross/joint (bilateral) filter in the literature <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b15">16]</ref>. Let f j 1 denote the confidence of an edge at pixel j. f j is the output of <ref type="bibr" target="#b12">[13]</ref> at pixel j and represents the probability of an edge at j. Eq. (3) can be modified as follows to suppress gradients (due to textures) inside a region:</p><formula xml:id="formula_3">t i = x 0 + i j=1 (1 + σ s σ r · f j ),<label>(4)</label></formula><p>The corresponding filter is referred to as cross DTF. This is a good solution given a perfect edge classifier which however, does not exist in practice. It may introduce visible artifacts or blur the image as shown in <ref type="figure" target="#fig_1">Fig.3(d)</ref>.  This paper proposes to use the edge confidence to adjust the original distance measurement in DTF:</p><formula xml:id="formula_4">t i = x 0 + i j=1 (1 + σ s σ r · f j |x j − x j−1 |),<label>(5)</label></formula><p>The combination of the edge confidence and the image gradients can effectively suppress the potential artifacts cause by incorrect edge detection.  A simple and robust solution is removing these textures using rolling guidance filter <ref type="bibr" target="#b53">[54]</ref> in advance as demonstrated in (d). However, it will be relatively slow. To improve the efficiency, this paper alternatively uses the differential structure of median filtered image to smooth the original input image as shown in (g). Dashed ellipses will be discussed in text.</p><p>The gray curves in <ref type="figure" target="#fig_3">Fig. 2 (k)</ref> represent the original image gradients of the red and green rows of <ref type="figure" target="#fig_3">Fig. 2 (a)</ref>, respectively. Traditional anisotropic filters are vulnerable to textures in these two rows. The red curves in <ref type="figure" target="#fig_3">Fig. 2 (j)</ref> represent the edge confidence detected from these two rows, respectively. The peaks in the two red curves correspond to the edges in the red and green rows in <ref type="figure" target="#fig_3">Fig. 2 (a)</ref>. The edge confidence is used to suppress the image gradients inside the textured regions and enable texture removal according to Eq. (5). The red curves in <ref type="figure" target="#fig_3">Fig. 2 (k)</ref> represent the modified image gradients (which correspond to the f j |x j − x j−1 | values in Eq. 5). Note that the variance of the image gradients inside the textured regions were significantly suppressed, and thus the resulted anisotropic filter can successfully remove most of the textures (e.g., the hat) as can be seen in <ref type="figure" target="#fig_3">Fig. 2 (b)</ref> and the red curves in (i). New edge confidence can be obtained from the filtered image and used to further suppress the textures/noise.</p><p>The proposed structure-preserving filtering technique iteratively compute edge confidence using structuredlearning based edge classifier and use it to suppress the textures until convergence. Same as <ref type="bibr" target="#b19">[20]</ref>, the filter kernels, that is σ s and σ r in Eq. <ref type="formula" target="#formula_4">(5)</ref> are iteratively reduced by half to guarantee convergence <ref type="bibr" target="#b1">2</ref> . Although it will not affect the transform in Eq.(5), reducing σ s will decrease the filter kernel of the low-pass filter used to smooth the transformed signal (see the text below Eq.3 for details), and thus convergence can be guaranteed. <ref type="figure" target="#fig_3">Fig. 2 (c)</ref> presents the filtered image after 10 iterations. It shows that most of the visible textures are removed. The green, blue and purple lines in the first row of <ref type="figure" target="#fig_3">Fig. 2 (i)-(k)</ref> correspond to the pixel intensities, edge confidence measurements and updated image gradients of the red row in (a) after 2, 3 and 10 iterations, respectively. It shows that the proposed filter converges quickly (after only about 3 iterations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Suppress small-scale textures around edges</head><p>The filter presented in Eq. (5) cannot sufficiently remove small-scale textures around highly-confident edges as shown in the close-ups below <ref type="figure" target="#fig_3">Fig. 2 (b)-(c)</ref>. This is due to the imperfect confidence measurements around a texture edge. As shown in the yellow ellipse in <ref type="figure" target="#fig_3">Fig. 2 (k)</ref>, large image gradients around texture edges cannot be effectively suppressed even after a large number of iterations. As a result, the original pixel values will be preserved as can be seen from the yellow ellipse in <ref type="figure" target="#fig_3">Fig. 2 (i)</ref>. Applying a small median filter (MF) to the input image cannot significantly affect the edge confidence around highly-confident edges as can be seen in the blue and purple lines in <ref type="figure" target="#fig_3">Fig. 2 (j)</ref>. However, it is very effective for removing textures around edges as demonstrated in <ref type="figure" target="#fig_3">Fig. 2 (e)-(f)</ref> and the blue and purple lines in the second row of <ref type="figure" target="#fig_3">Fig. 2 (i)</ref> and (k) (see the values around the two yellow ellipses). Nevertheless, median filter will of course remove thin-structured objects as shown in the close-ups under <ref type="figure" target="#fig_3">Fig. 2 (e)-(f)</ref>. Let x MF denote the median filter result of the input signal x, this paper ONLY uses x MF to compute the image gradients in Eq. (5). The proposed structure-preserving DTF are computed as follows: <ref type="figure" target="#fig_3">Fig. 2 (g</ref>) presents the filtered images with the proposed DTF (Eq. <ref type="formula" target="#formula_5">(6)</ref>). They both successfully remove the textures in <ref type="figure" target="#fig_3">Fig. 2 (a)</ref>-(c) while better preserving the details around thin-structured objects. An alternative solution is directly applying rolling guidance filter <ref type="bibr" target="#b53">[54]</ref> to the input image to remove the small-scale textures and the result is presented in <ref type="figure" target="#fig_3">Fig. 2 (d)</ref>. However, it will be relatively slow. The median filter size, σ s and σ r will be reduced by half after every iteration to guarantee convergence, and it normally converges after as few as two iterations. As a natural scene contains textures of different scales, the size of the employed median filter should be adjusted accordingly. Otherwise it may either blur structures or cannot completely remove all textures as shown in <ref type="figure" target="#fig_5">Fig. 4</ref>. This paper directly relies on the level of textureness which is represented by the percentage of low confident edges detected by <ref type="bibr" target="#b12">[13]</ref> to decide the median filter size.</p><formula xml:id="formula_5">t i = x 0 + i j=1 (1 + σ s σ r f j |x MF j − x MF j−1 |),<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Computational complexity</head><p>The computation cost of the proposed filtering technique resides in the adopted state-of-the-art edge detector <ref type="bibr" target="#b12">[13]</ref>, DTF and the median filter <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b34">35]</ref>. They can all run in real-time and thus the whole pipeline will be very fast if the number of iterations is low. This paper uses the BSDS500 benchmark <ref type="bibr" target="#b2">[3]</ref> to analyze the convergence problem. The average PSNR values from the filtered images between every two iterations are presented in <ref type="figure" target="#fig_6">Fig. 5</ref>. As can be seen, it is safe to stop after only 2 iterations as the PSNR value computed from the filtered images after 2 and 3 iterations is higher than 40 dB (which corresponds to almost invisible difference). In practice, a downsample-version is sufficient for both the edge detector <ref type="bibr" target="#b12">[13]</ref> and the median filter when the image resolution is relatively large (e.g., one megapixel). As a result, the computation cost mainly resides in the adopted anisotropic filter which operates on the full-resolution input image.   The complete comparison with the other state-of-the-art filters is presented in <ref type="table">Table 1</ref>. The last row presents the runtime when the rolling guidance filter <ref type="bibr" target="#b53">[54]</ref> is used as a pre-smoothing step (to remove small-scale textures around edges). Note that both the proposed filter and <ref type="bibr" target="#b53">[54]</ref> are significantly faster than the others. However, <ref type="bibr" target="#b53">[54]</ref> is not suitable for images containing various structure scales as shown in <ref type="figure" target="#fig_8">Fig. 6.</ref>   . Proposed filter and the rolling guidance filter <ref type="bibr" target="#b53">[54]</ref> are significantly faster than the others. Rolling guidance filter requires an estimate of the structure scale and can effectively smooth out the corresponding textures. However, it is not suitable for scenes containing objects/structures of multiple scales as can be seen from (c)-(e). It either cannot sufficiently remove textures in a large-scale object or blur small-scale objects. The computational complexity of proposed filter is close to <ref type="bibr" target="#b53">[54]</ref>  eter setting <ref type="bibr" target="#b2">3</ref> . The adoption of learning-based edge detection technique <ref type="bibr" target="#b12">[13]</ref> enable the proposed filter to be robust to natural scenes containing objects of different sizes and structures of various scales.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Comparison with the state-of-the-art</head><p>Quantitative evaluation of structure-preserving filtering is difficult, and thus the state-of-the-art methods <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b44">45]</ref> present only visual evaluation. In this section, we propose to numerically evaluate the improvement over the state-ofthe-art saliency detection algorithm when the original image is processed by the state-of-the-art filters. We choose the ECSSD dataset <ref type="bibr" target="#b45">[46]</ref> which is known to be difficult and Minimum Barrier Saliency (MBS) detection algorithm <ref type="bibr" target="#b52">[53]</ref> are presented in <ref type="figure" target="#fig_9">Fig. 8</ref>. Note that the proposed filter consistently outperforms the state-of-the-art filters <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b44">45]</ref>. The corresponding mean absolute errors (MAE) <ref type="bibr" target="#b32">[33]</ref> and weighted-F-measure scores <ref type="bibr" target="#b26">[27]</ref> are presented in <ref type="table">Table 2</ref> which show that the proposed filter has the lowest error rate and the highest weighted-F-measure score.  <ref type="table">Table 2</ref>. Mean absolute errors (MAE) and weighted-F-measure scores (WFM). The proposed filter has the lowest error and the highest weighted-F-measure score.</p><p>(a)Input (b)Edge <ref type="bibr" target="#b12">[13]</ref> (c)L0 smoothing <ref type="bibr" target="#b43">[44]</ref> (d)Rolling GF <ref type="bibr" target="#b53">[54]</ref> (e)Relative TV <ref type="bibr" target="#b44">[45]</ref> (f)Proposed. Visual comparison with the state-of-the-art structure-preserving filters under constant/default parameter setting. Unlike the stateof-the-art filters, the proposed filter is more robust to various object scales due to adoption of learning-based edge detection technique <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>An efficient structure-preserving filtering technique is proposed in the paper. Unlike the current state-of-the-art structure-preserving filters that use low-level vision features to design the filter kernel, the proposed technique is developed based on high-level understanding of the image structures. It is a seamless combination of the fast anisotropic filtering technique(s) with the structure learning based edge detector. The use of edge models trained from humanlabelled data sets enables the proposed filter to better preserve the structure edges that can be detected by the human visual system. As a result, it is more robust to objects/structures with different sizes/scales.</p><p>The proposed technique cannot be directly applied to other edge-preserving filters like the guided filter <ref type="bibr" target="#b22">[23]</ref> and most of the quantization-based fast bilateral filters <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b20">21]</ref>. <ref type="figure" target="#fig_11">Fig.9(a)-(b)</ref> show that the guided filter is vulnerable to textures when a constant filter kernel is used. A simple extension is adjusting the edge confidence to adaptively control the guided filter kernel so that small kernel will be used around edges. <ref type="figure" target="#fig_11">Fig.9(c)-(d)</ref> present the edge confidence before and after minimum filtering, and <ref type="figure" target="#fig_11">Fig.9</ref>(e) presents the guided filtered image using an adaptive kernel based on the edge confidence in (d). It outperforms the original guided filter for suppressing textures while capable of maintaining the most salient structure edges. However, the quality is obviously lower than the integration of an anisotropic filter as shown in <ref type="figure" target="#fig_11">Fig.9(f)</ref>. A better extension for other edge-preserving filters will be investigated in the near future. . The proposed technique can be adjusted for the integration with guided filter but the quality will be lower than anisotropic filters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>DTF (w.r.t. different parameters).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Direct use of the edge confidence as the guidance may introduce visible artifacts or blur the image as shown in (d) (zoom in for details). (c) shows that the combination of the image gradients from (a) and the edge confidence in (b) can effectively suppress the potential artifacts due to imperfect edge detection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>values (on the red channel) (j) Edge confidence (k) Image gradients.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Integration of anisotropic filters with edge detector can successfully remove textures except for small-scale textures around the edges as can be seen in (b)-(c). A simple and robust solution is removing these textures using rolling guidance filter [54] in advance as demonstrated in (d). However, it will be relatively slow. To improve the efficiency, this paper alternatively uses the differential structure of median filtered image to smooth the original input image as shown in (g). Dashed ellipses will be discussed in text.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Different median filter size will affect the texture removal result around edges and thus the filter size should be adjusted according to the scene content.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Average PSNR values computed from filtered images between every two iterations. PSNR values larger than 100 was shown as 100 for better visualization (as it can be infinity).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7</head><label>7</label><figDesc>Fig. 7 visually compare the proposed filtering technique with the state-of-the-art filters under constant param-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6</head><label>6</label><figDesc>Figure 6. Proposed filter and the rolling guidance filter [54] are significantly faster than the others. Rolling guidance filter requires an estimate of the structure scale and can effectively smooth out the corresponding textures. However, it is not suitable for scenes containing objects/structures of multiple scales as can be seen from (c)-(e). It either cannot sufficiently remove textures in a large-scale object or blur small-scale objects. The computational complexity of proposed filter is close to [54] but is more robust to this limitation as demonstrated in (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Precision-recall curves for saliency detection. Note that the combination of the structure-preserving filters can outperform the original MBS method on average and the proposed filter consistently outperforms the others.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Visual comparison with the state-of-the-art structure-preserving filters under constant/default parameter setting. Unlike the stateof-the-art filters, the proposed filter is more robust to various object scales due to adoption of learning-based edge detection technique[13].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Limitation. The guided filter is not effective for removing textures as shown in (b). The proposed technique can be adjusted for the integration with guided filter but the quality will be lower than anisotropic filters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>but is more robust to this limitation as demonstrated in (b).Rolling GF[54](with D.T. Filter[20]) 0.15 Proposed (with D.T. Filter[20]) 0.14 Proposed (with [54]+D.T. Filter[20]) 0.27 Table 1. Exact runtime for processing a one megapixel color image on an Intel i7 3.4GHz CPU.</figDesc><table>Method 
Runtime(Sec./Mp) 
Relative TV[45] 
35 
L0 Smoothing[44] 
18 
WMF[55] 
18 
Covariance M2[24] 
614 
</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">f j will be re-computed after every iteration.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">σs = 0.4 and σr =0.04 in all the conducted experiments.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">which is the latest algorithm that outperforms all the others on this dataset. The precision-recall curves which evaluate the overall performance of a saliency detection method 3 The default parameters included in the implementations published by the authors of [44, 54, 45] were used. 4 The implementation published by the authors was used.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast high-dimensional filtering using the permutohedral lattice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="753" to="762" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Gaussian kd-trees for fast high-dimensional filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gelfand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dolson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2009-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Contour detection and hierarchical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="898" to="916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Art and Visual Perception: A Psychology of the Creative Eye</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Arnheim</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1956" />
			<publisher>University of California Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast local laplacian filters: Theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aubry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Hasinoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ToG</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Structure-texture image decomposition-modeling, algorithms, and parameter selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Aujol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="111" to="136" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A computational approach to edge detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Canny</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>PA-MI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Efficient, high-quality image contour detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sundaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Real-time edge-aware image processing with the bilateral grid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Geodesic image and video editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ToG</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Supervised learning of edges and object boundaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Structured forests for fast edge detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Fast edge detection using structured forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>PAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Pattern Classification and Scene Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">O</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Hart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast bilateral filtering for the display of high-dynamic-range images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dorsey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Flash photography enhancement via intrinsic relighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Siggraph</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="673" to="678" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Diffusion maps for edge-aware image editing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Farbman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fattal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<idno>145:1-145:10</idno>
	</analytic>
	<monogr>
		<title level="j">ToF</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Edgepreserving decompositions for multi-scale tone and detail manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Farbman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fattal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ToG</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Edge-avoiding wavelets and their applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ToG</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Domain transform for edge-aware image and video processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gastal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oliveira</surname></persName>
		</author>
		<idno>69:1-69:12</idno>
	</analytic>
	<monogr>
		<title level="j">TOG</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adaptive manifolds for real-time high-dimensional filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gastal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOG</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Perceptual organization and recognition of indoor scenes from rgb-d images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<title level="m">Guided image filtering. PAMI</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1397" to="1409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Structure-preserving image smoothing via region covariances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Karacan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Erdem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Erdem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ToG</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="176" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Visual boundary prediction: A deep neural prediction network and quality dissection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Kivinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sketch tokens: A learned mid-level representation for contour and object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">How to evaluate foreground maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Margolin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Oscillating Patterns in Image Processing and Nonlinear Evolution Equations: The Fifteenth Dean Jacqueline B</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lewis Memorial Lectures. American Mathematical Society</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A fast approximation of the bilateral filter using a signal processing approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="24" to="52" />
			<date type="published" when="2009-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kornprobst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tumblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<title level="m">Bilateral filtering: Theory and applications. Foundations and Trends in Computer Graphics and Vision</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Local laplacian filters: Edge-aware image processing with a laplacian pyramid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parisand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Hasinoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<idno>68:1-68:12</idno>
	</analytic>
	<monogr>
		<title level="j">ToG</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Local laplacian filters: Edge-aware image processing with a laplacian pyramid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parisand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Hasinoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Saliency filters: Contrast based filtering for salient region detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pritch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hornung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="733" to="740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="629" to="639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Median filtering in constant time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Perreault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2389" to="2394" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Digital photography with flash and no-flash image pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Petschnigg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Siggraph</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="664" to="672" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Separable bilateral filtering for fast video preprocessing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Van Vliet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimedia and Expo</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Constant time o(1) bilateral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Discriminatively trained sparse code gradients for contour detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liefeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Nonlinear total variation based noise removal algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. D</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Edge-preserving multiscale image decomposition based on local extrema</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Subr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Soler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ToG</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Bilateral filtering for gray and color images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manduchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="839" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Fast median and bilateral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Siggraph</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="519" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Image smoothing via l0 gradient minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Structure extraction from texture via natural variation measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (SIGGRAPH Asia)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Hierarchical saliency detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Recursive bilateral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="399" to="413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Recursive approximation of the bilateral filter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1919" to="1927" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Constant time median and bilateral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-H</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="307" to="318" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Real-time o(1) bilateral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="557" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Svm for edge-preserving filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1775" to="1782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Image cartoon-texture decomposition and feature selection using the total variation regularized l1 functional</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goldfarb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLSM</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="73" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Minimum barrier salient object detection at 80 fps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mech</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Rolling guidance filter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">100+ times fasterweighted median filter (wmf)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Detecting object boundaries using low-,mid-, and high-level information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Edge detection techniquesan overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ziou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tabbone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition and Image Analysis</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="537" to="559" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Edge boxes: Locating object proposals from edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">The role of image understanding in contour detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
