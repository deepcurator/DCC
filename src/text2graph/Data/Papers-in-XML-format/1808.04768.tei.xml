<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive Skip Intervals: Temporal Abstraction for Recurrent Dynamical Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Neitz</surname></persName>
							<email>3aneitz@tue.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giambattista</forename><surname>Parascandolo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Max Planck ETH Center for Learning Systems</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Max Planck ETH Center for Learning Systems</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Max Planck ETH Center for Learning Systems</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptive Skip Intervals: Temporal Abstraction for Recurrent Dynamical Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We introduce a method which enables a recurrent dynamics model to be temporally abstract. Our approach, which we call Adaptive Skip Intervals (ASI), is based on the observation that in many sequential prediction tasks, the exact time at which events occur is irrelevant to the underlying objective. Moreover, in many situations, there exist prediction intervals which result in particularly easy-to-predict transitions. We show that there are prediction tasks for which we gain both computational efficiency and prediction accuracy by allowing the model to make predictions at a sampling rate which it can choose itself.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A core component of intelligent agents is the ability to predict certain properties of future states of their environments <ref type="bibr" target="#b16">(Legg and Hutter, 2007)</ref>. For example, model-based reinforcement learning <ref type="bibr" target="#b7">(Daw, 2012;</ref><ref type="bibr" target="#b0">Arulkumaran et al., 2017)</ref> decomposes the task into the two components of learning a model and then using the learned model for planning ahead.</p><p>Despite significant recent advances, even relatively simple tasks like pushing objects is still a challenging robotic task and foresight for robot planning is still limited to relatively short horizon tasks . This is partially due to the fact that errors even from early stages in the prediction pipeline are accumulating especially when new or complex environments are considered.</p><p>Many dynamical systems have the property that long-term predictions of future states are easiest to learn if they are obtained by a sequence of incremental predictions. Our starting point is the hypothesis that at each instant of the evolution, there is an ideal temporal step length associated with those state transitions which are easiest to predict: Intervals which are too long correspond to complicated mechanisms that could be simplified by breaking them down into a successive application of simpler mechanisms. On the other hand, intervals which are too short do not contain much change, which means that the predictor has to represent roughly the identity -this can lead to a situation where the model makes small absolute errors δs, but a large relative error δs ∆t , which is the rate at which the prediction error accumulates. This tradeoff is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. An additional drawback of too short prediction intervals is that it requires many predictions, which can be computationally expensive. Somewhere in-between the two extremes, there is an ideal step length corresponding to transitions that are easiest to represent and learn. right level of temporal granularity. This idea is closely related to causal inference <ref type="bibr" target="#b24">(Peters et al., 2017)</ref> and the identification of invariances <ref type="bibr" target="#b22">(Pearl, 2009;</ref><ref type="bibr" target="#b27">Schölkopf et al., 2012;</ref><ref type="bibr" target="#b23">Peters et al., 2016)</ref> and mechanisms <ref type="bibr" target="#b21">(Parascandolo et al., 2017)</ref>. ASI allows the model to dynamically adjust the temporal resolution at which predictions are made, based on the specific observed input. In other words, the model has the option to converge to the easiest-to predict transitions, with prediction intervals ∆t that are not constant over the whole trajectory, but situation-dependent. Moreover, the model is more robust to certain shifts in the evolution speed at training time, and also to shifts to datasets where the trajectories are partly corrupted. For example, when some frames are missing or extremely noisy, a frame-by-frame prediction method would be forced to model the noise, especially if it is not independent of the state. Flexibly adjusting the time resolution of predictions also results in more computationally efficiency, as fewer steps need to be predicted where they are not necessary -a key requirement for real-time applications. A type of prediction task which can especially profit from our proposed method is one which exhibits a property we call inconsequential chaos. To illustrate this, consider the following example: In <ref type="figure" target="#fig_1">Figure 2</ref> we visualize the trajectories of a ball which falls into a funnel-shaped object at different initial horizontal velocities. The exact trajectories that are taken within the funnel depend sensitively on the initial state and are therefore difficult to predict ahead of time. On the other hand, predicting that the ball will hit the horizontal platform on the bottom is easy because it only requires knowing that when the ball falls somewhere into the funnel, it will come out at the bottom end, irrespective of how long it bounces around. If we are only interested in predicting where the ball will ultimately land, we can skip the difficult parts, provided that they are inconsequential. <ref type="figure" target="#fig_2">Figure 3</ref> explains another perspective to motivate our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem statement</head><p>The machine learning problem we are considering is a classification problem where the labels are generated by a dynamical process, such as a Hidden Markov Model. As auxiliary data, we get access to observations of the system's internal state. The training data consists of observation sequences {x (i) } i∈1,...,N and labels {y (i) } i∈1,...,N . The trajectories x are ordered sequences of elements x t from an observation space X . Typically, a trajectory x arises from repeatedly measuring the dynamical system's state at some fixed sampling rate. To keep the scope limited, we assume the labels y (i) to be categorical, i.e. belonging to a finite set Y. In our formulation, there is only a single label for each trajectory, which intuitively corresponds to the eventual "outcome" of the particular system evolution. At test time, we are only given some initial observations (x 0 , x 1 , ..., x k ), for some small k (e.g., k = 0 in the fully-observable case) and have to predict the corresponding label y.</p><p>Note that the problem does not demand the prediction of any future observations x t . As a performance measure we use the accuracy of the label predictions. The role of the classification task is to provide  a way to measure performance, as the objective is to know how well the model is suited to predict the qualitative outcome of each instance. We explicitly do not care about the loss in pixel space. Since frames may be skipped, video-prediction metrics are not relevant for this task. In the future we would like to use our model in latent spaces as well.</p><p>It is straightforward to generalize the classification task to a value prediction task in a (hierarchical) reinforcement learning setting, given a fixed policy (e.g. an option, as introduced in <ref type="bibr" target="#b29">Sutton et al. (1999)</ref>). However, in this work we focus on uncontrolled tasks only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Environment simulators</head><p>Environment simulators are models which approximate the conditional probability distribution</p><formula xml:id="formula_0">P (X t+1 , R t+1 |X t )<label>(1)</label></formula><p>where X t is a random variable with range X which describes the Markovian state of the system at time t. R t is the random variable over some real-valued cumulant which we want to track for our task. In order to simplify our experiments, in this paper we consider the special case of fully-observable tasks. For this reason, we use the terms "observation" and "state" interchangeably. However, note that in realistic applications, it may be desirable to predict future states given past observations, which poses the additional challenge of state inference. As an additional simplification, we consider deterministic simulators, which put a probability point mass of one on a single future state. For a recent, more detailed investigation of several efficient state-space architectures, see <ref type="bibr" target="#b5">Buesing et al. (2018)</ref>.</p><p>Note that given a distribution over an initial X 0 , we can apply an environment simulator multiple times to a distribution over the initial state, yielding a probability distribution over trajectories and cumulants.</p><formula xml:id="formula_1">P (X 0:N , G 0:N ) = P (X 0 ) N t=1 P (X t , G t |X t−1 )<label>(2)</label></formula><p>Temporally abstract environment simulators only need to represent a relaxed version of the above conditional probability distribution:</p><formula xml:id="formula_2">P (X t+τ , R τ t |X t )<label>(3)</label></formula><p>where τ is some arbitrary time skip interval up to the end of the trajectory, which can be chosen by the model and R τ t denotes the sum τ k=t R k . In other words, a temporally abstract environment simulator must only be able to predict some future state of the system and additionally provide the sum of the cumulants since the last step. To address the classification problem defined in Section 2.1, we only consider tasks where the cumulant is zero everywhere except for the last state of the trajectory, which is a plausible restriction if the cumulant tracks some form of "outcome" of the trajectory.</p><p>The dynamical models we consider in this paper consist at their core of a deep neural network f : X → X which is meant to represent the dynamical law of the environment. In order to learn to predict multiple time-steps into the future, f is iterated multiple times, which makes the architecture a recurrent neural network. As the model predicts the new state at time t + 1, it needs to be conditioned … <ref type="figure">Figure 4</ref>: Visualization of the first three steps of ASI with a horizon of H = 3. The blue lines represent loss components between the ground truth frames x and predicted framesx. For simplicity, we do not consider scheduled sampling here, therefore f is always applied to the previous predicted state.</p><p>on the previous state at the previous time step t. During training, there is a choice for the source of the next input frame for the model: Either the ground truth (observed) frame or the model's own previous prediction can be taken. The former provides more signal when f is weak, while the latter matches more accurately the conditions during inference, when the ground truth is not known. We found the technique of scheduled sampling <ref type="bibr" target="#b3">(Bengio et al., 2015)</ref> to be a simple and effective curriculum to address the trade-off described above. Note that other works, such as <ref type="bibr" target="#b6">Chiappa et al. (2017)</ref> and <ref type="bibr" target="#b20">(Oh et al., 2017)</ref> have addressed the issue in different ways. The exact way of dealing with this issue is orthogonal to the use of temporal abstraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Adaptive skip intervals for recurrent dynamical models</head><p>We now introduce a method to inject temporal abstraction into deterministic recurrent environment simulators.</p><p>Training process The main idea of ASI is that the dynamical model f is not forced to predict every single time step in the sequence. Instead, it has the freedom to skip an arbitrary number of frames up to some pre-defined horizon H ∈ N. We train f in such a way that it has the incentive to focus on representing those transitions which allow it to predict extended sequences which are accurate over many time steps into the future. <ref type="figure">Figure 4</ref> visualizes the three steps of the ASI training procedure with a horizon of H = 3.</p><p>Algorithm 1: Dynamical model learning with ASI</p><formula xml:id="formula_3">Input :i'th trajectory x (i) = (x1, x2, ..., xT i ) ∈ X T i Differentiable model f : X → X w/ params θ Loss function L : X × X → R Matching-horizon H ∈ N Exploration schedule µ : N → [0, 1] Scheduled sampling temperatures : N → [0, 1] t ← 1, u ← 1 Data timestep t, abstract timestep u l ← 0 Trajectory loss p ← x1</formula><p>Next input to the dynamics model f</p><formula xml:id="formula_4">while t &lt; |x| dô xu ← f (p) T ← min(t + H, |x|) Upper time step limit if Bernoulli(µ(i)) = 0 then t ← arg min t ∈{t+1..T } L(xu, x t ) else t ∼ unif{t + 1, T } Exploration end l ← l + L(xu, xt)</formula><p>Accumulate trajectory loss p ← binary_choice(xu, xt; p = (i)) Scheduled sampling <ref type="bibr" target="#b3">(Bengio et al., 2015</ref>) u ← u + 1 end θ ← gradient descent step on θ to reduce l At training time, we feed the first frame x 1 into a differentiable model f , producing the output x 1 := f (x 1 ). In contrast to classical autoregressive modeling,x 1 does not have to correspond to the next frame in the ground truth sequence, x 2 , but can be matched with any frame from x 2 to x 2+H . Importantly, f is not required to know how many frames it is going to skip -the temporal matching is performed by a "training supervisor" who takes f 's prediction and selects the best-fitting ground-truth frame to compute the loss, which is later on reduced using gradient based optimization.</p><p>To soften the winner-takes-all mechanism, we use an exploration-curriculum. At every step, a Bernoulli trial with probability µ decides whether an exploration or an exploitation step is executed: In an exploration step, the supervisor selects a future frame at random with a frameskip value between 1 and H; in an exploitation step, the supervisor takes the best-fitting groundtruth frame</p><formula xml:id="formula_5">x i = argmin t∈{2..2+H} L x (x b , x t )</formula><p>to provide the training signal. At the beginning of training, µ is high, such that exploration is encouraged. Over the course of several epochs, µ is gradually decreased such that f can converge to predicting sharp mechanisms. The goal of the exploration schedule is to avoid being caught in a local optimum early on during training. Over the course of the learning process, we gradually decrease the chance of picking a random frame, effectively transitioning to the winner-takes-all mechanism. We refer to this curriculum scheme Exploration of temporal matching.</p><p>The best fitting frame x i is then fed into f again, iterating the same procedure as described above, but from a later starting point. At every step, we accumulate a loss l x , leading to an overall prediction loss L x which is simply the mean of all the step-losses. We train the model f via gradient descent to reduce the prediction loss L x .</p><p>In the example with the funnel, this could intuitively work as follows: the transition from the ball which falls into the funnel to the ball which is at the end of the funnel is the most robust one (let's call it the "robust transition") -it occurs virtually every time. All other positions within the funnel are visited less often. Therefore, f will tend to get most training signal from the robust transition. Hence, f will begin to predict something that resembles the robust transition, which will subsequently be reinforced because it will often be the best-fitting transition which wins in the matching process.</p><p>Instead of using a greedy matching algorithm it is conceivable to use a global optimization method which is applied to the whole sequence of iteratively predicted frames, which would then be aligned in the globally best possible way to the ground truth data. However, in this case, we would not be able to alternate randomly between the input sources for f , as we currently do with scheduled sampling, because in order to know which ground truth frame to take next, we already need to know the alignment.</p><p>Besides exploration of temporal matching,as mentioned in Section 2.2 we adopt another curriculum scheme, scheduled sampling <ref type="bibr" target="#b3">(Bengio et al., 2015)</ref>, which gradually shifts the training distribution from observation-dependent transitions towards prediction-dependent transitions.</p><p>Predicting the labels Since the learning procedure can choose to skip difficult-to-predict frames, the mean loss in pixel space would not be a fair metric to evaluate whether ASI serves a purpose. As explained in Section 2.1, one of our central assumptions is that we are dealing with environments which have the notion of a qualitative outcome, represented e.g. by the classification problem associated with the task. Therefore, as a way to measure the learning success, we let a separate classifier ψ : X → P(Y) predict the label of the underlying classification task based on the frames predicted by f . At test time, f can unfold the dynamics over multiple steps and ψ is applied to the resulting frames, allowing the combined model to predict the label from the initial frame.</p><p>In principle, the classifier ψ could be trained alongside the model f , or after convergence of f -the two training processes do not interfere with each other. For the experiments described in Section 4, we hand-specify a classifier ψ ahead of time for each environment. Since our classification tasks are easy, given the last frame of a trajectory, the classifiers are simple functions which achieve perfect accuracy when fed the ground truth frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We demonstrate the efficacy of our approach by introducing two environments for which our approach is expected to perform well. Code to reproduce our experiments is available at https://github.com/neitzal/adaptive-skip-intervals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Domains</head><p>Room runner In the Room runner task, an agent, represented by a green dot, moves through a randomly generated map of rooms, which are observed in 2D from above. The agent follows the policy of always trying to move towards and into the next room, until it reaches a dead end. Two rooms are colored -the actual dead end which the agent will reach and another room, which is a dead end for another path. One of these two rooms is red, the other one blue, but the assignment is chosen by a fair coin flip. The underlying classification task is to predict whether the agent will end up in the red room or in the blue one. Since there is always exactly one passage between two adjacent rooms, the final room is always well-defined and there is no ambiguity in the outcome. We add noise to the runner's acceleration at every step, simulating an imperfect controller -for example one which is still taking exploratory actions in order to improve.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funnel board</head><p>In this task, a ball falls through a grid of obstacles onto one of five platforms. Every other row of obstacles consists of funnel-shaped objects, which are meant to capture the ball and release it at a well-defined exit position. Variety arises from the random rotations of the sliders, from the random presence or absence of funnels in every layer except for the last one, and from slight perturbations in the funnel and slider positions. The courses are generated such that the ball is always guaranteed to hit exactly one of the platforms. <ref type="figure" target="#fig_5">Figure 6</ref> shows three examples for the first states and the ball's resulting paths. In order to simplify the problem, we make the states nearly fully observable by preprocessing the video frames such that they include a trace of the ball's position at the previous step.</p><p>The underlying classification task is to predict, given only access to the first frame, on which of the five platforms the ball will land eventually. Note that the task does not include predicting the time when the ball will reach its goal. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiment setup</head><p>The experiments are ablation studies of our method. We would like to investigate the efficacy of adaptive skip intervals and whether the exploration schedule is beneficial to obtain good results. For each of our two environments, we compare four methods: (a) The recurrent dynamics model with adaptive skip intervals as described in Section 3. (ASI) (b) The dynamics model with adaptive skip intervals, but without any exploration phase, i.e. µ = 0. (ASI w/o exploration) (c) The dynamics model without adaptive skip intervals such that it is forced to predict every step (fixed (∆t = 1)). (d) The dynamics model without adaptive skip intervals such that it is forced to predict every second step (fixed (∆t = 2)). In each experiment we train with a training set of 500 trajectories, and we report validation metrics evaluated on a validation set of 500 trajectories. We perform validation steps four times per epoch in order to obtain a higher resolution in the training curves.</p><p>For our experiments, we use a neural network with seven convolutional layers as the dynamics model f . Architectural details, which are the same in all experiments, are described in the Appendix. Like <ref type="bibr" target="#b31">(Weber et al., 2017)</ref>, we train f using a pixel-wise binary cross entropy loss. Hyperpararameter settings such as the learning rates are determined for each method individually by using the set of parameters which led to the best result (highest maximum achieved accuracy on the validation set), out of 9 runs each. We use the same search ranges for all experiments and methods. The remaining  hyperparameters, including search ranges, are provided in the Appendix. For instance, as a value for the horizon H in the ASI runs, our search yielded optimal results for values of around 20 in both experiments. After fixing the best hyperparameters, each method is evaluated 8 additional times with different random seeds, which we use to report the results. We additionally included baselines with ∆t &gt; 2, but to reduce the amount of computation did not perform another hyperparameter search for them, instead taking the best parameters for the baseline "fixed (∆t = 2)".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results</head><p>We begin by visualizing how the network with adaptive skip intervals performs after training. In <ref type="figure" target="#fig_7">Figure 8</ref> we show a portion of one trajectory from the Funnel board, as processed by the network. As shown, the network trained with ASI has learned to skip a variable number of frames, specifically avoiding the bouncing in the funnel, and directly predicting the exiting ball. Similarly, <ref type="figure" target="#fig_6">Figure 7</ref> shows a portion of a sequence from the Room runner domain. As the videos presented at http://tiny.cc/x2suwy demonstrate, ASI is able to produce sharp predictions over many time-steps while the fixed-skip baselines produce blurry predictions.</p><p>Quantitative results As shown in <ref type="figure" target="#fig_9">Figure 9</ref>, ASI outperforms the fixed-steps baselines on both datasets. On Funnel board the networks equipped with adaptive skip intervals achieve higher accuracy and in a shorter time, with exploration of adaptive skip intervals obtaining even better results. In the  Room runner task, we observe a significant improvement of ASI with exploration over the version without exploration and the baselines. Note that some of the baselines curves get worse after an initial improvement. This can be explained by the fact that the two training curricula, scheduled sampling and exploration of temporal matching, create a nonstationary distribution for the network. We observe that ASI appears more resilient to this effect.</p><formula xml:id="formula_6">fixed ( t = 1) fixed ( t = 2) fixed ( t = 3) fixed ( t = 4) fixed ( t = 5) fixed ( t = 10) fixed ( t = 20)</formula><p>Computational efficiency Note that the x-axis in <ref type="figure" target="#fig_9">Figure 9</ref> represents the number of forward-passes through f , which loosely corresponds to the wall clock time during the training process. Since the adaptive skip intervals methods are allowed to skip frames, they need fewer model evaluations (and therefore fewer backpropagation passes at training time) than fixed-rate training schemes. In the tasks we considered, not only this gain in training speed does not come at the cost of reduced accuracy, but it actually improves the overall performance. Full-resolution timelines can be viewed at http://tiny.cc/x2suwy Robustness w.r.t. perturbation of dynamics Another advantage of the temporally abstract model which we hypothesize is that the training process is more stable when the dynamical systems changes in a certain way. This is relevant because in real systems, the i.i.d. assumption is often violated. The same is true for reinforcement learning tasks, in which the distribution over observed transition changes as the agent improves its policy or due to changes in the environment over time. As a test for our hypothesis, we prepare a second version of the Funnel board dataset with 500 trajectories of slightly altered physics: The bounciness of the funnel walls is reduced to zero. This leads to a slightly different behavior in the funnels, but the final platforms are the same in the majority of trajectories. We start with the perturbed version and before the start of the 75th epoch, we exchange it with the original one. <ref type="figure" target="#fig_0">Figure 10</ref> shows the accuracy curves for this experiment. We observe that while the fixed frame-rate baselines learn the correct classification better than in the more difficult original task, after the switch the validation accuracy quickly deteriorates. Note that freezing the network at epoch 75 would leave the validation accuracy almost unchanged, since both versions of the task have similar labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>The observation that every environment has an optimal sampling frequency has also been made for reinforcement learning. For instance, <ref type="bibr" target="#b4">Braylan et al. (2000)</ref> investigate the effect of different frameskip intervals on the performance of agents learning to play Atari 2600 games. A constant frame-skip value of four frames is considered standard for Deep RL agents <ref type="bibr" target="#b17">(Machado et al., 2017)</ref>. Focusing on spatio-temporal prediction problems, <ref type="bibr" target="#b19">(Oh et al., 2015)</ref> introduce a neural network architecture for action conditional video prediction. Their approach benefits from using curriculum learning to stabilize the training of the network. <ref type="bibr" target="#b5">Buesing et al. (2018)</ref> investigate action-conditional state-space models and explicitly consider "jumpy" models which skip a certain number of timesteps in order to be more computationally efficient. In contrast to our work they do not use adaptive skip intervals, but skip at a fixed frame rate. <ref type="bibr" target="#b2">Belzner (2016)</ref> introduces a time-adaptive version of model-based online planning in which the planner can optimize the step-length adaptively. Their approach focuses on temporal abstraction in the space of actions and plans. Temporal abstraction in the planning space is also a motivation of the field of hierarchical reinforcement learning <ref type="bibr" target="#b1">(Barto and Mahadevan, 2003)</ref>, often in the framework of semi-MDPs -Markov Decision Processes with temporally extended actions (e.g. <ref type="bibr" target="#b26">Puterman, 1994)</ref>.</p><p>The idea of skipping time steps has also been investigated in <ref type="bibr" target="#b14">Ke et al. (2017)</ref>, where the authors present a way to attack the problem of long-term credit assignment in recurrent neural networks by only propagating errors through selected states instead of every single past timestep.</p><p>Closely related to our work is the Predictron , which is a deep neural network architecture which is set up to perform a sequence of temporally abstract lookahead steps in a latent space. It can be trained end-to-end in order to approximate the values in a Markov Reward Process. In contrast to ASI, the outputs of the Predictron are regressed exclusively towards rewards and values, which circumvents the need for an explicit solution to the temporal alignment problem. However, by ignoring future states, the training process ignores a large amount of dynamical information from the underlying system. Similar in spirit to the Predictron, the value prediction network (VPN) <ref type="bibr" target="#b20">(Oh et al., 2017)</ref> proposes a neural network architecture to learn a dynamics model whose abstract states make option-conditional predictions of future values rather than of future observations. Their temporal abstraction is "grounded" by using option-termination as the skip-interval. <ref type="bibr" target="#b8">Ebert et al. (2017)</ref> introduced temporal skip connections for self-supervised visual planning to keep track of objects through occlusion. <ref type="bibr" target="#b25">(Pong et al., 2018)</ref> introduce temporal difference models (TDM) which are dynamical models trained by temporal difference learning. Their approach starts with a temporally fine-grained dynamics model, which is represented with a goal-conditioned value function. The temporal resolution is successively coarsened so as to converge toward a model-free formulation.</p><p>Concurrently to our work, <ref type="bibr" target="#b13">Jayaraman et al. (2018)</ref> propose a training framework with a similar motivation to ours. They further explore ways to generalize the objective and include experiments on hierarchical planning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented a time skipping framework for the problem of sequential predictions. Our approach builds on concepts from causal discovery <ref type="bibr" target="#b24">(Peters et al., 2017;</ref><ref type="bibr" target="#b21">Parascandolo et al., 2017)</ref> and can be included in multiple fields where planning is important. In cases where our approach fails, e.g. when the alignment of predicted and ground truth is lost and the model does not have the power to restore it, more advanced optimization methods like dynamic time warping <ref type="bibr" target="#b18">(Müller, 2007)</ref> during the matching phase may help at the cost of the simplicity and seamless integration of the scheduled sampling, as described in Section 3.</p><p>An interesting direction for future work is the combination of temporal abstraction with abstractions in a latent space. As noted for instance by <ref type="bibr" target="#b20">Oh et al. (2017)</ref>, predicting future observations is a too difficult task for realistic environment due to the high dimensionality of typical observation spaces.</p><p>The idea of an optimal prediction skip interval should extend to the case of stochastic generative models, where instead of a deterministic mapping from current to next state, the model provides a probability distribution over next states. In this case, ASI should lead to simpler distributions, allowing for simpler models and more data efficiency just as in the deterministic case. The evaluation of this claim is left for future work.</p><p>Another line of investigation which is left to future work is to integrate ASI with action-conditional models. As mentioned in Section 2.1, the problem could be addressed by using a separate ASIdynamical model for each policy or option, which would allow for option-conditional planning. However, there may be a more interesting interplay between ideal skip intervals and switching points for options, which suggest that they should ideally be learned jointly.</p><p>The learning rate was decayed by a factor of 0.2 after n D steps, where n D was sampled from the set {7500, 10000, 15000}. The maximum ASI horizon H was sampled from the set {15, 18, 21, 25}. The number of trajectories per training batch was chosen to be 2 in all experiments. As schedule of exploration for temporal matching we choose µ(t) = max(0, 1 −</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Hypothesized relationship between skip interval ∆t and error accumulation rate L ∆t .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Visualization of a ball which is dropped into a funnel at different initial horizontal velocities. The part of the trajectory within the funnel can be considered inconsequential chaos.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: One way to motivate the need for adaptive skip intervals compared to a fixed temporal coarsening is to consider the complexity of the learned model. If the underlying true dynamics have recurring "mechanisms" which take different amounts of time, ASI enables the model to represent fewer distinct transition types, reducing the required model capacity and thus the amount of training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5</head><label>5</label><figDesc>Figure 5 shows examples for the first states and the resulting trajectories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Examples of first states of the Room runner domain, along with the corresponding trajectories which arise from evolving the environment dynamics and the agent's policy. Darker regions in the trajectory correspond to parts where the agent was moving more slowly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Examples of first states of the Funnel board domain, along with the corresponding trajectories which arise from evolving the environment dynamics. The trajectories are merged into one image for visualization purposes only -in the dataset every frame is separate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Portion of a sequence from Room runner using ASI, with ground truth frames on top and predicted, temporally aligned sequence on bottom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Portion of a sequence from Funnel board using ASI, with ground truth frames on top and predicted, temporally aligned sequence on bottom. Darker lines connecting a predicted frame to the ground truth frames correspond to better matching in terms of pixel loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Learning progress, curves show validation accuracies on two tasks. For each task, we show on the horizontal axis the number of model evaluations and the epoch number. Curves show mean validation accuracy, evaluated on 500 trajectories. The training sets consist of 500 trajectories in each experiment. Shaded areas correspond to the interquartile range over all eight runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 :</head><label>10</label><figDesc>Figure 10: Up to epoch 75 we use a version of the Funnel board task where the funnels' bounciness is set to zero. At epoch 75 we switch the dataset for the standard one but otherwise keep the training procedure going.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">t K ), where K was sampled from the set {7500, 10000, 15000}.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is partially supported by the International Max Planck Research School for Intelligent Systems and the Max Planck ETH Center for Learning Systems.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>; each xt ∈ X Differentiable model f : X → X with parameters θ Loss function L : X × X → R Matching-horizon H ∈ N Exploration schedule µ :</p><p>Ground truth timestep t and abstract timestep u l ← 0 Trajectory loss p ← x1</p><p>Next input to the dynamics model f</p><p>Accumulate trajectory loss if Bernoulli( (training_step)) = 0 then p ←xu Scheduled sampling <ref type="bibr" target="#b3">(Bengio et al., 2015</ref>) else p ← xt Take ground truth frame as next model input end u ← u + 1 end Perform a gradient descent step on θ to reduce l training_step ← training_step + 1 until stopping criterion is reached;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Model architecture</head><p>In all experiments, the model f consists of 7 convolutional layers with padding mode "same" and the following specifications, where Conv(a, (b, c)) means "a kernels of size <ref type="figure">(1, 1))</ref>]. Before the 6th layer, the three channels of the model input are concatenated to the feature map. As part of the hyperparameter search, n k was randomly chosen from the set {32, 48}. We added two variations of this architecture to the hyperparameter search:</p><p>• f-strided: the second convolutional layer performs a strided convolution with stride 2 and the 4th convolutional layer performs a transposed convolution.</p><p>• f-dilated: the fourth convolutional layer uses a dilation rate of 2.</p><p>We did not observe substantial difference in the performances of our architectures.</p><p>All convolutions were used with a stride of 1. The weight initialization for all layers follows <ref type="bibr" target="#b11">He et al. (2015)</ref>. We use rectified linear units (ReLU) as activation <ref type="bibr" target="#b10">(Glorot et al., 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Training details</head><p>For all experiments, the Adam optimizer <ref type="bibr" target="#b15">(Kingma and Ba, 2014)</ref> was used. For hyperparameter search, learning rates for the model f were sampled from the set {1.0×10 −3 , 7.5×10 −4 , 5.0×10 −4 }.</p><p>The hyperparameter search described in Section 4 resulted in the parameters shown in <ref type="table">Tables 1 and 2</ref>, which were used to produce the resulting plots.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ASI</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Arulkumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Deisenroth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brundage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Bharath</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.05866</idno>
		<title level="m">A brief survey of deep reinforcement learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Recent advances in hierarchical reinforcement learning. Discrete event dynamic systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="41" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Time-adaptive cross entropy planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Belzner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Annual ACM Symposium on Applied Computing</title>
		<meeting>the 31st Annual ACM Symposium on Applied Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="254" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Scheduled sampling for sequence prediction with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1171" to="1179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Frame skip is a powerful parameter for learning to play atari</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Braylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hollenbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Space</title>
		<imprint>
			<biblScope unit="volume">1600</biblScope>
			<biblScope unit="page">1800</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning and querying fast generative models for reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Racaniere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Reichert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Besse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03006</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chiappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Racaniere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1704.02254</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">Recurrent environment simulators. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Model-based reinforcement learning as cognitive search: neurocomputational theories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Self-supervised visual planning with temporal skip connections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.05268</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep visual foresight for planning robot motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2786" to="2793" />
		</imprint>
	</monogr>
	<note>Robotics and Automation (ICRA</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth international conference on artificial intelligence and statistics</title>
		<meeting>the fourteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="315" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Learning and transfer of modulated locomotor controllers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tassa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.05182</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Time-agnostic prediction: Predicting predictable video frames</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.07784</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bilaniuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Binas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.02326</idno>
		<title level="m">Sparse attentive backtracking: Long-range credit assignment in recurrent networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Universal intelligence: A definition of machine intelligence. Minds and Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Legg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="391" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Revisiting the arcade learning environment: Evaluation protocols and open problems for general agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Machado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Talvitie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hausknecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bowling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.06009</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Dynamic time warping. Information retrieval for music and motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Müller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Action-conditional video prediction using deep networks in atari games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2863" to="2871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Value prediction network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6120" to="6130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Learning independent causal mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Parascandolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rojas-Carulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kilbertus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.00961</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Causality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Causal inference by using invariant prediction: identification and confidence intervals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bühlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="947" to="1012" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Elements of causal inference: foundations and learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.09081</idno>
		<title level="m">Temporal difference models: Model-free deep rl for model-based control</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Markov decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Puterman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Wiley and Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On causal and anticausal learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sgouritsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Machine Learning (ICML)</title>
		<editor>Langford, J. and Pineau, J.</editor>
		<meeting>the 29th International Conference on Machine Learning (ICML)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1255" to="1262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Van Hasselt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dulac-Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reichert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barreto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.08810</idno>
		<title level="m">The predictron: End-to-end learning and planning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="181" to="211" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Embed to control: A locally linear latent dynamics model for control from raw images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Watter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boedecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2746" to="2754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Imagination-augmented agents for deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Racanière</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Reichert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06203</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
