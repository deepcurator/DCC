<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On GANs and GMMs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eitan</forename><surname>Richardson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">School of Computer Science and Engineering</orgName>
								<orgName type="institution">The Hebrew University of Jerusalem Jerusalem</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
							<email>yweiss@cs.huji.ac.il</email>
							<affiliation key="aff1">
								<orgName type="institution">The Hebrew University of Jerusalem Jerusalem</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On GANs and GMMs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>A longstanding problem in machine learning is to find unsupervised methods that can learn the statistical structure of high dimensional signals. In recent years, GANs have gained much attention as a possible solution to the problem, and in particular have shown the ability to generate remarkably realistic high resolution sampled images. At the same time, many authors have pointed out that GANs may fail to model the full distribution ("mode collapse") and that using the learned models for anything other than generating samples may be very difficult. In this paper, we examine the utility of GANs in learning statistical models of images by comparing them to perhaps the simplest statistical model, the Gaussian Mixture Model. First, we present a simple method to evaluate generative models based on relative proportions of samples that fall into predetermined bins. Unlike previous automatic methods for evaluating models, our method does not rely on an additional neural network nor does it require approximating intractable computations. Second, we compare the performance of GANs to GMMs trained on the same datasets. While GMMs have previously been shown to be successful in modeling small patches of images, we show how to train them on full sized images despite the high dimensionality. Our results show that GMMs can generate realistic samples (although less sharp than those of GANs) but also capture the full distribution, which GANs fail to do. Furthermore, GMMs allow efficient inference and explicit representation of the underlying statistical structure. Finally, we discuss how a pix2pix network can be used to add high-resolution details to GMM samples while maintaining the basic diversity.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural images take up only a tiny fraction of the space of possible images. Finding a way to explicitly model the statistical structure of such images is a longstanding problem with applications to engineering and to computational neuroscience. Given the abundance of training data, this would also seem a natural problem for unsupervised learning methods and indeed many papers apply unsupervised learning to small patches of images <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b30">31]</ref>. Recent advances in deep learning, have also enabled unsupervised learning of full sized images using various models: Variational Auto Encoders <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b16">17]</ref>, PixelCNN <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b37">38]</ref>, Normalizing Flow <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b7">8]</ref> and Flow GAN <ref type="bibr" target="#b13">[14]</ref>.</p><p>Perhaps the most dramatic success in modeling full images has been achieved by Generative Adversarial Networks (GANs) <ref type="bibr" target="#b12">[13]</ref>, which can learn to generate remarkably realistic samples at high resolution <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b24">25]</ref>, <ref type="figure">(Fig. 1)</ref>. A recurring criticism of GANs, at the same time, is that while they are excellent at generating pretty pictures, they often fail to model the entire data distribution, a phenomenon usually referred to as mode collapse: "Because of the mode collapse problem, applications of GANs are often limited to problems where it is acceptable for the model to produce a small number of distinct outputs" <ref type="bibr" target="#b11">[12]</ref>. (see also <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b24">25]</ref>.) Another criticism is the lack of a robust and consistent evaluation method for GANs <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>Two evaluation methods that are widely accepted <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b0">1]</ref> are Inception Score (IS) <ref type="bibr" target="#b33">[34]</ref> and Fr√©chet Inception Distance (FID) <ref type="bibr" target="#b15">[16]</ref>. Both methods rely on a deep network, pre-trained for classification, to provide a low-dimensional representation of the original and generated samples that can be compared statistically. There are two significant drawbacks to this approach: the deep representation is insensitive to image properties and artifacts that the underlying classification network is trained to be invariant to <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b17">18]</ref> and when the evaluated domain (e.g. faces, digits) is very different from the dataset used to train the deep representation (e.g. ImageNet) the validity of the test is questionable <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>Another family of methods are designed with the specific goal of evaluating the diversity of the generated samples, regardless of the data distribution. Two examples are applying a perceptual multiscale similarity metric (MS-SSIM) on random patches <ref type="bibr" target="#b29">[30]</ref> and, basing on the Birthday Paradox (BP), looking for the most similar pair of images in a batch <ref type="bibr" target="#b2">[3]</ref>. While being able to detect severe cases of mode collapse, these methods do not manage (or aim) to measure how well the generator captures the true data distribution <ref type="bibr" target="#b19">[20]</ref>.</p><p>Many unsupervised learning methods are evaluated using log likelihood on held out data <ref type="bibr" target="#b40">[41]</ref> but applying this to GANs is problematic. First, since GANs by definition only output samples on a manifold within the high dimensional space, converting them into full probability models requires an arbitrary noise model <ref type="bibr" target="#b1">[2]</ref>. Second, calculating the log likelihood for a GAN requires integrating out the latent variable and this is intractable in high dimensions (although encouraging results have been obtained for smaller image sizes <ref type="bibr" target="#b39">[40]</ref>). As an alternative to log likelihood, one could calculate the Wasserstein distance betweeen generated samples and the training data, but this is again intractable in high dimensions so approximations must be used <ref type="bibr" target="#b19">[20]</ref>.</p><p>Overall, the current situation is that while many authors criticize GANs for "mode collapse" and decry the lack of an objective evaluation measure, the focus of much of the current research is on improved learning procedures for GANs that will enable generating high quality images of increasing resolution, and papers often include sentences of the type "we feel the quality of the generated images is at least comparable to the best published results so far." <ref type="bibr" target="#b19">[20]</ref>.</p><p>The focus on the quality of the generated images has perhaps decreased the focus on the original question: to what extent are GANs learning useful statistical models of the data? In this paper, we try to address this question more directly by comparing GANs to perhaps the simplest statistical model, the Gaussian Mixture Model. First, we present a simple method to evaluate generative models based on relative proportions of samples that fall into predetermined bins. Unlike previous automatic methods for evaluating models, our method does not rely on an additional neural network nor does it require approximating intractable computations. Second, we compare the performance of GANs to GMMs trained on the same datasets. While GMMs have previously been shown to be successful in modeling small patches of images, we show how to train them on full sized images despite the high dimensionality. Our results show that GMMs can generate realistic samples (although less sharp than those of GANs) but also capture the full distribution which GANs fail to do. Furthermore, GMMs allow efficient inference and explicit representation of the underlying statistical structure. Finally, we discuss how a pix2pix network can be used to add high-resolution details to GMM samples while maintaining the basic diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A New Evaluation Method</head><p>Our proposed evaluation method is based on a very simple observation: If we have two sets of samples and they both represent the same distribution, then the number of samples that fall into a given bin should be the same up to sampling noise. More formally, we define I B (s) as an indicator function for bin B. I B (s) = 1 if the sample s falls into the bin B and zero otherwise. Let {s p i } be N p samples from distribution p and {s q j } be N q samples from distribution q, then if p = q, we expect</p><formula xml:id="formula_0">1 Np i I B (s p i ) ‚âà 1 Nq j I B (s q j ).</formula><p>The decision whether the number of samples in a given bin are statistically different is a classic two-sample problem for Bernoulli variables <ref type="bibr" target="#b6">[7]</ref>. We calculate the pooled sample proportion P (the pro- portion that falls into B in the joined sets) and its standard error:</p><formula xml:id="formula_1">SE = P (1 ‚àí P )[1/N p + 1/N q ].</formula><p>The test statistic is the z-score: z = Pp‚àíPq SE , where P p and P q are the proportions from each sample that fall into bin B. If the probability of the observed test statistic is smaller than a threshold (determined by the significance level) then the number is statistically different. There is still the question of which bin to use to compare the two distributions. In high dimensions, a randomly chosen bin in a uniform grid is almost always going to be empty. We propose to use Voronoi cells. This guarantees that each bin is expected to contain some samples.</p><p>Our binning-based evaluation method is demonstrated in <ref type="figure">Fig. 2</ref>, using a toy example where the data is in R 2 . We have a set of N p training samples from the reference distribution p and a set of N q samples with distribution q, generated by the model we wish to evaluate. To define the Voronoi cells, we perform K-means clustering of the N p training samples to some arbitrary number of clusters K (K N p , N q ). Each training sample s p i is assigned to one of the K cells (bins). We then assign each generated sample s q j to the nearest (L2) of the K centroids. We perform the two-sample test on each cell separately and report the number of statistically-different bins (NDB).</p><p>Note that unlike the popular IS and FID, our NDB method is applied directly on the image pixels and does not rely on a representation learned for other tasks. This makes our metric domain agnostic and sensitive to different image properties the deep-representation is insensitive to. Compared to MS-SSIM and BP, our method has the advantage of providing a metric between the data and generated distributions and not just measuring the general diversity of the generated sample.</p><p>A possible concern about using Voronoi cells as bins is that this essentially treats images as vectors in pixel spaces, where L2 distance may not be meaningful. In Appendix A we show that for the datasets we used, the bins are usually semantically meaningful. Even in cases where the bins do not correspond to semantic categories, we still expect a good generative model to preserve the statistics of the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Full Image Gaussian Mixture Model</head><p>In order to provide context on the utility of GANs in learning statistical models of images, we compare it to perhaps the simplest possible statistical model: the Gaussian Mixture Model (GMM) trained on the same datasets.</p><p>There are two possible concerns with training GMMs on full images. The first is the dimensionality. If we work with 64 √ó 64 color images then a single covariance matrix will have 7.5 √ó 10 7 free parameters and during training we will need to store and invert matrices of this size. The second concern is the complexity of the distribution. While a GMM can approximate any density with a sufficiently large number of Gaussians, it is easy to construct densities for which the number of Gaussians required grows exponentially with the dimension.</p><p>In order to address the computational concern, we use a GMM training algorithm where the memory and complexity grow linearly with dimension (not quadratically as in the standard GMM). Specifically we use the Mixture of Factor Analyzers <ref type="bibr" target="#b10">[11]</ref>, as described in the next paragraph. Regarding the second concern, our experiments (section 4) show that for the tested datasets, a relatively modest number of components is sufficient to approximate the data distribution, despite the high dimensionality. Of course, this may not be necessarily true for every dataset.</p><p>Probabilistic PCA <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b35">36]</ref> and Factor Analyzers <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b10">11]</ref> both use a rectangular scale matrix A d√ól multiplying the latent vector z of dimension l d, which is sampled from a standard normal distribution. Both methods model a normal distribution on a low-dimensional subspace embedded in the full data space. For stability, isotropic (PPCA) or diagonal-covariance (Factor Analyzers) noise is added. We chose to use the more general setting of Factor Analyzers, allowing to model higher noise variance in specific pixels (for example, pixels containing mostly background).</p><p>The model for a single Factor Analyzers component is: </p><formula xml:id="formula_2">x = Az + ¬µ + , z ‚àº N (0, I) , ‚àº N (0, D) ,<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Avoiding Inversion of Large Matrices</head><p>The log-likelihood of a set of N data points in a Mixture of K Factor Analyzers is:</p><formula xml:id="formula_3">L = N n=1 log K i=1 œÄ i P (x n |¬µ i , Œ£ i ) = N n=1 log K i=1 e [log(œÄi)+log P (xn|¬µi,Œ£i)] ,<label>(2)</label></formula><p>where œÄ i are the mixing coefficients. Because of the high dimensionality, we calculate the log of the normal probability and the last expression is evaluated using log sum exp operation over the K components.</p><p>The log-probability of a data point x given the component is evaluated as follows:</p><formula xml:id="formula_4">logP (x|¬µ, Œ£) = ‚àí 1 2 d log(2œÄ) + log det(Œ£) + (x ‚àí ¬µ) T Œ£ ‚àí1 (x ‚àí ¬µ)<label>(3)</label></formula><p>Using the Woodbury matrix inversion lemma:</p><formula xml:id="formula_5">Œ£ ‚àí1 = (AA T + D) ‚àí1 = D ‚àí1 ‚àí D ‚àí1 A(I + A T D ‚àí1 A) ‚àí1 A T D ‚àí1 = D ‚àí1 ‚àí D ‚àí1 AL ‚àí1 l√ól A T D ‚àí1<label>(4)</label></formula><p>To avoid holding the d √ó d matrix Œ£ ‚àí1 and performing large matrix multiplications, we evaluate the Mahalanobis distance as follows (denotingx = (x ‚àí ¬µ)):</p><formula xml:id="formula_6">x T Œ£ ‚àí1x =x T [D ‚àí1 ‚àí D ‚àí1 AL ‚àí1 A T D ‚àí1 ]x =x T [D ‚àí1x ‚àí D ‚àí1 AL ‚àí1 (A T D ‚àí1x )]<label>(5)</label></formula><p>The log-determinant is calculated using the matrix determinant lemma: Using equations 4 -6, the complexity of the log-likelihood computation is linear in the image dimension d, allowing to train the MFA model efficiently on full-image datasets.</p><formula xml:id="formula_7">log det(AA T + D) = log det(I + A T D ‚àí1 A) + log det D = log det L l√ól + d j=1 log d j<label>(6)</label></formula><p>Rather than using EM <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b10">11]</ref> (which is problematic with large datasets) we decided to optimize the log-likelihood (equation 2) using Stochastic Gradient Descent and utilize available differentiable programming frameworks <ref type="bibr" target="#b0">[1]</ref> that perform the optimization on GPU. The model is initialized by K-means clustering of the data and then Factor Analyzers parameters estimation for each component separately. Our experiments show that the training process is very robust and the likelihood increases until convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We conduct our experiments on three popular datasets of natural images: CelebA <ref type="bibr" target="#b25">[26]</ref> (aligned, cropped and resized to 64√ó64), SVHN <ref type="bibr" target="#b28">[29]</ref> and MNIST <ref type="bibr" target="#b23">[24]</ref>. On these three datasets we compare the MFA model to the following generative models: GANs (DCGAN <ref type="bibr" target="#b32">[33]</ref>, BEGAN <ref type="bibr" target="#b4">[5]</ref> and WGAN <ref type="bibr" target="#b1">[2]</ref>. On the more challenging CelebA dataset we also compared to WGAN-GP <ref type="bibr" target="#b14">[15]</ref>) and Variational Auto-encoders (VAE <ref type="bibr" target="#b20">[21]</ref>, VAE-DFC <ref type="bibr" target="#b16">[17]</ref>). We compare the GMM model to the GAN models along three attributes: (1) visual quality of samples (2) our quantitative NDB score and (3) ability to capture the statistical structure and perform efficient inference.</p><p>Random samples from our MFA models trained on the three datasets are shown in <ref type="figure">Fig. 3</ref>. Although the results are not as sharp as the GAN samples, the images look realistic and diverse. As discussed earlier, one of the concerns about GMMs is the number of components required. In Appendix E we show the log-likelihood of the test set and the quality of a reconstructed random test image as a function of the number of components. As can be seen, they both converge with a relatively small number of components.</p><p>We now turn to comparing the models using our proposed new evaluation metric.  We trained all models, generated 20,000 new samples and evaluated them using our evaluation method (section 2). <ref type="table" target="#tab_0">Tables 1 -3</ref> present the evaluation scores for 20,000 samples from each model. We also included, for reference, the score of 20,000 samples from the training and test sets. The simple MFA model has the best (lowest) score for all values of K. Note that neither the bins nor the number of bins is known to any of the generative models. The evaluation result is consistent over multiple runs and is insensitive to the specific NDB clustering mechanism (e.g. replacing K-means with agglomerative clustering). In addition, initializing MFA differently (with k-subspaces) does not change the result.</p><p>The results show clear evidence of mode collapse (large distortion from the train bin-proportions) in BEGAN and DCGAN and some distortion in WGAN. The improved training in WGAN-GP seems to reduce the distortion. <ref type="figure">Fig. 4</ref> visualizes the bin proportions (as in <ref type="figure">Fig. 2</ref>) for K = 300 in CelebA.</p><p>Our evaluation method can provide visual insight into the mode collapse problem. <ref type="figure" target="#fig_3">Fig. 5</ref> shows random samples generated by BEGAN that were assigned to over-allocated and under allocated bins. As can be seen, each bin represents some prototype and the GAN failed to generate samples belonging to some of them. Note that the simple binning process (in the original image space) captures both semantic properties such as sunglasses and hats, and physical properties such as colors and pose. Interestingly, our metric also reveals that VAE also suffers from "mode collapse" on this dataset.</p><p>Finally, we compare the models in terms of disentangling the manifold the and ability to perform inference.</p><p>It has often been reported that the latent representation z in most GANs does not correspond to meaningful directions on the statistical manifold <ref type="bibr" target="#b5">[6]</ref>. <ref type="figure" target="#fig_4">Fig. 6(a)</ref> shows that in contrast, in the learned   MFA model both the components and the directions are meaningful. For CelebA, two of 1000 learned components are shown, each having a latent dimension l of 10. Each component represents some prototype, and the learned column-vectors of the rectangular scale matrix A represent changes from the mean image, which span the component on a 10-dimensional subspace in the full image dimension of 64 √ó 64 √ó 3 = 12, 288. As can be seen, the learned vectors affect different aspects of the represented faces such as facial hair, glasses, illumination direction and hair color and style. For MNIST, we learned 256 components with a latent dimension of 4. Each component typically learns a digit and the vectors affect different style properties, such as the angle and the horizontal stroke in the digit 7. Very different styles of the same digit will be represented by different components.</p><p>The latent variable z controls the combination of column-vectors added to the mean image. As shown in <ref type="figure" target="#fig_4">Fig. 6(a)</ref>, adding a column-vector to the mean with either a positive or a negative sign results in a realistic image. In fact, since the latent variable z is sampled from a standard-normal (iid) distribution, any linear combination of column vectors from the component should result in a realistic image, as guaranteed by the log-likelihood training objective. This property is demonstrated in <ref type="figure" target="#fig_4">Fig. 6(b)</ref>. Even though the manifold of face images is very nonlinear, the GMM successfully models it as a combination of local linear manifolds.</p><p>As discussed earlier, one the the main advantages of an explicit model is the ability to calculate the likelihood and perform different inference tasks. <ref type="figure" target="#fig_5">Fig. 7(a)</ref> shows images from CelebA that have low likelihood according to the MFA. Our model managed to detect outliers. <ref type="figure" target="#fig_5">Fig. 7(b)</ref> demonstrates the task of image reconstruction from partially observed data (in-painting). For both tasks, the MFA model provides a closed-form expression -no optimization or re-training is needed. Both inpainting and calculation of log likelihood using the GAN models is difficult and requires special purpose approximations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Pairing GMM with a Conditional GAN</head><p>Summarizing our previous results, GANs are better than GMMs in generating sharp images while GMMs are better at actually capturing the statistical structure and enabling efficient inference. For applications where the quality of generated images is of paramount importance, we experiment with the idea of combining the benefits of GMM with the fine-details of GAN in order to generate higher-resolution images while still being loyal to the data distribution.  We combine the MFA model with a pix2pix conditional GAN <ref type="bibr" target="#b18">[19]</ref>: We first train our MFA model and then generate for each training sample a matching image from our model: For each real image x, we find the most likely component c and a latent variable z that maximizes the posterior probability P (z|x, ¬µ c , Œ£ c ). We then generatex = A c z + ¬µ c . This is equivalent to projecting the training image on the component subspace and bringing it closer to the mean. We then train a pix2pix model on pairs {x,x} for the task of convertingx to x.x can be resized to any arbitrary size. In run time, the learned pix2pix deterministic transformation is applied to new images sampled from the GMM model to generate matching fine-detailed images. Higher-resolution samples generated by our MFA+pix2pix models are shown in <ref type="figure" target="#fig_6">Fig. 8</ref>. As can be seen, pix2pix adds fine details without affecting the global structure dictated by the MFA model sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The abundance of training data along with advances in deep learning have enabled learning generative models of full images. GANs have proven to be tremendously popular due to their ability to generate high quality images, despite repeated reports of "mode collapse" and despite the difficulty of performing explicit inference with them. In this paper we investigated the utility of GANs for learning statistical models of images by comparing them to the humble Gaussian Mixture Model. We showed that it is possible to efficiently train GMMs on the same datasets that are usually used with GANs. We showed that the GMM also generates realistic samples (although not as sharp as the GAN samples) but unlike GANs it does an excellent job of capturing the underlying distribution and provides explicit representation of the statistical structure. For settings in which the visual quality of samples is of paramount importance, we presented a method that adds detail to the GMM samples using a pix2pix network.</p><p>We don't suggest that Gaussian Mixture Models are the ultimate solution to the problem of learning models of full images. Nevertheless, the success of such a simple model motivates the search for more elaborate statistical models that still allow efficient inference and accurate representation of statistical structure, even at the expense of not generating the prettiest pictures. <ref type="figure" target="#fig_0">Figures 9 -12</ref> show examples of training images from the three datasets that are assigned to different bins in our NDB evaluation methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Interpretation of the NDB Bins</head><p>As can be seen, the bins (implicitly) correspond to combinations of discrete semantic properties such as (for CelebA) glasses, hairstyle and hats, physical properties such as pose and skin shade, and photometric properties such as image contrast. We argue that a reliable generative model needs to represent the joint distribution of all these properties, which are manifested in the observed pixels, and not just the semantic ones, which is (to some extent) the case when the training objective and evaluation criteria are based on a deep representation.     The internal MFA representation for a toy dataset containing points in R 2 is shown in <ref type="figure" target="#fig_7">Fig. 19(a)</ref>. <ref type="figure" target="#fig_7">Fig. 19(b)</ref> demonstrates the elaborate representation learned by a GAN for the same toy dataset (by sampling z on a grid). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E MFA Representation Quality vs Number of Components</head><p>Section 3 discussed a concern about the number of MFA components required to represent the dataset.</p><p>In <ref type="figure">Fig. 20</ref> we show the test-set log likelihood as a function of the number of components in the mixture model. In addition, we show a reconstruction of a random test image using the different models. As can be seen, the log-likelihood and reconstruction quality improve quickly with the number of components. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Samples from three datasets (first two rows) and samples generated by GANs (last two rows): CelebA -BEGAN, MNIST -DCGAN, SVHN -Wasserstein GAN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>where ¬µ is the mean and is the added noise with a diagonal covariance D. This results in the Gaussian distribution x ‚àº N (¬µ, AA T + D). The number of free parameters in a single Factor Analyzers component is d(l + 2), and K[d(l + 2) + 1] in a Mixture of Factor Analyzers (MFA) model with K components, where d and l are the data and latent dimensions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure 3: Random samples generated by our MFA model trained on CelebA, MNIST and SVHN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Examples for mode-collapse in BEGAN trained on CelebA, showing three over-allocated bins and three under-allocated ones. The first image in each bin is the cell centroid (marked in red).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: (a) Examples of learned MFA components trained on CelebA and MNIST: Mean image (¬µ) and noise variance (D) are shown on top. Each row represents a column-vector of the rectangular scale matrix A -the learned changes from the mean (showing vectors 1-5 of 10). The three images shown in row i are: ¬µ + A (i) , 0.5 + A (i) , ¬µ ‚àí A (i) . (b) Combinations of two column-vectors (A (i) , A (j) ): z i changes with the horizontal axis and z j with the vertical axis, controlling the combination. Both variables are zero in the central image, showing the component mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Inference using the explicit MFA model: (a) Samples from the 100 images in CelebA with the lowest likelihood given our MFA model (outliers) (b) Image reconstruction -in-painting: In each row, the original image is shown first and then pairs of partially-visible image and reconstruction of the missing (black) part conditioned on the observed part.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Pairs of random samples from our MFA model, resized to 128x128 pixels and the matching samples generated by the conditional pix2pix model (more detailed)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: The largest 20 out of 200 bins in the NDB K-means clustering for CelebA. The first image in each row is the bin centroid and the other images are random training samples from this bin.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :Figure 11 :Figure 12 :</head><label>101112</label><figDesc>Figure 10: Similar to Figure 9, but showing the smallest (least allocated) 20 out of 200 bins.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 13 :Figure 14 :</head><label>1314</label><figDesc>Figure 13: The binning proportions (and therefore the NDB scores) are consistent for different number of bins (100, 200, 300). Note that the same trained MFA and WGAN model is evaluated in all three cases. In all three cases, the distribution of the MFA samples is similar to the reference train distribution (and also has similar NDB as the test samples) while WGAN exhibits significant distortions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 15 :Figure 16 :Figure 17 :</head><label>151617</label><figDesc>Figure 15: Additional random samples drawn from the MFA model trained on CelebA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig</head><label></label><figDesc>Fig. 18 provides additional examples of the learned MFA representation for CelebA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: Additional examples of learned MFA components trained on CelebA: Mean image (¬µ) and noise variance (D) are shown on top. Each row represents a column-vector of the rectangular scale matrix A -the learned changes from the mean. The three images shown in row i are: ¬µ + A (i) , 0.5 + A (i) , ¬µ ‚àí A (i) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 19 :Figure 20 :</head><label>1920</label><figDesc>Figure 19: Internal representations of generative models (b) the MFA component centers, direction and added noise (a) GAN learns an elaborate non-linear transformation from latent to data space. z points are on a grid (with larger steps in one dimension)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Bin-proportions NDB scores for different models trained on CelebA, using 20,000 samples from each model or set, for dif- ferent number of bins (K). NDB values are the numbers of statis- tically different bins, with signifi- cance level of 0.05 (lower is better).</figDesc><table>MODEL 
K=100 K=200 K=300 

TRAIN 
1 
6 
8 
TEST 
12 
13 
23 

MFA 
21 
25 
49 

VAE 
78 
146 
215 
VAE-DFC 
77 
129 
187 

DCGAN 
68 
137 
195 
BEGAN 
94 
170 
247 
WGAN 
76 
132 
185 
WGAN-GP 
42 
64 
81 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 :</head><label>2</label><figDesc>NDB scores for MNIST</figDesc><table>MODEL 
K=100 K=200 K=300 

TRAIN 
6 
7 
15 

MFA 
14 
26 
42 
DCGAN 
41 
75 
137 
WGAN 
16 
39 
64 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 :</head><label>3</label><figDesc>NDB scores for SVHN</figDesc><table>MODEL 
K=100 K=200 K=300 

TRAIN 
3 
5 
9 

MFA 
32 
45 
73 
DCGAN 
78 
148 
228 
WGAN 
87 
166 
245 </table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Code will be made available at https://github.com/eitanrich/gans-n-gmms Preprint. Work in progress. arXiv:1805.12462v1 [cs.CV] 31 May 2018</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">TensorFlow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart√≠n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L√©on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gan</forename><surname>Wasserstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Do GANs actually learn the distribution? an empirical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.08224</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Edges are the&apos;independent components&apos; of natural scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrence</forename><forename type="middle">J</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="831" to="837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">BEGAN: Boundary equilibrium generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Schumm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10717</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Infogan: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rein</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2172" to="2180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Biostatistics: a foundation for analysis in the health sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chad</forename><forename type="middle">Lee</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cross</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Comparison of maximum likelihood and GAN-based training of Real NVPs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benigno</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Dayan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.05263</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Density estimation using Real NVP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.08803</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Many paths to equilibrium: GANs do not need to decrease a divergence at every step</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihaela</forename><surname>Rosca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.08446</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The EM algorithm for mixtures of factor analyzers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno>CRG-TR-96-1</idno>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.00160</idno>
		<title level="m">NIPS 2016 tutorial: Generative adversarial networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Flow-GAN: Combining maximum likelihood and adversarial learning in generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manik</forename><surname>Dhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5769" to="5779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">GANs trained by a two time-scale update rule converge to a nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G√ºnter</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.08500</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep feature consistent variational autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianxu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoping</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of Computer Vision (WACV), 2017 IEEE Winter Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1133" to="1141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Quantitatively evaluating GANs with divergences proposed for training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Daniel Jiwoong Im</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Branson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.01045</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07004</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Progressive growing of GANs for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10196</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Latent variable models and factor analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Knott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bartholomew</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<pubPlace>Arnold</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">PixelCNN models with auxiliary variables for natural image modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1905" to="1914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L√©on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Cheng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barnab√°s</forename><surname>P√≥czos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08584</idno>
		<title level="m">Towards deeper understanding of moment matching network</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Are GANs created equal? a large-scale study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.10337</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02163</idno>
		<title level="m">Unrolled generative adversarial networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS workshop on deep learning and unsupervised feature learning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2011</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.09585</idno>
		<title level="m">Conditional image synthesis with auxiliary classifier GANs</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Emergence of simple-cell receptive field properties by learning a sparse code for natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bruno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David J</forename><surname>Olshausen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Field</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">381</biblScope>
			<biblScope unit="issue">6583</biblScope>
			<biblScope unit="page">607</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.06759</idno>
		<title level="m">Pixel recurrent neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Improved techniques for training GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akash</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lazar</forename><surname>Valkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vee-Gan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07761</idno>
		<title level="m">Reducing mode collapse in GANs using implicit variational learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Mixtures of probabilistic principal component analyzers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tipping</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="443" to="482" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Probabilistic principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tipping</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="611" to="622" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Rnade: The real-valued neural autoregressive density-estimator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benigno</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2175" to="2183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Conditional image generation with pixelcnn decoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4790" to="4798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">On the quantitative analysis of decoder-based generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04273</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">From learning models of natural image patches to whole image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="479" to="486" />
		</imprint>
	</monogr>
	<note>Computer Vision (ICCV</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
