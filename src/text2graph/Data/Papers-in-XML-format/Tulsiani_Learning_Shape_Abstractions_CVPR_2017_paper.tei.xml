<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T22:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Shape Abstractions by Assembling Volumetric Primitives</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubham</forename><surname>Tulsiani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
							<email>2haosu@cs.stanford.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
							<email>guibas@cs.stanford.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
							<email>efros@eecs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
							<email>malik@eecs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Shape Abstractions by Assembling Volumetric Primitives</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Figure 1</ref><p>: Examples of chair and animal shapes assembled by composing simple volumetric primitives (cuboids). The obtained reconstructions allows an interpretable representation for each object and provides a consistent parsing across shapes e.g. chair seats are captured by the same primitive across the category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We present a learning framework for abstracting complex shapes by learning to assemble objects using 3D volumetric primitives. In addition to generating simple and geometrically interpretable explanations of 3D objects, our framework also allows us to automatically discover and exploit consistent structure in the data. We demonstrate that using our method allows predicting shape representations which can be leveraged for obtaining a consistent parsing across the instances of a shape collection and constructing an interpretable shape similarity measure. We also examine applications for image-based prediction as well as shape manipulation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>"Treat nature by means of the cylinder, the sphere, the cone, everything brought into proper perspective"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Paul Cezanne</head><p>Cezanne's insight that an object can be conceived as assembled from a set of volumetric primitives has resurfaced multiple times in the vision and graphics literature. In computer vision, generalized cylinders were introduced by Binford back in 1971, where a cross-sectional area is swept along a straight or curved axis while possibly being shrunk or expanded during the process <ref type="bibr" target="#b1">[3]</ref>. One of the key motivations was parsimony of description -an object could be described by relatively few generalized cylinders, each of which in turn requiring only a few parameters. Volumetric primitives remained popular through the 1990s as they provided a coherent framework for explaining shape inference from a single image, perceptual organization, as well as recognition of a 3D object from 2D views. However, fitting generalized cylinders to image data required considerable hand crafting, and as machine learning techniques for object recognition came to the fore in the 1990s, this paradigm faded from the main stage.</p><p>Of course, finding parsimonious explanations for complex phenomena lies at the core of learning-based visual understanding. Indeed, machine learning is only possible because our visual world, despite its enormous complexity, is also highly structured -visual patterns don't just happen once, but keep on repeating in various configurations. In contemporary computer vision, this structure is most often modeled via human supervision: the repeating patterns are labeled as objects or object parts, and supervised learning methods are employed to find and name them in novel imagery. However, it would seem more satisfying if complex structures could be explained in terms of simpler underlying structures.</p><p>In this paper we return to the classic problem of explaining objects with volumetric primitives, but using the modern tools of unsupervised learning and convolutional neural networks (CNNs). We choose the simplest possible primitives, rigidly transformed cuboids, and show how deep convolutional networks can be trained to assemble arbitrary 3D objects out of them (at some level of approximation). The main reason we succeed where the classic approaches failed is because we aim to explain the entire dataset of 3D objects jointly, allowing us to learn the common 3D patterns directly from the data.</p><p>While the representation of the 3D object shapes e.g. as meshes or voxel occupancies, is typically complex and high-dimensional, the resulting explanation in terms of basic primitives is parsimonious, with a small number of parameters. As examples of their applicability, we leverage the primitive based representation for various tasks e.g. part discovery, image based abstraction, shape manipulation etc. Here we do not wish to reprise the classic debates on the value of volumetric primitives -while they were oversold in the 70s and 80s, they suffer from complete neglect now, and we hope that this demonstration of feasibility of learning how to assemble an object from volumetric primitives will reignite interest. Code is available at https://shubhtuls.github.io/volumetricPrimitives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>3D Representation and Reconstruction. The classic approaches for modeling objects and scenes dating to the very beginnings of the computer vision discipline, such as blocks world <ref type="bibr" target="#b26">[28]</ref>, generalized cylinders <ref type="bibr" target="#b1">[3]</ref>, and geons <ref type="bibr" target="#b0">[2]</ref>, emphasized the compactness of representation as the central goal. In a similar spirit, a few modern approaches have attempted to reconstruct objects/scenes using simple primitives, including Lego pieces <ref type="bibr" target="#b33">[35]</ref> and qualitative 3D blocks <ref type="bibr" target="#b10">[12]</ref>. Apart from these attempts, most mainstream methods for representing and reconstructing objects typically use much higher-dimensional representations e.g. objects as point clouds <ref type="bibr" target="#b18">[20,</ref><ref type="bibr" target="#b34">36]</ref> or exemplar CAD models <ref type="bibr" target="#b22">[24,</ref><ref type="bibr" target="#b23">25,</ref><ref type="bibr" target="#b37">39]</ref>. The success of the latter set of approaches have been largely driven by the data-driven reasoning which the classical methods did not leverage. Our work aims to combine the two -we aim for a parsimonious representation but discover the underlying parsimony in a data-driven manner instead of relying on hand-crafted cues and priors. An additional property of our learned approach is the consistency of representation across instances. Classical approaches solve a per-instance optimization and obtain an unordered set of primitives whereas our our approach outputs a consistent indexed set of primitives -this allows several applications examined in Section 5.</p><p>Parsing Objects, Scenes and 3D Shapes. The idea of exploiting repeating structures in large datasets has been central to efforts on unsupervised object discovery and cosegmentation <ref type="bibr" target="#b29">[31,</ref><ref type="bibr" target="#b27">29]</ref>. Data-driven compositionality, in particular, has been used for co-segmentation <ref type="bibr" target="#b5">[7]</ref>, as well as scene parsing and novel scene generation <ref type="bibr" target="#b28">[30,</ref><ref type="bibr" target="#b16">18]</ref>. In the domain of 3D shapes, the idea of exploiting compositionality has played a similarly important role for object representation, parsing, and manipulation. Pre-labeled, part-based shape representations were used for capturing the categoryspecific shape manifold <ref type="bibr" target="#b6">[8]</ref>, as well as generating novel objects <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b15">17]</ref> or recovering 3D from 2.5D data <ref type="bibr" target="#b32">[34]</ref>. Other methods aim to automatically discover these components in 3D shape datasets <ref type="bibr" target="#b14">[16]</ref>, as well as model their relative arrangements <ref type="bibr" target="#b38">[40]</ref>. Similar to these shape and scene based methods, our framework can automatically discover consistent components and understand the structure of the data, but we do so by virtue of learning to generate parsimonious explanations.</p><p>Deep Generative Models. The rapid recent progress in supervised learning tasks by using deep learning techniques has been accompanied by a growing interest in leveraging similar methods to discover structure in the visual data. Some recent approaches demonstrate that using generative adversarial networks <ref type="bibr" target="#b8">[10,</ref><ref type="bibr" target="#b25">27]</ref> allows learning the data distribution but the underlying latent space lacks interpretability. Other generative methods aim to explicitly decouple the underlying factors of variation <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b21">23]</ref> but rely on supervision for disentangling these factors. More closely related to our work, some recent approaches use recurrent networks to iteratively generate components to explain a simple 2D input scene <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b13">15,</ref><ref type="bibr" target="#b4">6]</ref>. Our work uses similar principles of learning component based explanations of complex shapes where the components are interpretable 3D primitives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Learning Object Assembly</head><p>We formulate the problem of assembling a target object O, given input signal I as that of predicting (up to) M distinct parts which are then composed to output the final shape. Towards this, we learn a CNN h θ parametrized by θ which outputs a primitive based representation. The task of learning this CNN is an unsupervised one -we do not have any annotations for the primitive parameters that best describe the target objects. However, even though there is no direct supervision, one can measure if a predicted primitive configuration is good by checking if the assembled object matches the target object. Using this insight, we formulate a loss function which informs us if the shape assembled us- <ref type="figure">Figure 2</ref>: Overview of our approach. Given the input volume corresponding to an object O, we use a CNN to predict primitive shape and transformation parameters {(z m , q m , t m )} for each part (Section 3.1). The predicted parameters implicitly define transformed volumetric primitives {P m } whose composition induces an assembled shape. We train our system using a loss function which attempts to minimize the discrepancy between the ground-truth mesh for O and the assembled shape which is implicitly defined by the predicted parameters (Section 3.2).</p><p>ing the predicted primitives matches the target shape and optimize this loss to train the CNN.</p><p>An overview of our approach is presented in <ref type="figure">Figure 2</ref>. Given a discretized representation of the target shape as input, we use a CNN to predict a primitive representation (described in Section 3.1). The predicted representation implicitly defines an assembled shape by composing the predicted primitives. Section 3.2 describes a differentiable loss function that allows using this representation in a learning framework. While the initial presentation assumes the use of a fixed number of primitives, Section 3.3 extends our approach to allow a variable number of primitives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Primitive based Representation</head><p>We represent an assembled shape by composing the predicted simple transformed primitives. Each primitive is encoded in terms of a tuple (z, q, t) where z represents its shape in a canonical frame and (q, t) represent the spatial transformation (rotation and translation). The assembled shape predicted by the neural network h θ can therefore be written as below.</p><formula xml:id="formula_0">{(z m , q m , t m )|m = 1, · · · , M } = h θ (I)<label>(1)</label></formula><p>The motivation for this parametrization is to exploit the compositionality of parts as well as the independence of 'what' and 'where' (part shape and spatial transformation respectively). The representation of a shape as a set of parts allows independent reasoning regarding semantically separate units like chair legs, seat etc. The decomposition in terms of part shape and transformation parameters further decomposes factors of variation like 'broad aeroplane wing' (captured by shape) and 'tilted chair back' (captured by transformation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Loss Function for Assembled Shape</head><p>We want to define a differentiable loss function L({(z m , q m , t m )}, O) between the CNN prediction {(z m , q m , t m )} and the target object O. This is a challenging task because the prediction and the groundtruth have different 3D representations -the prediction is a parametrized shape whereas the groundtruth is a mesh consisting of triangles. To overcome this, we leverage the fact that the parametrization in terms of simple primitives allows efficient computation of some properties of the shape induced by their composition. In particular, we can compute the distance field (Section 3.2.1) of the assembled shape as well as sample points on the surface of the primitives. These allow us to define two complimentary losses which together aim to minimize the discrepancy between the predicted and ground-truth shape. The Coverage Loss tries to enforce that the object O is subsumed by the predicted assembled shape. The Consistency Loss enforces the other direction -that the object O subsumes the predicted shape. By optimizing these losses together, we ensure that the assembled shape tries to be maximally consistent with the target object.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Preliminaries</head><p>Notation. We represent by P m , the untransformed primitive as predicted according to z m and useP m to denote the primitive P m after rotation, translation according to (q m , t m ). Therefore, the final shape induced by the composition of the predicted primitives is ∪ mP m . We use the function S(·) to represent the surface of the argument and p ∼ S(·) represents a random point sampled on it e.g. p ∼ S(P m ) corresponds to a point sampled on the surface of m th primitive. We also require notations for simple rigid transformations -we denote by R(p, q) result of rotating a point p according to rotation specified by quaternion q and similarly, T (p, t) denotes the result of translating a point p by t. Note that the operations R, T are both differentiable.</p><p>Distance Field. A distance field C( · ; O) corresponding to an object O is a function R 3 → R + that computes the distance to the closest point of the object. Note that it evaluates to 0 in the object interior.</p><formula xml:id="formula_1">C(p; O) = min p ′ ∈O p − p ′ 2 (2) 3.2.2 Coverage Loss : O ⊆ ∪ mP m .</formula><p>We want to penalize the CNN prediction if the target object O is not completely covered by the predicted shape ∪ mP m . A sufficient condition to ensure this is that the distance field of the assembled shape evaluates to zero for all points on the surface of O.</p><formula xml:id="formula_2">L 1 ({(z m , q m , t m )}, O) = E p∼S(O) C(p; ∪ mP m ) 2 (3)</formula><p>Computation can be simplified due to a nice property of distance fields. It is easy to show that the distance field of a composed shape equals to the pointwise minimum of the distance fields of all composing shapes:</p><formula xml:id="formula_3">C(p; ∪ mP m ) = min m C(p;P m )<label>(4)</label></formula><p>This decomposition rule boils the distance field of a whole shape down to the distance field of a primitive. In the following, we show how to efficiently compute C for primitives as cuboids.</p><p>Distance field of Primitives. Given an origin-centred cuboid represented by z ≡ (w, h, d) -its extent in the three dimensions, its distance field C cub ( · ; z) can be computed as below (using max(0, x) ≡ x + ):</p><formula xml:id="formula_4">C cub (p; z) 2 = (|p x | − w) 2 + + (|p y | − h) 2 + + (|p z | − d) 2 +</formula><p>Consider an object O (with an associated field C( · ; O)) undergoing a rotation R (parametrized by quaternion q) followed by a translation t. The distance field at a point p w.r.t. the transformed object is the same as the distance field at p ′ wrt. the canonical object where p ′ = R −1 (p − t). This observations allows us to complete the formulation by defining C(p;P m ) (required in Eq. 4) as below.</p><formula xml:id="formula_5">C(p;P m ) = C(p ′ ; P m ); p ′ = R(T (p, −t m ),q m ) (5) C( · ; P m ) = C cub ( · ; z m )<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Consistency Loss</head><formula xml:id="formula_6">: ∪ mP m ⊆ O.</formula><p>We want to penalize the CNN prediction if the predicted shape ∪ mP m is not completely inside the target object O. A sufficient condition is to ensure this is that the distance field of the object O shape evaluates to zero for all points on the surface of individual primitivesP m .</p><formula xml:id="formula_7">L 2 ({(z m , q m , t m )}, O) = m E p∼S(Pm) C(p; O) 2<label>(7)</label></formula><p>Additionally, we observe that to sample a point p on the surface ofP m , one can equivalently sample p ′ on the surface of the untransformed primitive P m and then rotate, translate p ′ according to (q m , z m ).</p><formula xml:id="formula_8">p ∼ S(P m ) ≡ T (R(p ′ , q m ), t m ); p ′ ∼ S(P m )</formula><p>An aspect for computing gradients for the predicted parameters using this loss is the ability to compute derivatives for z m given gradients for a sampled point on the canonical untransformed primitive p ′ ∼ S(P m ). We do so by using the re-parametrization trick <ref type="bibr" target="#b20">[22]</ref> which decouples the parameters from the random sampling. As an example, consider a point being sampled on a rectangle extending from (−w</p><note type="other">, −h) to (w, h). Instead of sampling the x-coordinate as x ∼ [−w, w], one can use u ∼ [−1, 1] and x = uw. This re-parametrization of sampling allows one to compute ∂x ∂w . We provide the details for applying the re-parametrization trick for a cuboid primitive in the appendix [1].</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Allowing Variable Number of Primitives</head><p>The framework we have presented so far reconstructs each instance in an object category using exactly M primitives. However, different instances in an object category can be explained by different number of primitives e.g. some chairs have handles, others don't. To incorporate this, in addition to predicting the shape and transformation of each primitive, we also predict the probability of its existence p m . We first discuss the modified representation predicted by the CNN and discuss how the loss function can incorporate this.</p><p>Primitive Representation. As we mentioned above, the primitive representation has an added parameter p m -the probability of its existence. To incorporate this, we factor the primitive shape z m into two components -(z </p><formula xml:id="formula_9">{(z s m , q m , t m , p m )|m = 1 · · · M } = h θ (I) (8) ∀ m z e m ∼ Bern(p m ); z m ≡ (z s m , z e m )<label>(9)</label></formula><p>Note that the CNN predicts p m -the parameter of the Bernoulli distribution from which the part existence variable z e m is sampled. This representation allows the prediction of a variable number of parts e.g. if a chair is best explained using k &lt; M primitives, the network can predict a high p m for only k primitives and a low p m for the remaining M − k primitives.</p><p>Learning. Under the reformulated representation of primitives, the CNN output does not induce a unique assembled shape -it induces a distribution of possible shapes where the m th primitive stochastically exists with probability p m . In this scenario, we want to minimize the expected loss across the possible assemblies. The first step is to modify the consistency and coverage losses to incorporate z m ≡ (z We can now define the final loss L(h θ (I), O) using the concepts developed. Note that this is simply the expected loss across possible samplings of z e m according to p m .</p><formula xml:id="formula_10">L({(z m , q m , t m )}, O) = L 1 ({(z m , q m , t m )}, O) + L 2 ({(z m , q m , t m )}, O) (11) L(h θ (I), O) = E ∀m z e m ∼Bern(pm) L({(z m , q m , t m )}, O)</formula><p>Under this loss function, the gradients for the continuous variables i.e. {(z s m , q m , t m )} can be estimated by averaging their gradients across samples. However, to compute gradients for the distribution parameter p m , we use the REINFORCE algorithm <ref type="bibr" target="#b36">[38]</ref> which basically gives positive feedback if the overall error is low (reward is high) and negative feedback otherwise. To further encourage parsimony, we include a small parsimony reward (reward for choosing fewer primitives) when computing gradients for p m .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Dataset. We perform our experiments primarily using the ShapeNet <ref type="bibr" target="#b2">[4]</ref> dataset which has a large collection of 3D models. In particular, we use the 'airplane' and 'chair' object categories which have thousands of meshes available. The ShapeNet models are already aligned in a canonical frame and are of a fixed scale. Additionally, in order to demonstrate applicability beyond rigid objects, we also manually download and similarly preprocess a set of around 100 models corresponding to four-legged animals.</p><p>Network Architecture and Training. The dataset described above gives us a set of 3D objects {O i }. Corresponding to O i , the input to our CNN is a discretized representation as a volumetric occupancy grid I i of size 32 * 32 * 32 (we later experiment with rendered images as input in Section 5.3). The encoder used in our shape assembler, as shown in <ref type="figure">Figure 2</ref>, takes in as input an occupancy grid and passes it through 3D convolutional and fully con- represents the width, height and thickness of cuboids. We use ADAM <ref type="bibr" target="#b19">[21]</ref> to train our network according to the loss L(h θ (I i ), O i ) described in Section 3 which aims to make the assembled shape predicted using I i match to the target object O i .</p><p>Implementation Details. The coverage and consistency loss functions are both defined using expectations over sampled points. In practice, we randomly sample 1000 points on S(O) to implement Eq. 3 and 150 points from each S(P m ) to implement Eq. 7. To efficiently compute the distance field of the target object O at an arbitrary point p in Eq. 7, we precompute the distance field and its derivatives for samples in a dense regular grid and use it to obtain efficient but approximate gradients</p><formula xml:id="formula_11">∂C(p,O) ∂p</formula><p>. Another practical difficulty is that the gradients for the primitive existence probabilities p m are extremely noisy in the initial training stages -e.g. in the initial stages if a primitive is incorrectly placed, the CNN may learn to predict a very small p m instead of learning to align the primitive correctly. To overcome this, we use a two-stage training process. We first train the network using a fixed high value of p m across primitives and later allow the network to also learn p m while also encouraging simplicity by the external parsimony reward. As shown in <ref type="figure" target="#fig_5">Figure 5</ref>, this has the effect of first using a large number of primitives and in later stages, merging them together and using fewer primitives.</p><p>After the CNN has been trained, when computing the assembled representation for an object, we use MLE estimates instead of sampling i.e. z e m = ✶(p m &gt; 0.5). The final shape predictions using the CNN may still have redundant parts used and we use a simple post-processing step to refine the prediction by removing the parts which significantly overlap with others.</p><p>Results and Analysis. We show the results of our method for three object categories -chairs, aeroplanes and animals in <ref type="figure" target="#fig_3">Figure 3</ref>. We observe that the predictions successfully capture the coarse structure and are consistent across objects. The results indicate that the we can handle structural variations within a category e.g. the objects in the right side of <ref type="figure" target="#fig_3">Figure 3</ref> have a different structure than those on the left which occur more commonly in the dataset.</p><p>We visualize in <ref type="figure" target="#fig_5">Figure 5</ref> the training error across iterations. We observe that in the initial training stage (up to 20000 iterations), the loss rapidly decreases as the correct configuration is being learned. In the second stage of training, when we allow p m to be learned, the error initially increases -this is because some primitives, encouraged by the parsimony reward, now start disappearing and the network eventually learns to use fewer primitives better. Even though the reconstruction error in the initial stages is lower, the reconstructions using fewer primitives, are more parsimonious. This provides an insight regarding the tradeoff between representation parsimony and reconstruction accuracy -and that we should not judge the former by the latter.  We visualize the prediction for two instances (shown in column 1) after every 10,000 iterations (left to right, in columns 2-6). The last column shows the result after post-processing to remove redundant parts that overlap significantly with others. The initial training stage (up to 20,000 iterations) uses all primitives but we later allow the network to learn to use fewer primitives and the predictions gradually become more parsimonious.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Applications</head><p>We observe in <ref type="figure">Figure 1</ref> and <ref type="figure" target="#fig_3">Figure 3</ref> that the inferred representations are consistent across a category -chair seat is explained consistently using the same primitive. They are also descriptive of the underlying shape and are, by construction, interpretable. Therefore, our framework allows us to automatically discover descriptive, consistent and interpretable shape abstractions using a collection of 3D models. By virtue of these properties, our representation can enable several applications related to shape similarity, part discovery, perception and shape manipulation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Unsupervised Parsing and Correspondence</head><p>The learned primitive decomposition is useful for obtaining part-level correspondences across instances. Since we use a common network across an object category, simple and consistent solutions are preferred to explain the data i.e. the same primitive explains the chair back across the category. We can leverage this observation to extract correspondences across the category by assigning labels to points according to the primitive that explains them -we assign each point to the primitive that has the lowest C(p,P m ), giving preference to larger primitives to break ties. We therefore obtain a consistent labelling of all points across instances using the predicted primitive decomposition -some examples are depicted in <ref type="figure">Figure 6</ref>.</p><p>We also evaluate this parsing on the Shape COSEG <ref type="bibr" target="#b35">[37]</ref> Figure 6: Projection of the predicted primitives onto the original shape. We assign each point p in the original shape to the corresponding primitive with lowest distance field C(p,P m ). We visualize the parsing by coloring each point according to the assigned primitive. We see that similar parts e.g. aeroplane wings, chair seat, etc. are consistently colored. While the IoU based embedding conflates chairs different fine level structure (e.g. with/without handles), our embedding using all primitives encodes them separately. Additionally, unlike common shape representations, our inferred abstractions give us control over similarity measures -we can choose to consider only specific primitives if required e.g. chair back and seat which, as expected, results in ignoring existence of chair handles. We can also focus on specific properties e.g. chair back orientation and observe a 1D manifold emerge in this scenario. See appendix [1] for high-resolution images.</p><p>dataset by measuring the accuracy using annotated groundtruth. While the ground-truth only has 3 clusters (chair back, seat, legs), our method as well as previous unsupervised approaches <ref type="bibr" target="#b30">[32,</ref><ref type="bibr" target="#b35">37]</ref> cluster shapes into a larger number of partitions (number of primitives in our case) and assign each partition a ground-truth label to evaluate. We obtain a mean accuracy of 89.0% whereas <ref type="bibr" target="#b30">[32]</ref> reports 78.6% and 84.8% accuracy with initial and refined parsings respectively 1 . See appendix [1] for qualitative results.</p><p>1 Unfortunately, we found that <ref type="bibr" target="#b30">[32]</ref> used a preliminary version of the Shape COSEG dataset <ref type="bibr" target="#b35">[37]</ref>. We were unable to obtain this preliminary version, therefore the results are not exactly comparable. The algorithm in <ref type="bibr" target="#b35">[37]</ref> does use the current dataset but reports no quantitative results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Interpretable Shape Similarity</head><p>The trained CNN of our shape assembler maps every 3D shape to corresponding primitive parameters {(z m , q m , t m )}. These parameters succinctly capture the geometry of the underlying object. We find that a simple euclidean distance in the embedding space is a reliable measure of shape similarity. We use this distance to compute a t-sne <ref type="bibr" target="#b24">[26]</ref> embedding of shapes and visualize 1000 random instances in <ref type="figure" target="#fig_6">Figure 7</ref> . We observe that the automatically discovered structure captures similarity better than a simple voxel IoU based metric and that clusters correspond to natural sub-categories e.g. sofa etc.</p><p>One aspect unique to our approach is that the shape embedding is interpretable and instead of using primitive pa-rameters for all parts, we can modify the distance measure to focus on specifics of interest for the application. As an example, we show the resulting t-sne embedding if only 2 primitives, which correspond to back and seat, are used to compute the distance across shapes. We observe that the embedding reflects the desired similarity e.g. unlike in the case of using all primitives to measure shape similarity, chairs with and without handles are now embedded together. We also compute the embedding for the distance measure which only measures the difference in the orientation (q m ) for a specific part (chair back) and observe that this is a 1D manifold with the tilt increasing as we traverse it. Therefore, unlike common shape representations, our inferred abstractions give us control over similarity measures.  We deform the source mesh (top) to have a shape similar to the target mesh (bottom) by using the inferred primitive representation. Each source mesh point is assigned a local coordinate in the closest primitive's frame. A deformation of the primitives from the source to target configuration induces a deformed mesh (shown on right).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Image based Abstraction</head><p>Given our trained model h θ which infers primitive representation using volume inputs, we can train an image based prediction model g θ ′ . We obtain volume-image pairs (V i , I i ) by rendering ShapeNet models with random lighting and background (as suggested in <ref type="bibr" target="#b31">[33]</ref>) and train the image based network to mimic the volume based network's predictions i.e. we train g θ ′ to minimize h θ (V i )−g θ ′ (I i )</p><p>2 . This distillation technique <ref type="bibr" target="#b12">[14]</ref> for using paired data to train a model for predicting outputs similar to a pre-trained CNN is common <ref type="bibr" target="#b11">[13]</ref> and has previously also been used for learning shape embeddings <ref type="bibr" target="#b7">[9]</ref>. We find that we can successfully apply this to our scenario and learn an image-based prediction model that outputs the abstraction of the underlying shape given a single image. We show some results in <ref type="figure" target="#fig_7">Figure 8</ref>. This demonstrates that one can learn to predict shape abstractions using varying inputs and this might enable applications in robotics settings where such inference might help in grasping, planning etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Shape Manipulation</head><p>The inferred primitive based shape abstractions can be used as a skeleton to guide manipulation of the underlying objects. We can assign each mesh point a local coordinate in the frame of its corresponding primitive (as computed in Section 5.1). A rotation, translation or scaling of the corresponding primitive can thereby induce a change in the global coordinates of the associated mesh points. We show some examples in <ref type="figure" target="#fig_8">Figure 9</ref> where we deform a source mesh to have a similar configuration as a target mesh. While the transformation used in this example is defined using a target mesh, one can also use our representation for other transformation e.g. making the legs longer or tilting the back etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work, we take an unsupervised, data-driven approach to explain visual information in terms of simpler primitives. Taking inspiration from the classic work on generalized cylinders <ref type="bibr" target="#b1">[3]</ref> and geons <ref type="bibr" target="#b0">[2]</ref>, we too argue that any visual explanation must be in terms of 3D volumetric entities, not 2D pixel patches. However, unlike the earlier work in this area we firmly believe in being data-driven and letting the data itself discover the best representation.</p><p>We demonstrated the applicability of data-driven 3D understanding of the visual world in a very simple settingthat of explaining objects from cuboidal primitives. This merely represents the first steps towards the goal of generating parsimonious descriptions of the visual input and hope that this will motivate further efforts, including the use of a wider catalogue of basic parametrized primitives, to understand the underlying 3D structure of the world.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>the primitive's dimensions (e.g. cuboid height, width, depth) as before and z e m ∼ Bern(p m ) is a binary variable which denotes if the primitive actually ex- ists i.e. if z e m = 0 we pretend as if the m th primitive does not exist. The prediction of the CNN in this scenario is as below.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>. Towards this, we note that the un-transformed primitive P m is either a cuboid (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>nected layers with intermediate non-linearities to output the primitive parameters {(z s m , q m , t m , p m )|m = 1 · · · M } ≡ h θ (I i ). In this work, we use cuboid primitives and z s m</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Final predictions of our method on chairs, animals and aeroplanes. We visualize the more commonly occurring modes on the left and progressively towards the right show rarer configurations predicted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Visualization of the training progression. We visualize the prediction for two instances (shown in column 1) after every 10,000 iterations (left to right, in columns 2-6). The last column shows the result after post-processing to remove redundant parts that overlap significantly with others. The initial training stage (up to 20,000 iterations) uses all primitives but we later allow the network to learn to use fewer primitives and the predictions gradually become more parsimonious.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: We plot the Coverage (L1) and Consistency (L2) losses over training iterations. The losses both decreases in the initial stage of training (up to 20,000 iterations) but when we allow the use of varying number of primitives along with parsimony reward, the losses initially increase. This reveals a tradeoff between representation parsimony and reconstruction accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Embeddings computed using various distance measures -a) Voxel IoU based distance b) Ours (all primitives) c) Ours (chair back, seat primitives) d) Ours (chair back orientation). While the IoU based embedding conflates chairs different fine level structure (e.g. with/without handles), our embedding using all primitives encodes them separately. Additionally, unlike common shape representations, our inferred abstractions give us control over similarity measures -we can choose to consider only specific primitives if required e.g. chair back and seat which, as expected, results in ignoring existence of chair handles. We can also focus on specific properties e.g. chair back orientation and observe a 1D manifold emerge in this scenario. See appendix [1] for high-resolution images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Inferred abstractions using real image inputs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: We deform the source mesh (top) to have a shape similar to the target mesh (bottom) by using the inferred primitive representation. Each source mesh point is assigned a local coordinate in the closest primitive's frame. A deformation of the primitives from the source to target configuration induces a deformed mesh (shown on right).</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Saurabh Gupta and David Fouhey for insightful discussions. This work was supported in part by Intel/NSF Visual and Experiential Computing award IIS-1539099, NSF Award IIS-1212798, and the Berkeley Fellowship to ST. We gratefully acknowledge NVIDIA corporation for the donation of Tesla GPUs used for this research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Recognition-by-components: a theory of human image understanding. Psychological review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Biederman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Visual perception by computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">O</forename><surname>Binford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Systems and Control</title>
		<imprint>
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03012</idno>
		<title level="m">ShapeNet: An Information-Rich 3D Model Repository</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
	<note>cs.GR</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Discovering hidden factors of variation in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Livezey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Olshausen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6583</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tassa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.08575.2</idno>
		<title level="m">Attend, infer, repeat: Fast scene understanding with generative models</title>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Co-segmentation by composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Faktor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV 2013</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Meta-representation of shape families</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Averkiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Van Kaick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning a predictable and generative vector representation for objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girdhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fouhey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Draw: A recurrent neural network for image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.04623</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Blocks world revisited: Image understanding using qualitative geometry and mechanics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<idno>ECCV. 2010. 2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cross modal distillation for supervision transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Efficient inference in occlusionaware generative models of images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06362</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Joint shape segmentation with linear programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2011" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Single-view reconstruction via joint analysis of image and shape collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scene collaging: Analysis and synthesis of natural images with semantic layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A probabilistic model for component-based shape synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Categoryspecific object reconstruction from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tulsiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980.5</idno>
		<imprint/>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Whitney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.03167</idno>
		<title level="m">Deep convolutional inverse graphics network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Joint embeddings of shapes and images via cnn image purification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Parsing ikea objects: Fine pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV 2013</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Machine Perception of Three-Dimensional Solids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIT</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1963" />
		</imprint>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised joint object discovery and segmentation in internet images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2013</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Segmenting scenes by matching image composites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Using multiple segmentations to discover objects and their extent in image collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unsupervised co-segmentation of a set of shapes via descriptor-space spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Van Kaick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kleiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohenor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH Asia)</title>
		<meeting>SIGGRAPH Asia)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Render for cnn: Viewpoint estimation in images using cnns trained with rendered 3d model views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Data-driven structural priors for shape completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Angst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Part-based modelling of compound scenes from images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Hengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bastian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pooley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Agapito</surname></persName>
		</author>
		<idno>CVPR 2015. 2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Reconstructing pascal voc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vicente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Agapito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Active co-analysis of a set of shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Asafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Van Kaick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Beyond pascal: A benchmark for 3d object detection in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Recurring part arrangements in shape collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Averkiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
