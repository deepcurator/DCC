<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:21+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NetGAN: Generating Graphs via Random Walks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Shchur</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zügner</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
						</author>
						<title level="a" type="main">NetGAN: Generating Graphs via Random Walks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We propose NetGAN -the first implicit generative model for graphs able to mimic real-world networks. We pose the problem of graph generation as learning the distribution of biased random walks over the input graph. The proposed model is based on a stochastic neural network that generates discrete output samples and is trained using the Wasserstein GAN objective. NetGAN is able to produce graphs that exhibit well-known network patterns without explicitly specifying them in the model definition. At the same time, our model exhibits strong generalization properties, as highlighted by its competitive link prediction performance, despite not being trained specifically for this task. Being the first approach to combine both of these desirable properties, Net-GAN opens exciting avenues for further research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Generative models for graphs have a longstanding history, with applications including data augmentation, anomaly detection and recommendation <ref type="bibr" target="#b10">(Chakrabarti &amp; Faloutsos, 2006)</ref>. Explicit probabilistic models such as Barabási-Albert or stochastic blockmodels are the de-facto standard in this field <ref type="bibr" target="#b14">(Goldenberg et al., 2010)</ref>. However, it has also been shown on multiple occasions that our intuitions about structure and behavior of graphs may be misleading. For instance, heavy-tailed degree distributions in real graphs were in strong disagreement with the models existing at the time of their discovery <ref type="bibr" target="#b3">(Barabási &amp; Albert, 1999)</ref>. More recent works like <ref type="bibr" target="#b13">Dong et al. (2017)</ref> and <ref type="bibr" target="#b9">Broido &amp; Clauset (2018)</ref> keep bringing up other surprising characteristics of realworld networks that question the validity of the established models. This leads us to the question: "How do we define a model that captures all the essential (potentially still unknown) properties of real graphs?" An increasingly popular way to address this issue in other fields is by switching from explicit (prescribed) models to implicit ones. This transition is especially notable in computer vision, where generative adversarial networks (GANs) <ref type="bibr" target="#b16">(Goodfellow et al., 2014)</ref> significantly advanced the state of the art over the classic prescribed approaches like mixtures of Gaussians <ref type="bibr" target="#b6">(Blanken et al., 2007)</ref>. GANs achieve unparalleled results in scenarios such as image and 3D objects generation (e.g., <ref type="bibr" target="#b24">Karras et al., 2017;</ref><ref type="bibr" target="#b5">Berthelot et al., 2017;</ref><ref type="bibr" target="#b42">Wu et al., 2016)</ref>. However, despite their massive success when dealing with real-valued data, adapting GANs to handle discrete objects like graphs or text remains an open research problem <ref type="bibr" target="#b15">(Goodfellow, 2016)</ref>. In fact, discreteness is only one of the obstacles when applying GANs to network data. Large repositories of graphs that all come from the same distribution are not available. This means that in a typical setting one has to learn from a single graph. Additionally, any model operating on a graph necessarily has to be permutation invariant, as graphs are isomorphic under node reordering.</p><p>In this work we introduce NetGAN -the first implicit generative model for graphs and networks that tackles all of the above challenges. We formulate the problem of learning the graph topology as learning the distribution of biased random walks over the graph. Like in the typical GAN setting, the generator G -in our case defined as a stochastic neural network with discrete output samples -learns to generate random walks that are plausible in the real graph, while the discriminator D then has to distinguish them from the true ones that are sampled from the original graph.</p><p>The main requirement for a graph generative model is the ability to generate realistic graphs. In the experimental section we compare NetGAN to other established prescribed models on this task. We observe that our proposed method consistently reproduces most known patterns inherent to real-world networks without explicitly specifying any of them in the model definition (e.g., degree distribution, as seen in <ref type="figure" target="#fig_0">Fig. 1</ref>). However, a model that simply replicates the original graph would also trivially fulfill this requirement, which clearly isn't our goal. In order to prove that this is not the case we examine the generalization properties of NetGAN by evaluating its link prediction performance. As our experiments show, our model exhibits competitive performance in this task and even achieves state-of-the-art results on some datasets. This result is especially impressive, since NetGAN is not trained explicitly for performing link prediction. To summarize, our main contributions are:</p><p>• We introduce NetGAN 1 -the first of its kind GAN architecture that generates graphs via random walks. Our model tackles the associated challenges of staying permutation invariant, learning from a single graph and generating discrete output.</p><p>• We show that our method preserves important topological properties, without having to explicitly specifying them in the model definition. Moreover, we demonstrate how latent space interpolation leads to producing graphs with smoothly changing characteristics.</p><p>• We highlight the generalization properties of NetGAN by its link prediction performance that is competitive with the state of the art on real-word datasets, despite the model not being trained explicitly for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>So far, no GAN architectures applicable to real-world networks have been proposed. <ref type="bibr" target="#b32">Liu et al. (2017)</ref> propose a GAN architecture for learning topological features of subgraphs. <ref type="bibr" target="#b40">Tavakoli et al. (2017)</ref> apply GANs to graph data by trying to directly generate adjacency matrices. Because their model produces the entire adjacency matrix -including the zero entries -it requires computations and memory quadratic in the number of nodes. Such quadratic complexity is infeasible in practice, allowing to process only small graphs, with reported runtime of over 60 hours for a graph with only 154 nodes. In contrast, NetGAN operates on random walks -it considers only the non-zero entries of the adjacency matrix efficiently exploiting the sparsity of real-world graphs -and is readily applicable to graphs with thousands of nodes.</p><p>1 Code available at: https://www.kdd.in.tum.de/netgan</p><p>Deep learning methods for graph data have mostly been studied in the context of node embeddings <ref type="bibr" target="#b37">(Perozzi et al., 2014;</ref><ref type="bibr" target="#b17">Grover &amp; Leskovec, 2016;</ref><ref type="bibr" target="#b28">Kipf &amp; Welling, 2016)</ref>. The main idea behind these approaches is that of modeling the probabilities of each individual edge's existence, p(A uv ), as some function of the respective node embeddings, f (h u , h v ), where f is represented by a neural network. The recently proposed GraphGAN  is another instance of such prescribed edge-level probabilistic models, where f is optimized using the GAN objective instead of the traditional cross-entropy. Deep embedding based methods achieve state-of-the-art scores in tasks like link prediction and node classification. Nevertheless, as we show in Sec. 3.2, using such approaches for generating entire graphs produces samples that don't preserve any of the patterns inherent to real-world networks.</p><p>Prescribed generative models for graphs have a long history and are well-studied. For a survey we refer the reader to <ref type="bibr" target="#b10">Chakrabarti &amp; Faloutsos (2006)</ref> and <ref type="bibr" target="#b14">Goldenberg et al. (2010)</ref>. Typically, prescribed generative approaches are designed to capture and reproduce some predefined subset of graph properties (e.g., degree distribution, community structure, clustering coefficient). Notable examples include the configuration model <ref type="bibr" target="#b4">(Bender &amp; Canfield, 1978;</ref><ref type="bibr" target="#b34">Molloy &amp; Reed, 1995)</ref>, variants of the degree-corrected stochastic blockmodel <ref type="bibr" target="#b25">(Karrer &amp; Newman, 2011;</ref>, Exponential Random Graph Models <ref type="bibr" target="#b22">(Holland &amp; Leinhardt, 1981)</ref>, Multiplicative Attribute Graph model <ref type="bibr" target="#b26">(Kim &amp; Leskovec, 2011)</ref>, and the block two-level Erdős-Réniy random graph model <ref type="bibr" target="#b39">(Seshadhri et al., 2012)</ref>. In Sec. 4 we compare with some of these prescribed models on the tasks of graph generation and link prediction.</p><p>Due to the challenging nature of the problem, only few approaches able to generate discrete data using GANs exist. Most approaches focus on generating discrete sequences such as text, with some of them using reinforcement learn-ing techniques to enable backpropagation through sampling discrete random variables <ref type="bibr" target="#b43">(Yu et al., 2017;</ref><ref type="bibr" target="#b29">Kusner &amp; Hernández-Lobato, 2016;</ref><ref type="bibr" target="#b30">Li et al., 2017;</ref><ref type="bibr" target="#b31">Liang et al., 2017)</ref>. Other approaches modify the GAN objective to tackle the same challenge <ref type="bibr" target="#b20">Hjelm et al., 2017)</ref>. Focusing on non-sequential discrete data, <ref type="bibr" target="#b12">Choi et al. (2017)</ref> generate high-dimensional discrete features (e.g. binary indicators, counts) in patient records. None of these methods have considered graph structured data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Model</head><p>In this section we introduce NetGAN -a Generative Adversarial Network model for graph / network data. Its core idea lies in capturing the topology of a graph by learning a distribution over the random walks. Given an input graph of N nodes, defined by a binary adjacency matrix A ∈ {0, 1} N ×N , we first sample a set of random walks of length T from A. This collection of random walks serves as a training set for our model. We use the biased secondorder random walk sampling strategy described in <ref type="bibr" target="#b17">Grover &amp; Leskovec (2016)</ref>, as it better captures both local and global graph structure. An important advantage of using random walks is their invariance under node reordering. Additionally, random walks only include the nonzero entries of A, thus efficiently exploiting the sparsity of real-world graphs.</p><p>Like any typical GAN architecture, NetGAN consists of two main components -a generator G and a discriminator D. The goal of the generator is to generate synthetic random walks that are plausible in the input graph. At the same time, the discriminator learns to distinguish the synthetic random walks from the real ones that come from the training set. Both G and D are trained end-to-end using backpropagation. At any point of the training process it is possible to use G to generate a set of random walks, which can then be used to produce an adjacency matrix of a new generated graph. In the rest of this section we describe each stage of this process and our design choices in more detail. An overview of our model's complete architecture can be seen in <ref type="figure" target="#fig_1">Fig. 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Architecture</head><p>Generator. The generator G defines an implicit probabilistic model for generating random walks:</p><formula xml:id="formula_0">(v 1 , ..., v T ) ∼ G.</formula><p>We model G as a sequential process based on a neural network f θ parametrized by θ. At each step t, f θ produces two values: the probability distribution over the next node to be sampled, parametrized by the logits p t , and the current memory state of the model, denoted as m t . The next node v t , represented as a one-hot vector, is sampled from a categorical distribution v t ∼ Cat(σ(p t )), where σ(·) denotes the softmax function, and together with m t is passed into f θ at the next step t + 1. Similarly to the classic GAN setting, a latent code z drawn from a multivariate standard normal distribution is passed through a parametric function g θ to initialize m 0 . The generative process of G is summarized in the box below.</p><formula xml:id="formula_1">z ∼ N (0, I d ) m 0 = g θ (z) v 1 ∼ Cat(σ(p 1 )), (p 1 , m 1 ) = f θ (m 0 , 0) v 2 ∼ Cat(σ(p 2 )), (p 2 , m 2 ) = f θ (m 1 , v 1 ) . . . . . . v T ∼ Cat(σ(p T )), (p T , m T ) = f θ (m T −1 , v T −1 )</formula><p>In this work we focus our attention on the Long short-term memory (LSTM) architecture for f θ , introduced by <ref type="bibr" target="#b21">Hochreiter &amp; Schmidhuber (1997)</ref>. The memory state m t of an LSTM is represented by the cell state C t , and the hidden state h t . The latent code z goes through two separate streams, each consisting of two fully connected layers with tanh activation, and then used to initialize (C 0 , h 0 ).</p><p>A natural question might arise: "Why use a model with memory and temporal dependencies, when the random walks are Markov processes?" (2nd order Markov for biased RWs). Or put differently, what's the benefit of using random walks of length greater than 2? In theory, a model with large enough capacity could simply memorize all existing edges in the graph and recreate them. However, for large graphs achieving this in practice is not feasible. More importantly, pure memorization is not the goal of NetGAN, rather we want to have generalization and to generate graphs with similar properties, not exact replicas. Having longer random walks combined with memory helps the model to learn the topology and general patterns in the data (e.g., community structure). Our experiments in Sec. 4.2 confirm this, showing that longer random walks are indeed beneficial.</p><p>After each time step, to generate the next node in the random walk, the network f θ should output the logits p t of length N . However, operating in such high dimensional space leads to an unnecessary computational overhead. To tackle this issue, the LSTM outputs o t ∈ R H instead, with H N , which is then up-projected to R N using the matrix W up ∈ R H×N . This enables us to efficiently handle large-scale graphs.</p><p>Sampling the next node in the random walk v t presents another challenge. Since sampling from a categorical distribution is a non-differentiable operation it blocks the flow of gradients and precludes backpropagation. We solve this problem by using the Straight-Through Gumbel estimator by <ref type="bibr" target="#b23">Jang et al. (2016)</ref>. More specifically, we perform the following transformation: First, we let v * t = σ ((p t + g)/τ )), where τ is a temperature parameter, and g i 's are i.i.d. samples from a Gumbel distribution with zero mean and unit scale. Then, the next sample is chosen as v t = onehot(arg max v * t ). While the one-hot sample v t is passed as input to the next time step, during the backward pass the gradients will flow through the differentiable v * t . The choice of τ allows to trade-off between better flow of gradients (large τ , more uniform v * t ) and more exact calculations (small τ , v * t ≈ v t ). Now that a new node v t is sampled, it needs to be projected back to a lower-dimensional representation before feeding into the LSTM. This is done by means of down-projection matrix W down ∈ R N ×H .</p><p>Discriminator. The discriminator D is based on the standard LSTM architecture. At every time step t, a one-hot vector v t , denoting the node at the current position, is fed as input. After processing the entire sequence of T nodes, the discriminator outputs a single score that represents the probability of the random walk being real.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Training</head><p>Wasserstein GAN. We train our model based on the Wasserstein GAN (WGAN) framework , as it prevents mode collapse and leads to more stable training overall. To enforce the Lipschitz constraint of the discriminator, we use the gradient penalty as in <ref type="bibr" target="#b18">Gulrajani et al. (2017)</ref>. The model parameters {θ, θ } are trained using stochastic gradient descent with Adam <ref type="bibr" target="#b27">(Kingma &amp; Ba, 2014)</ref>. Weights are regularized with an L 2 penalty.</p><p>Early stopping. Because we are interested in generalizing the input graph, the "trivial" solution where the generator has memorized all existing edges is of no interest to us. This means that we need to control how closely the generated graphs resemble the original one. To achieve this, we propose two possible early stopping strategies, either of which can be used depending on the task at hand. The first strategy, named VAL-CRITERION is concerned with the generalization properties of NetGAN. During training, we keep a sliding window of the random walks generated in the last 1,000 iterations and use them to construct a matrix of transition counts. This matrix is then used to evaluate the link prediction performance on a validation set (i.e. ROC and AP scores, for more details see Sec. 4.2). We stop with training when the validation performance stops improving.</p><p>The second strategy, named EO-CRITERION makes Net-GAN very flexible and gives the user control over the graph generation. We stop training when we achieve a user specified edge overlap between the generated graphs (see next section) and the original one at a given iteration. Based on her end task the user can choose to generate graphs with either small or large edge overlap with the original, while maintaining structural similarity. This will lead to generated graphs that either generalize better or are closer replicas respectively, yet still capture the properties of the original.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Assembling the Adjacency Matrix</head><p>After finishing the training, we use the generator G to construct a score matrix S of transition counts, i.e. we count how often an edge appears in the set of generated random walks (typically, using a much larger number of random walks than for early stopping, e.g., 500K). While the raw counts matrix S is sufficient for link prediction purposes, we need to convert it to a binary adjacency matrixÂ if we wish to reason about the synthetic graph. First, S is symmetrized by setting s ij = s ji = max{s ij , s ji }. Because we cannot explicitly control the starting node of the random walks generated by G, some high-degree nodes will likely be overrepresented. Thus, a simple binarization strategy like thresholding or choosing top-k entries might lead to leaving out the low-degree nodes and producing singletons. To address this issue, we use the following approach: (i) We ensure that every node i has at least one edge by sampling a neighbor j with probability p ij = sij v siv . If an edge was already sampled before, we repeat the procedure; (ii) We continue sampling edges without replacement using for each edge (i, j) the probability p ij = sij u,v suv , until we reach the desired amount of edges (e.g., as many edges as in the original graph). To obtain an undirected graph for every edge (i, j) we also include (j, i). Note that this procedure is not guaranteed to produce a fully connected graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section we evaluate the quality of the graphs generated by NetGAN by computing various graph statistics. We quantify the generalization power of the proposed model by evaluating its link prediction performance. Furthermore, we demonstrate how we can generate graphs with smoothly changing properties via latent space interpolation. Additional experiments are provided in the supp. mat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets.</head><p>For the experiments we use five well-known citation datasets and the Political Blogs dataset. For the large CORA dataset and its commonly used subset of machine learning papers denoted with CORA-ML we use the same preprocessing as in . For all the experiments we treat the graphs as undirected and only consider the largest connected component (LCC). Information about the datasets is listed in <ref type="table" target="#tab_1">Table 2</ref>.  <ref type="bibr" target="#b1">(Adamic &amp; Glance, 2005)</ref> 4.1. Graph Generation Setup. In this task, we fit NetGAN to the CORA-ML and CITESEER citation networks in order to evaluate quality of the generated graphs. We compare to the following baselines: configuration model <ref type="bibr" target="#b34">(Molloy &amp; Reed, 1995)</ref>, degree-corrected stochastic blockmodel (DC-SBM) <ref type="bibr" target="#b25">(Karrer &amp; Newman, 2011)</ref>, exponential random graph model (ERGM) <ref type="bibr" target="#b22">(Holland &amp; Leinhardt, 1981</ref>) and the block twolevel Erdős-Réniy random graph model (BTER) <ref type="bibr" target="#b39">(Seshadhri et al., 2012)</ref>. Additionally, we use the variational graph autoencoder (VGAE) <ref type="bibr" target="#b28">(Kipf &amp; Welling, 2016)</ref> as a representative of network embedding approaches. We randomly hide 15% of the edges (which are used for the stopping criterion; see Sec. 3.2) and fit all the models on the remaining graph. We sample 5 graphs from each of the trained models and report their average statistics in <ref type="table" target="#tab_0">Table 1</ref>. Definitions of the statistics, additional metrics, standard deviations and details about the baselines are given in the supplementary material.</p><p>Evaluation. The general trend that becomes apparent from the results in <ref type="table" target="#tab_0">Table 1 (and Table 2</ref> in supplementary material) is that prescribed models excel at recovering the statistics that they directly model (e.g., degree sequence for DC-SBM). At the same time, these models struggle when dealing with graph properties that they don't account for (e.g., assortativity for BTER). On the other hand, NetGAN is able to capture all the graph properties well, although none of them are explicitly specified in its model definition.</p><p>We also see that VGAE is not able to produce realistic graphs. This is expected, since the main purpose of VGAE is learning node embeddings, and not generating entire graphs.</p><p>The final column shows the average rank of each method for all statistics, with NetGAN performing the best. ERGM seems to be performing surprisingly well, however it suffers from severe overfitting -using the same fitted ERGM for the link prediction task we get both AUC and AP scores close to 0.5 (worst possible value). In contrast, NetGAN does a good job both at preserving properties in generated graphs, as well as generalizing, as we see in Sec. 4.2. Is the good performance of NetGAN in this experiment only due to the overlapping edges (existing in the input graph)? To rule out this possibility we perform the following experiment: We take the graph generated by NetGAN, fix the overlapping edges and rewire the rest according to the configuration model. The properties of the resulting graph (row #3 in <ref type="table" target="#tab_0">Table 1</ref>) deviate strongly from the input graph. This confirms that NetGAN does not simply memorize some edges and generates the rest at random, but rather captures the underlying structure of the network.</p><p>In line with our intuition, we can see that higher EO leads to generated graphs with statistics closer to the original.</p><p>Figs. 3b and 3c show how the graph statistics evolve during the training process. <ref type="figure" target="#fig_2">Fig. 3c</ref> shows that the edge overlap smoothly increasing with the number of epochs. We provide plots for other statistics and for CITESEER in the supp. mat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Link Prediction</head><p>Setup. Link prediction is a common graph mining task where the goal is to predict the existence of unobserved links in a given graph. We use it to evaluate the generalization properties of NetGAN. We hold out 10% of edges from the graph for validation and 5% as the test set, along with the same amount of randomly selected non-edges, while ensuring that the training network remains connected. We measure the performance with two commonly used metrics: area under the ROC curve (AUC) and average precision (AP). To evaluate NetGAN's performance, we sample a given number of random walks (500K/100M) from the trained generator and we use the observed transition counts between any two nodes as a measure of how likely there is an edge between them. We compare with DC-SBM, node2vec and VGAE, as well as Adamic/Adar <ref type="bibr" target="#b0">(Adamic &amp; Adar, 2003)</ref>.</p><p>Evaluation. The results are listed in <ref type="table" target="#tab_2">Table 3</ref>. There is no overall dominant method, with different methods achieving best results on different datasets. NetGAN shows competitive performance for all datasets, even achieving state-of-theart results for some of them (CITESEER and POLBLOGS), despite not being explicitly trained for this task.</p><p>Interestingly, the NetGAN performance increases when increasing the number of random walks sampled from the generator. This is especially true for the larger networks (CORA, DBLP, PUBMED), since given their size we need more random walks to cover the entire graph. This suggests that for an additional computational cost one can get significant gains in link prediction performance. Note, that while 100M may seem like a large number, the sampling procedure can be trivially parallelized.</p><p>Sensitivity analysis. Although NetGAN has many hyperparameters -typical for a GAN model -in practice most of them are not critical for performance, as long as they are within a reasonable range (e.g. H ≥ 30).  One important exception is the the random walk length T . To choose the optimal value, we evaluate the change in link prediction performance as we vary T on CORA-ML. We train multiple models with different random walk lengths, and evaluate the scores ensuring each one observes equal number of transitions. Results averaged over 5 runs are given in <ref type="figure" target="#fig_4">Fig. 6</ref>. We empirically confirm that the model benefits from using longer random walks as opposed to just edges (i.e. T =2). The performance gain for T = 20 over T = 16 is marginal and does not outweigh the additional computational cost, thus we set T = 16 for all experiments. Setup. Latent space interpolation is a good way to gain insight into what kind of structure the generator was able to capture. To be able to visualize the properties of the generated graphs we train our model using a 2-dimensional noise vector z drawn as before from a bivariate standard normal distribution. This corresponds to a 2-dimensional latent space Ω = R 2 . Then, instead of sampling z from the entire latent space Ω, we now sample from subregions of Ω and visualize the results. Specifically, we divide Ω into 20 × 20 subregions (bins) of equal probability mass using the standard normal cumulative distribution function Φ. For each bin we generate 62.5K random walks. We evaluate properties of both the generated random walks themselves, as well as properties of the resulting graphs obtained by sampling a binary adjacency matrix for each bin.</p><p>Evaluation. In <ref type="figure">Fig. 4a and 4b</ref> we see properties of the generated random walks; in <ref type="figure">Fig. 4c and 4d</ref>, we visualize properties of graphs sampled from the random walks in the respective bins. In all four heatmaps, we see distinct patterns, e.g. higher average degree of starting nodes for the bottom right region of <ref type="figure">Fig. 4a</ref>, or higher degree distribution inequality in the top-right area of <ref type="figure">Fig. 4c</ref>. While <ref type="figure">Fig. 4c and  4d</ref> show that certain regions of z correspond to generated graphs with very different degree distributions, recall that sampling from the entire latent space (Ω) yields graphs with degree distribution similar to the original graph (see <ref type="figure" target="#fig_0">Fig. 1c)</ref>. The model was trained on CORA-ML. More heatmaps for other metrics (16 in total) and visualizations for CITESEER can be found in the supplementary material.</p><p>This experiment clearly demonstrates that by interpolating in the latent space we can obtain graphs with smoothly changing properties. The smooth transitions in the heatmaps provide evidence that our model learns to map specific parts of the latent space to specific properties of the graph.</p><p>We can also see this mapping from latent space to the generated graph properties in the community distribution histograms on a 10 × 10 grid in <ref type="figure">Fig. 5</ref>. Marked by (*) and (Ω) we see the community distributions for the input graph and the graph obtained by sampling on the complete latent space respectively. In <ref type="figure">Fig. 5b and 5c</ref>, we see the evolution of selected community shares when following a trajectory from top to bottom, and left to right, respectively. The community histograms resulting from sampling random walks from opposing regions of the latent space are very different; again the transitions between these histograms are smooth, as can be seen in the trajectories in <ref type="figure">Fig. 5b</ref> and 5c.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion and Future Work</head><p>When evaluating different graph generative models in Sec. 3.2, we observed a major limitation of explicit models. While the prescribed approaches excel at recovering the properties directly included in their definition, they perform significantly worse with respect to the rest. This clearly indicates the need for implicit graph generators such as NetGAN. Indeed, we notice that our model is able to consistently capture all the important graph characteristics (see <ref type="table" target="#tab_0">Table 1</ref>). Moreover, NetGAN generalizes beyond the input graph, as can be seen by its strong link prediction performance in Sec. 4.2. Still, being the first model of its kind, NetGAN possesses certain limitations, and a number of related questions could be addressed in follow-up works:</p><p>Scalability. We have observed in Sec. 4.2 that it takes a large number of generated random walks to get representative transition counts for large graphs. While sampling random walks from NetGAN is trivially parallelizable, a possible extension of our model is to use a conditional generator, i.e. the generator can be provided a desired starting node, thus ensuring a more even coverage. On the other hand, the sampling procedure itself can be sped up by incorporating a hierarchical softmax output layer -a method commonly used in natural language processing.</p><p>Evaluation. It is nearly impossible to judge whether a graph is realistic by visually inspecting it (unlike images, for example). In this work we already quantitatively evaluate the performance of NetGAN on a large number of standard graph statistics. However, developing new measures applicable to (implicit) graph generative models will deepen our understanding of their behavior, and is an important direction for future work. Experimental scope. In the current work we focus on the setting of a single large graph. Adaptation to other scenarios, such as a collection of smaller i.i.d. graphs, that frequently occur in other fields (e.g., chemistry, biology), would be an important extension of our model. Studying the influence of the graph topology (e.g., sparsity, diameter) on NetGAN's performance will shed more light on the model's properties.</p><p>Other types of graphs. While plain graphs are ubiquitous, many of important applications deal with attributed, k-partite or heterogeneous networks. Adapting the Net-GAN model to handle these other modalities of the data is a promising direction for future research. Especially important would be an adaptation to the dynamic / inductive setting, where new nodes are added over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work we introduce NetGAN -an implicit generative model for network data. NetGAN is able to generate graphs that capture important topological properties of complex networks, such as community structure and degree distribution, without having to manually specify any of them.</p><p>Moreover, our proposed model shows strong generalization properties, as highlighted by its competitive link prediction performance on a number of datasets. NetGAN can also be used for generating graphs with continuously varying characteristics using latent space interpolation. Combined our results provide strong evidence that implicit generative models for graphs are well-suited for capturing the complex nature of real-world networks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (a) Subgraph of the CITESEER network and (b) the respective subset of the graph generated by NetGAN. Both have similar structure but are not identical. (c) shows that the degree distributions of the two graphs are very close.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The NetGAN architecture proposed in this work (b) and the generator architecture (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Properties of graphs generated by NetGAN trained on CORA-ML.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Effect of the random walk length T on the performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: Properties of the random walks (4a and 4b) as well as the graphs (4c and 4d) sampled from the 20 × 20 bins.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Statistics of CORA-ML and the graphs generated by NetGAN and the baselines, averaged over 5 trials. NetGAN closely matches the input networks in most properties, while other methods either deviate significantly in at least one statistic or overfit. * indicates values for the conf. model that by definition exactly match the original.</figDesc><table>Graph 
Max. 
degree 

Assort-
ativity 

Triangle 
count 

Power 
law exp. 

Inter-comm. 
unity density 

Intra-comm. 
unity density 

Cluster-
ing coeff. 

Charac. 
path len. 

Average 
rank 
CORA-ML 
240 
-0.075 
2,814 
1.860 
4.3e-4 
1.7e-3 
2.73e-3 
5.61 
Conf. model 
(1% EO) 
* 
-0.030 
322 
* 
1.6e-3 
2.8e-4 
3.00e-4 
4.38 
7.50 
Conf. model 
(52% EO) 
* 
-0.051 
626 
* 
9.8e-4 
9.9e-4 
6.10e-4 
4.46 
5.83 
DC-SBM 
(11% EO) 
165 
-0.052 
1,403 
1.814 
6.7e-4 
1.2e-3 
3.30e-3 
5.12 
3.36 
ERGM 
(56% EO) 
243 
-0.077 
2,293 
1.786 
6.9e-4 
1.2e-3 
2.17e-3 
4.59 
2.88 
BTER 
(2.2% EO) 
199 
0.033 
3,060 
1.787 
1.0e-3 
7.5e-4 
4.62e-3 
4.59 
4.75 
VGAE 
(0.3% EO) 
13 
-0.009 
14 
1.674 
1.4e-3 
3.2e-4 
1.17e-3 
5.28 
5.88 
NetGAN VAL (39% EO) 
199 
-0.060 
1,410 
1.773 
6.5e-4 
1.3e-3 
2.33e-3 
5.17 
3.00 
NetGAN EO 
(52% EO) 
233 
-0.066 
1,588 
1.793 
6.0e-4 
1.4e-3 
2.44e-3 
5.20 
1.75 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Dataset statistics. N LCC , E LCC -number of nodes and edges respectively in the largest connected component.</figDesc><table>Name 
N LCC E LCC Reference 
CORA-ML 
2,810 
7,981 (McCallum et al., 2000) 
CORA 
18,800 64,529 (McCallum et al., 2000) 
CITESEER 
2,110 
3,757 (Sen et al., 2008) 
PUBMED 
19,717 44,324 (Sen et al., 2008) 
DBLP 
16,191 51,913 (Pan et al., 2016) 
POL. BLOGS 
1,222 16,714 </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 :</head><label>3</label><figDesc>Link prediction performance (in %).</figDesc><table>Method 
CORA-ML 
CORA 
CITESEER 
DBLP 
PUBMED 
POLBLOGS 
AUC 
AP 
AUC 
AP 
AUC 
AP 
AUC 
AP 
AUC 
AP 
AUC 
AP 
Adamic/Adar 
92.16 85.43 93.00 86.18 88.69 77.82 91.13 82.48 84.98 70.14 85.43 92.16 
DC-SBM 
96.03 95.15 98.01 97.45 94.77 93.13 97.05 96.57 96.76 95.64 95.46 94.93 
node2vec 
92.19 91.76 98.52 98.36 95.29 94.58 96.41 96.36 96.49 95.97 85.10 83.54 
VGAE 
95.79 96.30 97.59 97.93 95.11 96.31 96.38 96.93 94.50 96.00 93.73 94.12 
NetGAN (500K) 94.00 92.32 82.31 68.47 95.18 91.93 82.45 70.28 87.39 76.55 95.06 94.61 
NetGAN (100M) 95.19 95.24 84.82 88.04 96.30 96.89 86.61 89.21 93.41 94.59 95.51 94.83 

4.3. Latent Variable Interpolation 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by the German Research Foundation, Emmy Noether grant GU 1409/2-1, and by the Technical University of Munich -Institute for Advanced Study, funded by the German Excellence Initiative and the European Union Seventh Framework Programme under grant agreement no 291763, co-funded by the European Union.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Friends and neighbors on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Adamic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social networks</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="230" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The political blogosphere and the 2004 US election: divided they blog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Adamic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Glance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international workshop on Link discovery</title>
		<meeting>the international workshop on Link discovery</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="36" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wasserstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Emergence of scaling in random networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-L</forename><surname>Barabási</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="issue">5439</biblScope>
			<biblScope unit="page" from="509" to="512" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The asymptotic number of labeled graphs with given degree sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Canfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Combinatorial Theory, Series A</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="296" to="307" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schumm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Began</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10717</idno>
		<title level="m">Boundary equilibrium generative adversarial networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Blanken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Blok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bayesian robust attributed graph clustering: Joint learning of partial anomalies and group structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2738" to="2745" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep gaussian embedding of graphs: Unsupervised inductive learning via ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Scale-free networks are rare</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Broido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clauset</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.03400</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<title level="m">Graph mining: Laws, generators, and algorithms. Computing Surveys (CSUR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">38</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.07983</idno>
		<title level="m">Maximum-likelihood augmented discrete generative adversarial networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Generating multi-label discrete electronic health records using generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Biswal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Malin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">F</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.06490</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Structural diversity and homophily: A study across more than one hundred big networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="807" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A survey of statistical network models. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goldenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Fienberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Airoldi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="129" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.00160</idno>
		<title level="m">NIPS 2016 tutorial: Generative adversarial networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00028</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>Improved training of Wasserstein GANs</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">ERGM: Fit, Simulate and Diagnose Exponential-Family Models for Networks. The Statnet Project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Handcock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Butts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Goodreau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Krivitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morris</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>R package version 3.8.0</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08431</idno>
		<title level="m">Boundary-seeking generative adversarial networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An exponential family of probability distributions for directed graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Leinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the american Statistical association</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">373</biblScope>
			<biblScope unit="page" from="33" to="50" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<title level="m">Categorical reparameterization with Gumbel-softmax</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">NetGAN: Generating Graphs via Random Walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10196</idno>
	</analytic>
	<monogr>
		<title level="m">Progressive growing of gans for improved quality, stability, and variation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Stochastic blockmodels and community structure in networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Karrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">16107</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Modeling social networks with node attributes using the multiplicative attribute graph model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1106.5053</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Variational graph auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07308</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">GANs for sequences of discrete elements with the Gumbel-softmax distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hernández-Lobato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04051</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Adversarial learning for neural dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurafsky</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06547</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Recurrent topic-transition GAN for visual paragraph generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07022</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Suzumura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Can</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06197</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automating the construction of internet portals with machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rennie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Seymore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="127" to="163" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">A critical point for random graphs with a given degree sequence. Random structures &amp; algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Molloy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Reed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="161" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Tri-party deep network representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">The graph-tool python library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Peixoto</surname></persName>
		</author>
		<ptr target="http://figshare.com/articles/graph_tool/1164194" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deepwalk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Collective classification in network data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bilgic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Galligher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Eliassi-Rad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">93</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Community structure and scale-free collections of Erdős-Rényi graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Seshadhri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pinar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">56109</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Learning social graph topologies using generative adversarial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tavakoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hajibagheri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sukthankar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Graphgan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.08267</idno>
		<title level="m">Graph representation learning with generative adversarial nets</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">SeqGAN: Sequence generative adversarial nets with policy gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2852" to="2858" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
