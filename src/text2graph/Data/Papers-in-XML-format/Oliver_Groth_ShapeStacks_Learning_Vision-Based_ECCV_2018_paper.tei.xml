<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T23:19+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ShapeStacks: Learning Vision-Based Physical Intuition for Generalised Object Stacking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Groth</surname></persName>
							<email>ogroth@robots.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">B</forename><surname>Fuchs</surname></persName>
							<email>fabian@robots.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingmar</forename><surname>Posner</surname></persName>
							<email>ingmar@robots.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
							<email>vedaldi@robots.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ShapeStacks: Learning Vision-Based Physical Intuition for Generalised Object Stacking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>Intuitive Physics · Stability Prediction · Object Stacking</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract. Physical intuition is pivotal for intelligent agents to perform complex tasks. In this paper we investigate the passive acquisition of an intuitive understanding of physical principles as well as the active utilisation of this intuition in the context of generalised object stacking. To this end, we provide ShapeStacks 1 : a simulation-based dataset featuring 20,000 stack configurations composed of a variety of elementary geometric primitives richly annotated regarding semantics and structural stability. We train visual classifiers for binary stability prediction on the ShapeStacks data and scrutinise their learned physical intuition. Due to the richness of the training data our approach also generalises favourably to real-world scenarios achieving state-of-the-art stability prediction on a publicly available benchmark of block towers. We then leverage the physical intuition learned by our model to actively construct stable stacks and observe the emergence of an intuitive notion of stackability -an inherent object affordance -induced by the active stacking task. Our approach performs well exceeding the stack height observed during training and even manages to counterbalance initially unstable structures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Research in cognitive science <ref type="bibr" target="#b16">[14,</ref><ref type="bibr" target="#b7">8]</ref> highlights how the ability of humans to manipulate the environment depends strongly on our ability to intuitively understand its physics from visual observations. Intuitive physics may be just as important for autonomous agents to effectively and efficiently perform complex tasks such as object stacking or (dis-)assembly -and even the creation and use of tools. Central to these deliberations is an understanding of the physical properties of objects in the context of how they are meant to be used. Such object affordances are typically pre-defined given knowledge of the task at hand <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b12">12]</ref>. In contrast, we posit that relevant affordances do not need to be specified a priori but can be learned in a task-driven manner.</p><p>Inspired by recent work in computer vision <ref type="bibr" target="#b18">[15,</ref><ref type="bibr" target="#b27">23]</ref> and robotics <ref type="bibr" target="#b20">[17,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b29">25]</ref> we consider the task of object stacking and the problem of learning -from passive We present a visual classifier which is trained on stacks of diverse shapes to distinguish between stable and unstable structures. We demonstrate that the implicit knowledge captured by the predictor can be utilised to detect structural instabilities, infer the stackability (utility with regard to stacking) of objects and guide a simulated stacking process solely from visual cues.</p><p>visual observations -its intuitive physical principles. By leveraging the model's acquired intuitions, we are able to utilise the passive observation in an active manipulation task as outlined in <ref type="figure">Figure 1</ref>, which sets us apart from prior art in both scope and reach.</p><p>Firstly, we argue that in order for agents to perform complex tasks they need to be able to interact with a variety of different object types. We therefore investigate the stacking problem using a broader set of geometric primitives than found in related works. To this end we introduce ShapeStacks, a simulation-based dataset specifically created to enable exploration of stackability of a variety of objects. Furthermore, ShapeStacks is, to the best of our knowledge, the first such dataset with annotations of the mechanical points of failure of stacks, which are inferred by formally analysing the underlying physics. This makes ShapeStacks the most rigorous and complete publicly available dataset in this space.</p><p>Secondly, based on the ShapeStacks dataset, we extend the investigation of stability prediction presented in <ref type="bibr" target="#b18">[15,</ref><ref type="bibr" target="#b27">23]</ref> to include stacks containing multiple object geometries. This allows for a more rigorous qualitative and quantitative evaluation of system performance. For example, our work, for the first time, quantifies if a model trained for stability prediction correctly localizes the underlying stability violations. We demonstrate that our model based on ShapeStacks outperforms the baseline by Lerer et al. <ref type="bibr" target="#b18">[15]</ref> and performs commensurately with the current state-of-the-art <ref type="bibr" target="#b27">[23]</ref> on real-world image data without requiring a physics engine during test time.</p><p>Lastly, in order to investigate our main hypothesis -namely that meaningful affordances emerge from representations learned by performing concrete tasks -our work goes beyond the passive assessment of stacked towers as stable or unstable and actively performs stacking. In particular, we argue that, through the passive task of stability prediction, our system implicitly learns to assess the stackability of the individual object geometries involved. We demonstrate this by extracting a stackability score for different block geometries and by using it to prioritise piece selection in the construction of tall stacks. By inserting noise in the actual stacking process in lieu of disturbances present in real agents (e.g. motor and perception noise as well as contact physics) we demonstrate that a more intuitive notion of object stackability emerges.</p><p>As a result, our approach discovers an object's suitability towards stacking, ranks pieces accordingly and successfully builds stable towers. In addition, we show that our model is able to stabilise previously unstable structures by the addition of counterweights, arguably by developing an intuitive understanding of counterbalancing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The idea of vision-based physical intuition is firmly rooted in cognitive science where it is a long standing subject of investigation <ref type="bibr" target="#b16">[14]</ref>. Humans are very apt at predicting structural stability <ref type="bibr" target="#b0">[1]</ref>, inferring relative masses <ref type="bibr" target="#b7">[8]</ref> and extrapolating trajectories of moving objects <ref type="bibr" target="#b16">[14]</ref>. Although the exact workings of human physical intuition remain elusive, it has recently gained increasing traction in the machine learning, computer vision and robotics communities. The combination of powerful deep learning models and physics simulators yielded encouraging results in predicting the movement of objects on inclined surfaces <ref type="bibr" target="#b28">[24]</ref> and the dynamics of ball collision <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref>.</p><p>While some prior work on intuitive physics assumed direct access to physical parameters, such as position and velocity, several authors have considered learning physics from visual observations instead. Examples include reasoning about support relations <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">10]</ref> and their geometric affordances and inferring forces in Newtonian image understanding <ref type="bibr" target="#b21">[18]</ref>. Our aim is similar in that we learn the affordance of stackability -an object's utility towards stacking -from visual observation. Importantly, however, in our work affordances are not specified a priori, but emerge by passively predicting the stability of object stacks.</p><p>The latter is related to several recent works in stability prediction. Lerer et al. <ref type="bibr" target="#b18">[15]</ref> pioneered the area by demonstrating feed-forward stability prediction of stacks from simulated and real images, releasing a collection of the latter as a public benchmark. Wu et al. <ref type="bibr" target="#b27">[23]</ref> proposed more sophisticated predictors based on re-rendering an observed scene and using a physics engine to compute stability, outperforming <ref type="bibr" target="#b18">[15]</ref> on their real-world data. In contrast, our approach achieves performance commensurate to <ref type="bibr" target="#b27">[23]</ref> while using only efficient feed forward prediction as in <ref type="bibr" target="#b18">[15]</ref>.</p><p>The problem of structural stability is also well studied in the robotics community, especially in the context of manipulation tasks. Early work implements rule-based approaches with rudimentary visual perception for the game of Jenga <ref type="bibr" target="#b25">[21]</ref> or the safe deconstruction of object piles <ref type="bibr" target="#b22">[19]</ref>. More recently, advances in 3D perception and physical simulation have been exploited to stack irregular objects like stones <ref type="bibr" target="#b5">[6]</ref>.</p><p>The experimental setup of Li et al. <ref type="bibr" target="#b20">[17,</ref><ref type="bibr" target="#b19">16]</ref> is related to ours in that a stability predictor is trained for Kappla blocks in simulation which is then applied to guide stacking with a robotic arm. Our work is set apart from <ref type="bibr" target="#b20">[17,</ref><ref type="bibr" target="#b19">16]</ref> in that we are considering a variety of object geometries as well as more challenging stack configurations. Furthermore, <ref type="bibr" target="#b20">[17,</ref><ref type="bibr" target="#b19">16]</ref> do not consider object affordances.</p><p>More recently, Zhu et al. <ref type="bibr" target="#b29">[25]</ref> show that an end-to-end approach with an end-effector in the loop can be used to learn visuo-motor skills sufficient to stack two blocks on top of one another -both in simulation and in the real world. Their work can be seen as complementary to ours, focusing on the end-effector actuation during stacking while we concentrate on the visual feedback loop and the emerging object affordances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The ShapeStacks Dataset</head><p>In this section we describe the ShapeStacks dataset, starting from an overview of its contents (Section 3.1) followed by an analysis of the physics of stacking (Section 3.2). The latter is required to explain the design of ShapeStacks as well as to precisely define some of its physical data annotations. The full dataset including simulation descriptions and data generation scripts is publicly available. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset Content</head><p>ShapeStacks is a large collection of 20,000 simulated block-stacking scenarios. The selection of the scenarios emphasizes diversity by featuring multiple geometries, degrees of structural complexity and types of structural stability violations, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>. A detailed summary of the dataset content is provided in <ref type="table" target="#tab_0">Table 1</ref>. Each scenario is a single-stranded stack of cubes, cuboids, cylinders and spheres, all with varying dimensions, proportions and colours. The 20,000 scenarios are split roughly evenly among scenarios that contain only cubes (for comparing to related work on stability prediction <ref type="bibr" target="#b18">[15,</ref><ref type="bibr" target="#b27">23]</ref>, and scenarios containing cuboids, cylinders and spheres (abbrev. CCS). Stacks have variable heights, from two to six objects, with the majority built up to a height of three. Each scenario can either be stable or unstable. This is determined by running a physics simulation with the given scenario as starting condition 2 . For every stack height, we provide an equal amount of stable and unstable scenarios. Furthermore, unstable scenarios are evenly divided into the two different instability types (cf. Section 3.2).</p><p>Scenarios are split into train (∼ 70%), validation (∼ 15%), and test (∼ 15%) sets. Each scenario is rendered with a randomised set of background textures, object colours and lighting conditions. We record every scenario from 16 different camera angles and save RGB images of a resolution of 224 x 224 pixels.</p><p>Every recorded image carries a binary stability label. Also, every image is aligned with a segmentation map relating the different parts of the image to their semantics with regard to stability. The segmentation map annotates the <ref type="figure">Fig. 3</ref>: Centre of Mass criterion. The stability of a stack can be tested by considering sub-stacks sequentially, from top to bottom. For stability, the projection of the CoM of each sub-stack must lie within the contact surface with the block supporting it. As shown on the right, a cylindrical or spherical object offers an infinitesimally small contact surface which does not afford stability.</p><p>object which violates the stability of the tower, the first object to fall during the collapse and the base and top of the tower.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Mechanics of Stacking</head><p>While our goal is to study intuitive physics and the emergence of object affordances, we argue that a precise understanding of the physical properties of the scenarios is essential to control data generation as well as to evaluate models.</p><p>In this paper, we restrict our attention to single-stranded stacks: each object S rests on top of another object S ′ or the ground plane and no two objects are at the same level. That is, we exclude structures such as arches, multiple columns, forks, etc. We also assume that all objects are convex, so that a straight line between any two points of the object is fully contained within it.</p><p>In order to determine the stability of a stack, we must use the notion of Centre of Mass (CoM). Let p = (x, y, z) ∈ S i ⊂ R 3 be a point contained within the rigid body S i . If m is the mass of the object and if the material is homogeneous with density ρ, then its CoM is given by r i = ρ Si p dx dy dz/m.</p><p>We now study the stability of an object on top of another and then generalize the result to a full stack. For that, it is useful to refer to the topmost two blocks in <ref type="figure">Figure 3</ref>. Assume that the rigid body S 4 is immersed in a uniform gravity field acting in the negative direction of the z axis. Furthermore, assume that S 4 is resting on a horizontal surface (in this case S 3 ) such that all of its contact points are contained in a horizontal plane π and A ⊂ π denotes the convex hull of such points. Then S 4 is stable if, and only if, the projection of its CoM r 4 on π is contained in A <ref type="bibr" target="#b26">[22]</ref>, which we write as Proj π (r 4 ) ∈ A. If S 4 rests in a stable position on S 3 , the combination of (S 3 , S 4 ) can be seen as a rigid body with CoM r 4 3 . We can then check the stability of the entity (S 4 , S 3 ) with respect to S 2 . Proceeding iteratively for every object from top to bottom of the stack results in the following lemma illustrated in <ref type="figure">Figure 3</ref>:</p><formula xml:id="formula_0">Lemma 1. Let S 1 , .</formula><p>. . , S n be a collection of convex rigid bodies forming a singlestranded tower resting on a flat ground plane S 0 . Let m 1 , . . . , m n be the masses of the objects and r 1 , . . . , r n their centres of mass. Furthermore, let A i be the contact surface between object S i−1 and S i and let π i ⊂ A i be the plane containing it.</p><p>Assume</p><note type="other">that π is parallel to the xy plane, which in turn is orthogonal to gravity. Then, if the objects are initially at rest, the tower is stable if, and only if,</note><formula xml:id="formula_1">∀i = 1, . . . , n − 1 : Proj πi (r n i+1 ) ∈ A i , r n i+1 = n j=i+1 m j r j n j=i+1 m j (1)</formula><p>where r n i+1 is the overall CoM of the topmost n − i blocks. This lemma can be used to assess the stability of a stack by checking the CoM condition from top to bottom for every interface A i . Note that what is important is not the centre of mass of the individual blocks, but that of the part of the tower above each surface A i . Thus it is possible to construct a stable stack that has apparent CoM violations for individual blocks, but that is overall stable due to the counter-balancing effect of the other blocks on top. Importantly, this allows for complex stacks that cannot be constructed in a bottom-up manner by placing only one object at a time.</p><p>We specifically distinguish between two types of instabilities. The first is violation of the planar surface criterion (VPSF). This is caused by an object stacked on top of a curved surface which violates Equation (1) due to the infinitesimally small contact area. It is worth noting that this depends on the shape of the objects and not on the relative object positioning. The second type of instability is called violation of the centre of mass criterion (VCOM), and comprises violations of Equation <ref type="formula">(1)</ref> that depend instead on the positioning of the objects in the stack. For each unstable scenario we introduce either a VPSF or a VCOM violation for exactly one contact area A i .</p><p>For dataset construction, Lemma 1 thus allows us to tightly control which stability violation occurs in each simulated scenario and to mark in each image which object it is attributable to (cf. <ref type="figure" target="#fig_2">Figure 4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Stability Prediction</head><p>In this section, we construct models that can predict the stability of a stack from RGB images alone. We learn these models from passive observations of stable and unstable stacks. Specifically, our vision-based stability classifier is trained to distinguish between stable and unstable towers (Section 4.1) and validated by demonstrating state-of-the-art performance on both simulated and real data. We also quantify how reliably the models can localise the mechanical stability violations present in the unstable stacks (Section 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training the Stability Predictor</head><p>We train a visual classifier for the task of predicting whether a shape stack is stable or not using images 3 from the ShapeStacks dataset, annotated with binary stability labels.</p><p>To this end we investigate the use of two neural network architectures commonly used for image-based classification: AlexNet <ref type="bibr" target="#b14">[13]</ref> and Inception v4 <ref type="bibr" target="#b24">[20]</ref>. In both cases we optimise the network parameters θ given our dataset D = {(x <ref type="bibr" target="#b0">(1)</ref> , y (1) ), . . . , (x (m) , y (m) )} of images x (i) and stability labels y (i) by minimising the following logistic regression loss:</p><formula xml:id="formula_2">L(θ; D) = − m i=1 y (i) log 1 1 + e −f (x (i) ;θ) + (1 − y (i) ) log 1 − 1 1 + e −f (x (i) ;θ)</formula><p>(2) The unscaled logit output of the CNNs is denoted by f (x; θ) and the label values are y = 0 for stable and y = 1 for unstable images. Inception v4 and AlexNet are both trained using the RMSProp optimiser <ref type="bibr" target="#b9">[9]</ref> with solver hyperparameters as reported in <ref type="bibr" target="#b24">[20]</ref> for 80 epochs.</p><p>We use the two different subsets of ShapeStacks during training (cf. <ref type="table" target="#tab_0">Table 1)</ref>, each one containing an equal amount of stable and unstable images. Both types of violations (VCOM and VPSF, cf. Section 3.2) are evenly represented among unstable images. We also reserve a set of 46,560 images featuring stacks of all shapes as final test set. During training, we augment the training images by randomising colours, varying aspect-ratios, and applying random cropping, vertical flipping and minimal in-plane rotation. We ensure that all data augmentations still yield physically plausible, upright towers. <ref type="table" target="#tab_1">Table 2</ref> presents the performance of the classifiers on our simulated test data and on the real-world block tower data provided by <ref type="bibr" target="#b18">[15]</ref>. Our experiments suggest that AlexNet provides a useful baseline for CNN performance on this task. However, it is consistently outperformed by the Inception network. We choose the Inception v4 architecture trained on ShapeStacks data as the reference model in all further experiments.</p><p>As expected, both models perform best on the real-world data when only trained on cubes as the real-world images also only show stacks of cubes. Best performance is reached for both models on the combined ShapeStacks test data (featuring all shapes) when training is also performed on multiple object types. However, it is surprising how well the Inception network generalises from cubes to other structures suggesting that it learned an intuition about the CoM principle (section 3.2) which is also applicable to more complex shapes.</p><p>On real images, Inception v4, trained from scratch on our dataset, outperforms the baseline from Lerer et al. <ref type="bibr" target="#b18">[15]</ref> and is on par with the more complex visual de-animation approach by Wu et al. <ref type="bibr" target="#b27">[23]</ref>, which translates the observed images into a physical state and checks stability with a physics engine. We attribute this to the richness of the ShapeStacks dataset as well as to our data augmentation scheme, which results in a visually and structurally diverse set of stacks and hence affords good generalisation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Instability Localisation</head><p>In order to probe whether the network grounds its stability prediction on sound mechanical principles we examine its ability to localise mechanical points of failure. Our approach is similar to that of <ref type="bibr" target="#b18">[15]</ref> though owing to the annotations included in the ShapeStacks dataset we are able to conduct a quantitative analysis on 1,500 randomly sampled images from the test set by comparing the network's attention maps with the corresponding ground truth stability segmentation maps (cf. <ref type="figure" target="#fig_2">Figure 4)</ref>. Specifically, we compute the attention maps by conducting an occlusion study whereby images are blurred using a Gaussian filter with a standard deviation of 30 pixels applied in a sliding window manner with stride 8 and a patch size of 14 x 14 pixels. To avoid creating object-like occlusion artefacts, the blurred patch does not have rigid boundaries but gradually fades into the image (cf. <ref type="figure" target="#fig_2">Figure 4A</ref> and D). The patched images are given as an input to the stability classifier and the predicted stability scores are aggregated in a map (cf. <ref type="figure" target="#fig_2">Figure 4</ref> B and E).</p><p>We then check whether the maximiser of the attention map is contained within the object responsible for stability violation (cf. <ref type="figure" target="#fig_2">Figure 4</ref> C and F) and report results in Section 4.2. In 79.9% of all unstable cases, the network focuses on the violation region, which we define as the smallest rectangle enclosing the violating object and the first object to fall.</p><p>For VPSF instabilities, the network attends to the violating, curved object with a likelihood of 52.1%. For VCOM instabilities, the network's main focus still remains on the violating object but is also spread out to the unsupported upper part of the tower (First Object to Fall + Tower Top) in 38.1% of the cases, which is in line with the physics governing VCOM instabilities (cf. eq. <ref type="formula">(1)</ref>). The fraction of times the network attends image areas with specific physical meaning (cf. <ref type="figure" target="#fig_2">Figure 4)</ref>. 1,500 images were analysed with an Inception v4 network trained on the CCS data (cf. Section 4.1). The first row is aggregated over all instability types and the second and third rows offer a breakdown for the CoM (VCOM) and planar surface violations (VPSF), respectively. The fourth row lists the fractions of the areas occupied with the respective label across the segmentation maps of all unstable scenarios and serves as a reference point of how likely it is to focus on a specific area just by random chance. Likewise, the fifth row reports random chance attention within the tower.   <ref type="figure">, D)</ref> , the increase (red) / decrease (blue) in the predicted stability is shown as a heatmap in (B, E), and the latter is compared to ground-truth segmentation maps in (C, F). The centres of attention are compared to the respective segmentation maps (C) and (F) and indeed correlate with the respective violation sites as indicated by the cross hairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Stacking and Stackability</head><p>So far, we have focussed on predicting the stability of stacks. However, it is not clear whether the models we learned understand the geometric affordances needed for actively building new stacks. Here, we answer this question by considering three active stacking tasks. The first one is to estimate the stackability of different objects and prioritise them while stacking (Section 5.1). The second is to accurately estimate the optimal placement of blocks on a stack through visual feedback (Section 5.2). The third is to counter-balance an unstable structure by placing an additional object on top (Section 5.3). All tasks show encouraging performance indicating that models do indeed acquire actionable physical knowledge from passive stability prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Stackability</head><p>Different object shapes intrinsically have different stacking potential: While a cuboid can serve as a solid base in every orientation, a cylinder can only support objects when placed upright and a sphere is never a good choice as a supporting object. If an agent is given a set of blocks to stack, it can use an understanding of such affordances to prioritise objects, placing the most stable ones at the bottom of the stack. We define stackability of an object (i.e. its utility with regard to stack construction) by answering the question: "How well can this object support the others in my set?" Next, we show how to answer this question quantitatively using our learned stability predictor. Given a set of objects, we compute their relative stackability scores as follows: Each object is placed on the ground as if it were the base of the stack using one of its discrete orientations <ref type="bibr" target="#b4">5</ref> . Then, all other objects are systematically placed on top of the base object, one at a time, in all of their respective orientations. An image of the resulting combination is generated and assessed for stability using our predictor. Positions for the top objects are sampled within a defined radius around the base object via simulated annealing and the maximum stability score is recorded. The stackability score of the base object is then estimated as the D C B A <ref type="figure">Fig. 6</ref>: Correlation of the stackability score with the projected surface area for different object classes. The projected surface area is calculated by projecting the object onto the x-y-plane. Spheres and lying cylinders are given very low stackability scores. Upright cylinders and cuboids are generally more stackable as the projected surface area grows.</p><p>average maximum stability achieved by all the other objects as they are placed on top of it. We also add random perturbations to the base position, with the idea of reflecting stackability robustness in the estimated score.</p><p>Stackability can then be used to rank objects' shapes and orientations based on how well they can be expected to support other objects, as illustrated in <ref type="figure" target="#fig_3">Figure 5</ref>. We also examine the model's understanding of stackability quantitatively in <ref type="figure">Figure 6</ref> computing scores over all object classes with varying volumes and aspect ratios. We generally find that the model ranks shapes in a sensible manner, preferring to stack on the largest face of cuboids, then on upright cylinders, and reject spheres as generally unsuitable for stacking. The results suggest that the suitability of different geometries to stacking is implicitly learned by stability prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Stacking Shapes in Simulation</head><p>Next, we investigate the ability of the stability predictor to not only order objects in an active stacking scenario, but also to accurately position them in stable configurations. To do so, we design three stacking scenarios involving different shape types: cubes, cuboids and CCS. In each scenario, the method is given a pool of 12 different object shapes and sizes to stack with the goal of building as tall a tower as possible. Every scenario is observed from six cameras (cf. <ref type="figure" target="#fig_5">Figure 8D</ref>) which move upwards as the stack grows to guarantee full coverage of the process at any time. At the beginning of every stacking episode, background textures, object colors and scene lights are randomised. Then the stack order and best orientation for each objects are computed according to the stackability score (cf. Section 5.1).</p><p>The stacking process commences with the first object being placed at the scene centre. The object at place r in the stacking queue is always spawned at a fixed height h r above the current tower trunk and candidate positions are sampled in the x-y-plane at z = h r according to the simulated annealing process described in Section 5.1. If no stable position is identified for a particular object (i.e. logistic regression score &lt; 0.5), it is put aside and disregarded for the rest of the process. The process is iterated until the placement of an object results in the collapse of the stack or no more objects are available.</p><p>In <ref type="figure" target="#fig_4">Figure 7</ref>, we report achieved stack heights for two differently trained models in the three scenarios with cubes, cuboids and CCS, respectively. For each stacking episode, the algorithm is given a pool of 12 randomised objects. However, CCS scenarios always include exactly two spheres, so the maximum achievable height in this case is 11. We compare two stability predictors: One trained on cubes only (blue bars) and one trained on CSS objects (orange bars). The CCS stability predictor clearly outperforms the one trained on cubes only in all three scenarios. In fact, the cubes predictor only manages perform decently on cube stacking and largely fails when confronted with varied shapes highlighting the importance of training on a diverse shape set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Balancing Unstable Structures</head><p>In the final task, we present our model with an unstable stack, freeze it such that it does not collapse, and then ask the algorithm to place an additional object on top to counter-balance the instability. This is a subtle task that requires the model to understand the concept of counterbalancing and cannot be solved by simply centering a block on top of the one below. <ref type="figure">Figure 9</ref> shows that our algorithm successfully solves this task with high probability in an "unstable T scenario" for different types of counterweight objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We investigate the acquisition of physical intuition and geometric affordances in the context of vision-based, generalised object stacking. To that end, we construct the ShapeStacks dataset featuring diverse stacks of shapes with detailed annotations of mechanical stability violations and release it publicly. We train a visual stability predictor on ShapeStacks which performs commensurately with state-of-the-art on simulated and real world images. Our model also correctly localises structural instabilities, yields an intuitive notion about the stackability of objects and successfully guides a simulated stacking process solely based on  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 1: We present a visual classifier which is trained on stacks of diverse shapes to distinguish between stable and unstable structures. We demonstrate that the implicit knowledge captured by the predictor can be utilised to detect structural instabilities, infer the stackability (utility with regard to stacking) of objects and guide a simulated stacking process solely from visual cues.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Different scenarios from the ShapeStacks data set. (A) -(D) depict initial stack setups: (A) stable, rectified tower of cubes, (B) stable tower where multiple objects counterbalance each other; some recorded images are cropped purposefully to include the difficulty of partial observability, (C) stable, but visually challenging scenario due to colours and textures, (D) violation of planar-surfaceprinciple (VPSF). (E) -(H) show the simulation of an unstable, collapsing tower due to a centre of mass violation (VCOM).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Attention visualisation obtained via an occlusion study. A Gaussian blur is applied in a sliding window manner to the image (A, D) , the increase (red) / decrease (blue) in the predicted stability is shown as a heatmap in (B, E), and the latter is compared to ground-truth segmentation maps in (C, F). The centres of attention are compared to the respective segmentation maps (C) and (F) and indeed correlate with the respective violation sites as indicated by the cross hairs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Top row : An unordered set of objects with random orientations. Bottom row : objects sorted from most stackable (left) to least stackable (right). Every object is oriented in the way which affords best stackability according to our network. The scores allow for division between different stability categories as visualised with white vertical lines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 :</head><label>7</label><figDesc>Fig. 7: Stacking performance. The height of the bars indicate how often the algorithm built a tower with the respective number of objects before it fell over. The mean tower height is indicated with a vertical dashed line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 :</head><label>8</label><figDesc>Fig. 8: Three examples of stacking attempts. In (A) and (B), the algorithm successfully stacked up cubes and cuboids to the maximum height of 12. In C, the algorithm placed the 10th object in a way that violates eq. (1). In (D), the images obtained from the different camera angles are shown for the failed stacking attempt in (C).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 :</head><label>1</label><figDesc>ShapeStacks contents. On the left, we present the number of scenarios and recorded images in both subsets of the dataset. CCS consists of cuboids, cylinders and spheres of varying size while Cubes only features regular blocks. On the right, we report the rendering and annotation details. See Section 3.2 for the derivation of the stability violation types VCOM and VPSF.</figDesc><table>CCS (# Scenarios) 
Cubes (# Scenarios) 

Stack height Train 
Val Test 
Train 
Val Test 

h = 2 
1,340 
286 
286 
1,680 
360 
360 
h = 3 
2,464 
528 
528 
1,680 
360 
360 
h = 4 
1,716 
368 
368 
1,558 
332 
332 
h = 5 
678 
144 
144 
1,274 
272 
272 
h = 6 
194 
40 
40 
1,030 
220 
220 

# Scenarios 
6,392 1,366 1,366 
7,222 1,544 1,544 
# Images 
102,272 21,856 21,856 
115,552 24,704 24,704 

Rendering &amp; Annotation 

Rendering 
224 × 224 RGB 
Randomised Scenes 
25 Background Textures 
6 Object Colours 
5 Lighting Conditions 
Annotation 
0/1 Stability 
VCOM &amp; VPSF 
Scene Semantics 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 :</head><label>2</label><figDesc>Stability prediction accuracy given as the percentage of correctly clas- sified images into stable or unstable. AlexNet and Inception v4 (INCPv4) are trained from scratch on simulated data consisting of stacks featuring either cubes or CCS. INCPv4-IMGN is pre-trained on ImageNet [4]. All algorithms are tested on both real images from [15] and simulated images from our ShapeStacks test split featuring all shapes.</figDesc><table>AlexNet 
INCPv4-IMGN 
INCPv4 
Physnet VDA 

Cubes CCS 
Cubes 
CCS 
Cubes 
CCS 
[15] 
[23] 

Simulated 
60.5% 58.8% 
76.2% 84.9% 
77.7% 84.9% 
N/A 
4 N/A 

4 

Real [15] 
65.5% 52.5% 
73.2% 64.9% 
74.7% 66.3% 
66.7% 75% 

Simulated 
Examples 

Real 
Examples 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>Fig. 9: Counterbalancing unstable structures. A: frozen, unstable stack; B: col- lapsing tower; C: successful placement of a counterweight that prevents col- lapse. Right: success rates for different counterweight types aggregated over 50 episodes. visual cues. Our results suggest that an intuitive understanding about physical principles and geometric affordances can be acquired from visual observation and effectively utilised in manipulation tasks. Acknowledgement. This research was funded by the European Research Coun- cil under grant ERC 677195-IDIU and the EPSRC AIMS Centre for Doctoral Training at Oxford University.</figDesc><table>Object 
Success Rate 

Cube 
76% 
Cuboid 
94% 
Cylinder 
72% 
Sphere 
98% 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Source code &amp; data are available at http://shapestacks.robots.ox.ac.uk</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We only report and release scenarios where the simulation outcome aligns with the physical derivation. Scenarios which behave differently due to imprecisions of the simulator are discarded.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We only use still images of initial stack configurations and no images depicting collapses from later time points in the simulations.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">No comparison possible because neither training data nor model are publicly available.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Cuboids afford three discrete orientations, one for each of its three distinct faces (considering symmetry). Cylinders afford two orientations (upright and sideways) and spheres afford only one orientation due to their radial symmetry.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Simulation as an engine of physical scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<idno type="doi">10.1073/pnas.1306572110</idno>
		<ptr target="http://www.pnas.org/cgi/doi/10.1073/pnas.1306572110" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">45</biblScope>
			<biblScope unit="page" from="18327" to="18332" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Interaction networks for learning about objects, relations and physics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4502" to="4510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A Compositional Object-Based Approach to Learning Physical Dynamics pp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1612.00341" />
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Learning Visual Predictive Models of Physics for Playing Billiards pp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fragkiadaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1511.07404" />
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Autonomous robotic stone stacking with online next best object target pose planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Furrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wermelinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gramazio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Siegwart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="doi">10.1109/ICRA.2017.7989272</idno>
		<ptr target="https://doi.org/10.1109/ICRA.2017.7989272" />
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2350" to="2356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Blocks world revisited: Image understanding using qualitative geometry and mechanics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision(ECCV)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Inferring mass in complex scenes by mental simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">157</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<idno type="doi">10.1016/j.cognition.2016.08.012</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2016.08.012" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Coursera, neural networks for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<ptr target="http://www.cs.toronto.edu/tij-men/csc321/slides/lectureslideslec6.pdf" />
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">3D reasoning from blocks to stability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<idno type="doi">10.1109/TPAMI.2014.2359435</idno>
		<ptr target="https://doi.org/10.1109/TPAMI.2014.2359435" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="905" to="918" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual object-action recognition: Inferring object affordances from human demonstration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kjellström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kragić</surname></persName>
		</author>
		<idno type="doi">10.1016/j.cviu.2010.08.002</idno>
		<ptr target="https://doi.org/10.1016/j.cviu.2010.08.002" />
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="90" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Anticipating Human Activities Using Object Affordances for Reactive Robotic Response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Koppula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="29" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<idno type="doi">10.1109/TPAMI.2015.2430335</idno>
		<ptr target="https://doi.org/10.1109/TPAMI.2015.2430335" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ImageNet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances In Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<idno type="doi">10.1016/j.protcy.2014.09.007</idno>
		<ptr target="https://doi.org/http://dx.doi.org/10.1016/j.protcy.2014.09.007" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Intuitive Physics: Current Research and Controversies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Kubricht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Holyoak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="749" to="759" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<idno type="doi">10.1016/j.tics.2017.06.002</idno>
		<ptr target="http://dx.doi.org/10.1016/j.tics.2017.06.002" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning physical intuition of block towers by example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3045390.3045437" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="430" to="438" />
		</imprint>
	</monogr>
	<note>ICML&apos;16, JMLR.org</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">To fall or not to fall: A visual approach to physical stability prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Azimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.00066</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visual stability prediction for robotic manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<idno type="doi">10.1109/ICRA.2017.7989304</idno>
		<ptr target="https://doi.org/10.1109/ICRA.2017.7989304" />
	</analytic>
	<monogr>
		<title level="m">Proceedings -IEEE International Conference on Robotics and Automation</title>
		<meeting>-IEEE International Conference on Robotics and Automation</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2606" to="2613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bagherinezhad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rastegari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="doi">10.1109/CVPR.2016.383</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2016.383" />
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Toward autonomous disassembling of randomly piled objects with minimal perturbation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ornan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Degani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="4983" to="4989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<idno type="doi">10.1109/IROS.2013.6697076</idno>
		<ptr target="https://doi.org/10.1109/IROS.2013.6697076" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robot Jenga: Autonomous and strategic block extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Parker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stilman</surname></persName>
		</author>
		<idno type="doi">10.1109/IROS.2009.5354303</idno>
		<ptr target="https://doi.org/10.1109/IROS.2009.5354303" />
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="5248" to="5253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On the stability of walking systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Wieber</surname></persName>
		</author>
		<idno type="doi">10.1088/0264-9381/12/2/003</idno>
		<ptr target="https://doi.org/10.1088/0264-9381/12/2/003" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third IARP International Workshop on Humanoid and Human Friendly Robotics</title>
		<meeting>the Third IARP International Workshop on Humanoid and Human Friendly Robotics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to See Physics via Visual De-animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (Nips</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Galileo : Perceiving Physical Object Properties by Integrating a Physics Engine with Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Yildirim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Reinforcement and imitation learning for diverse visuomotor skills</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Merel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tunyasuvunakool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kramár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<idno>CoRR abs/1802.09564</idno>
		<ptr target="http://arxiv.org/abs/1802.09564" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
