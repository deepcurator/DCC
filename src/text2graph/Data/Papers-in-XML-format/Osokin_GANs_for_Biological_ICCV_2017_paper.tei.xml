<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T23:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GANs for Biological Image Synthesis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Osokin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bristol</orgName>
								<address>
									<country>UK, France Amazon, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inria</forename><forename type="middle">/</forename><surname>Ens</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bristol</orgName>
								<address>
									<country>UK, France Amazon, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">France</forename><surname>Hse</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bristol</orgName>
								<address>
									<country>UK, France Amazon, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russia</forename><forename type="middle">Anatole</forename><surname>ChesseÄº</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bristol</orgName>
								<address>
									<country>UK, France Amazon, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ecole</forename><surname>Polytechnique</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bristol</orgName>
								<address>
									<country>UK, France Amazon, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">France</forename><surname>Rafael</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bristol</orgName>
								<address>
									<country>UK, France Amazon, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">Carazo</forename><surname>Salas</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bristol</orgName>
								<address>
									<country>UK, France Amazon, USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>ENS</roleName><forename type="first">Federico</forename><surname>Vaggi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bristol</orgName>
								<address>
									<country>UK, France Amazon, USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">GANs for Biological Image Synthesis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>In this paper, we propose a novel application of Generative Adversarial Networks (GAN)   </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the life sciences, the last 20 years saw the rise of light fluorescence microscopy as a powerful way to probe biological events in living cells and organisms with unprecedented resolution. The need to analyze quantitatively this deluge of data has given rise to the field of bioimage informatics <ref type="bibr" target="#b28">[29]</ref> and is the source of numerous interesting and novel data analysis problems, which current machine learning developments could, in principle, help solve.</p><p>Generative models of natural images are among the most long-standing and challenging goals in computer vision. Recently, the community has made significant progress in this task by adopting neural network machinery. Examples of recent models include denoising autoencoders <ref type="bibr" target="#b1">[2]</ref>, variational autoencoders <ref type="bibr" target="#b19">[20]</ref>, PixelCNNs <ref type="bibr" target="#b43">[44]</ref> and Generative Adversarial Networks (GANs) <ref type="bibr" target="#b13">[14]</ref>. Proteins Real images Generated images <ref type="figure">Figure 1</ref>. Real (left) and generated (right) images of fission yeast cells with protein Bgs4 depicted in the red channel and 6 other proteins depicted in the green channel. The synthetic images were generated with our star-shaped GAN. The star-shaped model can generate multiple green channels aligned with the same red channel whereas the training images have only one green channel.</p><p>GANs <ref type="bibr" target="#b13">[14]</ref> are family of successful models, which have recently received widespread attention. Unlike most other generative models, GANs do not rely on training objectives connected to the log likelihood. Instead, GAN training can be seen as a minimax game between two models: the generator aims to output images similar to the training set given random noise; while the discriminator aims to distinguish the output of the generator from the training set.</p><p>Originally, GANs were applied to the MNIST dataset of handwritten digits <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b13">14]</ref>. The consequent DCGAN model <ref type="bibr" target="#b37">[38]</ref> was applied to the CelebA dataset <ref type="bibr" target="#b23">[24]</ref> of human faces, the LSUN <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b37">38]</ref> and ImageNet <ref type="bibr" target="#b6">[7]</ref> datasets of natural images. We are not aware of any works applying GANs to biological images.</p><p>We work with a recently created bioimage dataset used to extract functional relationships between proteins, called the LIN dataset <ref type="bibr" target="#b8">[9]</ref> comprising 170,000 fluorescence microscopy images of cells. In the LIN dataset, each image corresponds to a cell and is composed of signals from two independent fluorescence imaging channels ("red" and "green"), corresponding to the two different proteins tagged with red or green-emitting fluorophores, respectively.</p><p>In the LIN dataset, the red channel signal always corresponds to a protein named Bgs4, which localizes to the areas of active growth of cells. The green channel signal instead corresponds to any of 41 different "polarity factors", that is proteins that mark specific areas of the cells' cortex that help define a cell's geometry. Polarity factors include proteins like Alp14, Arp3, Cki2, Mkh1, Sid2 or Tea1 (see <ref type="figure">Figure 1</ref> for image examples), each of which controls the same biological process "cellular polarity" albeit each in a slightly different way. Each of the green-labeled polarity factors was imaged independently of the others. The biological aim of the LIN study is to investigate how those polarity factors (or proteins) interact with one another.</p><p>In this paper, we present a novel application of GANs to generate biological images. Specifically, we want to tackle two concrete limitations of large scale fluorescent imaging screens: we want to use the common information contained in the red channel to learn how to generate a cell with several of the green-labeled proteins together. This would allow us to artificially predict how the localizations of those (independently imaged) proteins might co-exist in cells if they had been imaged together and circumvent the current technical limitations of being able to only image a limited number of signal channels at the same time. Second, taking advantage of the relationship between Bgs4 and the cell cycle stage, we want to study the dynamical changes in cellular localization that proteins undergo through time as cells grow and divide.</p><p>To accomplish this, we make several contributions. We modify the standard DCGAN <ref type="bibr" target="#b37">[38]</ref> architecture by substituting the interdependence of the channels with the causal dependence of the green on the red, allowing us to observe multiple modes of green signal for a single red setting. Observing the mode collapse effect of GANs <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b41">42]</ref> for our separable architecture, we incorporate the recent Wasserstein GAN (WGAN-GP) objective <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15]</ref>. We propose two approaches to generate multi-channel images: regular WGAN-GP trained on multi-channel images, where extra channels for training are mined by nearest neighbor search in the training set, and a novel star-shaped generator trained directly one the two-channel images. We carefully evaluate our models using two quantitative techniques: the neural network two-sample test (combining ideas from <ref type="bibr" target="#b25">[26]</ref> and <ref type="bibr" target="#b14">[15]</ref>) and by reconstructing samples in a held out test set with the optimization approach of <ref type="bibr" target="#b29">[30]</ref>. For reproducibility, we make the source code and data available online. <ref type="bibr" target="#b0">1</ref> This paper is organized as follows. In Section 2, we discuss related works. Section 3 reviews the relevant biological background for our application. In Section 4, we review GANs and present our modeling contributions. We present the experimental evaluation in Section 5 and conclude in Section 6.</p><p>1 https://github.com/aosokin/biogans</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Generative Adversarial networks (GANs). Since the seminal paper by Goodfellow et al. <ref type="bibr" target="#b13">[14]</ref> of 2014 (see also <ref type="bibr" target="#b12">[13]</ref> for a detailed review), GANs are becoming an increasingly popular model for learning to generate with the loss functions learned jointly with the model itself. Models with adversarial losses have been used in a wide range of applications, such as image generation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b37">38]</ref>, domain adaptation <ref type="bibr" target="#b11">[12]</ref>, text-to-image synthesis <ref type="bibr" target="#b38">[39]</ref>, synthesis of 3D shapes <ref type="bibr" target="#b48">[49]</ref> and texture <ref type="bibr" target="#b22">[23]</ref>, image-to-image translation <ref type="bibr" target="#b17">[18]</ref>, image super resolution <ref type="bibr" target="#b21">[22]</ref> and even generating radiation patterns in particle physics <ref type="bibr" target="#b5">[6]</ref>. However, these models suffer from issues such as mode collapse and oscillations during training, making them challenging to use in practice. The community is currently tackling these problems from multiple angles. Extensive effort has been placed on carefully optimizing the architecture of the network <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b39">40]</ref> and developing best practices to optimize the training procedure <ref type="bibr" target="#b1">2</ref> . Another active area of research is improving the training objective function <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b14">15]</ref>.</p><p>In this paper, we build on the DCGAN architecture <ref type="bibr" target="#b37">[38]</ref> combined with the Wasserstein loss <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15]</ref>, where the latter is used to help with the mode collapse issue, appearing especially in our separable setting.</p><p>Conditioning for GANs. Starting from conditioning on the class labels <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b10">11]</ref>, researchers have extended conditioning to user scribbles <ref type="bibr" target="#b53">[54]</ref> and images <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b54">55]</ref>. While the quality of images generated by <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b54">55]</ref> is high, their models suffer from conditional mode collapse, i.e., given the first (source) image there is very little or no variety in the second (target image). This effect might be related to the fact that the dataset contained only one target image available for each source image, so the model has only indirect supervision for generating multiple conditioned images. We have applied the pix2pix method of <ref type="bibr" target="#b17">[18]</ref> to the LIN dataset and it learned to produce high-quality green images given the red input. However, it was unable to generate multiple realistic green images for one red input.</p><p>Given the difficulty in learning robust latent spaces when conditioning on an image, we opted for an alternate approach. We propose a new architecture for the generator, where the red channel and green channels are given independent random noise, and only the red channel is allowed to influence the green channel, see <ref type="figure" target="#fig_1">Figure 2</ref> (right).</p><p>Factors of variation. Chen et al. <ref type="bibr" target="#b3">[4]</ref> and Mathieu et al. <ref type="bibr" target="#b27">[28]</ref> used unsupervised methods that encourage disentangling factors of variation in the learned latent spaces, e.g., separating the numerical value of a handwritten digit from its writing style. In contrast to these works, we do not rely on unsupervised training to discover factors of variations, but explicitly embed the separation into the model. Analysis and synthesis of biological images. With large scale imaging studies becoming more common in biology, the automated analysis of images is now crucial in many studies to prove the existence of an effect, process large datasets or link with models and simulation <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b4">5]</ref>. Although the field has only recently embraced deep learning, neural networks are now starting to make a splash, mainly in classical discriminative settings <ref type="bibr" target="#b44">[45]</ref>.</p><p>While, to our knowledge, this work is the first reported use of GANs on samples from fluorescent microscopy, generative models have been widely used in biology <ref type="bibr" target="#b31">[32]</ref>. For example, Johnson et al <ref type="bibr" target="#b18">[19]</ref> learned to generate punctuate patterns in cells (conditional on microtubule localization) showing the potential of those methods in studying the relative sub-cellular positions of several proteins of interest.</p><p>Recently, sharing of large biological datasets has greatly improved <ref type="bibr" target="#b24">[25]</ref>. Further, EBI has made a large investment to develop the IDR (Image Data Resource) <ref type="bibr" target="#b47">[48]</ref>, a database built on top of open source tools to facilitate the sharing of terabyte sized datasets with complex metadata.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Biological Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Fluorescent Imaging</head><p>Fluorescence microscopy is based on fluorescent compounds, i.e., compounds which can absorb light at given wavelength (the absorption spectrum) and re-emit it almost immediately at a slightly different wavelength (the emission spectrum). In the case of fluorescent proteins (FPs), of which the Green Fluorescent Protein (GFP) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b42">43]</ref> is the first and most widely used one, the fluorescing compound is attached to the protein of interest via genetic engineering. Many FPs of various absorption and emission spectra exist, e.g., Red Fluorescent Protein (RFP) <ref type="bibr" target="#b40">[41]</ref>. By genetically tagging different proteins of interest with FPs of different color, one can image them in the same cell at the same time and thus investigate their co-localization. However, the number of proteins that can be tagged and imaged at the same time is limited to 3-4 due to the limited number of FPs with non-overlapping absorption spectra.</p><p>Multi-channel fluorescent images are very different from natural images. In natural images, color is determined by the illumination and the properties of a particular material in the scene. In order to generate realistic natural samples, a GAN must capture the relationship between the materials that make up a particular object and its hues. In contrast, in fluorescent images, the intensity of light in a given channel corresponds to the local concentration of the tagged protein, and the correlation between signals in different channels represents important information about the relationship between proteins, but the color does not reflect any intrinsic property about the protein itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Fission Yeast Cells</head><p>Fission yeast (Schizosaccharomyces pombe) cells are rod shaped unicellular eukaryotes with spherical hemisphere caps. They are born 7 Âµm long and 4 Âµm wide, and grow in length to 14 Âµm while maintaining their width constant. Newly born fission yeast cells start by growing only at the pre-existing end until they reach a critical size, and then switch to bipolar (from the two sides) growth. Bipolar growth continues until cells reach their final length, when they stop growing and start to form a cytokinetic ring in the middle, which is responsible for cleaving the mother cells into two daughters <ref type="bibr" target="#b35">[36]</ref>. Interestingly, for most of the cell cycle the length of the cell is a good proxy for its "age", i.e. the time it has spent growing since its "birth".</p><p>Bgs4, the protein tagged in the red channel, is responsible for cell wall remodeling, and localizes to areas of active growth (see <ref type="figure">Figure 1</ref> for examples of images). Thus, by observing Bgs4, one can accurately infer growth cycle stage, and predict where cell growth is occurring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">The LIN Dataset</head><p>All experiments in this paper make use of a recent dataset of images of fission yeast cells, which was originally produced to study polarity networks <ref type="bibr" target="#b8">[9]</ref>. The LIN dataset consists of around 170,000 of images, with each image being centered on one cell; cell segmentation was performed separately (see <ref type="bibr" target="#b8">[9]</ref> for details) and the corresponding outline is also available. Each image is a 3D stack of 2D images where each pixel correspond to a physical size of 100nm; each z-plane is distant by 300nm. Every image is composed of two channels, informally called the "red" and the "green", where light emitted at a precise wavelength is recorded. In this dataset two types of fluorescent-tagged proteins are used: Bgs4 in the red channel, and one of 41 different polarity regulating proteins in the green channel. A full description of all tagged proteins is beyond the scope of this paper: we refer interested readers to <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b8">9]</ref>.</p><p>In this paper, we concentrate on a subset of 6 different polarity factors, spanning a large set of different cellular localizations. This gives us 26,909 images of cell, which we, for simplicity, center crop and resize to resolution of 48Ã80.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">GANs for Image Generation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Preliminaries</head><p>GAN. The framework of generative adversarial networks <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b12">13]</ref> is formulated as a minimax two-player game between two neural networks: generator and discriminator. The generator constructs images given random noise whereas the discriminator tries to classify if its input image is real (from the training set) or fake (from the generator). The goal of the generator is to trick the discriminator, such that it cannot easily classify. The discriminator is often referred to as the adversarial loss for training the generator.</p><p>More formally, consider a data-generating distribution I P d and a training set of images x â X coming from it. The generator G(z; Î¸ G ) is a neural network parameterized by Î¸ G that takes random noise z from distribution I P z as input and produces an image x fake â X . The discriminator D(x; Î¸ D ) is a neural network parameterized by Î¸ D that takes either a training image x or a generated image x fake and outputs a number in the segment [0, 1], where zero is associated with fake images and one -with the real images. As introduced in <ref type="bibr" target="#b13">[14]</ref>, the key quantity is the negative crossentropy loss on the discriminator output:</p><formula xml:id="formula_0">L(Î¸ D , Î¸ G ) = I E xâ¼I Pdata log D(x; Î¸ D ) + I E zâ¼I Pz log(1 â D(G(z; Î¸ G ); Î¸ D )). (1)</formula><p>The discriminator maximizes <ref type="formula">(1)</ref> w.r.t. Î¸ D and the generator, at the same time, minimizes (1) w.r.t. Î¸ G . In practice, both optimization tasks are attacked simultaneously by alternating between the steps of the two optimizers.</p><p>As noted by <ref type="bibr" target="#b13">[14]</ref>, the objective log(1 â D(G(z; Î¸ G ); Î¸ D )) often leads to saturated gradients at the initial stages of the training process when the generator is ineffective, i.e., its samples are easy to discriminate from the real data. One practical trick to avoid saturated gradients is to train the generator with</p><formula xml:id="formula_1">maximizing log D(G(z; Î¸ G ); Î¸ D ) instead.</formula><p>Goodfellow et al. <ref type="bibr" target="#b13">[14]</ref> showed that the minimax formulation (1) can be reformulated via minimization of the JensenShannon (JS) divergence 3 between the data-generating distribution I P d and the distribution I P G induced by I P z and G.</p><p>For the architectures of both the generator and the discriminator, we largely reuse a successful version of Radford et al. <ref type="bibr" target="#b37">[38]</ref> called DCGAN. The generator of DCGAN (see <ref type="figure" target="#fig_1">Figure 2</ref>, left) is based on up-convolutions <ref type="bibr" target="#b9">[10]</ref> interleaved with ReLu non-linearity and batch-normalization <ref type="bibr" target="#b15">[16]</ref>. We refer to <ref type="bibr" target="#b37">[38]</ref> for additional details.</p><p>Wasserstein GAN. Recently, Arjovsky et al. <ref type="bibr" target="#b0">[1]</ref> have demonstrated that in some cases the JS divergence behaves badly and cannot provide any useful direction for training, e.g., when it is discontinuous. To overcome these degeneracies, they consider the earth mover's distance (equivalent to the 1-st Wasserstein distance) between the distributions</p><formula xml:id="formula_2">W (I P d , I P G ) = inf I PâÎ (I P d ,I P G ) I E (x,x â² )â¼I P x â y ,<label>(2)</label></formula><p>where set Î (I P d , I P G ) is a set of all joint distributions I P on x and x â² whose marginals are I P d and I P G , respectively. Intuitively, the distance (2) indicates the cost of the optimal movement of the probability mass from I P d to I P G . According to <ref type="bibr" target="#b0">[1]</ref> by using duality, one can rewrite (2) as W (I P d , I P G ) = sup</p><formula xml:id="formula_3">DâC 1 I E xâ¼I P d D(x)âI E x â² â¼I P G D(x â² ) ,<label>(3)</label></formula><p>where C 1 is the set of all 1-Lipschitz functions D : X â R. Optimizing w.r.t. the set C 1 is complicated. As a practical approximation to the set of all 1-Lipschitz functions, Arjovsky et al. <ref type="bibr" target="#b0">[1]</ref> suggest to use neural networks D(x; Î¸ D ) with all parameters Î¸ D clipped to a fixed segment. Very recently, Gulrajani et al. <ref type="bibr" target="#b14">[15]</ref> proposed a surrogate objective to (3), which is based on the L 2 -distance between the norm of the discriminator gradient at specific points and one. In all, we arrive at the minimax game</p><formula xml:id="formula_4">W (Î¸ D , Î¸ G ) = I E zâ¼I Pz D(G(z; Î¸ G ); Î¸ D ) â I E xâ¼I Pdata D(x; Î¸ D ) + R(Î¸ D ),<label>(4)</label></formula><p>where R is the regularizer (see <ref type="bibr" target="#b14">[15]</ref> for details). The objective (4) is very similar to the original game of GANs (1), but has better convergence properties. In what follows, we refer to the method of <ref type="bibr" target="#b14">[15]</ref> as WGAN-GP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Model Extensions</head><p>In this section, we present our modeling contributions. First, we describe our approach to separate the red and green channels of the generator. Second, we discuss a way to train a multi-channel generator using the two-channel data in the LIN dataset. Finally, we propose a new star-shaped architecture that uses the red-green channel separation to obtain multiple channels in the output.</p><p>Channel separation. The key idea of the channel separation consists in separating the filters of all the upconvolutional layers and the corresponding features into two halves. The first set of filters is responsible for generating the red channel, while the second half generates the green channel. To make sure the green channel matches the red one, we use one way connections from the red convolutional filters towards the green ones. <ref type="figure" target="#fig_1">Figure 2</ref> (right) depicts our modification in comparison to DCGAN (left).</p><p>Multi-channel models. The LIN dataset <ref type="bibr" target="#b8">[9]</ref> contains only two-channel images, the red and one type of the green at a time. Obtaining up to 4 channels simultaneously from a set of 40 proteins (a fixed red and 3 greens) would require the creation of nearly 60,000 yeast strains. Scaling even higher is currently impossible with this imaging technique due to the limited number of FPs with non-overlapping absorption spectra. Because of these constraints, training the generator only on a subset of channels is a task of practical importance. The first approach we present consists in training a multi-channel GAN using an artificial training set of multi-channel images created from the real two-channel images. We proceed as follows: for each two-channel image, we search in every other class for its nearest-neighbors (using L 2 -distance) in the red channel. Then, we create a new sample by combining the original image with the green channels of its nearest neighbors in other classes.</p><p>We can then use this dataset to train a multi-output DC-GAN. The only difference in the architecture is that the generator outputs c+1 channels, where c is the number of green channels used in the experiment, and the discriminator takes (c + 1)-channel images as input.</p><p>Star-shaped model. In our experiments, the multichannel approach did not perform well, because, even using the nearest neighbors, the extra greens channels were not exactly consistent with the original red signal, emphasizing the importance of correlations between channels.</p><p>To overcome this effect, we propose a star-shaped architecture for the generator, consisting of a single red tower (a stack of upconvolutional layers with non-linearities inbetween) that feeds into c green towers (see <ref type="figure" target="#fig_1">Figure 2, right)</ref>. Unlike the multi-channel model described above, the green outputs are independent conditioned on the red. Thus, the model can be trained using the existing two-channel images.</p><p>In our experiments, we found it important to use batch normalization <ref type="bibr" target="#b16">[17]</ref> in the red tower only once, compared to a more naive way of c times. The latter leads to interference between several normalizations of the same features and prevents convergence of the training scheme.</p><p>After the forward pass, we use c discriminators attached to different versions of the greens, all paired with the same generated red. For the WGAN-GP version of this model, we apply the original procedure of <ref type="bibr" target="#b14">[15]</ref> with the modification that during the discriminator update we simultaneously update all c discriminators, and the generator receives back the accumulated gradient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>Evaluating generative models is in general non-trivial. In the context of GANs and other likelihood-free approaches, evaluation is even harder, because the models do not provide a way to compute the log-likelihood on the test set, which is the most common evaluation technique. Recently, a number of techniques applicable to evaluating GANs have been proposed <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b49">50]</ref>. Among those, we chose the following two: the neural-network two-sampled test discussed by <ref type="bibr" target="#b25">[26]</ref> combined with the surrogates of the earth mover's distance <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15]</ref> and an optimization-based approach of <ref type="bibr" target="#b29">[30]</ref> to check if the test samples can be well reconstructed. We modify these techniques to match our needs and check their performance using sensible baselines (Sections 5.1 and 5.2). Finally, in Section 5.3, we show the cell growth cycle generated with our star-shaped model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Neural-network Two-sample Test</head><p>Lopez-Paz and Oquab <ref type="bibr" target="#b25">[26]</ref> have recently applied the classifier two-sample test (C2ST) to evaluate the quality of GAN models. A trained generator is evaluated on a heldout test set. This test test is split again into a test-train and test-test subsets. The test-train set is then used to train a fresh discriminator, which tries to distinguish fake images (from the generator) from the real images. Afterwards, the final measure of the quality of the generator is computed as the performance of the new discriminator on the test-test set and the freshly generated images.</p><p>When C2ST is applied for images, the discriminator is usually a ConvNet, but even very small ConvNets can discriminate between fake and real images almost perfectly. To obtain a useful measure, Lopez-Paz and Oquab <ref type="bibr" target="#b25">[26]</ref> deliberately weaken the ConvNet by fixing some of its parameters to the values obtained by pre-training on ImageNet.</p><p>ImageNet-based features are clearly not suitable for LIN cell images, so we weaken the discriminator in another way. We use the negation of the WGAN-GP <ref type="bibr" target="#b14">[15]</ref> discriminator objective as a surrogate to the earth mover's distance. Similar to <ref type="bibr" target="#b25">[26]</ref>, we train this discriminator on the test-train subset and compute the final estimates on the test-test subset. For all the runs, we repeat the experiment on 10 different random splits of the test set and train the discriminator for 5000 steps with the optimizer used by <ref type="bibr" target="#b14">[15]</ref>. For the experiments involving multi-channel generators, we train a separate discriminator for each green channel paired with the red channel.</p><p>In our experiments, the training procedure occasionally failed and produced large outliers. To be more robust, we always report a median over 10 random splits together with the median absolute deviation to represent the variance. In the Suppl. Mat. <ref type="bibr" target="#b34">[35]</ref>, we additionally quantitatively and qualitatively compare the WGAN-GP <ref type="bibr" target="#b14">[15]</ref>, WGAN <ref type="bibr" target="#b0">[1]</ref> and cross-entropy discriminators used in C2ST. Sanity checks of the two-sample test. We evaluate C2ST in two baseline settings. First, we compare the separable GAN <ref type="bibr" target="#b37">[38]</ref> and the WGAN-GP <ref type="bibr" target="#b14">[15]</ref> models (based on the same DCGAN architecture, trained on the same set of images of 6 proteins) at different stages of the training process. For each of these models, we also show qualitative difference between the generated images. <ref type="figure" target="#fig_2">Figure 3</ref> shows that along the training process, quality of both GAN and WGAN-GP improves, i.e., generated images become sharper and contain less artifacts, consistent with the C2ST score. To better visualize the difference between the trained GAN and WGAN-GP models, in <ref type="figure">Figure 4</ref>, we show multiple samples of the green channel corresponding to the same red channel. We see that the C2ST evaluation captures several aspects of the visual quality (such as sharpness, correct shape, absence of artifacts, diversity of samples) and provides a meaningful score. From <ref type="figure" target="#fig_2">Figures 3 and 4</ref>, we also conclude that the quality of GAN samples is worse than the quality of WGAN-GP according to visual inspection. C2ST (based on WGAN-GP) confirms this observation, which is not surprising given that WGAN-GP was trained using the same methodology. Surprisingly, when evaluated with the cross-entropy C2ST, WGAN-GP also performs better than GAN (see Suppl. Mat. <ref type="bibr" target="#b34">[35]</ref> for details).</p><p>As the second baseline evaluation, we use C2ST to compare real images of different classes. <ref type="table" target="#tab_0">Table 1</ref> shows that when evaluated w.r.t. the test set of the same class the estiSamples from separable models separable GAN separable WGAN-GP <ref type="figure">Figure 4</ref>. Samples generated by separable GAN (top) and WGAN-GP (bottom) models trained on the 6 selected proteins shown in <ref type="figure">Figure 1</ref>. Each row has samples with identical red channel, but different green ones. We observe that WGAN-GP provides much larger variability of the green channel conditioned on the red. In particular, in the three bottom rows, even the type of the protein changes, which we have never observed for the samples of GAN (this effect should be present, because the model is trained without any distinction between the classes, but is surprisingly rare). This difference is captured by the C2ST evaluation: the GAN model has the score of 3.2 Â± 0.1 compared to 1.6 Â± 0.1 of WGAN-GP.</p><p>mates are significantly smaller (but with non-zero variance) compared to when evaluated w.r.t. different classes. Note that the C2ST score is not a metric. In particular, <ref type="table" target="#tab_0">Table 1</ref> is not symmetric reflecting biases between the train/test splits. Specifically to WGAN-GP, the score can also be negative, because the quadratic regularization term is the dominant part of the objective (4) when the two image sources are very similar.</p><p>As an additional test, we include two extra proteins Fim1 and Tea4 that are known to have similar localization to Arp3 and Tea1, respectively. We observe that C2ST reflects this similarity by giving the pairs of similar proteins a much smaller score compared to most of other pairs (but still significantly higher than comparing a protein to itself).</p><p>Results. <ref type="table">Table 2</ref> shows the results of C2ST applied to several models with multiple output channels (see Section 4.2): the multi-channel model and its separable version, the starshaped model and the two baselines, which do not align 9.7 Â± 0.6 15.8 Â± 0.7 14.0 Â± 0.9 13.9 Â± 0.9 6.2 Â± 0.4 5.9 Â± 0.3 19.5 Â± 0.7 -0.5 Â± 0.7  <ref type="table">Table 2</ref>. Results of C2ST with the WGAN-GP objective comparing several multi-channel models w.r.t. the real images. All the models were trained with WGAN-GP. The values in this table are directly comparable to the ones in <ref type="table" target="#tab_0">Table 1.</ref> green channels of different classes with the same red channel: one-class generators trained individually for each class and their separable versions. All the models were trained with WGAN-GP with the same ratio of the width of the generator tower to the number of output channels. We observe that the individual one-class WGAN-GP models lead to higher quality compared to all the models outputting synchronized channels for all the classes. Among the models that synchronize channels, the starshaped model performs best, but for some proteins there is a significant drop in quality w.r.t. the one-class models.</p><formula xml:id="formula_5">separable red/green - â â â â â class conditioned - â â â â â Alp14 0.1 Â± 0.2 0.6 Â± 0.3 1.2 Â± 0.2 3.2 Â± 0.4 2.3 Â± 0.5 0.6 Â± 0.3 Arp3 0.8 Â± 0.4 1.2 Â± 0.3 2.4 Â± 0.4 3.2 Â± 0.4 4.2 Â± 0.4 2.1 Â± 0.5 Cki2 -0.2 Â± 0.3 0.3 Â± 0.5 1.0 Â± 0.3 2.5 Â± 0.3 3.6 Â± 0.5 1.2 Â± 0.3 Mkh1 -0.2 Â± 0.4 0.8 Â± 0.6 0.5 Â± 0.4 4.6 Â± 0.5 6.6 Â± 0.5 2.4 Â± 0.6 Sid2 -0.6 Â± 0.3 0.8 Â± 0.4 1.0 Â± 0.5 4.5 Â± 0.5 3.2 Â± 0.6 1.1 Â± 0.6 Tea1 -0.1 Â± 0.4 0.8 Â± 0.5 0.8 Â± 0.5 4.4 Â± 0.3 2.8 Â± 0.5 1.1 Â± 0.4 6 proteins -0.1 Â± 0.2 0.8 Â± 0.2 1.1 Â± 0.2 3.7 Â± 0.1 3.8 Â± 0.2 1.4 Â± 0.1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Optimization to Reconstruct the Test Set</head><p>One of the common failures of GANs is the loss of modes from the distribution, usually referred to as mode collapse. There is evidence <ref type="bibr" target="#b36">[37]</ref> that image quality can be inversely correlated with mode coverage. To test for the mode collapse, we perform an experiment proposed in <ref type="bibr" target="#b29">[30]</ref>, where for a fixed trained generator G we examine how well it can reconstruct images from a held out test set. For each image in the test set, we minimize the L 2 -distance (normalized by the number of pixels) between the generated and test images w.r.t. the noise vector z. We call this task regular reconstruction. We use 50 iterations of L-BFGS and run it 5 times to select the best reconstruction. We also performed an additional task, separable reconstruction, which examines the ability of separable networks to reproduce modes of the green channel conditioned on the red. In this task, we use a two-step procedure: first, we minimize the L 2 -error between the red channels holding the green noise fixed, and then we minimize the L 2 -error in the green channel while keeping the red noise fixed at it's optimized value. To complete the study, we also report the negative log likelihood (NLL) w.r.t. the prior I P z of the noise vectors z obtained with a reconstruction procedure. As a baseline for the reconstruction error, we show the nearest neighbor cell (in both red and green channels) from the training set and the average L 2 -distance to the nearest neighbors. As a baseline for NLL, we show the averaged NLL for the random point generated from I P z .</p><p>We apply the reconstruction procedure to evaluate four models: separable one-class and star-shaped models trained with both GAN and WGAN-GP algorithms. <ref type="figure" target="#fig_4">Figure 5</ref> and <ref type="table">Table 3</ref> present qualitative and quantitative results, respectively. For all the measurements, we report the median values and the median absolute deviation. In <ref type="figure">Figure 6</ref>, we plot reconstruction errors vs. NLL values for the Mkh1, which was the hardest protein in the separable reconstruction task.</p><p>Analyzing the results, we observe that separable reconstruction is a harder task than the single step procedure. Second, WGAN-GP models can reconstruct better, probably because they suffer less from the mode collapse. And finally, the star-shaped models do not degrade the performance in terms of reconstruction, except for some hard proteins (see more details in the Suppl. Mat. <ref type="bibr" target="#b34">[35]</ref>).   <ref type="table">Table 3</ref>. Reconstruction experiment. For the four trained models (GAN/WGAN-GP and separable one-class/star-shaped), we report L2-errors of the reconstructions and the negative log likelihoods (NLL) of the latent vectors found by the reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Progression Through the Cell Cycle</head><p>As described in Section 3.2, the localization of Bgs4 can be used to accurately pinpoint the cell cycle stage. However, not nearly as much as is known about how the localization of the other proteins changes within the cell cycle <ref type="bibr" target="#b26">[27]</ref>.</p><p>Using our separable GAN architecture, we can interpolate between points in the latent space <ref type="bibr" target="#b46">[47]</ref> to move across the different stages of growth and division. Due to the architecture of our network, the output of the green channel will always remain consistent with the red output. We show an example of the reconstructed cell cycle in <ref type="figure">Figure 7</ref> and several animated examples in the Suppl. Mat. <ref type="bibr" target="#b34">[35]</ref>. As a validation of our approach, Arp3 is seen gradually moving a dot like pattern at the tips of the cell towards the middle of the cell during mitosis, as has been previously described in the literature <ref type="bibr" target="#b50">[51]</ref>.</p><p>It's important to highlight that the LIN dataset lacks true multi-channel (3+) images, and as such, we are unable to compare how our generated multi-channel images compare to real fluorescent images. We hope that as more datasets in biology become open, we will have a better baseline to compare our model too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>Although generative modeling has seen an explosion in popularity in the last couple of years, so far it has mostly been applied to the synthesis of real world images. Our results in this paper suggest that modern generative models can be fruitfully applied to images obtained by fluorescent microscopy. By leveraging correlation between different image channels, we were able to simulate the localization of multiple proteins throughout the cell cycle. This could enable in the future the exploration of uninvestigated, inaccessible or unaffordable biological/biomedical experiments, to catalyze new discoveries and potentially enable new diagnostic and prognostic bioimaging applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>* DIÃcole normale supÃ©rieure, CNRS, PSL Research University, Paris â  National Research University Higher School of Economics, Moscow â¡ LOB,Ãcole Polytechnique, CNRS, INSERM, UniversitÃ© Paris-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Architectures of the DCGAN generator (left) and our separable generator (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Scores of the classifier two-sample test (C2ST) between the generators and the hold-out test sets of images. We report the scores of separable GAN and WGAN-GP at different stages of training. For each line, we show the samples from the corresponding models to demonstrate that the lower C2ST scores correspond to better-looking (sharper, less artifacts, etc.) images. Best viewed in color and on a screen. An extended version of this figure is given in the Suppl. Mat. [35].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Examples of cell reconstructions. (a) -a test image; (b) -the L2 nearest neighbor; (c) -regular reconstruction by oneclass separable WGAN-GP; (d) -regular reconstruction by starshaped WGAN-GP; (e) -separable reconstruction by star-shaped WGAN-GP; (e) -separable reconstruction by star-shaped GAN. An extended version of this figure is given in the Suppl. Mat. [35].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .Figure 7 .</head><label>67</label><figDesc>Figure 6. Reconstruction errors against negative log likelihood (NLL) of the latent vectors found by reconstruction. We show all the cells corresponding to protein Mkh1, which appears to be the hardest for the star-shaped models. The vertical gray line shows the median L2-error of the nearest neighbor. Horizontal gray lines show mean NLL (Â± 3 std) of the noise sampled from the Gaussian prior. In the separable (red-first) setting, the star-shaped model trained with GAN provides very bad reconstructions, whereas the same model trained with WGAN-GP results in high NLL values. An extended version of this figure is given in the Suppl. Mat. [35]. Bgs4 Alp14 Arp3 Cki2 Mkh1 Sid2 Tea1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>Results of C2ST with WGAN-GP when comparing real images of different proteins. For each run, the training images of one 
class are evaluated w.r.t. the test images of another class. The reported values are comparable with Table 2, but not with Figure 3. 

real images 
one-class 
non-separable 

one-class 
separable 

multi-channel 
non-separable 

multi-channel 
separable 
star-shaped 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>WGAN-GP-star 0.058 Â± 0.010 143 Â± 7</figDesc><table>L 2 -error 
NLL 
Nearest neighbors 0.079 Â± 0.009 
-
Gaussian noise 
-
142 Â± 5 

regular 
GAN-sep 
0.053 Â± 0.007 
166 Â± 17 
WGAN-GP-sep 
0.043 Â± 0.006 
149 Â± 8 
GAN-star 
0.061 Â± 0.008 
139 Â± 12 
WGAN-GP-star 
0.041 Â± 0.005 150 Â± 8 

separable 
GAN-sep 
0.069 Â± 0.011 
158 Â± 13 
WGAN-GP-sep 
0.062 Â± 0.009 
143 Â± 6 
GAN-star 
0.074 Â± 0.011 
142 Â± 7 
</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/soumith/ganhacks</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The Jensen-Shannon divergence is a symmetrized version of the Kullback-Leibler divergence between the two distributions, i.e., JS(I P d , I P G ) = KL(I P d I P G ) + KL(I P G I P d ).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. A. Osokin was supported by the ERC grant Activia (no. 307574). F. Vaggi was supported by a grant from the chair Havas-Dauphine.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generalized denoising auto-encoders as generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Green fluorescent protein as a marker for gene expression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chalfie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Euskirchen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Prasher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="802" to="805" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">An overview of data science uses in bioimage informatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning particle physics by example: Location-aware generative adversarial networks for physics synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paganini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nachman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.05927v1</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feifei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep generative image models using a Laplacian pyramid of adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Reconstructing regulatory pathways by systematically mapping protein localization interdependency networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dodgson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vaggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Giordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Arai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Madrid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geymonat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Abenza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cansado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Csikasz-Nagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Salas</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>bioRxiv:11674, 2017. 1, 3, 5</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning to generate chairs, tables and cars with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tatarchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="692" to="705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adversarially learned inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mastropietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00704v3</idno>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Domainadversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">59</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.00160v3</idno>
		<title level="m">NIPS 2016 tutorial: Generative adversarial networks</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00028v2</idno>
		<title level="m">Improved training of Wasserstein GANs</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automated Learning of Subcellular Variation among Punctate Protein Patterns and a Generative Model of Their Relation to Microtubules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shariff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Rohde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1004614</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114v10</idno>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The MNIST database of handwritten digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huszar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Precomputed real-time texture synthesis with markovian generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Annotated high-throughput microscopy image sets for validation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ljosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Sokolnicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Carpenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">637</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Revisiting classifier twosample tests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oquab</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.06545v3</idno>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cell polarization in budding and fission yeasts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Arkowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">FEMS microbiology reviews</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="228" to="253" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Disentangling factors of variation in deep representation using adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sprechmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Imagining the future of bioimage analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Meijering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Olivo-Marin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Biotechnology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unrolled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02163v3</idno>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.1784v1</idno>
		<title level="m">Conditional generative adversarial nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Building cell models and simulations from microscope images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="33" to="39" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Training generative neural samplers using variational divergence minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tomiokao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Conditional image synthesis with auxiliary classifier GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">GANs for biological image synthesis. Code and supplementary materials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Osokin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Salas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vaggi</surname></persName>
		</author>
		<ptr target="https://github.com/aosokin/biogans,2017.5" />
		<imprint>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Understanding cytokinesis: lessons from fission yeast</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Q</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature reviews Molecular cell biology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Improved generator objectives for GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Angelovam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.02780v1</idno>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Adversarial Training</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434v2</idno>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Generative adversarial text to image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Improved techniques for training GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Improved monomeric red, orange and yellow fluorescent proteins derived from Discosoma sp. red fluorescent protein</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Shaner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Steinbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Giepmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Y</forename><surname>Tsien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature biotechnology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1567</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tolstikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Simon-Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>SchÃ¶lkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.02386v1</idno>
		<title level="m">AdaGAN: Boosting generative models</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">The green fluorescent protein. Annual review of biochemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Y</forename><surname>Tsien</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="509" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Conditional image generation with PixelCNN decoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Van Valen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Macklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">T</forename><surname>Quach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Defelice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Maayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tanouchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Covert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deep Learning Automates the Quantitative Analysis of Individual Cells in Live-Cell Imaging Experiments</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">1005177</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Generative image modeling using style and structure adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Sampling generative networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>White</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04468v3</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The Image Data Resource: A scalable platform for biological image data access, integration, and dissemination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rustici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarkowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Leo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Antal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Sarkans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brazma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Salas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Swedlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="775" to="781" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning a probabilistic latent space of object shapes via 3D generative-adversarial modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">On the quantitative analysis of decoder-based generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04273v1</idno>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Meiotic actin rings are essential for proper sporulation in fission yeast</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Balasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cell Science</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1429" to="1439" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.03365v3</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Energy-based generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03126v4</idno>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Generative visual manipulation on the natural image manifold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>KrÃ¤henbÃ¼hl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Unpaired imageto-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
