<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Style Transfer from Non-Parallel Text by Cross-Alignment</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianxiao</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">MIT CSAIL</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">ASAPP Inc</orgName>
								<address>
									<addrLine>1 {tianxiao, regina</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">MIT CSAIL</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">MIT CSAIL</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Style Transfer from Non-Parallel Text by Cross-Alignment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>This paper focuses on style transfer on the basis of non-parallel text. This is an instance of a broad family of problems including machine translation, decipherment, and sentiment modification. The key challenge is to separate the content from other aspects such as style. We assume a shared latent content distribution across different text corpora, and propose a method that leverages refined alignment of latent representations to perform style transfer. The transferred sentences from one style should match example sentences from the other style as a population. We demonstrate the effectiveness of this cross-alignment method on three tasks: sentiment modification, decipherment of word substitution ciphers, and recovery of word order.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Using massive amounts of parallel data has been essential for recent advances in text generation tasks, such as machine translation and summarization. However, in many text generation problems, we can only assume access to non-parallel or mono-lingual data. Problems such as decipherment or style transfer are all instances of this family of tasks. In all of these problems, we must preserve the content of the source sentence but render the sentence consistent with desired presentation constraints (e.g., style, plaintext/ciphertext).</p><p>The goal of controlling one aspect of a sentence such as style independently of its content requires that we can disentangle the two. However, these aspects interact in subtle ways in natural language sentences, and we can succeed in this task only approximately even in the case of parallel data. Our task is more challenging here. We merely assume access to two corpora of sentences with the same distribution of content albeit rendered in different styles. Our goal is to demonstrate that this distributional equivalence of content, if exploited carefully, suffices for us to learn to map a sentence in one style to a style-independent content vector and then decode it to a sentence with the same content but a different style.</p><p>In this paper, we introduce a refined alignment of sentence representations across text corpora. We learn an encoder that takes a sentence and its original style indicator as input, and maps it to a style-independent content representation. This is then passed to a style-dependent decoder for rendering. We do not use typical VAEs for this mapping since it is imperative to keep the latent content representation rich and unperturbed. Indeed, richer latent content representations are much harder to align across the corpora and therefore they offer more informative content constraints. Moreover, we reap additional information from cross-generated (style-transferred) sentences, thereby getting two distributional alignment constraints. For example, positive sentences that are style-transferred into negative sentences should match, as a population, the given set of negative sentences. We illustrate this cross-alignment in <ref type="figure">Figure 1</ref>.</p><p>Figure 1: An overview of the proposed cross-alignment method. X 1 and X 2 are two sentence domains with different styles y 1 and y 2 , and Z is the shared latent content space. Encoder E maps a sentence to its content representation, and generator G generates the sentence back when combining with the original style. When combining with a different style, transferredX 1 is aligned with X 2 and X 2 is aligned with X 1 at the distributional level.</p><p>To demonstrate the flexibility of the proposed model, we evaluate it on three tasks: sentiment modification, decipherment of word substitution ciphers, and recovery of word order. In all of these applications, the model is trained on non-parallel data. On the sentiment modification task, the model successfully transfers the sentiment while keeps the content for 41.5% of review sentences according to human evaluation, compared to 41.0% achieved by the control-gen model of <ref type="bibr" target="#b8">Hu et al. (2017)</ref>. It achieves strong performance on the decipherment and word order recovery tasks, reaching Bleu score of 57.4 and 26.1 respectively, obtaining 50.2 and 20.9 gap than a comparable method without cross-alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Style transfer in vision Non-parallel style transfer has been extensively studied in computer vision <ref type="bibr" target="#b4">(Gatys et al., 2016;</ref><ref type="bibr" target="#b29">Zhu et al., 2017;</ref><ref type="bibr" target="#b17">Liu and Tuzel, 2016;</ref><ref type="bibr" target="#b18">Liu et al., 2017;</ref><ref type="bibr" target="#b25">Taigman et al., 2016;</ref><ref type="bibr" target="#b27">Yi et al., 2017)</ref>. <ref type="bibr" target="#b4">Gatys et al. (2016)</ref> explicitly extract content and style features, and then synthesize a new image by combining "content" features of one image with "style" features from another. More recent approaches learn generative networks directly via generative adversarial training <ref type="bibr" target="#b5">(Goodfellow et al., 2014)</ref> from two given data domains X 1 and X 2 . The key computational challenge in this non-parallel setting is aligning the two domains. For example, CoupledGANs <ref type="bibr" target="#b17">(Liu and Tuzel, 2016)</ref> employ weight-sharing between networks to learn cross-domain representation, whereas CycleGAN <ref type="bibr" target="#b29">(Zhu et al., 2017)</ref> introduces cycle consistency which relies on transitivity to regularize the transfer functions. While our approach has a similar high-level architecture, the discreteness of natural language does not allow us to reuse these models and necessitates the development of new methods.</p><p>Non-parallel transfer in natural language In natural language processing, most tasks that involve generation (e.g., translation and summarization) are trained using parallel sentences. Our work most closely relates to approaches that do not utilize parallel data, but instead guide sentence generation from an indirect training signal <ref type="bibr" target="#b21">(Mueller et al., 2017;</ref><ref type="bibr" target="#b8">Hu et al., 2017)</ref>. For instance, <ref type="bibr" target="#b21">Mueller et al. (2017)</ref> manipulate the hidden representation to generate sentences that satisfy a desired property (e.g., sentiment) as measured by a corresponding classifier. However, their model does not necessarily enforce content preservation. More similar to our work, <ref type="bibr" target="#b8">Hu et al. (2017)</ref> aims at generating sentences with controllable attributes by learning disentangled latent representations <ref type="bibr" target="#b2">(Chen et al., 2016)</ref>. Their model builds on variational auto-encoders (VAEs) and uses independency constraints to enforce that attributes can be reliably inferred back from generated sentences. While our model builds on distributional cross-alignment for the purpose of style transfer and content preservation, these constraints can be added in the same way.</p><p>Adversarial training over discrete samples Recently, a wide range of techniques addresses challenges associated with adversarial training over discrete samples generated by recurrent networks <ref type="bibr" target="#b16">Lamb et al., 2016;</ref>. In our work, we employ the Professor-Forcing algorithm <ref type="bibr" target="#b16">(Lamb et al., 2016)</ref> which was originally proposed to close the gap between teacher-forcing during training and self-feeding during testing for recurrent networks. This design fits well with our scenario of style transfer that calls for cross-alignment. By using continuous relaxation to approximate the discrete sampling process <ref type="bibr" target="#b10">(Jang et al., 2016;</ref><ref type="bibr" target="#b19">Maddison et al., 2016)</ref>, the training procedure can be effectively optimized through back-propagation <ref type="bibr" target="#b15">(Kusner and Hernández-Lobato, 2016;</ref><ref type="bibr" target="#b6">Goyal et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Formulation</head><p>In this section, we formalize the task of non-parallel style transfer and discuss the feasibility of the learning problem. We assume the data are generated by the following process:</p><p>1. a latent style variable y is generated from some distribution p(y); 2. a latent content variable z is generated from some distribution p(z); 3. a datapoint x is generated from conditional distribution p(x|y, z).</p><p>We observe two datasets with the same content distribution but different styles y 1 and y 2 , where y 1 and y 2 are unknown. Specifically, the two observed datasets X 1 = {x</p><formula xml:id="formula_0">(1) 1 , · · · , x (n) 1 } and X 2 = {x (1) 2 , · · · , x (m)</formula><p>2 } consist of samples drawn from p(x 1 |y 1 ) and p(x 2 |y 2 ) respectively. We want to estimate the style transfer functions between them, namely p(x 1 |x 2 ; y 1 , y 2 ) and p(x 2 |x 1 ; y 1 , y 2 ).</p><p>A question we must address is when this estimation problem is feasible. Essentially, we only observe the marginal distributions of x 1 and x 2 , yet we are going to recover their joint distribution:</p><formula xml:id="formula_1">p(x 1 , x 2 |y 1 , y 2 ) = z p(z)p(x 1 |y 1 , z)p(x 2 |y 2 , z)dz<label>(1)</label></formula><p>As we only observe p(x 1 |y 1 ) and p(x 2 |y 2 ), y 1 and y 2 are unknown to us. If two different y and y lead to the same distribution p(x|y) = p(x|y ), then given a dataset X sampled from it, its underlying style can be either y or y . Consider the following two cases: (1) both datasets X 1 and X 2 are sampled from the same style y; (2) X 1 and X 2 are sampled from style y and y respectively. These two scenarios have different joint distributions, but the observed marginal distributions are the same. To prevent such confusion, we constrain the underlying distributions as stated in the following proposition: Proposition 1. In the generative framework above, x 1 and x 2 's joint distribution can be recovered from their marginals only if for any different y, y ∈ Y, distributions p(x|y) and p(x|y ) are different.</p><p>This proposition basically says that X generated from different styles should be "distinct" enough, otherwise the transfer task between styles is not well defined. While this seems trivial, it may not hold even for simplified data distributions. The following examples illustrate how the transfer (and recovery) becomes feasible or infeasible under different model assumptions. As we shall see, for a certain family of styles Y, the more complex distribution for z, the more probable it is to recover the transfer function and the easier it is to search for the transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Example 1: Gaussian</head><p>Consider the common choice that z ∼ N (0, I) has a centered isotropic Gaussian distribution. Suppose a style y = (A, b) is an affine transformation, i.e. x = Az + b + , where is a noise variable. For b = 0 and any orthogonal matrix A, Az + b ∼ N (0, I) and hence x has the same distribution for any such styles y = (A, 0). In this case, the effect of rotation cannot be recovered.</p><p>Interestingly, if z has a more complex distribution, such as a Gaussian mixture, then affine transformations can be uniquely determined.</p><formula xml:id="formula_2">Lemma 1. Let z be a mixture of Gaussians p(z) = K k=1 π k N (z; µ k , Σ k ). Assume K ≥ 2, and there are two different Σ i = Σ j . Let Y = {(A, b)||A| = 0}</formula><p>be all invertible affine transformations, and p(x|y, z) = N (x; Az + b, 2 I), in which is a noise. Then for all y = y ∈ Y, p(x|y) and p(x|y ) are different distributions. Theorem 1. If the distribution of z is a mixture of Gaussians which has more than two different components, and x 1 , x 2 are two affine transformations of z, then the transfer between them can be recovered given their respective marginals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Example 2: Word substitution</head><p>Consider here another example when z is a bi-gram language model and a style y is a vocabulary in use that maps each "content word" onto its surface form (lexical form). If we observe two realizations x 1 and x 2 of the same language z, the transfer and recovery problem becomes inferring a word alignment between x 1 and x 2 .</p><p>Note that this is a simplified version of language decipherment or translation. Nevertheless, the recovery problem is still sufficiently hard. To see this, let M 1 , M 2 ∈ R n×n be the estimated bi-gram probability matrix of data X 1 and X 2 respectively. Seeking the word alignment is equivalent to finding a permutation matrix P such that P M 1 P ≈ M 2 , which can be expressed as an optimization problem,</p><formula xml:id="formula_3">min P P M 1 P − M 2 2</formula><p>The same formulation applies to graph isomorphism (GI) problems given M 1 and M 2 as the adjacency matrices of two graphs, suggesting that determining the existence and uniqueness of P is at least GI hard. Fortunately, if M as a graph is complex enough, the search problem could be more tractable. For instance, if each vertex's weights of incident edges as a set is unique, then finding the isomorphism can be done by simply matching the sets of edges. This assumption largely applies to our scenario where z is a complex language model. We empirically demonstrate this in the results section.</p><p>The above examples suggest that z as the latent content variable should carry most complexity of data x, while y as the latent style variable should have relatively simple effects. We construct the model accordingly in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head><p>Learning the style transfer function under our generative assumption is essentially learning the conditional distribution p(x 1 |x 2 ; y 1 , y 2 ) and p(x 2 |x 1 ; y 1 , y 2 ). Unlike in vision where images are continuous and hence the transfer functions can be learned and optimized directly, the discreteness of language requires us to operate through the latent space. Since x 1 and x 2 are conditionally independent given the latent content variable z,</p><formula xml:id="formula_4">p(x 1 |x 2 ; y 1 , y 2 ) = z p(x 1 , z|x 2 ; y 1 , y 2 )dz = z p(z|x 2 , y 2 ) · p(x 1 |y 1 , z)dz = E z∼p(z|x2,y2) [p(x 1 |y 1 , z)]<label>(2)</label></formula><p>This suggests us learning an auto-encoder model. Specifically, a style transfer from x 2 to x 1 involves two steps-an encoding step that infers x 2 's content z ∼ p(z|x 2 , y 2 ), and a decoding step which generates the transferred counterpart from p(x 1 |y 1 , z). In this work, we approximate and train p(z|x, y) and p(x|y, z) using neural networks (where y ∈ {y 1 , y 2 }).</p><p>Let E : X × Y → Z be an encoder that infers the content z for a given sentence x and a style y, and G : Y × Z → X be a generator that generates a sentence x from a given style y and content z. E and G form an auto-encoder when applying to the same style, and thus we have reconstruction loss,</p><formula xml:id="formula_5">L rec (θ E , θ G ) = E x1∼X1 [− log p G (x 1 |y 1 , E(x 1 , y 1 ))] + E x2∼X2 [− log p G (x 2 |y 2 , E(x 2 , y 2 ))]<label>(3)</label></formula><p>where θ are the parameters to estimate.</p><p>In order to make a meaningful transfer by flipping the style, X 1 and X 2 's content space must coincide, as our generative framework presumed. To constrain that x 1 and x 2 are generated from the same latent content distribution p(z), one option is to apply a variational auto-encoder <ref type="bibr" target="#b13">(Kingma and Welling, 2013)</ref>. A VAE imposes a prior density p(z), such as z ∼ N (0, I), and uses a KL-divergence regularizer to align both posteriors p E (z|x 1 , y 1 ) and p E (z|x 2 , y 2 ) to it,</p><formula xml:id="formula_6">L KL (θ E ) = E x1∼X1 [D KL (p E (z|x 1 , y 1 ) p(z))] + E x2∼X2 [D KL (p E (z|x 2 , y 2 ) p(z))]<label>(4)</label></formula><p>The overall objective is to minimize L rec + L KL , whose opposite is the variational lower bound of data likelihood.</p><p>However, as we have argued in the previous section, restricting z to a simple and even distribution and pushing most complexity to the decoder may not be a good strategy for non-parallel style transfer. In contrast, a standard auto-encoder simply minimizes the reconstruction error, encouraging z to carry as much information about x as possible. On the other hand, it lowers the entropy in p(x|y, z), which helps to produce meaningful style transfer in practice as we flip between y 1 and y 2 . Without explicitly modeling p(z), it is still possible to force distributional alignment of p(z|y 1 ) and p(z|y 2 ).</p><p>To this end, we introduce two constrained variants of auto-encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Aligned auto-encoder</head><p>Dispense with VAEs that make an explicit assumption about p(z) and align both posteriors to it, we align p E (z|y 1 ) and p E (z|y 2 ) with each other, which leads to the following constrained optimization problem:</p><formula xml:id="formula_7">θ * = arg min θ L rec (θ E , θ G ) s.t. E(x 1 , y 1 ) d = E(x 2 , y 2 ) x 1 ∼ X 1 , x 2 ∼ X 2<label>(5)</label></formula><p>In practice, a Lagrangian relaxation of the primal problem is instead optimized. We introduce an adversarial discriminator D to align the aggregated posterior distribution of z from different styles <ref type="bibr" target="#b20">(Makhzani et al., 2015)</ref>. D aims to distinguish between these two distributions:</p><formula xml:id="formula_8">L adv (θ E , θ D ) = E x1∼X1 [− log D(E(x 1 , y 1 ))] + E x2∼X2 [− log(1 − D(E(x 2 , y 2 )))]<label>(6)</label></formula><p>The overall training objective is a min-max game played among the encoder E, generator G and discriminator D. They constitute an aligned auto-encoder:</p><formula xml:id="formula_9">min E,G max D L rec − λL adv<label>(7)</label></formula><p>We implement the encoder E and generator G using single-layer RNNs with GRU cell. E takes an input sentence x with initial hidden state y, and outputs the last hidden state z as its content representation. G generates a sentence x conditioned on latent state (y, z). To align the distributions of z 1 = E(x 1 , y 1 ) and z 2 = E(x 2 , y 2 ), the discriminator D is a feed-forward network with a single hidden layer and a sigmoid output layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Cross-aligned auto-encoder</head><p>The second variant, cross-aligned auto-encoder, directly aligns the transfered samples from one style with the true samples from the other. Under the generative assumption, p(x 2 |y 2 ) = x1 p(x 2 |x 1 ; y 1 , y 2 )p(x 1 |y 1 )dx 1 , thus x 2 (sampled from the left-hand side) should exhibit the same distribution as transferred x 1 (sampled from the right-hand side), and vice versa. Similar to our first model, the second model uses two discriminators D 1 and D 2 to align the populations. D 1 's job is to distinguish between real x 1 and transferred x 2 , and D 2 's job is to distinguish between real x 2 and transferred x 1 .</p><p>Adversarial training over the discrete samples generated by G hinders gradients propagation. Although sampling-based gradient estimator such as REINFORCE <ref type="bibr" target="#b26">(Williams, 1992)</ref> can by adopted, training with these methods can be unstable due to the high variance of the sampled gradient. Instead, we employ two recent techniques to approximate the discrete training <ref type="bibr" target="#b8">(Hu et al., 2017;</ref><ref type="bibr" target="#b16">Lamb et al., 2016)</ref>. First, instead of feeding a single sampled word as the input to the generator RNN, we use the softmax distribution over words instead. Specifically, during the generating process of transferred x 2 from G(y 1 , z 2 ), suppose at time step t the output logit vector is v t . We feed its peaked distribution softmax(v t /γ) as the next input, where γ ∈ (0, 1) is a temperature parameter.</p><p>Secondly, we use Professor-Forcing <ref type="bibr" target="#b16">(Lamb et al., 2016)</ref> to match the sequence of hidden states instead of the output words, which contains the information about outputs and is smoothly distributed. That is, the input to the discriminator D 1 is the sequence of hidden states of either (1) G(y 1 , z 1 ) teacher-forced by a real example x 1 , or (2) G(y 1 , z 2 ) self-fed by previous soft distributions. Cross-aligning between x 1 and transferred x 2 . For x 1 , G is teacher-forced by its words w 1 w 2 · · · w t . For transfered x 2 , G is self-fed by previous output logits. The sequence of hidden states h 0 , · · · , h t andh 0 , · · · ,h t are passed to discriminator D 1 to be aligned. Note that our first variant aligned auto-encoder is a special case of this, where only h 0 andh 0 , i.e. z 1 and z 2 , are aligned.</p><p>Algorithm 1 Cross-aligned auto-encoder training. The hyper-parameters are set as λ = 1, γ = 0.001 and learning rate is 0.0001 for all experiments in this paper. Input: Two corpora of different styles X 1 , X 2 . Lagrange multiplier λ, temperature γ.</p><p>Initialize θ E , θ G , θ D1 , θ D2 repeat for p = 1, 2; q = 2, 1 do Sample a mini-batch of k examples {x  </p><formula xml:id="formula_10">(i) p } k i=1 from X p Get the latent content representations z (i) p = E(x (i) p , y p ) Unroll G from initial state (y p , z</formula><formula xml:id="formula_11">L adv1 = − 1 k k i=1 log D 1 (h (i) 1 ) − 1 k k i=1 log(1 − D 1 (h (i) 2 ))<label>(8)</label></formula><p>Update {θ E , θ G } by gradient descent on loss</p><formula xml:id="formula_12">L rec − λ(L adv1 + L adv2 )<label>(9)</label></formula><p>Update θ D1 and θ D2 by gradient descent on loss L adv1 and L adv2 respectively until convergence Output: Style transfer functions G(y 2 , E(·, y 1 )) : X 1 → X 2 and G(y 1 , E(·, y 2 )) :</p><formula xml:id="formula_13">X 2 → X 1</formula><p>The running procedure of our cross-aligned auto-encoder is illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>. Note that crossaligning strengthens the alignment of latent variable z over the recurrent network of generator G. By aligning the whole sequence of hidden states, it prevents z 1 and z 2 's initial misalignment from propagating through the recurrent generating process, as a result of which the transferred sentence may end up somewhere far from the target domain.</p><p>We implement both D 1 and D 2 using convolutional neural networks for sequence classification <ref type="bibr" target="#b12">(Kim, 2014)</ref>. The training algorithm is presented in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental setup</head><p>Sentiment modification Our first experiment focuses on text rewriting with the goal of changing the underlying sentiment, which can be regarded as "style transfer" between negative and positive sentences. We run experiments on Yelp restaurant reviews, utilizing readily available user ratings associated with each review. Following standard practice, reviews with rating above three are considered positive, and those below three are considered negative. While our model operates at the sentence level, the sentiment annotations in our dataset are provided at the document level. We assume that all the sentences in a document have the same sentiment. This is clearly an oversimplification, since some sentences (e.g., background) are sentiment neutral. Given that such sentences are more common in long reviews, we filter out reviews that exceed 10 sentences. We further filter the remaining sentences by eliminating those that exceed 15 words. The resulting dataset has 250K negative sentences, and 350K positive ones. The vocabulary size is 10K after replacing words occurring less than 5 times with the "&lt;unk&gt;" token. As a baseline model, we compare against the control-gen model of <ref type="bibr" target="#b8">Hu et al. (2017)</ref>.</p><p>To quantitatively evaluate the transfered sentences, we adopt a model-based evaluation metric similar to the one used for image transfer <ref type="bibr" target="#b9">(Isola et al., 2016)</ref>. Specifically, we measure how often a transferred sentence has the correct sentiment according to a pre-trained sentiment classifier. For this purpose, we use the TextCNN model as described in <ref type="bibr" target="#b12">Kim (2014)</ref>. On our simplified dataset for style transfer, it achieves nearly perfect accuracy of 97.4%.</p><p>While the quantitative evaluation provides some indication of transfer quality, it does not capture all the aspects of this generation task. Therefore, we also perform two human evaluations on 500 sentences randomly selected from the test set 2 . In the first evaluation, the judges were asked to rank generated sentences in terms of their fluency and sentiment. Fluency was rated from 1 (unreadable) to 4 (perfect), while sentiment categories were "positive", "negative", or "neither" (which could be contradictory, neutral or nonsensical). In the second evaluation, we evaluate the transfer process comparatively. The annotator was shown a source sentence and the corresponding outputs of the systems in a random order, and was asked "Which transferred sentence is semantically equivalent to the source sentence with an opposite sentiment?". They can be both satisfactory, A/B is better, or both unsatisfactory. We collect two labels for each question. The label agreement and conflict resolution strategy can be found in the supplementary material. Note that the two evaluations are not redundant. For instance, a system that always generates the same grammatically correct sentence with the right sentiment independently of the source sentence will score high in the first evaluation setup, but low in the second one.</p><p>Word substitution decipherment Our second set of experiments involves decipherment of word substitution ciphers, which has been previously explored in NLP literature <ref type="bibr" target="#b3">(Dou and Knight, 2012;</ref><ref type="bibr" target="#b22">Nuhn and Ney, 2013)</ref>. These ciphers replace every word in plaintext (natural language) with a cipher token according to a 1-to-1 substitution key. The decipherment task is to recover the plaintext from ciphertext. It is trivial if we have access to parallel data. However we are interested to consider a non-parallel decipherment scenario. For training, we select 200K sentences as X 1 , and apply a substitution cipher f on a different set of 200K sentences to get X 2 . While these sentences are nonparallel, they are drawn from the same distribution from the review dataset. The development and test sets have 100K parallel sentences</p><formula xml:id="formula_14">D 1 = {x (1) , · · · , x (n) } and D 2 = {f (x (1) ), · · · , f (x (n) )}.</formula><p>We can quantitatively compare between D 1 and transferred (deciphered) D 2 using Bleu score <ref type="bibr" target="#b23">(Papineni et al., 2002)</ref>.</p><p>Clearly, the difficulty of this decipherment task depends on the number of substituted words. Therefore, we report model performance with respect to the percentage of the substituted vocabulary. Note that the transfer models do not know that f is a word substitution function. They learn it entirely from the data distribution.</p><p>In addition to having different transfer models, we introduce a simple decipherment baseline based on word frequency. Specifically, we assume that words shared between X 1 and X 2 do not require translation. The rest of the words are mapped based on their frequency, and ties are broken arbitrarily. Finally, to assess the difficulty of the task, we report the accuracy of a machine translation system trained on a parallel corpus <ref type="bibr" target="#b14">(Klein et al., 2017</ref>  <ref type="table">Table 2</ref>: Human evaluations on sentiment, fluency and overall transfer quality. Fluency rating is from 1 (unreadable) to 4 (perfect). Overall transfer quality is evaluated in a comparative manner, where the judge is shown a source sentence and two transferred sentences, and decides whether they are both good, both bad, or one is better.</p><p>Word order recovery Our final experiments focus on the word ordering task, also known as bag translation <ref type="bibr" target="#b0">(Brown et al., 1990;</ref><ref type="bibr" target="#b24">Schmaltz et al., 2016)</ref>. By learning the style transfer functions between original English sentences X 1 and shuffled English sentences X 2 , the model can be used to recover the original word order of a shuffled sentence (or conversely to randomly permute a sentence). The process to construct non-parallel training data and parallel testing data is the same as in the word substitution decipherment experiment. Again the transfer models do not know that f is a shuffle function and learn it completely from data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>Sentiment modification <ref type="table">Table 1 and Table 2</ref> show the performance of various models for both human and automatic evaluation. The control-gen model of <ref type="bibr" target="#b8">Hu et al. (2017)</ref> performs better in terms of sentiment accuracy in both evaluations. This is not surprising because their generation is directly guided by a sentiment classifier. Their system also achieves higher fluency score. However, these gains do not translate into improvements in terms of the overall transfer, where our model faired better. As can be seen from the examples listed in <ref type="table">Table 3</ref>, our model is more consistent with the grammatical structure and semantic meaning of the source sentence. In contrast, their model achieves sentiment change by generating an entirely new sentence which has little overlap with the original. The discrepancy between the two experiments demonstrate the crucial importance of developing appropriate evaluation measures for comparing methods for style transfer.</p><p>Word substitution decipherment <ref type="table">Table 4</ref> summarizes the performance of our model and the baselines on the decipherment task, at various levels of word substitution. Consistent with our intuition, the last row in this table shows that the task is trivial when the parallel data is provided. In non-parallel case, the difficulty of the task is driven by the substitution rate. Across all the testing conditions, our cross-aligned model consistently outperforms its counterparts. The difference becomes more pronounced as the task becomes harder. When the substitution rate is 20%, all methods do a reasonably good job in recovering substitutions. However, when 100% of the words are substituted (as expected in real language decipherment), the poor performance of variational autoencoder and aligned auto-encoder rules out their application for this task.</p><p>Word order recovery The last column in <ref type="table">Table 4</ref> demonstrates the performance on the word order recovery task. Order recovery is much harder-even when trained with parallel data, the machine translation model achieves only 64.6 Bleu score. Note that some generated orderings may be completely valid (e.g., reordering conjunctions), but the models will be penalized for producing them. In this task, only the cross-aligned auto-encoder achieves grammatical reorder to a certain extent, demonstrated by its Bleu score 26.1. Other models fail this task, doing no better than no transfer.</p><p>From negative to positive consistently slow . consistently good . consistently fast . my goodness it was so gross . my husband 's steak was phenomenal . my goodness was so awesome .</p><p>it was super dry and had a weird taste to the entire slice . it was a great meal and the tacos were very kind of good . it was super flavorful and had a nice texture of the whole side .</p><p>From positive to negative i love the ladies here ! i avoid all the time ! i hate the doctor here ! my appetizer was also very good and unique . my bf was n't too pleased with the beans . my appetizer was also very cold and not fresh whatsoever .</p><p>came here with my wife and her grandmother ! came here with my wife and hated her ! came here with my wife and her son . <ref type="table">Table 3</ref>: Sentiment transfer samples. The first line is an input sentence, the second and third lines are the generated sentences after sentiment transfer by <ref type="bibr" target="#b8">Hu et al. (2017)</ref>   <ref type="table">Table 4</ref>: Bleu scores of word substitution decipherment and word order recovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>Transferring languages from one style to another has been previously trained using parallel data. In this work, we formulate the task as a decipherment problem with access only to non-parallel data. The two data collections are assumed to be generated by a latent variable generative model. Through this view, our method optimizes neural networks by forcing distributional alignment (invariance) over the latent space or sentence populations. We demonstrate the effectiveness of our method on tasks that permit quantitative evaluation, such as sentiment transfer, word substitution decipherment and word ordering. The decipherment view also provides an interesting open question-when can the joint distribution p(x 1 , x 2 ) be recovered given only marginal distributions? We believe addressing this general question would promote the style transfer research in both vision and NLP.  Therefore, for all y = y , p(x|y) = p(x|y ).</p><formula xml:id="formula_15">Aµ k + b = A µ k + b AΣ k A = A Σ k A Since all Y are invertible, (A −1 A )Σ k (A −1 A ) = Σ k Suppose Σ k = Q k D k Q k is Σ k 's</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Cross-aligning between x 1 and transferred x 2 . For x 1 , G is teacher-forced by its words w 1 w 2 · · · w t . For transfered x 2 , G is self-fed by previous output logits. The sequence of hidden states h 0 , · · · , h t andh 0 , · · · ,h t are passed to discriminator D 1 to be aligned. Note that our first variant aligned auto-encoder is a special case of this, where only h 0 andh 0 , i.e. z 1 and z 2 , are aligned.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Unroll G from initial state (y q , z (i) p ) by feeding previous soft output distribution with temper- ature γ, and get the transferred hidden states sequenceh</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Compute the reconstruction L rec by Eq. (3) Compute D 1 's (and symmetrically D 2 's) loss:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>.</head><label></label><figDesc>Let z be a mixture of Gaussians p(z) = K k=1 π k N (z; µ k , Σ k ). Assume K ≥ 2, and there are two different Σ i = Σ j . Let Y = {(A, b)||A| = 0} be all invertible affine transformations, and p(x|y, z) = N (x; Az + b, 2 I), in which is a noise. Then for all y = y ∈ Y, p(x|y) and p(x|y ) are different distributions. Proof. p(x|y = (A, b)) = K k=1 π k N (x; Aµ k + b, AΣ k A + 2 I) For different y = (A, b) and y = (A , b ), p(x|y) = p(x|y ) entails that for k = 1, · · · , K,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>orthogonal diagonalization. If k = 1, all solutions for A −1 A have the form: QD 1/2 U D −1/2 Q U is orthogonal However, when K ≥ 2 and there are two different Σ i = Σ j , the only solution is A −1 A = I, i.e. A = A , and thus b = b .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>).</figDesc><table>Method 

accuracy 
Hu et al. (2017) 
83.5 
Variational auto-encoder 
23.2 
Aligned auto-encoder 
48.3 
Cross-aligned auto-encoder 
78.4 

Table 1: Sentiment accuracy of transferred sentences, as measured by a pretrained classifier. 

Method 
sentiment fluency overall transfer 
Hu et al. (2017) 
70.8 
3.2 
41.0 
Cross-align 
62.6 
2.8 
41.5 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>and our cross-aligned auto-encoder, respectively.Cross-aligned auto-encoder 83.8 79.1 74.7 66.1</figDesc><table>Method 
Substitution decipher 
Order recover 
20% 40% 60% 80% 100% 
No transfer (copy) 
56.4 21.4 
6.3 
4.5 
0 
5.1 
Unigram matching 
74.3 48.1 17.8 10.7 
1.2 
-
Variational auto-encoder 
79.8 59.6 44.6 34.4 
0.9 
5.3 
Aligned auto-encoder 
81.0 68.9 50.7 45.6 
7.2 
5.2 
57.4 
26.1 
Parallel translation 
99.0 98.9 98.2 98.5 
97.2 
64.6 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Our code and data are available at https://github.com/shentianxiao/language-style-transfer. 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">we eliminated 37 sentences from them that were judged as neutral by human judges.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Nicholas Matthews for helping to facilitate human evaluations, and Zhiting Hu for sharing his code. We also thank Jonas Mueller, Arjun Majumdar, Olga Simek, Danelle Shah, MIT NLP group and the reviewers for their helpful comments. This work was supported by MIT Lincoln Laboratory.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A statistical approach to machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen A Della</forename><surname>Cocke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fredrick</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jelinek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">S</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roossin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="79" to="85" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanran</forename><surname>Tong Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruixiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devon</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.07983</idno>
		<title level="m">Yangqiu Song, and Yoshua Bengio. Maximum-likelihood augmented discrete generative adversarial networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Infogan: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rein</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Large scale decipherment for out-of-domain machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="266" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image style transfer using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">S</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2414" to="2423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Differentiable scheduled sampling for credit assignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.06970</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Boundaryseeking generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>R Devon Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08431</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00955</idno>
		<title level="m">Controllable text generation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07004</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<title level="m">Categorical reparameterization with gumbel-softmax</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning to discover cross-domain relations with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taeksoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moonsu</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunsoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungkwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.05192</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5882</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Opennmt: Open-source toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.02810</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Gans for sequences of discrete elements with the gumbel-softmax distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José Miguel Hernández-Lobato</forename><surname>Kusner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04051</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Professor forcing: A new algorithm for training recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex M</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alias</forename><surname>Parth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4601" to="4609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Coupled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oncel</forename><surname>Tuzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="469" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Unsupervised image-to-image translation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00848</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Chris J Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.00712</idno>
		<title level="m">The concrete distribution: A continuous relaxation of discrete random variables</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Frey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05644</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">Adversarial autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sequence to better sequence: continuous revision of combinatorial structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decipherment complexity in 1: 1 substitution ciphers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><surname>Nuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (1)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="615" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting on association for computational linguistics</title>
		<meeting>the 40th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Word ordering without syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><surname>Schmaltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Shieber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2319" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Unsupervised cross-domain image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Polyak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02200</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Unsupervised dual learning for image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zili</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><forename type="middle">Tan</forename><surname>Gong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.02510</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Seqgan: sequence generative adversarial nets with policy gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lantao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.05473</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10593</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
