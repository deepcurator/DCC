<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T23:19+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Estimating the Success of Unsupervised Image to Image Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sagie</forename><surname>Benaim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Blavatnik School of Computer Science</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Tomer</roleName><forename type="first">Galanti</forename><surname>1⋆</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Blavatnik School of Computer Science</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Blavatnik School of Computer Science</orgName>
								<orgName type="institution">Tel Aviv University</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Estimating the Success of Unsupervised Image to Image Translation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>Unsupervised Learning · Generalization Bounds · Image to Image Translation · GANs</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract. While in supervised learning, the validation error is an unbiased estimator of the generalization (test) error and complexity-based generalization bounds are abundant, no such bounds exist for learning a mapping in an unsupervised way. As a result, when training GANs and specifically when using GANs for learning to map between domains in a completely unsupervised way, one is forced to select the hyperparameters and the stopping epoch by subjectively examining multiple options. We propose a novel bound for predicting the success of unsupervised cross domain mapping methods, which is motivated by the recently proposed Simplicity Principle. The bound can be applied both in expectation, for comparing hyperparameters and for selecting a stopping criterion, or per sample, in order to predict the success of a specific cross-domain translation. The utility of the bound is demonstrated in an extensive set of experiments employing multiple recent algorithms. Our code is available at https: //github.com/sagiebenaim/gan bound.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In unsupervised learning, the process of selecting hyperparameters and the lack of clear stopping criteria are a constant source of frustration. This issue is commonplace for GANs <ref type="bibr" target="#b10">[11]</ref> and the derived technologies, in which the training process optimizes multiple losses that balance each other. Practitioners are often uncertain regarding the results obtained when evaluating GAN-based methods, and many avoid using these altogether. One solution is to employ more stable methods such as <ref type="bibr" target="#b3">[4]</ref>. However, these methods do not always match the results obtained by GANs. In this work, we offer, for an important family of GAN methodologies, an algorithm for selecting the hyperparameters, as well as a stopping criterion.</p><p>Specifically, we focus on predicting the success of algorithms that map between two image domains in an unsupervised manner. Multiple GAN-based methods have recently demonstrated convincing results, despite the apparent inherent ambiguity, which is described in Sec. <ref type="bibr" target="#b1">2</ref>. We derive what is, as far as we know, the first error bound for unsupervised cross domain mapping.</p><p>In addition to the novel capability of predicting the success, in expectation, of a mapping that was trained using one of the unsupervised mapping methods, we can predict the success of mapping every single sample individually. This is remarkable for two reasons: (i) even supervised generalization bounds do not deliver this capability; and (ii) we deal with complex multivariate regression problems (mapping between images) and not with classification problems, in which pseudo probabilities are often assigned.</p><p>In Sec. 2, we formulate the problem and present background on the Simplicity Principle of <ref type="bibr" target="#b8">[9]</ref>. Then, in Sec. 3, we derive the prediction bounds and introduce multiple algorithms. Sec. 4 presents extensive empirical evidence for the success of our algorithms, when applied to multiple recent methods. This includes a unique combination of the hyperband method <ref type="bibr" target="#b15">[16]</ref>, which is perhaps the leading method in hyperparameter optimization, in the supervised setting, with our bound. This combination enables the application of hyperband in unsupervised learning, where, as far as we know, no hyperparameter selection method exists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related Work</head><p>Generative Adversarial Networks GAN <ref type="bibr" target="#b10">[11]</ref> methods train a generator network G that synthesizes samples from a target distribution, given noise vectors, by jointly training a second, adversarial, network D. Conditional GANs employ a vector of parameters that directs the generator, in addition to (or instead of) the noise vector. These GANs can generate images from a specific class <ref type="bibr" target="#b18">[19]</ref> or based on a textual description <ref type="bibr" target="#b21">[22]</ref>, or invert mid-level network activations <ref type="bibr" target="#b5">[6]</ref>. Our bound also applies in these situations. However, this is not the focus of our experiments, which target image mapping, in which the created image is based on an input image <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b1">2]</ref>. Unsupervised Mapping The validation of our bound focuses on recent cross-domain mapping methods that employ no supervision, except for sample images from the two domains. This ability was demonstrated recently <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b1">2]</ref> in image to image translation and slightly earlier for translating between natural languages <ref type="bibr" target="#b27">[28]</ref>.</p><p>The DiscoGAN <ref type="bibr" target="#b14">[15]</ref> method, similar to other methods <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b29">30]</ref>, learns mappings in both directions, i.e., from domain A to domain B and vice versa. Our experiments also employ the DistanceGAN method <ref type="bibr" target="#b1">[2]</ref>, which unlike the circularity based methods, is applied only in one direction (from A to B). The constraint used by this method is that the distances for a pair of inputs x 1 , x 2 ∈ A before and after the mapping, by the learned mapping G, are highly correlated, i.e., ||x 1 − x 2 || ∼ ||G(x 1 ) − G(x 2 )||. Weakly Supervised Mapping Our bound can also be applied to GAN-based methods that match between the source domain and the target domain by also incorporating a fixed pre-trained feature map f and requiring f -constancy, i.e, that the activations of f are the same for the input samples and for mapped samples <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b26">27]</ref>. During training, the various components of the loss (GAN, f-constancy, and a few others) do not provide a clear signal when to stop training or which hyperparameters to use. Generalization Bounds for Unsupervised Learning Only a few generalization bounds for unsupervised learning were suggested in the literature. In <ref type="bibr" target="#b22">[23]</ref>, PAC-Bayesian generalization bounds are presented for density estimation. <ref type="bibr" target="#b20">[21]</ref> gives an algorithm for estimating a bounded density using a finite combination of densities from a given class. This algorithm has estimation error bounded by O(1/ √ n). Our work studies the error of a mapping and not the KL-divergence with respect to a target distribution. Further, our bound is data-dependent and not based on the complexity of the hypothesis class. Hyperparameter Optimization Hyperparameters are constants and configurations that are being used by a learning algorithm. Hyperparameter selection is the process of selecting the hyperparameters that will produce better learning. This includes optimizing the number of epochs, size and depth of the neural network being trained, learning rate, etc. Many of the earlier hyperparameter methods that go beyond a random-or a gridsearch were Bayesian in nature <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b6">7]</ref>. The hyperband method <ref type="bibr" target="#b15">[16]</ref>, which is currently leading various supervised learning benchmarks, is based on the multi-arm bandit problem. It employs partial training and dynamically allocates more resources to successful configurations. All such methods crucially rely on a validation error to be available for a given configuration, which means that these can only be used in the supervised settings. Our work enables, for the first time, the usage of such methods also in the unsupervised setting, by using our bound in lieu of the validation error for predicting the ground truth error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Setup</head><p>In Sec. 2.1 we define the alignment problem. Sec 2.2 illustrates the Simplicity Principle which was introduced in <ref type="bibr" target="#b8">[9]</ref> and was verified with an extensive set of experiments. Sec. 2.3 and everything that follows are completely novel. The section proposes the Occam's razor property, which extends the definition of the Simplicity Principle, and which is used in Sec. 3 to derive the main results and algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Alignment Problem</head><p>The learning algorithm is provided with two unlabeled datasets: one includes i.i.d samples from a first distribution and the second, i.i.d samples from a second distribution.</p><formula xml:id="formula_0">S A := {x i } m i=1 i.i.d ∼ D m A and S B := {y i } n i=1 i.i.d ∼ D n B<label>(1)</label></formula><p>D A and D B are distributions over X A and X B (resp.). In this paper we focus on the deterministic case, i.e, there is a target function, y AB , which is one of the functions that map the first domain to the second, such that</p><formula xml:id="formula_1">y AB • D A = D B (g • D is defined</formula><p>to be the distribution of g(x) where x ∼ D). The theory can be extended to the nondeterministic case, where there are multiple possible target functions <ref type="bibr" target="#b7">[8]</ref>. The goal of the learner is to fit a function G ∈ H, for some hypothesis class H that is closest to</p><formula xml:id="formula_2">y AB , i.e, inf G∈H R D A [G, y AB ], where R D [f 1 , f 2 ] = E x∼D [ℓ(f 1 (x), f 2 (x))], for a loss function ℓ : R M × R M → R and distribution D.</formula><p>It is not clear that such fitting is possible, without additional information. Assume, for example, that there is a natural order on the samples in X B . A mapping that maps an input sample x ∈ X A to the sample that is next in order to y AB (x), could be just as feasible. More generally, one can permute the samples in X A by some function Π that replaces each sample with another sample that has a similar likelihood and learn G that satisfies G = Π • y AB . This difficulty is referred to in <ref type="bibr" target="#b8">[9]</ref> as "the alignment problem".</p><p>In multiple recent contributions <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b29">30]</ref>, circularity is employed. Circularity requires the recovery of both y AB and y BA = y −1 AB simultaneously. Namely, functions G and G ′ are learned jointly by minimizing the following objective:</p><formula xml:id="formula_3">disc(G • DA, DB) + disc(G ′ • DB, DA) + RD A [G ′ • G, IdA] + RD B [G • G ′ , IdB]<label>(2)</label></formula><p>where disc(D1, D2) := sup</p><formula xml:id="formula_4">c 1 ,c 2 ∈C RD 1 [c1, c2] − RD 2 [c1, c2] = sup c 1 ,c 2 ∈C Ex∼D 1 [ℓ(c1(x), c2(x))] − Ex∼D 2 [ℓ(c1(x), c2(x))]<label>(3)</label></formula><p>denotes the discrepancy between distributions D 1 and D 2 , C is a selected class of functions and Id A : X A → X A and Id B : X B → X B are the identity functions over X A and X B (resp.). The discrepancy is similar to the WGAN divergence <ref type="bibr" target="#b0">[1]</ref>, where instead of 1-Lipschitz discriminators, we use discriminators of the form ℓ(c 1 (x), c 2 (x)), where c 1 , c 2 ∈ C. This discrepancy is implemented by a GAN, as in <ref type="bibr" target="#b9">[10]</ref>. As shown in <ref type="bibr" target="#b8">[9]</ref>, the circularity constraint does not eliminate the uncertainty in its entirety. In DistanceGAN <ref type="bibr" target="#b1">[2]</ref>, the circularity was replaced by a multidimensional scaling type of constraint, which enforces a high correlation between the distances in the two domains. However, since these constraints hold only approximately, the ambiguity is not completely eliminated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Simplicity Principle</head><p>In order to understand how the recent unsupervised image mapping methods work despite the inherent ambiguity, <ref type="bibr" target="#b8">[9]</ref> recently showed that the target ("semantic") mapping y AB is typically the distribution preserving mapping (h • D A = D B ) with the lowest complexity. It was shown that such mappings are expected to be unique.</p><p>As a motivating example to the key role of minimal mappings, consider the domain A of uniformly distributed points (x 1 , x 2 ) ⊤ ∈ R 2 , where</p><formula xml:id="formula_5">x 1 = x 2 ∈ [−1, 1]. Let B be the domain of uniformly distributed points in {(x 1 , x 2 ) ⊤ |x 1 ∈ [0, 1], x 2 = 0} ∪ {(x 1 , x 2 ) ⊤ |x 2 ∈ [0, 1], x 1 = 0}.</formula><p>We note that there are infinitely many mappings from domain A to B that, given inputs in A, result in the uniform distribution of B and satisfy the circularity constraint (Eq. 2).</p><p>However, it is easy to see that when restricting the hypothesis class to neural networks with one layer of size 2, and ReLU activations σ, there are only two options left. In this case,</p><formula xml:id="formula_6">h(x) = σ a (W x), for W ∈ R 2×2 ,b ∈ R 2 .</formula><p>The only admissible solutions</p><formula xml:id="formula_7">are of the form W = a 1 − a b −1 − b or W ′ = a −1 − a b 1 − b , which are identical,</formula><p>for every a, b ∈ R, to one of the following functions:</p><formula xml:id="formula_8">y 1 AB ((x, x) ⊤ ) = (x, 0) ⊤ if x ≥ 0 (0, −x) ⊤ if x ≤ 0 and y 2 AB ((x, x) ⊤ ) = (0, x) ⊤ if x ≥ 0 (−x, 0) ⊤ if x ≤ 0<label>(4)</label></formula><p>Therefore, by restricting the hypothesis space to be minimal, we eliminate all alternative solutions, except two. These two are exactly the two mappings that would commonly be considered "more semantic" than any other mapping, see <ref type="figure" target="#fig_0">Fig. 1</ref>. Another motivating example can be found in <ref type="bibr" target="#b8">[9]</ref>. </p><formula xml:id="formula_9">(-1,0) (0,0) (1,0) (0,-1) (0,1) (-1,0) (0,0) (1,0) (0,-1) (0,1) (a) (b)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Occam's Razor</head><p>We note that the Simplicity Principle, presented in <ref type="bibr" target="#b8">[9]</ref>, is highly related to the principle known as Occam's razor. In this section we provide a definition of the Occam's razor property which extends the formulation of the Simplicity Principle used in <ref type="bibr" target="#b8">[9]</ref>. Our formulation is not limited to Kolmogorov-like complexity of multi-layered neural networks as in <ref type="bibr" target="#b8">[9]</ref> and is more general. Given two domains A = (X A , D A ) and B = (X B , D B ), a mapping y AB : X A → X B satisfies the Occam's razor property between domains A and B, if it has minimal complexity among the functions h :</p><formula xml:id="formula_10">X A → X B that satisfy h • D A ≈ D B .</formula><p>Minimal complexity is defined by the nesting of hypothesis classes, which forms a partial order, and not as a continuous score. For example, if H j is the set of neural networks of a specific architecture and H i is the set of neural networks of the architecture obtained after deleting one of the hidden neurons, then, H i ⊂ H j . Intuitively, minimal complexity would mean that there is no sub-class that can implement a mapping h :</p><formula xml:id="formula_11">X A → X B such that h • D A ≈ D B .</formula><p>For this purpose, we define,</p><formula xml:id="formula_12">P(H; ǫ) := {G ∈ H | disc(G • D A , D B ) ≤ ǫ}.</formula><p>Definition 1 (Occam's razor property). Let A = (X A , D A ) and B = (X B , D B ) be two domains and U = {H i } i∈I be a family of hypothesis classes. A mapping y AB :</p><formula xml:id="formula_13">X A → X B satisfies an (ǫ 1 , ǫ 2 )-Occam's razor property if for every H ∈ U such that P(H; ǫ 1 ) = ∅, we have: inf G∈P(H;ǫ1) R D A [G, y AB ] ≤ ǫ 2 .</formula><p>Informally, according to Def. 1, a function satisfies the Occam's razor property, if it can be approximated by even the lowest-complexity hypothesis classes that successfully map between the domains A and B. If y AB has the (ǫ 1 , ǫ 2 )-Occam's razor property, then it is ǫ 2 -close to a function in every minimal hypothesis class H ∈ U such that P(H; ǫ 1 ) = ∅. As the hypothesis class H grows, so does P(H; ǫ 1 ), i.e., H i ⊂ H j implies that P(H i ; ǫ 1 ) ⊂ P(H j ; ǫ 1 ). Therefore, the growing P(H; ǫ 1 ) would always con-tain at least one function that is ǫ 2 -close to y AB . Nevertheless, as the hypothesis class grows, P(H; ǫ 1 ) can potentially contain many functions f that satisfy f • D A ≈ D B and differ from each other, causing an increased amount of ambiguity. In addition, we note that uniqueness is not assumed, and the property may hold for multiple mappings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Estimating the Ground Truth Error</head><p>In this section, we introduce a bound on the generalization risk between a given function G 1 ∈ H and an unknown target function y AB , i.e.,</p><formula xml:id="formula_14">R D A [G 1 , y AB ].</formula><p>This bound is based on a bias-variance decomposition and sums two terms: the bias error and the approximation error. The bias error is the maximal risk possible with a member G 2 of the class P(H; ǫ 1 ), i.e., sup</p><formula xml:id="formula_15">G2∈P(H;ǫ1) R D A [G 1 , G 2 ].</formula><p>The approximation error is the minimal possible risk between a member G of the class P(H; ǫ 1 ) with respect to y AB , i.e., inf</p><formula xml:id="formula_16">G∈P(H;ǫ1) R D A [G, y AB ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Derivation of the Bound and the Algorithms</head><p>The bound is a consequence of using a loss ℓ that satisfies the triangle inequality. Losses of this type include the L 1 loss, which is often used in cross domain mapping. The L 2 loss and the perceptual loss <ref type="bibr" target="#b13">[14]</ref> satisfy the triangle inequality up to a factor of three, which would incur the addition of a factor into the bound. The following Lem. 1 provides an upper bound on the generalization risk.</p><formula xml:id="formula_17">Lemma 1. Let A = (X A , D A ) and B = (X B , D B )</formula><p>be two domains, U = {H i } i∈I be a family of hypothesis classes and ǫ 1 &gt; 0. In addition, assume that ℓ is a loss function that satisfies the triangle inequality. Then, for all H ∈ U such that P(H; ǫ 1 ) = ∅ and two functions y AB and G 1 , we have:</p><formula xml:id="formula_18">RD A [G1, yAB] ≤ sup G 2 ∈P(H;ǫ 1 ) RD A [G1, G2] + inf G∈P(H;ǫ 1 ) RD A [G, yAB]<label>(5)</label></formula><p>Proof. Let G * = arg inf</p><formula xml:id="formula_19">G∈P(H;ǫ1) R D A [G, y AB ].</formula><p>By the triangle inequality, we have:</p><formula xml:id="formula_20">RD A [G1, yAB] ≤RD A [G1, G * ] + RD A [G * , yAB] ≤ sup G 2 ∈P(H;ǫ 1 ) RD A [G1, G2] + inf G∈P(H;ǫ 1 ) RD A [G, yAB]<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>⊓ ⊔</head><p>If y AB satisfies Occam's razor, then the approximation error is lower than ǫ 2 and by Eq. 5 in Lem. 1 the following bound is obtained:</p><formula xml:id="formula_21">RD A [G1, yAB] ≤ sup G 2 ∈P(H;ǫ 1 ) RD A [G1, G2] + ǫ2<label>(7)</label></formula><p>Eq. 7 provides us with an accessible bound for the generalization risk. The right hand side can be directly approximated by training a neural network G 2 that has a discrepancy lower than ǫ 1 and has the maximal risk with regards to G 1 , i.e.,</p><formula xml:id="formula_22">sup G 2 ∈H RD A [G1, G2] s.t: disc(G2 • DA, DB) ≤ ǫ1<label>(8)</label></formula><p>Algorithm 1 Deciding when to stop training G 1</p><p>Require: SA and SB: unlabeled training sets; H: a hypothesis class; ǫ1: a threshold; λ: a tradeoff parameter; T2: a fixed number of epochs for G2; T1: a maximal number of epochs.</p><note type="other">1: Initialize G 0 1 ∈ H and G 0 2 ∈ H randomly. 2: for i = 1, ..., T1 do 3: Train G i−1 1 for one epoch to minimize disc(G i−1 1 • DA, DB), obtaining G i 1 . 4: Train G i 2 for T2 epochs to minimize disc(</note><formula xml:id="formula_23">G i 2 • DA, DB) − λRD A [G i 1 , G i 2 ]. ⊲</formula><note type="other">T2 provides a fixed comparison point. 5: end for 6: return G t 1 such that: t = arg min</note><formula xml:id="formula_24">i∈[T ] RD A [G i 1 , G i 2 ].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Model Selection</head><p>Require: SA and SB: unlabeled training sets; U = {Hi}i∈I : a family of hypothesis classes; ǫ: a threshold; λ: a trade-off parameter.</p><formula xml:id="formula_25">1: Initialize J = ∅. 2: for i ∈ I do 3:</formula><p>Train</p><formula xml:id="formula_26">G i 1 ∈ Hi to minimize disc(G i 1 • DA, DB). 4: if disc(G i 1 • DA, DB) ≤ ǫ then 5: Add i to J. 6: Train G i 2 ∈ Hi to minimize disc(G i 2 • DA, DB) − λRD A [G i 1 , G i 2 ]. 7:</formula><p>end if 8: end for 9:</p><formula xml:id="formula_27">return G i 1 such that: i = arg min j∈J RD A [G j 1 , G j 2 ].</formula><p>In general, it is computationally impossible to compute the exact solution h 2 to Eq. 8 since in most cases we cannot explicitly compute the set P(H; ǫ 1 ). Therefore, inspired by Lagrange relaxation, we employ the following relaxed version of Eq. 8:</p><formula xml:id="formula_28">min G 2 ∈H disc(G2 • DA, DB) − λRD A [G1, G2]<label>(9)</label></formula><p>where λ &gt; 0 is a trade-off parameter. Therefore, instead of computing Eq. 8, we maximize the dual form in Eq. 9 with respect to G 2 . In addition, we optimize λ to be the maximal values such that disc(</p><formula xml:id="formula_29">G 2 • D A , D B ) ≤ ǫ 1 is still satisfied. The expectation over x ∼ D A (resp x ∼ D B )</formula><p>in the risk and discrepancy are replaced, as is often done, with the sum over the training samples in domain A (resp B). Based on this, we present a stopping criterion in Alg. 1, and a method for hyperparameter selection in Alg. 2. Eq. 9 is manifested in Step 4 of the former and Step 6 of the latter is the selection criterion that appears as the last line of both algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Bound on the Loss of Each Sample</head><p>We next extend the bound to estimate the error ℓ(G 1 (x), y AB (x)) of mapping by G 1 a specific sample x ∼ D A . Lem. 2 follows very closely to Lem. 1. It gives rise to a simple method for bounding the loss of G 1 on a specific sample x. Note that the second Algorithm 3 Bounding the loss of G 1 on sample x</p><p>Require: SA and SB: unlabeled training sets; H: a hypothesis class; G1 ∈ H: a mapping; λ: a trade-off parameter; x: a specific sample. 1: Train G2 ∈ H to minimize disc(G2 • DA, DB) − λℓ(G1(x), G2(x)). 2: return ℓ(G1(x), G2(x)).</p><p>term in the bound does not depend on G 1 and is expected to be small, since it denotes the capability of overfitting on a single sample x. </p><formula xml:id="formula_30">ℓ(G 1 (x), y AB (x)) ≤ sup G2∈P(H;ǫ) ℓ(G 1 (x), G 2 (x)) + inf G∈P(H;ǫ) ℓ(G(x), y AB (x))<label>(10)</label></formula><p>Similarly to the analysis done in Sec. 3, Eq. 10 provides us with an accessible bound for the generalization risk. The RHS can be directly approximated by training a neural network G 2 of a discrepancy lower than ǫ and has maximal loss with regards to G 1 , i.e.,</p><formula xml:id="formula_31">sup G2∈H ℓ(G 1 (x), G 2 (x)) s.t: disc(G 2 • D A , D B ) ≤ ǫ<label>(11)</label></formula><p>With similar considerations as in Sec. 3, we replace Eq. 11 with the following objective:</p><formula xml:id="formula_32">min G2∈H disc(G 2 • D A , D B ) − λℓ(G 1 (x), G 2 (x))<label>(12)</label></formula><p>As before, the expectation over x ∼ D A and x ∼ D B in the discrepancy are replaced with the sum over the training samples in domain A and B (resp.). In practice, we modify Eq. 12 such that x is weighted to half the weight of all samples, during the training of G 2 . This emphasizes the role of x and allows us to train G 2 for less epochs. This is important, as a different G 2 must be trained for measuring the error of each sample x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Deriving an Unsupervised Variant of Hyperband using the Bound</head><p>In order to optimize multiple hyperparameters simultaneously, we create an unsupervised variant of the hyperband method <ref type="bibr" target="#b15">[16]</ref>. Hyperband requires the evaluation of the loss for every configuration of hyperparameters. In our case, our loss is the risk function, R D A [G 1 , y AB ]. Since we cannot compute the actual risk, we replace it with our bound sup</p><formula xml:id="formula_33">G2∈P(H;ǫ1) R D A [G 1 , G 2 ].</formula><p>In particular, the function 'run then return val loss' in the hyperband algorithm (Alg. 1 of <ref type="bibr" target="#b15">[16]</ref>), which is a plug-in function for loss evaluation, is provided with our bound from Eq. 7 after training G 2 , as in Eq. 9. Our variant of this function is listed in Alg. 4. It employs two additional procedures that are used to store the learned models G 1 and G 2 at a certain point in the training process and to retrieve these to continue the training for a set amount of epochs. The retrieval function is simply a map between a vector of hypermarkets and a tuple of the learned networks and the number of epochs T when stored. For a new vector of hyperparameters, it returns T = 0 and two randomly initialized networks, with architectures that are determined by the given set of hyperparameters. When a network is retrieved, it is then trained for a number of epochs that is the difference between the required number of epochs T , which is given by the hyperband method, and the number of epochs it was already trained, denoted by T last .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We test the three algorithms on two unsupervised alignment methods: DiscoGAN <ref type="bibr" target="#b14">[15]</ref> and DistanceGAN <ref type="bibr" target="#b1">[2]</ref>. In DiscoGAN, we train G 1 (and G 2 ), using two GANs and two circularity constraints; in DistanceGAN, one GAN and one distance correlation loss are used. The published parameters for each dataset are used, except when applying our model selection method, where we vary the number of layers and when using hyperband, where we vary the learning rate and the batch size as well. In the experiments we employ the L 1 loss between G 1 and G 2 and between G 1 and y. In the supplementary we also use the perceptual loss. When running the experiments, the discrepancy is implemented by a GAN, i.e., the error of the discriminator d measures the discrepancy. The exact architectures are given in the supplementary. Five datasets were used in the experiments: (i) aerial photographs to maps, trained on data scraped from Google Maps <ref type="bibr" target="#b12">[13]</ref>, (ii) the mapping between photographs from the cityscapes dataset and their per-pixel semantic labels <ref type="bibr" target="#b4">[5]</ref>, (iii) architectural photographs to their labels from the CMP Facades dataset <ref type="bibr" target="#b19">[20]</ref>, (iv) handbag images <ref type="bibr" target="#b31">[32]</ref> to their binary edge images as obtained from the HED edge detector <ref type="bibr" target="#b28">[29]</ref>, and (v) a similar dataset for the shoe images from <ref type="bibr" target="#b30">[31]</ref>.</p><p>Throughout the experiments, fixed values are used as the low-discrepancy threshold (ǫ 1 = 0.2). The tradeoff parameter between the dissimilarity term and the fitting term during the training of G 2 is set, per dataset, to be the maximal value such that the fitting of G 2 provides a solution that has a discrepancy lower than the threshold, disc(G 2 • D A , D B ) ≤ ǫ 1 . This is done once, for the default parameters of G 1 , as given in the original DiscoGAN and DistanceGAN <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b1">2]</ref>.</p><p>The results of all experiments are summarized in Tab. 1, which presents the correlation and p-value between the ground truth error, as a function of the independent variable, and the bound. The independent variable is either the training epoch, the architecture, or the sample, depending on the algorithm tested. For example, in Alg. 2 we wish to decide on the best architecture, the independent variable is the number of <ref type="table">Table 1</ref>: Pearson correlations and the corresponding p-values (in parentheses) of the ground truth error with: (i) the bound, (ii) the GAN losses, and (iii) the circularity losses or (iv) the distance correlation loss.</p><p>* The cycle loss A → B → A is shown for DiscoGAN and the distance correlation loss is shown for DistanceGAN. , in order to demonstrate that these are much less correlated with the ground truth error. In the plots of <ref type="figure" target="#fig_1">Fig. 2</ref>, we omit the other scores in order to reduce clutter. <ref type="figure" target="#fig_1">Fig 2 (all four columns)</ref>, can be used to quantify the gain from using the two algorithms. The "regret" when using the algorithm is simply the ground truth error at the minimal value of the bound minus the minimal ground truth error. Stopping Criterion (Alg. 1) For testing the stopping criterion suggested in Alg. 1, we compared, at each time point, two scores that are averaged over all training samples: ||G 1 (x)−G 2 (x)|| 1 , which is our bound, and the ground truth error ||G 1 (x)−y AB (x)|| 1 , where y AB (x) is the ground truth image that matches x in domain B. Note that similar to the experiments with ground truth in the literature <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b1">2]</ref>, the ground truth error is measured in the label space and not in the image domain. The mapping in the other direction y BA is not one to one.</p><p>The results are depicted in the main results table (Tab. 1) as well as in <ref type="figure" target="#fig_1">Fig. 2</ref> for both DiscoGAN (first column) and DistanceGAN (second column). As can be seen, there is an excellent match between the mean ground truth error of the learned mapping G 1 and the predicted error. No such level of correlation is present when considering the GAN losses or the reconstruction losses (for DiscoGAN), or the distance correlation loss of DistanceGAN. Specifically, the very low p-values in the first column of Tab. 1 show that there is a clear correlation between the ground truth error and our bound for all datasets. For the other columns, the values in question are chosen to be the losses used for G 1 . The lower scores in these columns show that none of these values are as correlated with the ground truth error, and so cannot be used to estimate this error.</p><p>In the experiment of Alg. 1 for DiscoGAN, which has a large number of sample points, the cycle from B to A and back to B is significantly correlated with the ground truth error with very low p-values in four out of five datasets. However, its correlation is significantly lower than that of our bound. In <ref type="figure" target="#fig_1">Fig. 2</ref>, the Facades graph shows a different behavior than the other graphs. This is because the Facades dataset is inherently ambiguous and presents multiple possible mappings from A to B. Each mapping satisfies the Occam's razor property separately. Selecting Architecture using Alg. 2 Next we vary the number of layers of G and consider its effect on the risk by measuring the bound and the ground truth error (which cannot be computed in an unsupervised way); A large correlation between our bound and the ground truth error is observed, see Tab. 1 and <ref type="figure" target="#fig_1">Fig. 2</ref>, columns 3 and 4. We can therefore optimize the number of layers based on our bound. With a much smaller number of sample points, the p-values are generally higher than in the previous experiment. Predicting per-Sample Loss with Alg. 3 Finally, we consider the per sample loss. The results are reported numerically in Tab. 1 and plotted in Figs. 3 and 4. As can be seen, there is a high degree of correlation between the measured bound and the ground truth error. Therefore, our method is able to reliably predict the per-sample success of a multivariate mapping learned in a fully unsupervised manner.</p><p>Remarkably, this correlation also seems to hold when considering the time axis, i.e., we can combine Alg. 1 and Alg. 3 and select the stopping epoch that is best for a specific sample. The results are shown in the supplementary. Selecting Architecture with the Modified Hyperband Algorithm Our bound is used in Sec. 3.3 to create an unsupervised variant of the hyperband method. In comparison to Alg. 2, this allows for the optimization of multiple hyperparameters at once, while enjoying the efficient search strategy of the hyperband method.   <ref type="figure" target="#fig_8">6</ref> demonstrates the applicability of our unsupervised hyperband-based method for different datasets, employing both DiscoGAN and DistanceGAN. The graphs show the error and the bound obtained for the selected configuration after up to 35 hyperband iterations. As can be seen, in all cases, the method is able to recover a configuration that is significantly better than what is recovered, when only optimizing for the number of layers. To further demonstrate the generality of our method, we applied it on the UNIT <ref type="bibr" target="#b16">[17]</ref> architecture. As the runtime of UNIT is much higher than DiscoGAN and DistanceGAN, this did not allow for extensive experimentation. We therefore focused on the most useful application of applying hyperband on a relatively complex dataset, specifically Maps. <ref type="figure" target="#fig_6">Fig. 5</ref> and Tab. 6(b) show the convergence on the hyperband method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We extend the envelope of what is known to be possible in unsupervised learning by showing that we can reliably predict the error of a cross-domain mapping that was trained without matching samples. This is true both in expectation, with application to hyperparameter selection, and per sample, thus supporting dynamic confidence-based run time behavior, and (future work) unsupervised boosting during training.</p><p>The method is based on measuring the maximal distance within the set of low discrepancy mappings. This measure becomes the bound by applying what we define as the Occam's razor property, which is a general form of the Simplicity Principle. Therefore, the clear empirical success observed in our experiments supports the recent hypothesis that simplicity plays a key role in unsupervised learning.</p><p>For an extended version of this work, which is more rigorous than what can be provided here, and which also handles the non-deterministic case, please see <ref type="bibr" target="#b7">[8]</ref>.  1st column is the input, the 2nd is the result of DiscoGAN's default configuration, 3rd is the result of the configuration selected by our unsupervised Hyperband.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: An illustrative example, where the two domains are the blue and green areas. There are infinitely many mappings that preserve the uniform distribution on the two domains. However, only two stand out as "semantic". These two, which are depicted in red, are exactly the two mappings that can be captured by a minimal neural network with ReLU activations. (a) the mapping y 1 AB . (b) the mapping y 2 AB (see Eq. 4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Lemma 2 .</head><label>2</label><figDesc>Let A = (X A , D A ) and B = (X B , D B ) be two domains and H a hypothe- sis class. In addition, let ℓ be a loss function satisfying the triangle inequality. Then, for any target function y AB and G 1 ∈ H, we have:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 4</head><label>4</label><figDesc>Unsupervised run then return val loss for hyperband Require: SA, SB, and λ as before. T : Number of epochs. θ: Set of hyperparameters 1: [G1, G2, Tlast] = return stored functions(θ) 2: Train G1 for T − Tlast epochs to minimize disc(G1 • DA, DB). 3: Train G2 for T − Tlast epochs to minimize disc(G2 • DA, DB) − λRD A [G1, G2]. 4: store functions(θ, [G1, G2, T ]) 5: return RD A [G1, G2].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>. A high correlation (low p-value) between the bound and the ground truth error, both as a function of the number of layers, indicates the validity of the bound and the utility of the algorithm. Similar correlations are shown with the GAN losses and the reconstruction losses (DiscoGAN) or the distance correlation loss (DistanceGAN)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Results of Alg. 1, 2. Ground truth errors are in red and bound in black. x-axis is the iteration or number of layers. y-axis is expected risk. For Alg. 1 it takes a few epochs for G 1 to have a small enough discrepancy, until which the bound is ineffective.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 :Fig. 4 :</head><label>34</label><figDesc>Fig. 3: Results of Alg. 3. Results shown for DiscoGAN. Results for DistanceGAN are shown in supplementary due to lack of space. The ground truth errors (x-axis) vs. bound (y-axis) are shown per point. The coefficient of determination is shown (top right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Applying unsupervised hyperband for selecting the best configuration for UNIT for the Maps dataset. (a) blue and orange lines are bound and ground truth error as in Fig. 6. (b) Images produced for 3 different configurations as indicated on the plot in (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.</head><label></label><figDesc>Fig. 6 demonstrates the applicability of our unsupervised hyperband-based method for different datasets, employing both DiscoGAN and DistanceGAN. The graphs show the error and the bound obtained for the selected configuration after up to 35 hyperband iterations. As can be seen, in all cases, the method is able to recover a configuration that is significantly better than what is recovered, when only optimizing for the number of layers. To further demonstrate the generality of our method, we applied it on the UNIT [17] architecture. As the runtime of UNIT is much higher than DiscoGAN and DistanceGAN, this did not allow for extensive experimentation. We therefore focused on the most useful application of applying hyperband on a relatively complex dataset, specifically Maps. Fig. 5 and Tab. 6(b) show the convergence on the hyperband method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6 :</head><label>6</label><figDesc>Fig. 6: Applying unsupervised hyperband for selecting the best configuration. For DiscoGAN and DistanceGAN we optimize of the number of encoder and decoder layers, batch size and learning rate while for UNIT, we optmized for the number of encoder and decoder Layers, number of resnet layers and learning rate. (a) For each dataset, the first plot is of DiscoGAN and the second is of DistanceGAN. Hyperband optimizes according to the bound values indicated in blue. The corresponding ground truth errors are shown in orange. Dotted lines represent the best configuration errors, when varying only the number of layers without hyperband (blue for bound and orange for ground truth error). Each graph shows the error of the best configuration selected by hyperband as a function the number of hyperband iterations. (b) The corresponding hyperparameters of the best configuration as selected by hyperband. (c) Images produced for DiscoGAN's shoes2edges: 1st column is the input, the 2nd is the result of DiscoGAN's default configuration, 3rd is the result of the configuration selected by our unsupervised Hyperband.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant ERC CoG 725974). The contribution of Sagie Benaim is part of Ph.D. thesis research conducted at Tel Aviv University.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">One-sided unsupervised domain mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Benaim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Optimizing the latent space of generative networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.05776</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02644</idno>
		<title level="m">Generating images with perceptual similarity metrics based on deep networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards an empirical foundation for assessing bayesian optimization of hyperparameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eggensperger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS workshop on Bayesian Optimization in Theory and Practice</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Generalization bounds for unsupervised cross-domain mapping with wgans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Galanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Benaim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.08501</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The role of minimal complexity functions in unsupervised learning of semantic mappings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Galanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Benaim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Generative adversarial nets. In: NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sequential model-based optimization for general algorithm configuration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning and Intelligent Optimization</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Perceptual losses for real-time style transfer and superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning to discover cross-domain relations with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.05192</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desalvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06560</idno>
		<title level="m">Efficient hyperparameter optimization and infinitely many armed bandits</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Unsupervised image-to-image translation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Coupled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="469" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.1784</idno>
		<title level="m">Conditional generative adversarial nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Spatial pattern templates for recognition of objects with regular structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Š</forename><surname>Radim Tyleček</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. GCPR</title>
		<meeting>GCPR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Probability and statistics risk bounds for mixture density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rakhlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ESAIM: Probab. Statist</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Generative adversarial text to image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">ICML</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Pac-bayesian generalization bound for density estimation with application to co-clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Seldin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>AISTATS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unsupervised cross-domain image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Polyak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Auto-weka: Combined selection and hyperparameter optimization of classification algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Thornton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>KDD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unsupervised creation of parameterized avatars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Polyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.00179</idno>
		<title level="m">Dual learning for machine translation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Holistically-nested edge detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">DualGAN: Unsupervised dual learning for image-toimage translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.02510</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Fine-grained visual comparisons with local learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Generative visual manipulation on the natural image manifold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycleconsistent adversarial networkss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10593</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
