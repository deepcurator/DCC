<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader>
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T22:25+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recurrent Convolutional Neural Network for Object Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liang</surname></persName>
							<email>liangm07@mails.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology Center for Brain-Inspired Computing Research (CBICR)</orgName>
								<orgName type="laboratory">State Key Laboratory of Intelligent Technology and Systems Tsinghua National Laboratory for Information Science and Technology (TNList)</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Hu</surname></persName>
							<email>xlhu@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology Center for Brain-Inspired Computing Research (CBICR)</orgName>
								<orgName type="laboratory">State Key Laboratory of Intelligent Technology and Systems Tsinghua National Laboratory for Information Science and Technology (TNList)</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Recurrent Convolutional Neural Network for Object Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract xml:lang="en">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>In recent years, the convolutional neural network (CNN) has achieved great success in many computer vision tasks. Partially inspired by neuroscience, CNN shares many properties with the visual system of the brain. A prominent difference is that CNN is typically a feed-forward architecture while in the visual system recurrent connections are abundant. Inspired by this fact, we propose a recurrent CNN (RCNN) for object recognition by incorporating recurrent connections into each convolutional layer. Though the input is static, the activities of RCNN units evolve over time so that the activity of each unit is modulated by the activities of its neighboring units. This property enhances the ability of the model to integrate the context information, which is important for object recognition. Like other recurrent neural networks, unfolding the RCNN through time can result in an arbitrarily deep network with a fixed number of parameters. Furthermore, the unfolded network has multiple paths, which can facilitate the learning process. The model is tested on four benchmark object recognition datasets: CIFAR-10, CIFAR-100, MNIST and SVHN. With fewer trainable parameters, RCNN outperforms the state-of-the-art models on all of these datasets. Increasing the number of parameters leads to even better performance. These results demonstrate the advantage of the recurrent structure over purely feed-forward structure for object recognition.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text>
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The past few years have witnessed the bloom of convolutional neural network (CNN) in computer vision. Over many benchmark datasets CNN has substantially advanced the state-of-the-art accuracies of object recognition <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b42">43]</ref>. For example, after training on 1.2 million images from ImageNet <ref type="bibr" target="#b7">[8]</ref>, CNN <ref type="bibr" target="#b25">[26]</ref> has achieved better performance than handcraft features by a significant margin in classifying objects into 1000 categories. Furthermore, the pretrained CNN features on this dataset have been transfered to other datasets to achieve remarkable results <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b42">43]</ref>.</p><p>CNN is a type of artificial neural network, which originates from neuroscience dating back to the proposal of the first artificial neuron in 1943 <ref type="bibr" target="#b33">[34]</ref>. In fact, CNN, as well as other hierarchical models including Neocognitron <ref type="bibr" target="#b12">[13]</ref> and HMAX <ref type="bibr" target="#b37">[38]</ref>, is closely related to Hubel and Wiesel's findings about simple cells and complex cells in the primary visual cortex (V1) <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b21">22]</ref>. All of these models have purely feed-forward architectures, which can be viewed as crude approximations of the biological neural network in the brain. Anatomical evidences have shown that recurrent connections ubiquitously exist in the neocortex, and recurrent synapses typically outnumber feed-forward and topdown (or feedback) synapses <ref type="bibr" target="#b5">[6]</ref>. Due to the presence of recurrent and top-down synapses, object recognition is actually a dynamic process though the input is static. Specific functions of these synapses remain unclear, but it is generally believed that recurrent synapses play an important role in context modulation. The processing of visual signals is strongly modulated by their context <ref type="bibr" target="#b0">[1]</ref>. Normally we do not perceive this effect without attention, but the effect gets prominent in perceptual illusions, e.g., the famous Fraser spiral illusion <ref type="bibr" target="#b11">[12]</ref>. Context modulation is also observed in the responses of individual neurons in the visual system. For instance, the response properties of V1 neurons can be altered in many ways by changing the context around their classical receptive fields (RFs) <ref type="bibr" target="#b41">[42]</ref>. This phenomenon is suggested to be induced by recurrent synapses in V1 <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b53">54]</ref>.</p><p>The context is important for object recognition ( <ref type="figure">Figure  1)</ref>. A feed-forward model can only capture the context (e.g., the face in <ref type="figure">Figure 1</ref>) in higher layers where units have larger RFs, but this information cannot modulate the activities of units in lower layers responsible for recognizing smaller ob- <ref type="figure">Figure 1</ref>. Importance of context for object recognition. Without the context (face), it is hard to recognize the black curve in the middle area as a nose.</p><p>jects (e.g., the nose in <ref type="figure">Figure 1</ref>). To utilize this information, one strategy is to use top-down (or feedback) connections to propagate it downwards <ref type="bibr" target="#b31">[32]</ref>, which is adopted in the convolutional deep belief networks (CDBN) <ref type="bibr" target="#b30">[31]</ref>. In this study, we take a different strategy, that is, use recurrent connections within the same layer of deep learning models. It is expected that, equipped with context modulation ability, these lateral connections may boost the performance of deep learning models.</p><p>In the paper, we present a recurrent CNN for static object recognition. The architecture is illustrated in <ref type="figure">Figure  2</ref>, where both feed-forward and recurrent connections have local connectivity and shared weights among different locations. This architecture is very similar to the recurrent multilayer perceptron (RMLP) which is often used for dynamic control <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b36">37]</ref>  <ref type="figure">(Figure 2</ref>, middle). The main difference is that the full connections in RMLP are replaced by shared local connections, just as the difference between MLP <ref type="bibr" target="#b39">[40]</ref> and CNN. For this reason, the proposed model is called the recurrent convolutional neural network (RCNN).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN RMLP RCNN</head><p>Feed-forward connection Recurrent connection <ref type="figure">Figure 2</ref>. Illustration of the architectures of CNN, RMLP and RCNN. For each model two hidden layers are shown.</p><p>The proposed RCNN was tested on several benchmark object recognition datasets. With fewer parameters, RCNN achieved better results than the state-of-the-art CNNs over all of these datasets, which validates the advantage of RCNN over CNN. The remaining content is organized as follows. Section 2 reviews some related work. Section 3 describes the architecture of RCNN. Section 4 presents the experimental results and analysis. Finally, Section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Convolutional neural networks</head><p>Inspired by Hubel and Wiesel's breakthrough findings in cat <ref type="bibr" target="#b22">[23]</ref>[22], Fukushima <ref type="bibr" target="#b12">[13]</ref> proposed a hierarchical model called Neocognitron, which consisted of stacked pairs of simple unit layer and complex unit layer. The first CNN was proposed by LeCun et al. <ref type="bibr" target="#b27">[28]</ref> <ref type="bibr" target="#b26">[27]</ref>. Essentially CNN differs from the Neocognitron by incorporating the backpropagation (BP) algorithm for learning the receptive fields of simple units. Since its birth, CNN has been characterized by local connections, weight sharing and local pooling. The first two properties enable the model to discover local informative visual patterns with fewer adjustable parameters than MLP. The third property equips the network with some translation invariance. As suggested by Saxe et al. <ref type="bibr" target="#b40">[41]</ref>, the excellent performance of CNN can be largely attributed to these properties as certain structures with random weights could also achieve good results.</p><p>Over the past years, many techniques have have been developed for improving the performance of CNN. The rectified linear function <ref type="bibr" target="#b13">[14]</ref> becomes the most commonly used activation function due to its resistance to the notorious gradient vanishing effect in the BP algorithm. Dropout <ref type="bibr" target="#b47">[48]</ref> is an effective technique to prevent neural networks from overfitting in training. To leverage the model averaging ability of dropout, Goodfellow et al. <ref type="bibr" target="#b16">[17]</ref> used max pooling over feature channels as the activation function. To strengthen the nonlinearity of convolutional units, Lin et al. <ref type="bibr" target="#b32">[33]</ref> proposed the network in network (NIN) structure, in which convolution was replaced by the local multilayer perceptron (MLP) <ref type="bibr" target="#b38">[39]</ref> sliding over input feature maps. To prevent NIN from over-fitting, the fully connected layers were replaced by the global average pooling layer. Simonyan and Zisserman <ref type="bibr" target="#b43">[44]</ref> used 3 × 3 convolutions to build very deep networks, considering that a stack of small filters have stronger nonlinearity than a large filter with the same amount of parameters. Szegedy et al. <ref type="bibr" target="#b49">[50]</ref> proposed the multi-scale inception modules and built the GoogLeNet based on them. Small filters were also favored in this model. CNN is a computation-intensive model and is usually hard to run on CPU. The use of GPU has greatly facilitated the training and testing of CNN on large-scale datasets. The first successful GPU implementation of CNN refers to the AlexNet <ref type="bibr" target="#b25">[26]</ref> which won the recognition competition in the ImageNet <ref type="bibr" target="#b7">[8]</ref> Large Scale Visual Recognition Challenge (ILSVRC) 2012. Since then, most submissions to this annual competition were based on GPU implemented CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Recurrent neural networks</head><p>Recurrent neural network (RNN) has a long history in the artificial neural network community <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b23">24]</ref>, but most successful applications refer to the modeling of sequential data such as handwriting recognition <ref type="bibr" target="#b17">[18]</ref> and speech recognition <ref type="bibr" target="#b18">[19]</ref>. A few studies about RNN for static visual signal processing are briefly reviewed below.</p><p>In <ref type="bibr" target="#b19">[20]</ref> a multi-dimensional RNN (MDRNN) is proposed for off-line handwriting recognition. MDRNN has a directed structure in that it treats the image as 2D sequential data. Furthermore, MDRNN has a single hidden layer, which cannot produce the feature hierarchy as CNN.</p><p>In <ref type="bibr" target="#b1">[2]</ref> a hierarchical RNN called the Neural Abstraction Pyramid (NAP) is proposed for image processing. NAP is a biology-inspired architecture with both vertical and lateral recurrent connectivity, through which the image interpretation is gradually refined to resolve visual ambiguities. In designing the structure, biological plausibility is stressed. For example, it employs excitatory and inhibitory units, which are not considered in most deep learning models. It is unclear whether these more biologically plausible techniques would make NAP more effective than state-ofthe-art deep learning models. More importantly, though the general framework of NAP has recurrent and feedback connections, for object recognition only a feed-forward version was tested. The recurrent NAP was used for other tasks such as image reconstruction.</p><p>Besides NAP, top-down connections have been used in some other hierarchical models. Lee et al. <ref type="bibr" target="#b30">[31]</ref> proposed CDBN for unsupervised feature learning. During inference the information in the top layer could be propagated to the bottom layer through the intermediate layers between them. Different from this layer-by-layer propagation idea, Pinheiro and Collobert <ref type="bibr" target="#b35">[36]</ref> used extra connections from the top layer to the bottom layer of a CNN directly. This model was used for scene labeling. These models are different from RCNN where recurrent connections exist within the same layer, not between layers.</p><p>There is an interesting relationship between RCNN and some sparse coding models <ref type="bibr" target="#b14">[15]</ref> where fixed-point updates are used in inference. The iterative optimization procedures implicitly define recurrent neural networks. Note that supervised learning techniques can be incorporated into the unsupervised learning framework of sparse coding models <ref type="bibr" target="#b2">[3]</ref>. But these techniques have not made the sparse coding models competitive with CNN for object recognition.</p><p>Finally, our model is also related to the recursive neural network <ref type="bibr" target="#b45">[46]</ref>, in which a recursive layer is unfolded to a stack of layers with tied weights. Socher et al. <ref type="bibr" target="#b44">[45]</ref> used a recursive neural network to perform scene parsing. Eigen et al. <ref type="bibr" target="#b8">[9]</ref> studied the factors that influence the performance of CNN by employing a recursive convolutional neural network, which is equivalent to the time-unfolded version of RCNN but without feed-forward input to each unfolded layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RCNN Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Recurrent convolutional layer</head><p>The key module of RCNN is the recurrent convolutional layer (RCL). The states of RCL units evolve over discrete time steps. For a unit located at (i, j) on the kth feature map in an RCL, its net input z ijk (t) at time step t is given by:</p><formula xml:id="formula_0">z ijk (t) = (w f k ) T u (i,j) (t) + (w r k ) T x (i,j) (t − 1) + b k . (1)</formula><p>In the equation u (i,j) (t) and x (i,j) (t − 1) denote the feedforward and recurrent input, respectively, which are the vectorized patches centered at (i, j) of the feature maps in the previous and current layer, w f k and w r k denote the vectorized feed-forward weights and recurrent weights, respectively, and b k is the bias. The first term in (1) is used in standard CNN and the second term is induced by the recurrent connections.</p><p>The activity or state of this unit is a function of its net input</p><formula xml:id="formula_1">x ijk (t) = g(f (z ijk (t))),<label>(2)</label></formula><p>where f is the rectified linear activation function</p><formula xml:id="formula_2">f (z ijk (t)) = max(z ijk (t), 0),<label>(3)</label></formula><p>and g is the local response normalization (LRN) function <ref type="bibr" target="#b25">[26]</ref> </p><formula xml:id="formula_3">g(f ijk (t)) = f ijk (t)   1 + α N min(K,k+N/2) k =max(0,k−N/2) (f ijk ) 2   β (4)</formula><p>where K is the total number of feature maps in the current layer. Note that in the denominator in (4) the sum runs over N feature maps at the same location (i, j) (usually N &lt; K), and α and β are constants controlling the amplitude of normalization. In addition f (z ijk (t)) has been abbreviated as f ijk (t). LRN mimics the lateral inhibition in the cortex, where different features compete for large responses. LRN is used in our model for preventing the states from exploding.</p><p>Equations <ref type="formula">(1)</ref> and <ref type="formula" target="#formula_1">(2)</ref> describe the dynamic behavior of the RCL. Unfolding this layer for T time steps results in a feed-forward subnetwork of depth T + 1. See the top left of <ref type="figure" target="#fig_1">Figure 3</ref> for an example with T = 3. While the recurrent input evolves over iterations, the feed-forward input remains the same in all iterations. When t = 0 only the feedforward input is present. The subnetwork has several paths from the input layer to the output layer. The longest path goes through all unfolded recurrent connections (therefore  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Overall architecture</head><p>RCNN contains a stack of RCLs, optionally interleaved with max pooling layers. See <ref type="figure" target="#fig_1">Figure 3</ref> for the architecture used in this work. To save computation, layer 1 is the standard feed-forward convolutional layer without recurrent connections, followed by max pooling. On top of this, four RCLs are used with a max pooling layer in the middle. Between neighboring RCLs there are only feed-forward connections. Both pooling operations have stride 2 and size 3. The output of the fourth RCL follows a global max pooling layer, which outputs the maximum over every feature map, yielding a feature vector representing the image. This is different from the model in <ref type="bibr" target="#b25">[26]</ref> where fully connected layers are used or the models in <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b49">50]</ref> where global average pooling is used. Finally a softmax layer is used to classify the feature vectors to C categories whose output is given by</p><formula xml:id="formula_4">y k = exp w T k x k exp w T k x (k = 1, 2, ..., C)<label>(5)</label></formula><p>where y k is the predicted probability belonging to the kth category, and x is the feature vector generated by the global max pooling. Training is performed by minimizing the cross-entropy loss function using the backpropagation throught time (BPTT) algorithm <ref type="bibr" target="#b51">[52]</ref>. This is equivalent to using the standard BP algorithm on the time-unfolded network. The final gradient of a shared weight is the sum of its gradients over all time steps. If we unfold the recurrent connections for T time steps, the model becomes a very deep feed-forward network with 4(T + 1) + 2 parameterized layers, where T + 1 is the depth of each RCL. But 4(T + 1) + 2 is only the length of the longest path from the input layer to the output layer, and there are many other paths with different lengths. Among them the shortest path has length 6, which is the feedforward path bypassing all recurrent connections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Discussion</head><p>From the computational perspective, the recurrent connections in RCNN offer several advantages. First, they enable every unit to incorporate context information in an arbitrarily large region in the current layer. In fact, as the time steps increase, the state of every unit is influenced by other units in a larger and larger neighborhood in the current layer (equation <ref type="formula">(1)</ref>); as a consequence, the size of regions that the unit can "watch" in the input space also increases. In CNN, the size of the RFs of the units in the current layer is fixed, and "watching" a larger region is only possible for units in higher layers. But unfortunately the context seen by higher-level units cannot influence the states of the units in the current layer without top-down connections. Second, the recurrent connections increase the network depth while keep the number of adjustable parameters constant by weight sharing. This is consistent with the trend of modern CNN architecture: going deeper with relatively small number of parameters <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b49">50]</ref>. Note that simply increasing the depth of CNN by sharing weights between layers can result in the same depth and the same number parameters as RCNN, but such a model may not compete with RCNN in performance, as verified in our experiments (see Section 4.2.1). We attribute this fact to the difficulty in learning such a deep model. Then here comes the third advantage of RCNN -the time-unfolded RCNN is actually a CNN with multiple paths between the input layer to the output layer <ref type="figure" target="#fig_1">(Figure 3)</ref>, which may facilitate the learning. On one hand, the existence of longer paths makes it possible for the model to learn highly complex features. On the other hand, the existence of shorter paths may help gradient backpropagation during training. Multi-path is also used in <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b29">30]</ref>, but there extra objective functions are used in hidden layers to alleviate the difficulty in training deep networks, which are not used in RCNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Implementation</head><p>Many hyper-parameters may affect the performance of RCNN such as the numbers of feature maps and the filter size in each layer. We did not explore the best configuration. Instead, we limited the search in a constrained hyperparameter space. First, layers 1 to 5 were constrained to have the same number of feature maps K. As a consequence the model can be denoted by RCNN-K. For example, RCNN-96 indicates that each of the five layers has 96 feature maps. Second, the feed-forward filter size in layer 1 was 5 × 5, the feed-forward and recurrent filter sizes in layers 2 to 4 were all 3×3. So the total number of parameters of RCNN-K was approximately 72K 2 , which only accounted for the weights in RCLs because other layers had far fewer parameters.</p><p>The hyper-parameters of LRN in (4) were set as α = 0.001, β = 0.75 and N = K/8 + 1. Dropout <ref type="bibr" target="#b47">[48]</ref> was used after each RCL except layer 5, which was connected to the softmax layer. If the RCL was followed by a pooling layer, dropout was placed after pooling.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Overall settings</head><p>The RCNN was implemented using cuda-convnet2 <ref type="bibr" target="#b25">[26]</ref> developed by Alex krizhevsky. Experiments were run on two GPUs with data parallelism. The models were evaluated on four benchmark object classification datasets, CIFAR-10 <ref type="bibr" target="#b24">[25]</ref>, CIFAR-100 <ref type="bibr" target="#b24">[25]</ref>, MNIST <ref type="bibr" target="#b28">[29]</ref> and SVHN <ref type="bibr" target="#b34">[35]</ref>. We found that a few iterations of the dynamic process of RCNN were able to produce excellent results. Except on CIFAR-10, where different number of iterations were compared, on the other three datasets, the iteration number was set to 3.</p><p>The training procedure followed <ref type="bibr" target="#b25">[26]</ref>. The model was trained using the BPTT algorithm in combination with stochastic gradient descent. The initial learning rate was set heuristically and annealed according to a schedule predetermined on the validation set. When the accuracy stopped improving, the learning rate was decreased to its 1/10. Three annealing steps were used so that the final learning rate was 1/1000 of the initial value. The momentum for all datasets were fixed at 0.9. Weight decay was used as another regularizer besides dropout. All weights of the model were set to have the same decay term. Dropout probabilities and weight decay rate were tuned. For CIFAR-10, CIFAR100 and SVHN, the images were preprocessed by removing the per-pixel mean value calculated over the training set. For MNIST the raw images were used as input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">CIFAR-10</head><p>The CIFAR-10 dataset <ref type="bibr" target="#b25">[26]</ref> consists of 60000 color images of 32 × 32 pixels in 10 classes. The total dataset was split into 50000 training images and 10000 testing images. The last 10000 training images were used for validation. After the hyper-parameters were determined, the model was trained from scratch on all 50000 training images. We analyzed the properties of RCNN by comparing it with two baseline models. The first baseline model was constructed by removing the recurrent connections in RCNN, which becomes a conventional CNN. For fair comparison, we used more feature maps in each layer to make its number of parameters approximately the same as RCNN. To emphasize this point, the model was denoted by WCNN (wide CNN). Note that WCNN was similar to the VGG very deep model <ref type="bibr" target="#b43">[44]</ref> as most layers used 3 × 3 filters. The second baseline model was constructed by removing the recurrent connections in each RCL of RCNN but adding a cascade of duplicated convolutional layers. This was called recursive CNN <ref type="bibr" target="#b8">[9]</ref> or rCNN for short. The cascade of duplicated convolutional layers can be understood as the time-unfolded version of RCL starting at t = 1 without feed-forward input <ref type="figure" target="#fig_3">(Figure 4)</ref>. In other words in iterations of RCNN, the feedforward input (the first term in equation <ref type="formula">(1)</ref>) was always there, but in iterations of rCNN it was absent. Please compare the top-left of <ref type="figure" target="#fig_1">Figure 3</ref> and <ref type="figure" target="#fig_3">Figure 4</ref>. Note that rCNN had exactly the same number of parameters as RCNN.</p><p>RCNN-96 was used for comparison. Because cudaconvnet2 <ref type="bibr" target="#b25">[26]</ref> requires the number of filters to be multiples of 16, we selected WCNN-128 (0.6 million parameters) which has the closest complexity with RCNN-96 and rCNN-96 (0.67 million parameters). For both RCNN and rCNN, 1, 2 and 3 iterations were tested. <ref type="table">Table 1 shows the  comparison results.</ref> WCNN-128 achieved much better performance than rCNN in terms of testing accuracy. In fact, WCNN-128 already surpassed most of the models shown in <ref type="table">Table 2</ref>, which validates the effectiveness of extensive use of 3 × 3 filters <ref type="bibr" target="#b43">[44]</ref>. However, WCNN was significantly outperformed by RCNN with a few iterations.</p><p>More iterations in RCNN led to both lower training error and lower testing error, and more iterations in rCNN led to lower training error but higher testing error <ref type="table">(Table 1)</ref>. In fact, the training errors of the three rCNNs were even lower than the corresponding RCNNs. Clearly, overfitting has occurred in rCNN, a phenomenon also reported in <ref type="bibr" target="#b8">[9]</ref>. The comparison indicates that the multi-path structure of RCNN is less prone to overfitting than the chain structure of rCNN. We then compared RCNN with the state-of-the-art models on this dataset. Three models with different K's were tested: RCNN-96, RCNN-128 and RCNN-160. The number of iterations was set to 3. All of them outperformed existing models, and the performance was steadily improved with more features maps ( <ref type="table">Table 2</ref>). Among the existing models for comparison NIN and DSN had the fewest parameters, about 1 million. RCNN-96 had even fewer parameters, 0.67 million, but achieved better results. Note that the maxout networks, NIN and DSN pre-processed the data with global contrast normalization and ZCA whitening, while we simply subtracted the per-pixel mean value from the data.</p><p>Dropout played an important role for RCNN to achieve these remarkable results. Without dropout, the error rate of RCNN-96 was 13.56%, much higher than 9.31% with dropout. But this error rate was lower than that of NIN without dropout (14.51%).</p><p>We also tested RCNN when data was augmented with translations and horizontal reflections as in <ref type="bibr" target="#b16">[17]</ref>. In the training phase, crops of 24 × 24 pixels were randomly extracted from the original image and randomly horizontally reflected. In the testing phase, nine crops were uniformly extracted from the image so that the interval between neighboring crops was four pixels. All of the nine outputs were averaged to give the final output. RCNN-96 achieved significantly better result than the state-of-the-art models using much fewer parameters. And again, simply increasing K led to even better results. See <ref type="table">Table 2</ref>  CIFAR-100 has 100 classes of images in the same format as CIFAR-10. The two datasets have the same size, so the number of images in each CIFAR-100 class is only 1/10 of that in CIFAR-10. We tested three RCNNs without data augmentation. The same setting as in CIFAR-10 was adopted here without further tuning the hyper-parameters. Again RCNN-96 outperformed the state-of-the-art models with fewer parameters, and the performance kept improving by increasing K. MNIST <ref type="bibr" target="#b28">[29]</ref> is one of the most well known datasets in the machine learning community. It consists of hand written digits of 0 to 9. There are 60000 training images and 10000 testing images. The images are in gray scale with size 28 × 28 pixels. We compared RCNN with other models without data augmentation and model averaging techniques. This benchmark is much easier than the two CI-FAR datasets, and we preferred smaller Ks. The results are shown in <ref type="table">Table 4</ref>  <ref type="table">Table 5</ref>. Comparison with existing models on SVHN SVHN consists of real-world house numbers collected from Google Street View images. The dataset has two formats and we used the second format. Totally there are 630,420 color images of size 32 × 32 pixels, which are split into three sets. The training set contains 73,257 digits, the testing set contains 26,032 digits and an extra set contains 531,131 additional less difficult samples. Multiple digits may coexist in an image, and the task is to classify the center digit. We followed the training procedure described in <ref type="bibr" target="#b16">[17]</ref>. 400 samples per class were randomly selected from the training set, and 200 samples per class were randomly selected from the extra set. These samples composed the validation set. The other images in the training set and extra set composed the training set. The validation set was only used for tuning hyper-parameters and not used in training.</p><p>SVHN is much more difficult than MNIST due to large variations of color and brightness. Local contrast normalization was suggested to be an effective preprocessing step <ref type="bibr" target="#b52">[53]</ref> and was adopted by many models including the maxout networks, NIN, DSN and DropConnect. We only subtracted the mean value from each pixel. With this simple preprocessing step, RCNN-128 outperformed the state-ofthe-art models without data augmentation and two models with data augmentation (note that DropConnect used model averaging of five networks). See <ref type="table">Table 5</ref> for details. RCNN-128 had much fewer parameters than NIN (1.19 million versus 1.98 million), and increasing K kept improving the accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Inspired by the fact of abundant recurrent synapses in the brain, we proposed a recurrent convolutional neural network (RCNN) for (static) object recognition. The basic idea was to add recurrent connections within every convolutional layer of the feed-forward CNN. This structure enabled the units to be modulated by other units in the same layer, which enhanced the capability of the CNN to capture statistical regularities in the context of the object. The recurrent connections increased the depth of the original CNN while kept the number of parameters constant by weight sharing between layers. Experimental results demonstrated the advantage of RCNN over CNN for object recognition. Over four benchmark datasets, with fewer parameters RCNN outperformed the state-of-the-art models. Increasing the number of parameters led to even better performance. This work shows that it is possible to boost the performance of CNN by incorporating more facts of the brain. It would be interesting to see other fact of the brain to be integrated into deep learning models in future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The overall architecture of RCNN. Left: An RCL is unfolded for T = 3 time steps, leading to a feed-forward subnetwork with the largest depth of 4 and the smallest depth of 1. At t = 0 only feed-forward computation takes place. Right: The RCNN used in this paper contains one convolutional layer, four RCLs, three max pooling layers and one softmax layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The subnetworks used to construct rCNNs. They are used to replace the RCLs in RCNN. The layers surrounded by the dotted box have tied weights. From left to right, the subnetworks correspond to the RCL with one, two and three iterations, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>Comparison with existing models on CIFAR-10</figDesc><table>4.2.2 Comparison with state-of-the-art models 

Model 
No. of Param. 
Testing Error (%) 
Without Data Augmentation 
Maxout [17] 
&gt; 5 M 
11.68 
Prob maxout [47] 
&gt; 5 M 
11.35 
NIN [33] 
0.97 M 
10.41 
DSN [30] 
0.97 M 
9.69 
RCNN-96 
0.67 M 
9.31 
RCNN-128 
1.19 M 
8.98 
RCNN-160 
1.86 M 
8.69 
RCNN-96 (no dropout) 
0.67 M 
13.56 
NIN (no dropout) [33] 
0.97 M 
14.51 
With Data Augmentation 
Prob maxout [47] 
&gt; 5 M 
9.39 
Maxout [17] 
&gt; 5 M 
9.38 
DropConnect (12 nets) [51] 
-
9.32 
NIN [33] 
0.97 M 
8.81 
DSN [30] 
0.97 M 
7.97 
RCNN-96 
0.67 M 
7.37 
RCNN-128 
1.19 M 
7.24 
RCNN-160 
1.86 M 
7.09 
Table 2. </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>for details.Table 3. Comparison with existing models on CIFAR-100</figDesc><table>4.3. CIFAR-100 

Model 
No. of Param. Testing Error (%) 
Maxout [17] 
&gt; 5 M 
38.57 
Prob maxout [47] 
&gt; 5 M 
38.14 
Tree based priors [49] 
-
36.85 
NIN [33] 
0.98 M 
35.68 
DSN [30] 
0.98 M 
34.57 
RCNN-96 
0.68 M 
34.18 
RCNN-128 
1.20 M 
32.59 
RCNN-160 
1.87 M 
31.75 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>Table 3 shows the comparison result.Table 4. Comparison with existing models on MNIST</figDesc><table>4.4. MNIST 

Model 
No. of Param. Testing Error (%) 
NIN [33] 
0.35 M 
0.47 
Maxout [17] 
0.42 M 
0.45 
DSN [30] 
0.35 M 
0.39 
RCNN-32 
0.08 M 
0.42 
RCNN-64 
0.30 M 
0.32 
RCNN-96 
0.67 M 
0.31 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>. RCNN-64 outperformed other models us- ing only 0.30 million parameters. In contrast, 0.42 million parameters were used in Maxout networks and 0.35 million parameters were used in NIN and DSN. No preprocessing was used by RCNN while the other models used global con- trast normalization and ZCA whitening.</figDesc><table>4.5. SVHN 

Model 
No. of Param. Testing Error (%) 
Without Data Augmentation 
Maxout [17] 
&gt; 5 M 
2.47 
Prob maxout [47] 
&gt; 5 M 
2.39 
NIN [33] 
1.98 M 
2.35 
DSN [30] 
1.98 M 
1.92 

RCNN-128 
1.19 M 
1.87 
RCNN-160 
1.86 M 
1.80 
RCNN-192 
2.67 M 
1.77 
With Data Augmentation 
Multi-digit number 
recognition [16] 
&gt; 5 M 
2.16 

DropConnect (5 nets) [51] 
-
1.94 
</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We are grateful to the anonymous reviewers for their valuable comments. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Contextual influences on visual processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Albright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Stoner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual review of neuroscience</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="339" to="379" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hierarchical Neural Networks for Image Interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">2766</biblScope>
			<date type="published" when="2003" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning mid-level features for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2559" to="2566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A massively parallel architecture for a self-organizing neural pattern recognition machine. Computer vision, graphics, and image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Grossberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="54" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Return of the devil in the details: Delving deep into convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Theoretical neuroscience. Cambridge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Abbott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>MIT Press</publisher>
			<pubPlace>MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The role of early visual cortex in visual integration: a neural model of recurrent interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Deco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1089" to="1100" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feifei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Understanding deep architectures using a recursive convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rolfe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Finding structure in time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="211" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Nonlinear dynamic system identification using artificial neural networks (anns)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Parlos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tsai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="133" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A new visual illusion of direction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fraser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Psychiatry</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="307" to="320" />
			<date type="published" when="1908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological cybernetics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="193" to="202" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the 14th International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="315" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Large-scale feature learning with spike-and-slab sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Couville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multi-digit number recognition from street view imagery using deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bulatov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ibarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arnoud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Maxout networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning (ICML)</title>
		<meeting>the 30th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1319" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A novel connectionist system for unconstrained handwriting recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bertolami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="855" to="868" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="6645" to="6649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Offline handwriting recognition with multidimensional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="545" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural networks and physical systems with emergent collective computational abilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2554" to="2558" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Receptive fields of single neurones in the cat&apos;s striate cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Hubel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of physiology</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">574</biblScope>
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Receptive fields, binocular interaction and functional architecture in the cat&apos;s visual cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Hubel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Physiology</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">106</biblScope>
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">attractor dynamics and parallelism in a connectionist sequential machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>IEEE Press</publisher>
			<biblScope unit="page" from="112" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Computer Science Department, University of Toronto, Tech. Rep</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Handwritten digit recognition with a back-propagation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jackel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="396" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Backpropagation applied to handwritten zip code recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="541" to="551" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deeplysupervised nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS), Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Annual International Conference on Machine Learning (ICML)</title>
		<meeting>the 26th Annual International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Hierarchical bayesian inference in the visual cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Optical Society of America A</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1434" to="1448" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Network in network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A logical calculus of the ideas immanent in nervous activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Mcculloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pitts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin of Mathematical Biophysics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="115" to="133" />
			<date type="published" when="1943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2011</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Recurrent convolutional neural networks for scene labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML)</title>
		<meeting>the 31st International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neurocontrol of nonlinear dynamical systems with kalman filter trained recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">V</forename><surname>Puskorius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Feldkamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="279" to="297" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Hierarchical models of object recognition in cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riesenhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1019" to="1025" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Principles of neurodynamics; perceptrons and the theory of brain mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962" />
			<publisher>Spartan Books Washington</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Parallel distributed processing: Explorations in the microstructure of cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">chapter Learning Internal Representations by Error Propagation</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1986" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="318" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">On random weights and unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bhand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML)</title>
		<meeting>the 28th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1089" to="1096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The silent surround of V1 receptive fields: theory and experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Series</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lorenceau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Frégnac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of physiology-Paris</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="453" to="474" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Cnn features off-the-shelf: An astounding baseline for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharif Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>abs/1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Parsing natural scenes and natural language with recursive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML)</title>
		<meeting>the 28th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning continuous phrase representations and syntactic parsing with recursive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS), Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Improving deep neural networks with probabilistic maxout units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Discriminative transfer learning with tree-based priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2094" to="2102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.4842</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">Going deeper with convolutions. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Regularization of neural networks using dropconnect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">L</forename><surname>Cun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning (ICML)</title>
		<meeting>the 30th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1058" to="1066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Backpropagation through time: what it does and how to do it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Stochastic pooling for regularization of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Visual nonclassical receptive field effects emerge from sparse coding in a dynamical system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rozell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1003191</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
