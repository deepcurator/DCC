<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:42+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Causal Effect Inference with Deep Latent-Variable Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Louizos</surname></persName>
							<email>c.louizos@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Massachusetts Institute of Technology CSAIL &amp; IMES</orgName>
								<orgName type="department" key="dep2">CIFAR *</orgName>
								<orgName type="institution" key="instit1">University of Amsterdam TNO Intelligent Imaging</orgName>
								<orgName type="institution" key="instit2">New York University CIMS</orgName>
								<orgName type="institution" key="instit3">University of Amsterdam</orgName>
								<orgName type="institution" key="instit4">University of Toronto</orgName>
								<orgName type="institution" key="instit5">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Shalit</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Massachusetts Institute of Technology CSAIL &amp; IMES</orgName>
								<orgName type="department" key="dep2">CIFAR *</orgName>
								<orgName type="institution" key="instit1">University of Amsterdam TNO Intelligent Imaging</orgName>
								<orgName type="institution" key="instit2">New York University CIMS</orgName>
								<orgName type="institution" key="instit3">University of Amsterdam</orgName>
								<orgName type="institution" key="instit4">University of Toronto</orgName>
								<orgName type="institution" key="instit5">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joris</forename><surname>Mooij</surname></persName>
							<email>j.m.mooij@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Massachusetts Institute of Technology CSAIL &amp; IMES</orgName>
								<orgName type="department" key="dep2">CIFAR *</orgName>
								<orgName type="institution" key="instit1">University of Amsterdam TNO Intelligent Imaging</orgName>
								<orgName type="institution" key="instit2">New York University CIMS</orgName>
								<orgName type="institution" key="instit3">University of Amsterdam</orgName>
								<orgName type="institution" key="instit4">University of Toronto</orgName>
								<orgName type="institution" key="instit5">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
							<email>dsontag@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Massachusetts Institute of Technology CSAIL &amp; IMES</orgName>
								<orgName type="department" key="dep2">CIFAR *</orgName>
								<orgName type="institution" key="instit1">University of Amsterdam TNO Intelligent Imaging</orgName>
								<orgName type="institution" key="instit2">New York University CIMS</orgName>
								<orgName type="institution" key="instit3">University of Amsterdam</orgName>
								<orgName type="institution" key="instit4">University of Toronto</orgName>
								<orgName type="institution" key="instit5">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
							<email>zemel@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Massachusetts Institute of Technology CSAIL &amp; IMES</orgName>
								<orgName type="department" key="dep2">CIFAR *</orgName>
								<orgName type="institution" key="instit1">University of Amsterdam TNO Intelligent Imaging</orgName>
								<orgName type="institution" key="instit2">New York University CIMS</orgName>
								<orgName type="institution" key="instit3">University of Amsterdam</orgName>
								<orgName type="institution" key="instit4">University of Toronto</orgName>
								<orgName type="institution" key="instit5">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cifar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Massachusetts Institute of Technology CSAIL &amp; IMES</orgName>
								<orgName type="department" key="dep2">CIFAR *</orgName>
								<orgName type="institution" key="instit1">University of Amsterdam TNO Intelligent Imaging</orgName>
								<orgName type="institution" key="instit2">New York University CIMS</orgName>
								<orgName type="institution" key="instit3">University of Amsterdam</orgName>
								<orgName type="institution" key="instit4">University of Toronto</orgName>
								<orgName type="institution" key="instit5">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
							<email>m.welling@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Massachusetts Institute of Technology CSAIL &amp; IMES</orgName>
								<orgName type="department" key="dep2">CIFAR *</orgName>
								<orgName type="institution" key="instit1">University of Amsterdam TNO Intelligent Imaging</orgName>
								<orgName type="institution" key="instit2">New York University CIMS</orgName>
								<orgName type="institution" key="instit3">University of Amsterdam</orgName>
								<orgName type="institution" key="instit4">University of Toronto</orgName>
								<orgName type="institution" key="instit5">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Causal Effect Inference with Deep Latent-Variable Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Learning individual-level causal effects from observational data, such as inferring the most effective medication for a specific patient, is a problem of growing importance for policy makers. The most important aspect of inferring causal effects from observational data is the handling of confounders, factors that affect both an intervention and its outcome. A carefully designed observational study attempts to measure all important confounders. However, even if one does not have direct access to all confounders, there may exist noisy and uncertain measurement of proxies for confounders. We build on recent advances in latent variable modeling to simultaneously estimate the unknown latent space summarizing the confounders and the causal effect. Our method is based on Variational Autoencoders (VAE) which follow the causal structure of inference with proxies. We show our method is significantly more robust than existing methods, and matches the state-of-the-art on previous benchmarks focused on individual treatment effects.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Understanding the causal effect of an intervention t on an individual with features X is a fundamental problem across many domains. Examples include understanding the effect of medications on a patient's health, or of teaching methods on a student's chance of graduation. With the availability of large datasets in domains such as healthcare and education, there is much interest in developing methods for learning individual-level causal effects from observational data <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b42">43]</ref>.</p><p>The most crucial aspect of inferring causal relationships from observational data is confounding. A variable which affects both the intervention and the outcome is known as a confounder of the effect of the intervention on the outcome. On the one hand, if such a confounder can be measured, the standard way to account for its effect is by "controlling" for it, often through covariate adjustment or propensity score re-weighting <ref type="bibr" target="#b38">[39]</ref>. On the the other hand, if a confounder is hidden or unmeasured, it is impossible in the general case (i.e. without further assumptions) to estimate the effect of the intervention on the outcome <ref type="bibr" target="#b39">[40]</ref>. For example, socio-economic status can affect both the medication a patient has access to, and the patient's general health. Therefore socio-economic status acts as confounder between the medication and health outcomes, and without measuring it we cannot in Z t y X <ref type="figure">Figure 1</ref>: Example of a proxy variable. t is a treatment, e.g. medication; y is an outcome, e.g. mortality. Z is an unobserved confounder, e.g. socio-economic status; and X is noisy views on the hidden confounder Z, say income in the last year and place of residence.</p><p>general isolate the causal effect of medications on health measures. Henceforth we will denote observed potential confounders <ref type="bibr" target="#b1">2</ref> by X, and unobserved confounders by Z.</p><p>In most real-world observational studies we cannot hope to measure all possible confounders. For example, in many studies we cannot measure variables such as personal preferences or most genetic and environmental factors. An extremely common practice in these cases is to rely on so-called "proxy variables" <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr">Ch. 11]</ref>. For example, we cannot measure the socio-economic status of patients directly, but we might be able to get a proxy for it by knowing their zip code and job type.</p><p>One of the promises of using big-data for causal inference is the existence of myriad proxy variables for unmeasured confounders.</p><p>How should one use these proxy variables? The answer depends on the relationship between the hidden confounders, their proxies, the intervention and outcome <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b36">37]</ref>. Consider for example the causal graphs in <ref type="figure">Figure 1:</ref> it's well known <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b40">41]</ref> that it is often incorrect to treat the proxies X as if they are ordinary confounders, as this would induce bias. See the Appendix for a simple example of this phenomena. The aforementioned papers give methods which are guaranteed to recover the true causal effect when proxies are observed. However, the strong guarantees these methods enjoy rely on strong assumptions. In particular, it is assumed that the hidden confounder is either categorical with known number of categories, or that the model is linear-Gaussian.</p><p>In practice, we cannot know the exact nature of the hidden confounder Z: whether it is categorical or continuous, or if categorical how many categories it includes. Consider socio-economic status (SES) and health. Should we conceive of SES as a continuous or ordinal variable? Perhaps SES as confounder is comprised of two dimensions, the economic one (related to wealth and income) and the social one (related to education and cultural capital). Z might even be a mix of continuous and categorical, or be high-dimensional itself. This uncertainty makes causal inference a very hard problem even with proxies available. We propose an alternative approach to causal effect inference tailored to the surrogate-rich setting when many proxies are available: estimation of a latent-variable model where we simultaneously discover the hidden confounders and infer how they affect treatment and outcome. Specifically, we focus on (approximate) maximum-likelihood based methods.</p><p>Although in many cases learning latent-variable models are computationally intractable <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b6">7]</ref>, the machine learning community has made significant progress in the past few years developing computationally efficient algorithms for latent-variable modeling. These include methods with provable guarantees, typically based on the method-of-moments (e.g. Anandkumar et al. <ref type="bibr" target="#b3">[4]</ref>); as well as robust, fast, heuristics such as variational autoencoders (VAEs) <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b45">46]</ref>, based on stochastic optimization of a variational lower bound on the likelihood, using so-called recognition networks for approximate inference.</p><p>Our paper builds upon VAEs. This has the disadvantage that little theory is currently available to justify when learning with VAEs can identify the true model. However, they have the significant advantage that they make substantially weaker assumptions about the data generating process and the structure of the hidden confounders. Since their recent introduction, VAEs have been shown to be remarkably successful in capturing latent structure across a wide-range of previously difficult problems, such as modeling images <ref type="bibr" target="#b18">[19]</ref>, volumes <ref type="bibr" target="#b23">[24]</ref>, time-series <ref type="bibr" target="#b9">[10]</ref> and fairness <ref type="bibr" target="#b33">[34]</ref>.</p><p>We show that in the presence of noisy proxies, our method is more robust against hidden confounding, in experiments where we successively add noise to known-confounders. Towards that end we introduce a new causal inference benchmark using data about twin births and mortalities in the USA. We further show that our method is competitive on two existing causal inference benchmarks. Finally, we note that our method does not currently deal with the related problem of selection bias, and we leave this to future work.</p><p>Related work. Proxy variables and the challenges of using them correctly have long been considered in the causal inference literature <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b13">14]</ref>. Understanding what is the best way to derive and measure possible proxy variables is an important part of many observational studies <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b54">55]</ref>. Recent work by Cai and Kuroki <ref type="bibr" target="#b8">[9]</ref>, Greenland and Lash <ref type="bibr" target="#b17">[18]</ref>, building on the work of Greenland and Kleinbaum <ref type="bibr" target="#b16">[17]</ref>, Selén <ref type="bibr" target="#b46">[47]</ref>, has studied conditions for causal identifiability using proxy variables. The general idea is that in many cases one should first attempt to infer the joint distribution p(X, Z) between the proxy and the hidden confounders, and then use that knowledge to adjust for the hidden confounders <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b11">12]</ref>. For the example in <ref type="figure">Figure 1</ref>, Cai and Kuroki <ref type="bibr" target="#b8">[9]</ref>, Greenland and Lash <ref type="bibr" target="#b17">[18]</ref>, Pearl <ref type="bibr" target="#b40">[41]</ref> show that if Z and X are categorical, with X having at least as many categories as Z, and with the matrix p(X, Z) being full-rank, one could identify the causal effect of t on y using a simple matrix inversion formula, an approach called "effect restoration". Conditions under which one could identify more general and complicated proxy models were recently given by <ref type="bibr" target="#b36">[37]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Identification of causal effect</head><p>Throughout this paper we assume the causal model in <ref type="figure">Figure 1</ref>. For simplicity and compatibility with prior benchmarks we assume that the treatment t is binary, but our proposed method does not rely on that. We further assume that the joint distribution p (Z, X, t, y) of the latent confounders Z and the observed confounders X can be approximately recovered solely from the observations (X, t, y). While this is impossible if the hidden confounder has no relation to the observed variables, there are many cases where this is possible, as mentioned in the introduction. For example, if X includes three independent views of Z <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b1">2]</ref>; if Z is categorical and X is a Gaussian mixture model with components determined by X <ref type="bibr" target="#b4">[5]</ref>; or if Z is comprised of binary variables and X are so-called "noisy-or" functions of Z <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b7">8]</ref>. Recent results show that certain VAEs can recover a very large class of latent-variable models <ref type="bibr" target="#b50">[51]</ref> as a minimizer of an optimization problem; the caveat is that the optimization process is not guaranteed to achieve the true minimum even if it is within the capacity of the model, similar to the case of classic universal approximation results for neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Identifying individual treatment effect</head><p>Our goal in this paper is to recover the individual treatment effect (ITE), also known as the conditional average treatment effect (CATE), of a treatment t, as well as the average treatment effect (ATE):</p><formula xml:id="formula_0">IT E(x) := E [y|X = x, do(t = 1)] − E [y|X = x, do(t = 0)] , AT E := E[IT E(x)]</formula><p>Identification in our case is an immediate result of Pearl's back-door adjustment formula <ref type="bibr" target="#b39">[40]</ref>: Theorem 1. If we recover p (Z, X, t, y) then we recover the ITE under the causal model in <ref type="figure">Figure 1</ref>.</p><p>Proof. We will prove that p (y|X, do(t = 1)) is identifiable under the premise of the theorem. The case for t = 0 is identical, and the expectations in the definition of ITE above readily recovered from the probability function. ATE is identified if ITE is identified. We have that:</p><formula xml:id="formula_1">p (y|X, do(t = 1)) = Z p (y|X, do(t = 1), Z) p (Z|X, do(t = 1)) dZ (i) = Z p (y|X, t = 1, Z) p (Z|X) dZ,<label>(1)</label></formula><p>where equality (i) is by the rules of do-calculus applied to the causal graph in <ref type="figure">Figure 1</ref>  <ref type="bibr" target="#b39">[40]</ref>. This completes the proof since the quantities in the final expression of Eq. <ref type="formula" target="#formula_1">(1)</ref> can be identified from the distribution p (Z, X, t, y) which we know by the Theorem's premise.</p><p>Note that the proof and the resulting estimator in Eq. (1) would be identical whether there is or there is not an edge from X to t. This is because we intervene on t. Also note that for the model in <ref type="figure">Figure 1</ref>, y is independent of X given Z, and we obtain:</p><formula xml:id="formula_2">p (y|X, do(t = 1)) = Z p (y|t = 1, Z) p (Z|X) dZ.</formula><p>In the next section we will show how we estimate p (Z, X, t, y) from observations of (X, t, y).</p><p>3 Causal effect variational autoencoder . White nodes correspond to parametrized deterministic neural network transitions, gray nodes correspond to drawing samples from the respective distribution and white circles correspond to switching paths according to the treatment t.</p><formula xml:id="formula_3">(a) Inference network, q(z, t, y|x). (b) Model network, p(x, z, t, y).</formula><p>The approach we take in this paper to the problem of learning the latent variable causal model is by using variational autoencoders <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b45">46]</ref> to infer the complex non-linear relationships between X and (Z, t, y) and approximately recover p (Z, X, t, y). Recent work has dramatically increased the range and type of distributions which can be captured by VAEs <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b27">28]</ref>. The drawback of these methods is that because of the difficulty of guaranteeing global optima of neural net optimization, one cannot ensure that any given instance will find the true model even if it is within the model class.</p><p>We believe this drawback is offset by the strong empirical performance across many domains of deep neural networks in general, and VAEs in particular. Specifically, we propose to parametrize the causal graph of <ref type="figure">Figure 1</ref> as a latent variable model with neural net functions connecting the variables of interest. The flexible non-linear nature of neural nets will hopefully allow us to approximate well the true interactions between the treatment and its effect.</p><p>Our design choices are mostly typical for VAEs: we assume the observations factorize conditioned on the latent variables, and use an inference network <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b45">46]</ref> which follows a factorization of the true posterior. For the generative model we use an architecture inspired by TARnet <ref type="bibr" target="#b47">[48]</ref>, but instead of conditioning on observations we condition on the latent variables z; see details below. For the following, x i corresponds to an input datapoint (e.g. the feature vector of a given subject), t i corresponds to the treatment assignment, y i to the outcome of the of the particular treatment and z i corresponds to the latent hidden confounder. Each of the corresponding factors is described as:</p><formula xml:id="formula_4">p(z i ) = Dz j=1 N (z ij |0, 1); p(x i |z i ) = Dx j=1 p(x ij |z i ); p(t i |z i ) = Bern(σ(f 1 (z i ))),<label>(2)</label></formula><p>with p(x ij |z i ) being an appropriate probability distribution for the covariate j and σ(·) being the logistic function, D x the dimension of x and D z the dimension of z. For a continuous outcome we parametrize the probability distribution as a Gaussian with its mean given by a TARnet <ref type="bibr" target="#b47">[48]</ref> architecture, i.e. a treatment specific function, and its variance fixed tov, whereas for a discrete outcome we use a Bernoulli distribution similarly parametrized by a TARnet:</p><formula xml:id="formula_5">p(y i |t i , z i ) = N (µ =μ i , σ 2 =v)μ i = t i f 2 (z i ) + (1 − t i )f 3 (z i ) (3) p(y i |t i , z i ) = Bern(π =π i )π i = σ(t i f 2 (z i ) + (1 − t i )f 3 (z i )).<label>(4)</label></formula><p>Note that each of the f k (·) is a neural network parametrized by its own parameters θ k for k = 1, 2, 3.</p><p>As we do not a-priori know the hidden confounder z we have to marginalize over it in order to learn the parameters of the model θ k . Since the non-linear neural network functions make inference intractable we will employ variational inference along with inference networks; these are neural networks that output the parameters of a fixed form posterior approximation over the latent variables z, e.g. a Gaussian, given the observed variables. By the definition of the model at <ref type="figure">Figure 1</ref> we can see that the true posterior over Z depends on X, t and y. Therefore we employ the following posterior approximation: <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b45">46]</ref>:</p><formula xml:id="formula_6">q(z i |x i , t i , y i ) = Dz j=1 N (µ j =μ ij , σ 2 j =σ 2 ij ) (5) µ i = t i µ t=0,i + (1 − t i )µ t=1,iσ 2 i = t i σ 2 t=0,i + (1 − t i )σ 2 t=1,i µ t=0,i , σ 2 t=0,i = g 2 • g 1 (x i , y i ) µ t=1,i , σ 2 t=1,i = g 3 • g 1 (x i , y i ),</formula><note type="other">where we similarly use a TARnet [48] architecture for the inference network, i.e. split them for each treatment group in t after a shared representation g 1 (x i , y i ), and each g k (·) is a neural network with variational parameters φ k . We can now form a single objective for the inference and model networks, the variational lower bound of this graphical model</note><formula xml:id="formula_7">L = N i=1 E q(zi|xi,ti,yi) [log p(x i , t i |z i ) + log p(y i |t i , z i ) + log p(z i ) − log q(z i |x i , t i , y i )]. (6)</formula><p>Notice that for out of sample predictions, i.e. new subjects, we require to know the treatment assignment t along with its outcome y before inferring the distribution over z. For this reason we will introduce two auxiliary distributions that will help us predict t i , y i for new samples. More specifically, we will employ the following distributions for the treatment assignment t and outcomes y:</p><formula xml:id="formula_8">q(t i |x i ) = Bern(π = σ(g 4 (x i ))) (7) q(y i |x i , t i ) = N (µ =μ i , σ 2 =v)μ i = t i (g 6 • g 5 (x i )) + (1 − t i )(g 7 • g 5 (x i )) (8) q(y i |x i , t i ) = Bern(π =π i )π i = t i (g 6 • g 5 (x i )) + (1 − t i )(g 7 • g 5 (x i )),<label>(9)</label></formula><p>where we choose eq. 8 for continuous and eq. 9 for discrete outcomes. To estimate the parameters of these auxiliary distributions we will add two extra terms in the variational lower bound:</p><formula xml:id="formula_9">F CEVAE = L + N i=1 log q(t i = t * i |x * i ) + log q(y i = y * i |x * i , t * i ) ,<label>(10)</label></formula><p>with x i , t * i , y * i being the observed values for the input, treatment and outcome random variables in the training set. We coin the name Causal Effect Variational Autoencoder (CEVAE) for our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Evaluating causal inference methods is always challenging because we usually lack ground-truth for the causal effects. Common evaluation approaches include creating synthetic or semi-synthetic datasets, where real data is modified in a way that allows us to know the true causal effect or realworld data where a randomized experiment was conducted. Here we compare with two existing benchmark datasets where there is no need to model proxies, IHDP <ref type="bibr" target="#b20">[21]</ref> and Jobs <ref type="bibr" target="#b32">[33]</ref>, often used for evaluating individual level causal inference. In order to specifically explore the role of proxy variables, we create a synthetic toy dataset, and introduce a new benchmark based on data of twin births and deaths in the USA.</p><p>For the implementation of our model we used Tensorflow <ref type="bibr" target="#b0">[1]</ref> and Edward <ref type="bibr" target="#b51">[52]</ref>. For the neural network architecture choices we closely followed <ref type="bibr" target="#b47">[48]</ref>; unless otherwise specified we used 3 hidden layers with ELU <ref type="bibr" target="#b10">[11]</ref> nonlinearities for the approximate posterior over the latent variables q(Z|X, t, y), the generative model p(X|Z) and the outcome models p(y|t, Z), q(y|t, X). For the treatment models p(t|Z), q(t|X) we used a single hidden layer neural network with ELU nonlinearities. Unless mentioned otherwise, we used a 20-dimensional latent variable z and used a small weight decay term for all of the parameters with λ = .0001. Optimization was done with Adamax <ref type="bibr" target="#b25">[26]</ref> and a learning rate of 0.01, which was annealed with an exponential decay schedule. We further performed early stopping according to the lower bound on a validation set. To compute the outcomes p(y|X, do(t = 1)) and p(y|X, do(t = 0)) we averaged over 100 samples from the approximate posterior q(Z|X) = t q(Z|t, y, X)q(y|t, X)q(t|X)dy.</p><p>Throughout this section we compare with several baseline methods. LR1 is logistic regression, LR2 is two separate logistic regressions fit to treated (t = 1) and control (t = 0). TARnet is a feed forward neural network architecture for causal inference <ref type="bibr" target="#b47">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Benchmark datasets</head><p>For the first benchmark task we consider estimating the individual and population causal effects on a benchmark dataset introduced by <ref type="bibr" target="#b20">[21]</ref>; it is constructed from data obtained from the Infant Health and Development Program (IHDP). Briefly, the confounders x correspond to collected measurements of the children and their mothers used during a randomized experiment that studied the effect of home visits by specialists on future cognitive test scores. The treatment assignment is then "de-randomized" by removing from the treated set children with non-white mothers; for each unit a treated and a control outcome are then simulated, thus allowing us to know the "true" individual causal effects of the treatment. We follow <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b47">48]</ref> and use 1000 replications of the simulated outcome, along with the same train/validation/testing splits. To measure the accuracy of the individual treatment effect estimation we use the Precision in Estimation of Heterogeneous Effect (PEHE) <ref type="bibr" target="#b20">[21]</ref></p><formula xml:id="formula_10">, PEHE = 1 N N i=1 ((y i1 − y i0 ) − (ŷ i1 −ŷ i0 ))</formula><p>2 , where y 1 , y 0 correspond to the true outcomes under t = 1 and t = 0, respectively, andŷ 1 ,ŷ 0 correspond to the outcomes estimated by our model. For the population causal effect we report the absolute error on the Average Treatment Effect (ATE). The results can be seen at <ref type="table" target="#tab_0">Table 1</ref>. As we can see, CEVAE has decent performance, comparable to the Balancing Neural Network (BNN) of <ref type="bibr" target="#b24">[25]</ref>.  For the second benchmark we consider the task described at <ref type="bibr" target="#b47">[48]</ref> and follow closely their procedure. It uses a dataset obtained by the study of <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b48">49]</ref>, which concerns the effect of job training (treatment) on employment after training (outcome). Due to the fact that a part of the dataset comes from a randomized control trial we can estimate the "true" causal effect. Following <ref type="bibr" target="#b47">[48]</ref> we report the absolute error on the Average Treatment effect on the Treated (ATT), which is the E [IT E(X)|t = 1].</p><p>For the individual causal effect we use the policy risk, that acts as a proxy to the individual treatment effect. The results after averaging over 10 train/validation/test splits can be seen at <ref type="table" target="#tab_1">Table 2</ref>. As we can observe, CEVAE is competitive with the state-of-the art, while overall achieving the best estimate on the out-of-sample ATT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Synthetic experiment on toy data</head><p>To illustrate that our model better handles hidden confounders we experiment on a toy simulated dataset where the marginal distribution of X is a mixture of Gaussians, with the hidden variable Z determining the mixture component. We generate synthetic data by the following process:</p><formula xml:id="formula_11">z i ∼ Bern (0.5) ; x i |z i ∼ N z i , σ 2 z1 z i + σ 2 z0 (1 − z i ) t i |z i ∼ Bern (0.75z i + 0.25(1 − z i )) ; y i |t i , z i ∼ Bern (Sigmoid (3(z i + 2(2t i − 1)))) ,<label>(11)</label></formula><p>where σ z0 = 3, σ z1 = 5 and Sigmoid is the logistic sigmoid function. This generation process introduces hidden confounding between t and y as t and y depend on the mixture assignment z for x. Since there is significant overlap between the two Gaussian mixture components we expect that methods which do not model the hidden confounder z will not produce accurate estimates for the treatment effects. We experiment with both a binary z for CEVAE, which is close to the true model, as well as a 5-dimensional continuous z in order to investigate the robustness of CEVAE w.r.t. model misspecification. We evaluate across samples size N ∈ {1000, 3000, 5000, 10000, 30000} and provide the results in <ref type="figure" target="#fig_1">Figure 3</ref>. We see that no matter how many samples are given, LR1, LR2 and TARnet are not able to improve their error in estimating ATE directly from the proxies. On the other hand, CEVAE achieves significantly less error. When the latent model is correctly specified (CEVAE bin) we do better even with a small sample size; when it is not (CEVAE cont) we require more samples for the latent space to imitate more closely the true binary latent variable. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Binary treatment outcome on Twins</head><p>We introduce a new benchmark task that utilizes data from twin births in the USA between 1989-1991 <ref type="bibr" target="#b2">[3]</ref> 3 . The treatment t = 1 is being born the heavier twin whereas, the outcome corresponds to the mortality of each of the twins in their first year of life. Since we have records for both twins, their outcomes could be considered as the two potential outcomes with respect to the treatment of being born heavier. We only chose twins which are the same sex. Since the outcome is thankfully quite rare (3.5% first-year mortality), we further focused on twins such that both were born weighing less than 2kg. We thus have a dataset of 11984 pairs of twins. The mortality rate for the lighter twin is 18.9%, and for the heavier 16.4%, for an average treatment effect of −2.5%. For each twin-pair we obtained 46 covariates relating to the parents, the pregnancy and birth: mother and father education, marital status, race and residence; number of previous births; pregnancy risk factors such as diabetes, renal disease, smoking and alcohol use; quality of care during pregnancy; whether the birth was at a hospital, clinic or home; and number of gestation weeks prior to birth.</p><p>In this setting, for each twin pair we observed both the case t = 0 (lighter twin) and t = 1 (heavier twin). In order to simulate an observational study, we selectively hide one of the two twins; if we were to choose at random this would be akin to a randomized trial. In order to simulate the case of hidden confounding with proxies, we based the treatment assignment on a single variable which is highly correlated with the outcome: GESTAT10, the number of gestation weeks prior to birth. It is ordinal with values from 0 to 9 indicating birth before 20 weeks gestation, birth after 20-27 weeks of gestation and so on <ref type="bibr" target="#b3">4</ref> . We then set t i |x i , z i ∼ Bern σ(w o x + w h (z/10 − 0.1)) , w o ∼ N (0, 0.1 · I), w h ∼ N (5, 0.1), where z is GESTAT10 and x are the 45 other features.</p><p>We created proxies for the hidden confounder as follows: We coded the 10 GESTAT10 categories with one-hot encoding, replicated 3 times. We then randomly and independently flipped each of these 30 bits. We varied the probabilities of flipping from 0.05 to 0.5, the latter indicating there is no direct information about the confounder. We chose three replications following the well-known result that three independent views of a latent feature are what is needed to guarantee that it can be recovered <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b4">5]</ref>. We note that there might still be proxies for the confounder in the other variables, such as the incompetent cervix covariate which is a known risk factor for early birth. Having created the dataset, we focus our attention on two tasks: Inferring the mortality of the unobserved twin (counterfactual), and inferring the average treatment effect. We compare with TARnet, LR1 and LR2. We vary the number of hidden layers for TARnet and CEVAE (nh in the figures). We note that while TARnet with 0 hidden layers is equivalent to LR2, CEVAE with 0 hidden layers still infers a latent space and is thus different. The results are given respectively in <ref type="figure">Figures 4(a)</ref> (higher is better) and 4(b) (lower is better).</p><p>For the counterfactual task, we see that for small proxy noise all methods perform similarly. This is probably due to the gestation length feature being very informative; for LR1, the noisy codings of this feature form 6 of the top 10 most predictive features for mortality, the others being sex (males are more at risk), and 3 risk factors: incompetent cervix, mother lung disease, and abnormal amniotic fluid. For higher noise, TARnet, LR1 and LR2 see roughly similar degradation in performance; CEVAE, on the other hand, is much more robust to increasing proxy noise because of its ability to infer a cleaner latent state from the noisy proxies. Of particular interest is CEVAE nh = 0, which does much better for counterfactual inference than the equivalent LR2, probably because LR2 is forced to rely directly on the noisy proxies instead of the inferred latent state. For inference of average treatment effect, we see that at the low noise levels CEVAE does slightly worse than the other methods, with CEVAE nh = 0 doing noticeably worse. However, similar to the counterfactual case, CEVAE is significantly more robust to proxy noise, achieving quite a low error even when the direct proxies are completely useless at noise level 0.5. (a) Area under the curve (AUC) for predicting the mortality of the unobserved twin in a hidden confounding experiment; higher is better. (b) Absolute error ATE estimate; lower is better. Dashed black line indicates the error of using the naive ATE estimator: the difference between the average treated and average control outcomes. <ref type="figure">Figure 4</ref>: Results on the Twins dataset. LR1 is logistic regression, LR2 is two separate logistic regressions fit on the treated and control. "nh" is number of hidden layers used. TARnet with nh = 0 is identical to LR2 and not shown, whereas CEVAE with nh = 0 has a latent space component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper we draw a connection between causal inference with proxy variables and the groundbreaking work in the machine learning community on latent variable models. Since almost all observational studies rely on proxy variables, this connection is highly relevant.</p><p>We introduce a model which is the first attempt at tying these two ideas together: The Causal Effect Variational Autoencoder (CEVAE), a neural network latent variable model used for estimating individual and population causal effects. In extensive experiments we showed that it is competitive with the state-of-the art on benchmark datasets, and more robust to hidden confounding both at a toy artificial dataset as well as modifications of real datasets, such as the newly introduced Twins dataset. For future work, we plan to employ the expanding set of tools available for latent variables models (e.g. Kingma et al. <ref type="bibr" target="#b27">[28]</ref>, Tran et al. <ref type="bibr" target="#b50">[51]</ref>, Maaløe et al. <ref type="bibr" target="#b34">[35]</ref>, Ranganath et al. <ref type="bibr" target="#b43">[44]</ref>), as well as to further explore connections between method of moments approaches such as Anandkumar et al. <ref type="bibr" target="#b4">[5]</ref> with the methods for effect restoration given by Kuroki and Pearl <ref type="bibr" target="#b31">[32]</ref>, Miao et al. <ref type="bibr" target="#b36">[37]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Overall architecture of the model and inference networks for the Causal Effect Variational Autoencoder (CEVAE). White nodes correspond to parametrized deterministic neural network transitions, gray nodes correspond to drawing samples from the respective distribution and white circles correspond to switching paths according to the treatment t.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Absolute error of estimating ATE on samples from the generative process (11). CEVAE bin and CEVAE cont are CEVAE with respectively binary or continuous 5-dim latent z. See text above for description of the other methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Within-sample and out-of-sample mean and standard errors for the metrics for the various models at the IHDP dataset.</figDesc><table>Method 

within-s. 
PEHE 

within-s. 
ATE 

out-of-s. 
PEHE 

out-of-s. 
ATE 

OLS-1 
5.8±.3 
.73±.04 
5.8±.3 
.94±.06 
OLS-2 
2.4±.1 
.14±.01 
2.5±.1 
.31±.02 
BLR 
5.8±.3 
.72±.04 
5.8±.3 
.93±.05 
k-NN 
2.1±.1 
.14±.01 
4.1±.2 
.79±.05 
TMLE 
5.0±.2 
.30±.01 
-
-
BART 
2.1±.1 
.23±.01 
2.3±.1 
.34±.02 
RF 
4.2±.2 
.73±.05 
6.6±.3 
.96±.06 
CF 
3.8±.2 
.18±.01 
3.8±.2 
.40±.03 
BNN 
2.2±.1 
.37±.03 
2.1±.1 
.42±.03 
CFRW 
.71±.0 
.25±.01 
.76±.0 
.27±.01 

CEVAE 
2.7±.1 
.34±.01 
2.6±.1 
.46±.02 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Within-sample and out-of-sample 
policy risk and error on the average treatment 
effect on the treated (ATT) for the various 
models on the Jobs dataset. 

Method R 

within-s. 
pol 

within-s. 
ATT 

R 

out-of-s. 
pol 

out-of-s. 
ATT 

LR-1 
.22±.0 .01±.00 .23±.0 .08±.04 
LR-2 
.21±.0 .01±.01 .24±.0 .08±.03 
BLR 
.22±.0 .01±.01 .25±.0 .08±.03 
k-NN 
.02±.0 .21±.01 .26±.0 .13±.05 
TMLE 
.22±.0 .02±.01 
-
-
BART 
.23±.0 .02±.00 .25±.0 .08±.03 
RF 
.23±.0 .03±.01 .28±.0 .09±.04 
CF 
.19±.0 .03±.01 .20±.0 .07±.03 
BNN 
.20±.0 .04±.01 .24±.0 .09±.04 
CFRW 
.17±.0 .04±.01 .21±.0 .09±.03 

CEVAE .15±.0 .02±.01 .26±.0 .03±.01 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Including observed covariates which do not affect the intervention or outcome, and therefore are not truly confounders.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Data taken from the denominator file at http://www.nber.org/data/linked-birth-infant-death-data-vitalstatistics-data.html 4 The partition is given in the original dataset from NBER.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Fredrik D. Johansson for valuable discussions, feedback and for providing the data for IHDP and Jobs. We would also like to thank Maggie Makar for helping with the Twins dataset. Christos Louizos and Max Welling were supported by TNO, NWO and Google. Joris Mooij was supported by the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement 639466).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<title level="m">Large-scale machine learning on heterogeneous distributed systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Identifiability of parameters in latent structure models with many observed variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Allman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Rhodes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="page" from="3099" to="3132" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The costs of low birth weight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Almond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Y</forename><surname>Chay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Quarterly Journal of Economics</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1031" to="1083" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A method of moments for mixture models and hidden markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tensor decompositions for learning latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Telgarsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2773" to="2832" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Mostly harmless econometrics: An empiricist&apos;s companion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Angrist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-S</forename><surname>Pischke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Princeton university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning mixtures of separated nonspherical gaussians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kannan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Applied Probability</title>
		<imprint>
			<biblScope unit="page" from="69" to="92" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Provable learning of noisy-or networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Risteski</surname></persName>
		</author>
		<idno>abs/1612.08795</idno>
		<ptr target="http://arxiv.org/abs/1612.08795" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On identifying total effects in the presence of latent variables and selection bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kuroki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="62" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A recurrent latent variable model for sequential data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kastner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Fast and accurate deep network learning by exponential linear units (elus)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-A</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07289</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">All your data are always missing: incorporating bias due to measurement error into the potential outcomes framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Westreich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Epidemiology</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1452</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Estimating wealth effects without expenditure data-or tears: an application to educational enrollments in states of india</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Filmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">H</forename><surname>Pritchett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Demography</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="115" to="132" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Proxy variables and specification bias. The review of economics and Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Frost</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<biblScope unit="page" from="323" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Measurement error models. Wiley series in probability and mathematical statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fuller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Exploratory latent structure analysis using both identifiable and unidentifiable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="215" to="231" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Correcting for misclassification in two-way tables and matched-pair studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Greenland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Kleinbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Epidemiology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="97" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Bias analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Greenland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modern epidemiology</title>
		<imprint>
			<publisher>Lippincott Williams and Wilkins</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="345" to="380" />
		</imprint>
	</monogr>
	<note>3rd ed.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">DRAW: A Recurrent Neural Network For Image Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-02" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Errors in variables in panel data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Griliches</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hausman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of econometrics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="118" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bayesian nonparametric modeling for causal inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="217" to="240" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A spectral algorithm for learning hidden markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1460" to="1480" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Discovering hidden variables in noisy-or networks using quartet tests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2355" to="2363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Unsupervised Learning of 3D Structure from Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-07" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<title level="m">Learning representations for counterfactual inference. International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<meeting><address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04934</idno>
		<title level="m">Improving variational inference with inverse autoregressive flow</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Socioeconomic status measurement with discrete proxy variables: Is principal component analysis a reliable answer?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kolenikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Angeles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Review of Income and Wealth</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="128" to="165" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">More factors than subjects, tests and treatments: an indeterminacy theorem for canonical decomposition and individual differences scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="293" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Measurement bias and effect restoration in causal inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kuroki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DTIC Document</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Measurement bias and effect restoration in causal inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kuroki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">423</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Evaluating the econometric evaluations of training programs with experimental data. The American economic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Lalonde</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="page" from="604" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<title level="m">The variational fair autoencoder. International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.05473</idno>
		<title level="m">Auxiliary deep generative models</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Introduction to econometrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Maddala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lahiri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Macmillan</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Identifying causal effects with proxy variables of an unmeasured confounder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tchetgen Tchetgen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08816</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Measuring living standards with proxy variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Montgomery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gragnolati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Paredes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Demography</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="155" to="174" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Counterfactuals and causal inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Winship</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Causality</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">On measurement bias in causal inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1203.3504</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Detecting latent heterogeneity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="page">0049124115600597</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Combining observational and experimental data to find heterogeneous treatment effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Peysakhovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lada</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02385</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Operator variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Altosaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="496" to="504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.05770</idno>
		<title level="m">Variational inference with normalizing flows</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31th International Conference on Machine Learning</title>
		<meeting>the 31th International Conference on Machine Learning<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Adjusting for errors in classification and measurement in the analysis of partly and purely categorical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Selén</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">393</biblScope>
			<biblScope unit="page" from="75" to="81" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Estimating individual treatment effect: generalization bounds and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Does matching overcome lalonde&apos;s critique of nonexperimental estimators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Todd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of econometrics</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="305" to="353" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning mixtures of dag models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thiesson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence</title>
		<meeting>the Fourteenth conference on Uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="504" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<title level="m">The variational Gaussian process. International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kucukelbir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Dieng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Edward</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.09787</idno>
		<title level="m">A library for probabilistic modeling, inference, and criticism</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Estimation and inference of heterogeneous treatment effects using random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Athey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.04342</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A note on the use of proxy variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Wickens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica: Journal of the Econometric Society</title>
		<imprint>
			<biblScope unit="page" from="759" to="761" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">On estimating firm-level production functions using proxy variables to control for unobservables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Wooldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Economics Letters</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="112" to="114" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
