<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T22:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Light Field Blind Motion Deblurring</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratul</forename><forename type="middle">P</forename><surname>Srinivasan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Ramamoorthi</surname></persName>
							<email>2ravir@cs.ucsd.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Light Field Blind Motion Deblurring</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We study the   </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Motion blur is the result of relative motion between the scene and camera, where photons from a single incoming ray of light are spread over multiple sensor pixels during the exposure. In this work, we make both theoretical and practical contributions by studying the effects of camera motion on light fields and presenting a method to restore motionblurred light fields. Light field cameras are typically used in situations with optically significant scene depth ranges and out-of-plane camera motion, so it is important to consider how motion blur varies both spatially within each subaperture image and angularly between sub-aperture images. Theory We derive a forward model that describes a motion-blurred light field as an integration over transformations of the sharp light field along the camera motion path. By analyzing the motion-blurred light field in the primal and Fourier domains (Sec. <ref type="bibr">3 and Figs. 3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5)</ref>, we show that capturing a light field enables novel methods of motion deblurring that are not possible with just a conventional image. First, we show that a light field blurred with in-plane camera motion is a simple convolution of the sharp light field with the camera motion path kernel, regardless of the depth contents of the scene (Sec. 3.2.1). This allows us to use simple deconvolution to restore the sharp light field, which cannot be done with conventional images because the magnitude of the motion blur is depth-dependent <ref type="figure">(Figs. 4, 6</ref>). Addi- <ref type="figure">Figure 1</ref>. We theoretically study the effects of motion blur on a captured light field and present a practical algorithm to deblur light fields of general scenes captured with 3D camera motion. Left: a 4D light field (visualized as a 2D sub-aperture image and a 2D epipolar slice) is blurred by the synthetic camera motion shown in the inset. Right: absent knowledge of the synthetic motion path, our algorithm is able to accurately recover the sharp light field and the motion path. See <ref type="figure">Fig. 9</ref> for examples with real handheld camera motion.</p><p>tionally, we show that a light field blurred with out-of-plane camera motion is an integral over shears of the sharp light field (Sec. 3.2.2). Therefore, we can blindly deblur a light field of a textured plane captured with out-of-plane camera motion by modulating a slice of the Fourier spectrum of the motion-blurred light field <ref type="figure" target="#fig_2">(Figs. 4, 7)</ref>. This is not possible for conventional images due to the spatially-varying blur caused by out-of-plane camera motion. Practical Algorithm General light fields of 3D scenes captured with 3D camera motion are integrals over compositions of shears and shifts of the sharp light field. The general light field blind motion deblurring problem lacks a simple analytic approach and is severely ill-posed because there is an infinite set of pairs of sharp light fields and motion paths that explain any observed motion-blurred light field. We propose a practical light field blind motion deblurring algorithm to correct the complex blurring that occurs in situations where light field cameras are useful (Sec. 4). Our forward model is differentiable with respect to the camera motion path parameterization and the estimated light field, allowing us to simultaneously solve for both using firstorder optimization methods. Furthermore, by treating motion blur as an integration of transformations of the sharp light field, we can simplify the problem by bypassing any estimation of scene geometry. Instead of solving for a dense matrix that represents spatially and angularly varying motion blurs or separately deblurring each sub-aperture image by solving for a 2D blur kernel and 2D depth map, we directly solve for a parameterization of the continuous camera motion curve in R 3 . This is a much lower-dimensional optimization problem, and it allows us to utilize the structure of the light field to efficiently recover the motion curve and sharp light field. Finally, we demonstrate the performance of our algorithm on real <ref type="figure">(Fig. 9</ref>) and synthetically-blurred <ref type="figure">(Figs. 1, 8</ref>) light fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Light Fields The 4D light field <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24]</ref> is the total spatio-angular distribution of light rays passing through free space, and light field cameras capture the light field that exists inside the camera body <ref type="bibr" target="#b26">[27]</ref>. A conventional 2D fullaperture image is produced by integrating the rays entering the entire aperture for each spatial location. Therefore, a captured light field will be interesting and more useful than a conventional image when the equivalent full-aperture image contains significant depth-of-field effects, because this indicates that rays from different regions of the aperture have different values. Common photography situations where capturing a 4D light field would be useful include macro and portrait photography.</p><p>Previous work has demonstrated the benefits of lifting problems in computer vision, computer graphics, and computational photography into the 4D light field space. These include rendering 2D pinhole images as slices of the 4D light field <ref type="bibr" target="#b21">[22]</ref>, stereo reconstruction from a single capture <ref type="bibr" target="#b1">[2]</ref>, changing the focus and depth-of-field of photographs after capture <ref type="bibr" target="#b26">[27]</ref>, correcting lens aberrations <ref type="bibr" target="#b25">[26]</ref>, passive depth estimation <ref type="bibr" target="#b32">[33]</ref>, glare artifact reduction <ref type="bibr" target="#b30">[31]</ref>, and scene flow estimation <ref type="bibr" target="#b31">[32]</ref>.</p><p>Previous works have also examined the Fourier spectrum of light fields for various purposes. Chai et al. <ref type="bibr" target="#b5">[6]</ref> analyzed the spectral support of light fields for sampling in light field rendering and showed that Lambertian objects at specific depths correspond to angles in the Fourier domain. Durand et al. <ref type="bibr" target="#b10">[11]</ref> analyzed the effects of shading, occlusion, and propagation on the light field spectrum. Ng <ref type="bibr" target="#b24">[25]</ref> showed that refocusing a 2D full-aperture image is equivalent to taking 2D slices of the 4D light field spectrum and analyzed the performance of light field refocusing. Liang and Ramamoorthi <ref type="bibr" target="#b22">[23]</ref> developed a light transport framework to investigate the fundamental limits of light field camera resolution. Dansereau et al. <ref type="bibr" target="#b8">[9]</ref> derived the 4D spectral support of light fields for rendering, denoising, and refocusing. Additionally, Egan et al. <ref type="bibr" target="#b11">[12]</ref> analyzed the spectrum of motionblurred 3D space-time images to derive filters for efficient rendering of motion-blurred images. In this work, we analyze the Fourier spectrum of motion-blurred light fields to provide intuition for the effects of camera motion on the captured light field and methods to deblur light fields. Motion Deblurring Blind motion deblurring, removing the motion blur given just a noisy blurred image, is a very challenging problem that has been extensively studied (see <ref type="bibr" target="#b18">[19]</ref> for a recent review and comparison of various algorithms). Representative methods for single image blind deblurring include the variational Bayes approaches of Fergus et al. <ref type="bibr" target="#b12">[13]</ref> and Levin et al. <ref type="bibr" target="#b20">[21]</ref>, and algorithms using novel image priors such as normalized sparsity <ref type="bibr" target="#b17">[18]</ref>, an evolving approximation to the L 0 norm <ref type="bibr" target="#b33">[34]</ref>, and L 0 norms on both image gradients and intensities <ref type="bibr" target="#b27">[28]</ref>.</p><p>Previous multi-image blind deblurring works have also presented algorithms that recover a single 2D image, given multiple observations that have been blurred differently <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>. Jin et al. <ref type="bibr" target="#b14">[15]</ref> present a method that uses a motionblurred light field of a scene with two depth layers to recover a 2D image and bilayer depth map. Our method also takes a motion-blurred light field as input, but we recover a full 4D deblurred light field as opposed to a 2D texture. Moreover, our method does not need to estimate a depth map.</p><p>Many computational photography works have modified the imaging process to make motion deblurring easier. Raskar et al. <ref type="bibr" target="#b29">[30]</ref> used coded exposures to preserve high frequency details that would be attenuated due to object motion. Another line of work focused on modified imaging methods to engineer point spread functions that would be invariant to object motion. This includes focal sweeps <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17]</ref>, parabolic camera motions <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b19">20]</ref>, and circular sensor motions <ref type="bibr" target="#b2">[3]</ref>. In contrast, we focus on the problem of deblurring light fields that have already been captured, and we do not modify the imaging process.</p><p>Concurrently with our work, Dansereau et al. <ref type="bibr" target="#b7">[8]</ref> introduced a non-blind algorithm to deblur light fields captured with known camera motion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A Theory of Light Field Motion Blur</head><p>In our analysis below, we perform a flatland analysis of motion-blurred light fields with a single angular dimension u and a single spatial dimension x, and note that it is straightforward to extend this to the full 4D light field with spatial dimensions (x, y) and angular dimensions (u, v). We focus on 3D as opposed to 6D camera motion, so the camera motion path is a general 3D curve and the optical axis does not rotate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Forward Model</head><p>The observed blurred light field is the integration over the light fields captured at each time t during the exposure: <ref type="figure">Figure 2</ref>. Left: we use a 2-plane parameterization for light fields, where each ray (x, u) is defined by its intercept with the u and x planes separated by distance s. Note that the x coordinate is relative to the u coordinate, which is convenient for later derivations. Right: consider a camera translating along a path p(t) = (px(t), py(t), pz(t)) during its exposure (in flatland we consider x and z only). The local camera coordinate frame for each time t has its origin located at the center of the camera aperture. The light field lt(xt, ut) is the sharp light field that would have been recorded by the camera at time t, in the local camera coordinates at time t. The diagram shows that ray (xt, ut) in the local coordinate frame at time t is equal to ray (xt, ut + px(t) − where f is the observed light field and l t (x t , u t ) is the sharp light field at time t during the exposure. <ref type="figure">Figure 2</ref> illustrates that the light field at time t is a transformation of the sharp light field at time t = 0, l(x, u), based on the camera motion path p(t) = (p x (t), p z (t)) (p y (t) is not included in the flatland analysis but is included in the full 3D model). Our light field parameterization is equivalent to considering the light field as a collection of pinhole cameras with centers of projection u and sensor pixels x, and we set the separation between the x and u planes s = 1 so x is a ray's spatial intercept 1 unit above u in the z direction. The observed motion-blurred light field is then</p><formula xml:id="formula_0">f (x, u) = t l t (x t , u t )dt,<label>(1)</label></formula><formula xml:id="formula_1">f (x, u) = t l(x, u + p x (t) − xp z (t))dt.<label>(2)</label></formula><p>Since the light field contains all rays that intersect the two parameterization planes, this forward model accounts for occluded points, as long as the parameterization planes lie outside the convex hull of the visible scene geometry. Certain rare scenarios, such as a macro photography shot where the camera moves between blades of grass during the exposure, may violate this assumption, but it generally holds for typical photography situations. This model also assumes that the light field parameterization planes are infinite, because camera motion can cause the sharp light field at time t to contain rays outside the field-of-view of the light field at a previous time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Space-Angle and Fourier Analysis</head><p>We examine the motion-blurred light field in the primal space-angle and Fourier domains to better understand the effects of camera motion on the captured light field. We denote signals in the Fourier domain with capital letters, and use Ω x and Ω u to denote spatial and angular frequencies.</p><p>It is useful to utilize the Affine Theorem for Fourier transforms <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b28">29]</ref>: if h(a) = g(M b + c), where M is a matrix, a, b, and c are vectors, and h and g are functions, the relevant Fourier transforms are related as follows: </p><formula xml:id="formula_2">H(Ω) = |det(M )| −1 G(M −T Ω) exp(2πiΩ T M −1 c),<label>(3)</label></formula><formula xml:id="formula_3">F (Ωx, Ωu) = t L (Ωx + pz(t)Ωu, Ωu) exp [2πiΩupx(t)] dt.<label>(4)</label></formula><p>As visualized in <ref type="figure">Fig. 5</ref>, the Fourier spectrum is an integration over shears based on the out-of-plane motion p z (t) and there is also a phase in the complex exponential corresponding to in-plane motion. This complex exponential is the Fourier transform of δ(x)δ(u+p x (t)), so we can rewrite the flatland primal domain motion-blurred light field as</p><formula xml:id="formula_4">f (x, u) = t [l(x, u − xpz(t)) ⊗ δ(x)δ(u + px(t))]dt. (5)</formula><p>The spatial and frequency domain expressions now separate in-plane motion, which is a convolution with a kernel corresponding to the in-plane camera motion path, and outof-plane motion, which is an integration over shears in both the spatial and frequency domains. Note that this convolution kernel is restricted to a subspace of the light field space (1D subspace of 2D for flatland light fields, and 2D subspace of 4D for full light fields).</p><p>To gain greater insight into these expressions, we consider two special cases for purely in-plane camera motion, and purely out-of-plane camera motion, with general motion being an integral over compositions of these two cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">In-Plane Camera Motion</head><p>For camera motion paths that are parallel to the x and u parameterization planes, p z (t) = 0, and the expression for the primal domain motion-blurred light field simplifies to <ref type="figure">Figure 3</ref>. In-plane camera motion is equivalent to a convolution of the light field and the corresponding multiplication of the Fourier spectrum. We are able to easily recover a light field blurred with known in-plane camera motion using 4D deconvolution. Note that in-plane camera motion causes spatially-varying (with x) blur due to varying scene depths, as shown by the white brackets, while the blur magnitude does not vary angularly (with u), as shown by the yellow vertical arrows. <ref type="figure">Figure 4</ref>. Out-of-plane camera motion is equivalent to an integration over shears in both the primal and Fourier domains. Note that out-ofplane camera motion causes both spatially and angularly varying blur. Given a light field of a single fronto-parallel textured plane (Vincent van Gogh's "Wheat Field with Cypresses") with out-of-plane camera motion, we can blindly recover the texture, with slight artifacts due to finite aperture and edge effects, by modulating a 2D slice of the 4D Fourier spectrum. <ref type="figure">Figure 5</ref>. General 3D camera motion is an integration over shears and shifts of the light field and an integration over shears and phase multiplications of the Fourier spectrum. Blindly deblurring light fields captured with general camera motion lacks a simple analytic approach and is severely ill-posed, so we solve this as a regularized inverse problem.</p><formula xml:id="formula_5">f (x, u) = l(x, u) ⊗ t δ(x)δ(u + p x (t))dt = l(x, u) ⊗ δ(x)k(u),<label>(6)</label></formula><p>where k(u) = t δ(u + p x (t))dt is the integrated in-plane camera motion path.</p><p>In the Fourier domain,</p><formula xml:id="formula_6">F (Ω x , Ω u ) =L(Ω x , Ω u ) t exp[2πiΩ u p x (t)]dt =L(Ω x , Ω u )K(Ω u ),<label>(7)</label></formula><p>where</p><formula xml:id="formula_7">K(Ω u ) = t exp[2πiΩ u p x (t)]</formula><p>dt is the integrated inplane blur kernel spectrum.</p><p>An important insight is that for in-plane camera motion, it is possible to take the original light field out of the integral. <ref type="figure">Fig. 3</ref>. No such <ref type="bibr">Figure 6</ref>. Light fields of general 3D scenes blurred with known in-plane camera motion can be recovered by simple 4D deconvolution. This is not possible with conventional 2D images because the motion blur magnitude is depth-dependent. We synthetically blur a light field with increasing linear in-plane motion, and note that the root mean square error (RMSE) of the central sub-aperture image obtained by 2D deconvolution consistently increases, while the RMSE of the central sub-aperture image obtained by 4D deconvolution of the full light field stays relatively constant. <ref type="figure">Fig. 6</ref>, because the motion blur magnitude is depthdependent. Intuitively, in-plane motion is a convolution of the sharp light field because light field cameras at points along the motion path observe the same set of rays shifted, while conventional cameras at points along the motion path observe disjoint sets of rays. If we know the blur kernel, we can recover the sharp light field by simple deconvolution, as shown in <ref type="figure">Figs. 3, 6</ref>. However, if both the blur kernel and light field are unknown, we need to use priors to estimate the blur kernel and sharp light field, as discussed in Sec. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>This clearly identifies the motion-blurred light field as a simple convolution of the sharp light field with the inplane blur kernel, regardless of the content and range of depths present in the scene, as illustrated in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>simple result holds for conventional 2D images, as quantified in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Out-of-Plane Camera Motion</head><p>For purely out-of-plane camera motion, p x (t) = 0, and the expression for the primal domain motion-blurred light field simplifies to</p><formula xml:id="formula_8">f (x, u) = t l(x, u − xp z (t))dt<label>(8)</label></formula><p>In the Fourier domain,</p><formula xml:id="formula_9">F (Ω x , Ω u ) = t L(Ω x + p z (t)Ω u , Ω u )dt.<label>(9)</label></formula><p>These are simply integrations over different shears of the light field, as illustrated in <ref type="figure">Fig. 4</ref>. It is particularly interesting to consider the light field of a textured fronto-parallel plane w(x) at depth z ′ . The geometry of our light field parameterization indicates that l(x, u) = w(xz ′ + u). In the primal domain, the out-of-plane motion-blurred light field of this textured plane is</p><formula xml:id="formula_10">f (x, u) = t w(x(z ′ − pz(t)) + u)dt = t w(xz(t) + u)dt,<label>(10)</label></formula><p>where we define z(t) = z ′ − p z (t).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Using the Affine Theorem for Fourier transforms with transformation matrices</head><formula xml:id="formula_11">M = z(t) 1 0 1</formula><p>and c = ( 0 0 ), after noting that the original Fourier transform of the textured plane is W (Ω x )δ(Ω u ), the Fourier transform of the out-ofplane motion-blurred light field is</p><formula xml:id="formula_12">F (Ω x , Ω u ) = t 1 |z(t)| W Ω x z(t) δ Ω u − Ω x z(t) dt.</formula><p>(11) This is also an integration over various shears, each a line with slope given by Ω u = Ω x /z(t). The motion-blurred light field takes the original texture frequencies (in a line) and shears them to lines of different slopes, followed by integration. Using the sifting property of the delta function, we can simplify the above expression,</p><formula xml:id="formula_13">F (Ω x , Ω u ) =W (Ω u ) zmax zmin δ Ω u − Ω x z γ(z) dz,<label>(12)</label></formula><p>where we have switched to integration over z directly (effectively substituting z for t), and for simplicity, we assume z(t) monotonically increases with time. The term γ(z) = (|z|dz/dt) −1 accounts for the 1/|z| factor and change of variables.</p><p>Intuitively, the motion-blurred light-field spectrum is a double wedge <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11]</ref>, bounded by slopes z min and z max and containing an infinite number of lines in the frequencydomain. The magnitudes along each line are the same, determined by the original texture W (Ω u ), but every value is uniformly scaled by a factor γ(z), based on the amount of time the camera lingered at that depth (other than W (0), which is constant for all lines).</p><p>The delta function in Eq. 12 can then be evaluated, setting z = Ω x /Ω u , leading to the simple expression,</p><formula xml:id="formula_14">F (Ω x , Ω u ) = W (Ω u )β Ω x Ω u ,<label>(13)</label></formula><p>where the function β includes γ, as well as the change of variables from the delta function, and is given by</p><formula xml:id="formula_15">β(z) = |z| Ω x dz/dt β(Ω x /Ω u ) = |Ω u | dz dt Ωx/Ωu −1 .<label>(14)</label></formula><p>Texture Recovery The structure of the out-of-plane motion-blurred light field enables blind deblurring by a very simple factorization (essentially a rank-1 decomposition of the 2D light field matrix into 1D factors for W and γ or β).</p><p>One simple approach is to estimate W from any line, then fix the scaling by comparing the overall magnitude of W across lines to estimate the motion blur kernel (β or γ), and finally divide W (0) by the total exposure time. Taking a slice of the light field in the Fourier domain can be implemented in the primal domain by a sheared integral projection, and this is equivalent to refocusing the full-aperture image to a specific depth <ref type="bibr" target="#b24">[25]</ref>. Intuitively, this means that blind deblurring of the texture can be performed in the primal domain by computing the full-aperture image refocused to a single depth during the exposure. In summary, we can separately estimate the blur kernel and the original texture for out-of-plane motion of a light field camera, assuming a single fronto-parallel textured plane, by extracting a slice in the Fourier domain or equivalently refocusing the full-aperture image in the primal domain. <ref type="figure">Figure 4</ref> shows an example of a light field of a textured plane blurred by linear out-of-plane motion. We are able to blindly recover the texture, with slight artifacts due to finite aperture and edge effects, by computing a sheared integral projection (equivalent to taking a 2D slice of the 4D Fourier spectrum). As a practical note, when computing this in the discrete case, we must linearly scale frequencies in the extracted slice by |ζΩ x | + 1 to correct for the value of each discrete frequency being spread across the shear length during the exposure, where ζ is a constant corresponding to the relative time the camera lingers at the depth corresponding to that slice. ζ can be automatically determined by sampling Fourier slices and comparing their magnitudes to calculate the relative time spent at each depth along the motion path. This process is visualized in <ref type="figure" target="#fig_2">Fig. 7</ref>. As detailed in <ref type="bibr" target="#b24">[25]</ref>, the resolution of the recovered Fourier slice is limited by the angular resolution of the light field camera.</p><p>Comparison with a Conventional Image It is also insightful to compare this to information available from a conventional 2D image (1D in flatland), corresponding to the view from the central pinhole of a light field camera. In this case, we set u = 0 in Eq. 10, defining l(x) = w(xz ′ ). Since we are now working in 1D, from the Fourier scale theorem,</p><formula xml:id="formula_16">F (Ωx) = t 1 |z(t)| W Ωx z(t) dt = zmax z min W Ωx z γ(z)dz.<label>(15)</label></formula><p>This is similar to the light field case, except that we no longer have the delta function for multiple sheared lines in 2D; indeed we only have a single 1D line, with a frequency spectrum scaled according to z. It is clear that from the perspective of analysis and recovery, the conventional image case provides far less insight than in the light field case. We cannot separate out the texture W , and the methods for recovery discussed in the light field case do not apply, since there are not multiple lines in a 2D spectrum we can study. In fact, it is not even straightforward to recover texture and motion blur kernel even when one of the factors is known.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">General 3D Motion and Scenes</head><p>General 3D camera motion is an integral over compositions of shears and shifts of the light field, as shown in <ref type="figure">Fig. 5</ref>. Blindly deblurring a light field of a general scene captured with 3D camera motion lacks a simple analytic approach and is a severely ill-posed problem because there is an infinite set of pairs of light fields and motion paths that explain any observed motion-blurred light field. Below, we present an algorithm to estimate the sharp light field and camera motion path by solving a regularized inverse problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Blind Light Field Deblurring Algorithm</head><p>For blind light field motion deblurring, we estimate both the camera motion curve p(t) and the sharp light field l. We utilize our forward model derived in Eq. 2 to formulate a regularized inverse problem, and our approach is particularly efficient due to our direct representation of the camera motion curve, as discussed below. We solve a discrete optimization problem, since light field cameras record samples and not continuous functions:</p><formula xml:id="formula_17">min l,p(t) ||f (l, p(t)) − f || 2 2 + λψ(l),<label>(16)</label></formula><p>where the first term minimizes the L 2 norm of the difference between the observed motion-blurred light field f and that predicted by the forward modelf , and the second term, ψ(l), is a prior on the sharp light field. To address finite aperture and sensor planes, we assume replicating boundaries for the sharp light field. We use bilinear interpolation to transform the sharp light field along the camera motion path, so our forward model is differentiable with respect to the camera path and the sharp light field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Camera Motion Path Representation</head><p>We model the camera motion path p(t) as a Bézier curve made up of n control points in R 3 . This approach is much more efficient than the alternative approaches of solving for a dense matrix to represent spatially and angularly varying blurs, or separately deblurring each sub-aperture image. A dense motion blur ray transfer matrix would have size r ×r, where r is the number of rays sampled by the light field camera (this matrix would have size 2560000 × 2560000 for the light fields used in this work). Separately deblurring each sub-aperture image involves estimating a 2D depth map and a 2D convolution kernel, each of size s × s, where s is the number of samples along each spatial dimension (this equates to solving for two matrices of size 200 × 200 for the light fields used in this work). Instead, we solve for a much lowerdimensional vector of control points with 3n elements. In practice, we find that typical camera motion paths can be represented by n = 3 or n = 4 control points. <ref type="figure">Figure 8</ref>. Blind deblurring results on synthetically motion-blurred light fields. Our algorithm is able to correctly recover the sharp light field and estimate the 3D camera motion path, while alternative methods perform poorly due to the large spatial variance in the blur. Additionally, as demonstrated by the epipolar images, other algorithms do not recover a light field that is consistent across angular dimensions. The root mean square error (RMSE) of our deblurred results are consistently lower than those of the alternative methods.</p><p>Light Field Prior To regularize the inverse problem above, we use a 4D version of the sparse gradient prior proposed in <ref type="bibr" target="#b33">[34]</ref>:</p><formula xml:id="formula_18">ψ(l) = x,y,u,v 1 ǫ 2 |∇l| 2 if |∇l| ≤ ǫ, 1 otherwise.<label>(17)</label></formula><p>This function gradually approximates the L 0 norm of gradients by thresholding a quadratic penalty function parameterized by ǫ, and approaches the L 0 norm as ǫ → 0. Implementation Details We utilize the automatic differentiation of Tensorflow <ref type="bibr" target="#b0">[1]</ref> to differentiate the loss of the blind deblurring problem in Eq. 16 with respect to the camera motion path control points and sharp light field, and use the first-order Adam solver <ref type="bibr" target="#b15">[16]</ref> for optimization.</p><p>While the prior in Eq. 17 is effective for estimating the camera motion path, the sharp light fields estimated using this prior typically appear unnatural and over-regularized. We hold the camera motion path constant and solve Eq. 16 for the sharp light field using a 4D total variation (L 1 norm of gradients) prior to obtain the final sharp light field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Results</head><p>We validate our algorithm using light fields captured with the Lytro Illum camera, that have been blurred by both synthetic camera motion within a 2 mm cube using our forward model in Eq. 2 and real handheld camera motion using a shutter speed of 1/20 second. We compare our results to the alternative of applying state-of-the-art blind image motion deblurring algorithms to each sub-aperture image. As shown in a recent review and comparison paper <ref type="bibr" target="#b18">[19]</ref>, the algorithms of Krishnan et al. <ref type="bibr" target="#b17">[18]</ref> and Pan et al. <ref type="bibr" target="#b27">[28]</ref> are two of the top performers for blind deblurring of both real and synthetic images with spatially-varying blur, so we compare our algorithm to these two methods. As demonstrated by both the synthetically motion-blurred results in <ref type="figure">Fig. 8</ref> and the real motion-blurred results in <ref type="figure">Fig. 9</ref>, our algorithm is able to accurately estimate both the sharp light field and the camera motion path. The state-of-the-art blind image motion deblurring algorithms are not as successful due to the significant spatial variance of the blur. Furthermore, they are not designed to take advantage of the light field structure and do not estimate a 3D camera motion path, so their results are inconsistent between sub-aperture images, as demonstrated by the epipolar image results.</p><p>In the synthetically-blurred examples in <ref type="figure">Fig. 8</ref>, note that our algorithm correctly estimates the ground truth complex camera motion paths and corrects the large spatiallyvarying blurs in the flowers and leaves. In the real handheld blurred examples in <ref type="figure">Fig. 9</ref>, note that our algorithm corrects the blur in the specularities and edges of the circuit component, the leaves and flower of the rosemary plant, and the hair, eyebrows, teeth, and background plants. <ref type="bibr">Figure 9</ref>. Blind deblurring results on real handheld motion-blurred light fields. Our algorithm is able to correctly recover the sharp light field and estimate the 3D camera motion path. Note that we correct the motion seen in the specular reflections and object edges in the circuit component example, the motion seen in the leaves and flower in the rosemary plant example, and the motion seen in the hair, eyebrows, teeth, and background plants of the portrait example. Furthermore, our method produces angularly-consistent results, as demonstrated by the epipolar slices of all 3 examples. Please view our supplementary video and project webpage for animated visualizations of our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we studied the problem of deblurring light fields of general scenes captured with 3D camera motion. We analyzed the effects of motion blur on the light field in the primal and Fourier domains, derived simple methods to deblur light fields in specific cases, and presented an algorithm to infer the sharp light field and camera motion path from real and synthetically-blurred light fields. It would be interesting to extend our forward model to account for 3D rotations of the optical axis, and theoretically analyze the effects of camera rotation on the motion-blurred light field. Since the forward model would be differentiable with respect to the rotation parameters, our blind deblurring optimization algorithm can easily generalize to account for camera rotation.</p><p>We think that the insights of this work enable future investigations of light field priors that more explicitly consider the effects of motion blur on the light field, as well as novel interpretations of single and multi-image motion deblurring as subsets of the general light field motion deblurring problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>t)) in the local coordinate frame at time t = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>where det(M ) is the determinant of M and i = √ −1. We use this to take the Fourier transform of the observed motion-blurred light field in Eq. 2, with transformation ma-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Visualization of process to blindly recover a textured plane from a light field captured with out-of-plane camera motion.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments This work was supported in part by ONR grant N00014152013, NSF grant 1617234, NSF graduate research fellowship DGE 1106400, a Google Research Award, the UC San Diego Center for Visual Computing, and a GPU donation from NVIDIA.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<title level="m">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Single lens stereo with a plenoptic camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y A</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Motion deblurring from a single image using circular sensor motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-Y.</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nishita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Near-invariant blur for depth and 2D motion via time-varying light field analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Affine theorem for two-dimensional fourier transform. Electronics Letters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Bracewell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Plenoptic sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-X</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Motion blur removal with orthogonal parabolic exposures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCP</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Motion deblurring for light fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Dansereau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leitner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04308</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Linear volumetric focus for light field cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Dansereau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Pizarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Burst deblurring: removing camera shake through fourier burst accumulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Delbracio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sillion. A frequency analysis of light transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Holzschuch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Soler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Frequency analysis and sheared reconstruction for rendering motion blur</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Holzschuch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Removing camera shake from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The lumigraph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gortler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grzeszczuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bilayer blind deconvolution with the light field camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chandramouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV Workshops</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adam: a method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Depth and arbitrary motion deblurring using integrated PSF. ECCV Workshops</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sakaue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sato</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Blind deconvolution using a normalized sparsity measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A comparative study for single image blind deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Freeman. Motion-invariant photography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient marginal likelihood optimization in blind deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wiess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Light field rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIG-GRAPH</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A light transport framework for lenslet light field cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">La photographie intégrale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lippmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ComptesRendus, Académie des Sciences</title>
		<imprint>
			<date type="published" when="1908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fourier slice photography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Digital correction of lens aberrations in light field photography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE International Optical Design</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Light field photographhy with a hand-held plenoptic camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Levoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bredif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Duval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<idno>CSTR 2005-02</idno>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deblurring text images via L0-regularized intensity and gradient prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A firstorder analysis of lighting, shading, and shadows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Coded exposure photography: Motion deblurring using fluttered shutter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tumblin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Glare aware photography: 4D ray sampling for reducing glare effects of camera lenses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veeraraghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Oriented light-field windows for scene flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Depth from shading, defocus, and correspondence using light-field angular coherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Unnatural L0 sparse representation for natural image deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi-image blind deblurring using a coupled adaptive sparse prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deconvolving PSFs for a better motion deblurring using multiple images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sroubek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
