<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T23:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Adaptive Image Clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
							<email>jianlong.chang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer and Control Engineering</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfeng</forename><surname>Wang</surname></persName>
							<email>lfwang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
							<email>gfmeng@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiming</forename><surname>Xiang</surname></persName>
							<email>smxiang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhong</forename><surname>Pan</surname></persName>
							<email>chpan@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Adaptive Image Clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Image clustering is a crucial but challenging task in machine learning and computer vision. Existing methods often ignore the combination between feature learning and clustering. To tackle this problem, we propose Deep Adaptive Clustering (DAC) that recasts the clustering problem into a binary pairwise-classification framework to judge whether pairs of images belong to the same clusters. In DAC, the similarities are calculated as the cosine distance between label features of images which are generated by a deep convolutional network (ConvNet). By introducing a constraint into DAC, the learned label features tend to be one-hot vectors that can be utilized for clustering images. The main challenge is that the ground-truth similarities are unknown in image clustering. We handle this issue by presenting an alternating iterative Adaptive Learning algorithm where each iteration alternately selects labeled samples and trains the ConvNet. Conclusively, images are automatically clustered based on the label features. Experimental results show that DAC achieves state-of-the-art performance on five popular datasets, e.g., yielding 97.75% clustering accuracy on MNIST, 52.18% on CIFAR-10 and 46.99% on STL-10.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image clustering is an essential data analysis tool in machine learning and computer vision. Many applications such as content-based image annotation <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref> and image retrieval <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b32">34]</ref> can be viewed as different instances of image clustering. Technically, image clustering is the process of grouping images into clusters such that the images within the same clusters are similar to each other, while those in different clusters are dissimilar.</p><p>In the literature, much research has been dedicated to image clustering <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b36">38]</ref>. Traditionally, various clustering methods have been explored, including Kmeans <ref type="bibr" target="#b30">[32]</ref>, agglomerative clustering <ref type="bibr" target="#b8">[9]</ref>, and so on. In spite of their success in data clustering, traditional methods depend on predefined distance metrics which are difficult to identify</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initial stage</head><p>Intermediate stage Final stage <ref type="figure">Figure 1</ref>. Clustering results on the MNIST <ref type="bibr" target="#b15">[16]</ref> test set. Different colors represent different clusters, respectively. For clarity, we map the learned label features to the regular decagon in the twodimensional space. The ten vertexes correspond to the ten one-hot vectors in the ten-dimensional space, respectively. The details of the mapping function can be found in the supplementary material.</p><p>on image datasets. Recently, efforts have focused on deep unsupervised feature learning methods, such as the autoencoder <ref type="bibr" target="#b0">[1]</ref> and the auto-encoding variational bayes <ref type="bibr" target="#b12">[13]</ref>, for learning the representations of images which are used for clustering images. Technically, they adopt a multi-stage pipeline that pre-trains deep neural networks with unsupervised methods firstly and employs traditional methods for clustering images as post processing. While the advances are observable, these representation-based approaches also have some intrinsic limitations. First, multi-stage image clustering paradigms are obviously cumbersome in practice. Second, the learned representations are fixed after the unsupervised feature learning. Consequently, in the clustering process, the representations can not be further improved to obtain better performance. In this paper, we introduce Deep Adaptive Clustering, a single-stage ConvNet-based method to cluster images. To this end, we consider the image clustering task as a binary pairwise-classification problem to judge whether pairs of images belong to the same clusters. Specifically, the image are represented by label features generated by a deep ConvNet, and similarities are measured by the cosine distance between label features. Furthermore, the learned label features tend to be one-hot vectors by introducing a constraint into DAC. Since the ground-truth similarities are unknown, we also develop an Adaptive Learning algorithm, an alternating iterative method, to optimize our model. During each iteration, pairwise images with the estimated similarities are first selected based on the fixed ConvNet. Subsequently, DAC employs the selected labeled samples to train the ConvNet in a supervised way. The algorithm converges when all the samples are included for training and the objective function of the binary pairwise-classification problem can not be improved further. Finally, images are clustered by locating the largest response of label features. The visual results of DAC on the MNIST test set <ref type="bibr" target="#b15">[16]</ref> are illustrated in <ref type="figure">Figure 1</ref>.</p><p>To sum up, the main contributions of this work are:</p><p>• The proposed DAC model adopts a binary pairwiseclassification framework for image clustering, which benefits the feature learning in a "supervised" manner.</p><p>• The learned label features tend to be one-hot vectors by introducing a constraint into DAC. Thus we can perform clustering by locating the largest response of the learned label features, which can dramatically simplify the image clustering process.</p><p>• We introduce a single-stage method named Adaptive Learning algorithm to optimize our model, which can streamline the learning procedure for image clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Data Clustering. Much research has been devoted to data clustering methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b30">32,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b36">38]</ref>. Generally, existing methods can be roughly divided into three categories: distance-based, density-based and connectivitybased methods. Distance-based methods, such as the Kmeans <ref type="bibr" target="#b29">[31,</ref><ref type="bibr" target="#b30">32]</ref> and the agglomerative clustering (AC) <ref type="bibr" target="#b8">[9]</ref>, seek to find the relationship between data points based on various distance metrics. Density-based methods attempt to cluster data points via a proper density function, including the density-based spatial clustering of applications with noise <ref type="bibr" target="#b31">[33]</ref>. Compared with the previous methods, connectivity-based methods cluster data points into a cluster if they are highly connected. The frequently used method is the spectral clustering (SC) <ref type="bibr" target="#b38">[40]</ref>. The aforementioned ideas form the basis of a number of methods, such as the ensemble clustering <ref type="bibr" target="#b10">[11]</ref>, the non-negative matrix factorization (NMF) based clustering <ref type="bibr" target="#b2">[3]</ref>, and so on.</p><p>Image Representation. Image representation is one of the most important issues in image clustering. In the literature, several methods have been proposed. Clustering methods traditionally encode images according to low-level features, such as HOG <ref type="bibr" target="#b5">[6]</ref>, SIFT <ref type="bibr" target="#b16">[17]</ref>, and so on. While these feature descriptors may loose representations from messy variables (e.g., rotation, luminance), they often suffer from appearance variations of scenes and objects.</p><p>Over the last decade, deep unsupervised feature learning has been explored to learn the informative representations of images. Technically, most deep unsupervised learning methods aim to learn the feature representations that are able to reconstruct the inputs themselves, such as the auto-encoder (AE) <ref type="bibr" target="#b0">[1]</ref>, the sparse auto-encoder (SAE) <ref type="bibr" target="#b17">[18]</ref>, the denoising auto-encoder (DAE) <ref type="bibr" target="#b28">[30]</ref>, the deconvolutional network (DeCNN) <ref type="bibr" target="#b37">[39]</ref>, the stacked what-where auto-encoder (SWWAE) <ref type="bibr" target="#b39">[41]</ref>, and so on. Additionally, deep generative models, including the auto-encoding variational bayes (AEVB) <ref type="bibr" target="#b12">[13]</ref> and the generative adversarial network (GAN) <ref type="bibr" target="#b20">[21]</ref>, have been provided to encode visual information recently. However, clustering results can not be obtained immediately based on the generated representations by the aforementioned methods.</p><p>Combination. Recently, several methods have been proposed to combine feature learning with clustering into a single model. Inspired by the parametric t-SNE <ref type="bibr" target="#b26">[28]</ref>, Xie et al. <ref type="bibr" target="#b33">[35]</ref> proposed deep embedded clustering (DEC), which can be used to learn cluster centers. There is a nuisance fact that the utilized deep networks require pre-training in advance. However, how to effectively pre-train deep networks is an open problem. Unlike DEC, the joint unsupervised learning (JULE) <ref type="bibr" target="#b34">[36]</ref> guides agglomerative clustering and feature learning jointly based on the over-clustering initialized by KNN. Since the distances between different images are difficult to define, beginning with the over-clustering may degrade the performance of JULE, especially when image datasets are observably complicated.</p><p>Sample Selection. In machine learning, how to select training samples to learn more effective models is an active research topic. Primitively, boosting algorithm <ref type="bibr" target="#b7">[8]</ref> randomly selects partial samples from training set to train a set of diverse models. And a single strong learner is created by integrating these models. Furthermore, by mimicking the cognitive process of humans, curriculum learning <ref type="bibr" target="#b1">[2]</ref> uses the easy samples first and gradually provides the learning algorithm with more complex ones. To voluntarily select samples in training, Kumar et al. <ref type="bibr" target="#b14">[15]</ref> presented self-paced learning that incorporates curriculum choosing into model training. Although such achievements are notable, these methods are purely working with the labeled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Deep Adaptive Clustering Model</head><p>To begin with, we assume that the relationship of pairwise images is binary. That is, each pair of images belong to either the same clusters or different clusters. Based on this assumption, we recast the image clustering task into a binary pairwise-classification model. Since the similarities between images are unknown, we adaptively select pairwise images to train the model by investigating the similarities. The flowchart of DAC is illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>. More details are given in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Binary Pairwise-Classification for Clustering</head><p>Given the unlabeled image dataset X = {x i } n i=1 and the predefined number of clusters k, where x i indicates i-th images, we formulate the image clustering task as a binary pairwise-classification problem. Denote the training data Step 1 generates the label features (as shown in the pink box) of the images by using a ConvNet.</p><p>Step 2 calculates the cosine similarities between images based on the label features.</p><p>Step 3 selects training samples according to the cosine similarities, and the samples depicted in the red boxes represent the omitted samples in training procedure.</p><p>Step 4 utilizes the selected samples to train the ConvNet based on the formulated binary pairwise-classification model. Iterate step 1 to step 4 until all the samples are considered for training. Conclusively, images are clustered by locating the largest response of label features.</p><formula xml:id="formula_0">as D = {(x i , x j , r ij )} n i=1,j=1</formula><p>, where x i , x j ∈ X are the unlabeled images (which refer to the input) and r ij ∈ Y is the unknown binary variable (which refer to the output). In this work, r ij = 1 indicates that x i , x j belong to the same cluster and r ij = 0 otherwise. Accordingly, the objective function of DAC is defined as follows:</p><formula xml:id="formula_1">min w E(w) = i,j L(r ij , g(x i , x j ; w)),<label>(1)</label></formula><p>where L(r ij , g(x i , x j ; w)) is the loss between r ij and the estimated similarity g(x i , x j ; w), w represents the model parameters in function g. Formally,</p><formula xml:id="formula_2">L(r ij , g(x i , x j ; w)) = (2) −r ij log(g(x i , x j ; w)) − (1 − r ij ) log(1 − g(x i , x j ; w)).</formula><p>Generally, two issues in Eq. (1) need to be addressed, i.e., the clusters of x i and x j are unacquirable by only accessing to the estimated similarity g(x i , x j ; w) and Y is unknown in the image clustering process. Section 3.2 and 3.3 focus on addressing these two issues, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Label Features under Clustering Constraint</head><p>To measure the similarities of image pairs, we introduce</p><formula xml:id="formula_3">label features L = {l i ∈ R k } n i=1</formula><p>, where l i represents the k-dimensional label feature of the image x i <ref type="bibr" target="#b9">[10]</ref>. The similarity g(x i , x j ; w) is defined as the cosine distance between two label features. Further, we impose a clustering constraint on the label features to learn more beneficial feature representations for clustering images, i.e.,</p><formula xml:id="formula_4">∀ i, l i 2 = 1, and l ih ≥ 0, h = 1, · · · , k,<label>(3)</label></formula><p>where · 2 represents L 2 -norm of a vector and l ih is the h-th element of label feature l i . Due to ∀ i, l i 2 = 1, the cosine similarity g(x i , x j ; w) can be formulated as:</p><formula xml:id="formula_5">g(x i , x j ; w) = f (x i ; w) · f (x j ; w) = l i · l j ,<label>(4)</label></formula><p>where f w is a mapping function that maps input images to label features and the operator "·" represents dot product between two label features. By introducing the clustering constraint, the DAC model can be reformulated as:</p><formula xml:id="formula_6">min w E(w) = i,j L(r ij , l i · l j ), s.t. ∀ i, l i 2 = 1, and l ih ≥ 0, h = 1, · · · , k.<label>(5)</label></formula><p>The clustering constraint in Eq. (3) brings an interesting property for data clustering. Let E k denote the standard basis of the k-dimensional Euclidean space, we have the following theorem (the proof of this theorem is reported in the supplementary material):</p><formula xml:id="formula_7">THEOREM 1. If the optimal value of Eq. (5) is attained, for ∀ i, j, l i ∈ E k , l i = l j ⇔ r ij = 0 and l i = l j ⇔ r ij = 1.</formula><p>Theorem 1 indicates that the learned label features are k diverse one-hot vectors ideally. That is, images can be automatically clustered based on the learned label features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Labeled Training Samples Selection</head><p>In practice, a strategy for selecting labeled training samples is needed, since Y is unknown in image clustering. For ConvNets, specifically, we have two observations. First, if ConvNets are already trained, the high-level features of images can be generated. Second, for randomly initialized ConvNets, they can also capture the low-level features of images, since the randomly initialized filters act as edge detectors <ref type="bibr" target="#b25">[27]</ref>. Based on these observations, we employ ALLConvNets <ref type="bibr" target="#b24">[25]</ref> to implement f w and select labeled training samples based on the generated label features, i.e.,</p><formula xml:id="formula_8">r ij :=    1, if l i · l j ≥ u(λ), 0, if l i · l j &lt; l(λ), None, otherwise, i, j = 1, · · · , n, (6)</formula><p>where λ is an adaptive parameter for controlling the selection, u(λ) and l(λ) are the thresholds for selecting similar and dissimilar labeled samples, respectively. And "None" implies that the sample (x i , x j , r ij ) is omitted for training.</p><p>Inspired by curriculum learning <ref type="bibr" target="#b1">[2]</ref>, we attempt to control the clustering procedure such that the samples are increasingly selected. That is, "easy" samples with high likelihood are first selected as training samples to find rough cluster patterns. Then, as the clustering procedure progresses, the trained ALL-ConvNets can be utilized for extracting more effective label features and more samples will be gradually appended to find more refined cluster patterns. For this purpose, we control the parameter λ, u(λ) and l(λ) as follows. In the clustering process, λ is gradually increased. Furthermore, u(λ) ∝ −λ, l(λ) ∝ λ and l(λ) ≤ u(λ) are permanently satisfied. And u(λ) = l(λ) is satisfied if and only if all the samples are used for training.</p><p>So far we have addressed the two issues in Section 3.1. The DAC model can be rewritten as:</p><formula xml:id="formula_9">min w,λ E(w, λ) = i,j v ij L(r ij , l i · l j ) + u(λ) − l(λ), s.t. l(λ) ≤ u(λ), v ij ∈ {0, 1}, i, j = 1, · · · , n, ∀ i, l i 2 = 1, and l ih ≥ 0, h = 1, · · · , k, r ij :=    1, if l i · l j ≥ u(λ), 0, if l i · l j &lt; l(λ), None, otherwise, i, j = 1, · · · , n,<label>(7)</label></formula><p>where v is an indicator coefficient, i.e.,</p><formula xml:id="formula_10">v ij := 1, if r ij ∈ {0, 1}, 0, otherwise, i, j = 1, · · · , n,<label>(8)</label></formula><p>where v ij = 1 indicates that the sample (x i , x j , r ij ) is selected for training, and v ij = 0 otherwise. Notice that u(λ)−l(λ) is a penalty term for the number of training samples. By decreasing the penalty term, more samples will be selected for training until all the samples are included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Deep Adaptive Clustering Algorithm</head><p>In this section, we present an optimization algorithm for the DAC model in Eq. (7) and a label inference method for image clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Adaptive Learning</head><p>To optimize the model in Eq. <ref type="formula" target="#formula_9">(7)</ref>, Adaptive Learning algorithm, an alternating iterative optimization scheme, is de- </p><formula xml:id="formula_11">Algorithm 1 Deep Adaptive Clustering Input: Dataset X = {x i } n i=1 , f w , λ, u(λ), l(λ),</formula><formula xml:id="formula_12">for all k ∈ {1, 2, · · · , n m } do 4:</formula><p>Sample batch X k from X ; // m images per batch <ref type="bibr">5:</ref> Select training samples from X k ; // Eq. <ref type="formula">(6)</ref> 6:</p><p>Calculate the indicator parameter v; // Eq. <ref type="formula" target="#formula_10">(8)</ref> 7:</p><p>Update w by minimizing Eq. (10); <ref type="bibr">8:</ref> end for</p><formula xml:id="formula_13">9:</formula><p>Update λ according to Eq. (12); 10: until l(λ) &gt; u(λ) <ref type="bibr">11:</ref> for all x i ∈ X do 12:</p><p>l i := f (x i ; w); <ref type="bibr">13:</ref> c i := arg max h (l ih ); 14: end for veloped. The algorithm focuses on two issues, namely the clustering constraint and the iterative optimization.</p><p>We establish a restraint layer to implement the clustering constraint in Eq. (3). The mapping functions of the restraint layer are formulated as:</p><formula xml:id="formula_14">L out h := exp L in h −max h (L in h ) , h = 1, · · · , k, (9a) L out h := L out h L out 2 , h = 1, · · · , k,<label>(9b)</label></formula><p>where L in , L out ∈ R k are the input and output of the restraint layer, respectively. L The optimization of w and λ is performed alternately. Once r and v are obtained and λ is fixed, the DAC model degenerates as follows:</p><formula xml:id="formula_15">min w E(w) = i,j v ij L(r ij , f (x i ; w) · f (x j ; w)). (10)</formula><p>Since r and v are available, Eq. (10) is a supervised learning problem that the back-propagation learning algorithm can be utilized to update w. Specifically, the storage complexity of r and v is O(n 2 ) because the similarities of pairwise images need to be calculated. It is too high to deal with large datasets. To handle this issue, we randomly sample image batches from the original datasets and update w on each batch, as illustrated in the line 3 to line 8 of the Algorithm 1.</p><p>Similarly, our DAC model can be simplified as follows when w is fixed,</p><formula xml:id="formula_16">min λ E(λ) = u(λ) − l(λ).<label>(11)</label></formula><p>According to the gradient descent algorithm, in each iteration, the update rule of λ can be written as:</p><formula xml:id="formula_17">λ := λ − η · ∂E(λ) ∂λ ,<label>(12)</label></formula><p>where η is the learning rate of λ. Since u(λ) ∝ −λ and l(λ) ∝ λ,</p><formula xml:id="formula_18">∂E ∂λ = ∂u(λ) ∂λ − ∂l(λ)</formula><p>∂λ ≤ 0 is always satisfied. This corresponds to our target scenario that all the samples are gradually added for training with the increasing of λ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Label Inference for Image Clustering</head><p>The label features are ideally one-hot vectors according to Theorem 1. As a result, images can be clustered via:</p><formula xml:id="formula_19">c i := arg max h (l ih ), h = 1, · · · , k,<label>(13)</label></formula><p>where c i is the cluster label of image x i . In practice, however, the label features may not be one-hot vectors strictly due to the following two reasons. First, it is hard to reach the global optima for training a ConvNet due to its strong non-convex property. Second, even it achieves a global optimum on the training data, it is almost impossible for it to achieve a global optimum for all data (including the unseen testing data). To address this issue, we label images by locating the largest response of label features, i.e., Eq. (13) is implemented to cluster. In summary, we illustrate the DAC algorithm in Algorithm 1. The Adaptive Learning algorithm optimize the DAC model iteratively. During each iteration, the algorithm alternately selects samples via the fixed ConvNet and trains the ConvNet based on the selected samples. When all the samples are considered for training and the objective function in Eq. (10) can not be improved further, the algorithm converges. Conclusively, images are clustered by locating the largest response of the label features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In this section, we apply the proposed DAC model to image clustering and evaluate the performance on several popular datasets with three frequently-used measures. Specifically, our core code 1 is released at https://github. com/vector-1127/DAC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Datasets</head><p>We perform experiments on five popular image datasets, including MNIST <ref type="bibr" target="#b15">[16]</ref>, CIFAR-10 <ref type="bibr" target="#b13">[14]</ref>, CIFAR-100 <ref type="bibr" target="#b13">[14]</ref>, STL-10 <ref type="bibr" target="#b4">[5]</ref> and ILSVRC2012 1K <ref type="bibr" target="#b6">[7]</ref>. The number of images and clusters, and image size are listed in <ref type="table">Table 1</ref> described in <ref type="bibr" target="#b33">[35,</ref><ref type="bibr" target="#b34">36]</ref>, the training and testing images of each dataset are jointly utilized in our experiments. For the CIFAR-100 dataset, the 20 superclasses are considered in our experiments. Specifically, we randomly choose 10 subjects from the ILSVRC2012 1K dataset <ref type="bibr" target="#b6">[7]</ref> and resize these images to 96 × 96 × 3 to construct the ImageNet-10 dataset for our experiments. Furthermore, to compare the clustering methods on more complex dataset, we randomly select 15 kinds of dog images from ILSVRC2012 1K to establish the fine-grained ImageNet-Dog dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Evaluation Metrics</head><p>In our experiments, three popular measures in the literature are employed to evaluate the performance of clustering methods, including Adjusted Rand Index (ARI), Normalized Mutual Information (NMI) and clustering Accuracy (ACC). Specifically, these measures range in [0, 1], and higher scores imply more accurate clustering results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Compared methods</head><p>Several clustering algorithms are employed for comparison. Specifically, the traditional methods, including Kmeans <ref type="bibr" target="#b30">[32]</ref>, SC <ref type="bibr" target="#b38">[40]</ref>, AC <ref type="bibr" target="#b8">[9]</ref> and the NMF based clustering <ref type="bibr" target="#b2">[3]</ref>, are adopted to compare with our model. For the representation-based clustering approaches, as described in <ref type="bibr" target="#b33">[35]</ref>, we employ some unsupervised learning methods, including AE <ref type="bibr" target="#b0">[1]</ref>, SAE <ref type="bibr" target="#b17">[18]</ref>, DAE <ref type="bibr" target="#b28">[30]</ref>, DeCNN <ref type="bibr" target="#b37">[39]</ref>, SWWAE <ref type="bibr" target="#b39">[41]</ref>, AEVB <ref type="bibr" target="#b12">[13]</ref> and GAN <ref type="bibr" target="#b20">[21]</ref>, to learn feature representations of images and use K-means <ref type="bibr" target="#b30">[32]</ref> to cluster images as post processing. We also compare DAC with DEC <ref type="bibr" target="#b33">[35]</ref> and JULE <ref type="bibr" target="#b34">[36]</ref> for a comprehensive comparison. To evaluate the capability of Adaptive Learning algorithm, we consider all the samples for training during each iteration, and this training strategy denoted by DAC*.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Experimental Settings</head><p>For the traditional clustering methods, following the previous work <ref type="bibr" target="#b33">[35]</ref>, we concatenate HOG feature <ref type="bibr" target="#b5">[6]</ref> and a 8 × 8 color map as input when we experiment on STL-10, ImageNet-10 and ImageNet-Dog. For the remaining datasets and methods, the pixel intensities serve as inputs.</p><p>In our experiments, the ALL-ConvNet described in <ref type="bibr" target="#b24">[25]</ref> is utilized in our model (the details of the devised ConvNets are listed in the supplementary material). Since the prior probability of image pairs belonging to different clusters is   <ref type="table">Table 3</ref>. The results of the traditional methods based on the DAC learned label features. The best results are indicated in bold. higher than to the same clusters, we set u(λ) = 0.95 − λ and l(λ) = 0.455 + 0.1 · λ for selecting similar and dissimilar samples, respectively. The adaptive parameter λ is initialized to 0 with the learning rate η = 0.009. In each iteration, we randomly select m = 1000 images to select training samples. In DAC*, we set u(λ) = l(λ) = 0.95 for the beginning, followed by an annealing phase which decreases linearly to u(λ) = l(λ) = 0.5. More details of training settings are reported in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Image Clustering</head><p>In <ref type="table" target="#tab_2">Table 2</ref>, we report the quantitative clustering results of these clustering methods. Note that DAC dramatically outperforms the others methods with significant margins on all the three clustering quality measures. Further observation, several tendencies can be observed in <ref type="table" target="#tab_2">Table 2</ref>. First, the performance of representation-based clustering methods (e.g., AE <ref type="bibr" target="#b0">[1]</ref>, AEVB <ref type="bibr" target="#b12">[13]</ref>) is superior to the traditional methods (e.g., K-means <ref type="bibr" target="#b30">[32]</ref>, SC <ref type="bibr" target="#b38">[40]</ref>). This indicates that clustering methods have only a minor impact on performance, while representations are more important. It means that the representation learning plays a crucial role in image clustering. Second, although the effective representations can be learned by these unsupervised methods, the improvement is limited compared against our approach. This demonstrates that the end-to-end clustering scheme can observably improve the performance of image clustering. The reason is that our single-stage method can learn more excellent representations for image clustering. Thirdly, more distinct superiority is achieved by DAC on CIFAR-10, CIFAR-100, STL-10 and ImageNet. This verifies that DAC has enough capability to handle complex large-scale image datasets.</p><p>In <ref type="figure" target="#fig_4">Figure 3</ref>, we qualitatively analysis the label features learned by DAC on MNIST, STL-10 and a randomly chosen ImageNet-10. We observe that the same neurons will be distinctly activated in the label features if the images belong to the same clusters. That is, our method learns high-level features, rather than the simple combination of visual features. This is the reason why more complicated images, such as the airliner and airship images in ILSVRC2012 1K, can be distinguished by DAC. Furthermore, most of the label features of the failure modes appear reasonable. For example, in terms of car, only the other types of vehicle (e.g., truck) might be considered as plausible labels, rather than the clusters beyond vehicle. It implies that more interpretable features are leaned by DAC for image clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.">Empirical Analysis</head><p>Effect of Adaptive Learning Algorithm. We compare the performance of DAC* with DAC to investigate the effect of the Adaptive Learning algorithm. From <ref type="table" target="#tab_2">Table 2</ref>, we observe that DAC achieves better performance than DAC*. Further analysis, since ConvNets are initialized randomly, more noisy samples will be utilized for training in DAC*. Contrary to DAC*, DAC can select highly confident training data based on the Adaptive Learning algorithm. By using these selected samples, DAC can begin with more refined cluster patterns and improve the clustering performance consequently.</p><p>Effect of Clustering Tactics. In order to evaluate the effect of our clustering tactics in Eq. <ref type="formula" target="#formula_1">(13)</ref>, we employ the traditional methods (e.g., K-means <ref type="bibr" target="#b30">[32]</ref>) to cluster images  based on the label features learned by DAC. The results are listed in <ref type="table">Table 3</ref>. Note that our clustering tactics achieves better performance than the traditional methods. Furthermore, compared with these traditional methods, the clustering tactics is more terse since DAC just needs to locate the largest response of label features to cluster images.</p><p>Contribution of Clustering Constraint. To investigate the effect of the clustering constraint in Eq. (3), we report the distribution of the learned label features on MNIST and ImageNet-10 in different clustering stages in <ref type="figure" target="#fig_5">Figure 4</ref>. We count the elements of the learned label features in the four disjoint intervals, i.e., stage. This implies that the learned label features are sparse and the non-zero elements in the label features tend to be 1. It corresponds to our target that DAC attempts to learn one-hot vectors to represent and cluster images.</p><p>Performance on Imbalanced Datasets. We perform additional experiments to study the performance of DAC on imbalanced datasets. Following the previous work <ref type="bibr" target="#b33">[35]</ref>, we randomly sample subsets of MNIST with various minimum retention rates. For the minimum retention rate r, data points of class 0 will be kept with probability r and class 9 with probability 1, with the other classes linearly in between. From <ref type="figure" target="#fig_6">Figure 5</ref> we observe that DAC is more robust than the others methods on the various imbalanced datasets. A possible reason is that DAC executes image clustering based on similarities between images only, which can reduce the influence of the unbalancedness of datasets. Performance on Various Number of Clusters. We also conduct experiment on the ILSVRC2012 1K dataset <ref type="bibr" target="#b6">[7]</ref> to study the stabilities of these methods by varying the number of clusters. Intuitively, <ref type="figure">Figure 6</ref> shows the clustering results when the number of clusters various between 10 and 50 with an interval 5. In summary, as the number of clusters increases, all the methods are generally degraded. This is because more uncertainty is triggered as the number of clusters increases. However, contrary to other methods, the superiority of DAC still holds with the various number of clusters. The results demonstrate that DAC possesses adequate capability to tackle various clusters.</p><p>Performance on Various Number of Samples. To observe the effect of the number of samples to these methods, we vary it between 10000 and 60000 with an interval 10000 on MNIST and CIFAR-10. <ref type="figure">Figure 7</ref> visually shows that the performance of most methods improves with more samples. This indicates that more samples are beneficial for these methods. For the CIFAR-10 dataset, we observe that the performance of DAC increases rapidly when more samples are considered. Contrary to CIFAR-10, DAC reaches an saturation status by using less samples on MNIST. This is to be expected, since sufficient samples are essential for mapping more intricate images from the visual features to the label features. In particular, the performance of the JULE method <ref type="bibr" target="#b34">[36]</ref> approximates to our method on the MNIST dataset. However, there is a conspicuous margin on CIFAR-10. This is because the initialization strategy of the JULE method is invalidated on intricate image datasets, which degenerates the performance of JULE. Compared with JULE, DAC alleviates the dependence on additional techniques by introducing the Adaptive Learning algorithm, which elevates the dependability of DAC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We proposed a single-stage ConvNet-based method to cluster images. Our method is motivated from a basic assumption that the relationship between pairwise images is binary. Based on this assumption, a binary constrained pairwise-classification model is proposed by investigating the similarities between image pairs. We theoretically verified that our model can be guided to represent images via one-hot vectors that can be utilized for clustering images. In comparison with the existing approaches, the proposed method achieves superior performance on five challenging datasets. It shows that our method can deal with large-scale images, not merely limited to some simple image datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The flowchart of DAC. The input is a set of unlabeled images. Step 1 generates the label features (as shown in the pink box) of the images by using a ConvNet. Step 2 calculates the cosine similarities between images based on the label features. Step 3 selects training samples according to the cosine similarities, and the samples depicted in the red boxes represent the omitted samples in training procedure. Step 4 utilizes the selected samples to train the ConvNet based on the formulated binary pairwise-classification model. Iterate step 1 to step 4 until all the samples are considered for training. Conclusively, images are clustered by locating the largest response of label features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>h-th element of L in and L out , respectively. Note that all the ele- ments of the output L out are mapped into [0, 1] by Eq. (9a) and the output L out is simultaneously limited to unit vector by Eq. (9b). In our model, the ALL-ConvNets are always followed by the restraint layer. That is, ∀ i, l i invariably satisfies the clustering constraint in Eq. (3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. The label features learned by DAC on MNIST, STL-10 and a randomly chosen ImageNet-10. For each dataset, the correct labels are written on the upward side, the label features are shown on the right side of images and the bottom line shows some failure modes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. The distribution of elements in all label features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Clustering accuracy on imbalanced subset of MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .Figure 7 .</head><label>67</label><figDesc>Figure 6. Comparison of clustering performance with increasing number of clusters on ILSVRC2012 1K (1300 images per cluster).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>η, m. Output: Cluster label c i of x i ∈ X .</figDesc><table>1: Randomly initialize w; 
2: repeat 

3: 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>. As 1 Relies on Keras [4] with the Theano [26] backend. Table 1. The image datasets used in our experiments.</figDesc><table>Dataset 
Images 
Clusters 
Image size 

MNIST [16] 
70000 
10 
28 × 28 
CIFAR-10 [14] 
60000 
10 
32 × 32 × 3 
CIFAR-100 [14] 
60000 
20 
32 × 32 × 3 
STL-10 [5] 
13000 
10 
96 × 96 × 3 
ImageNet-10 [7] 
13000 
10 
96 × 96 × 3 
ImageNet-Dog [7] 
19500 
15 
96 × 96 × 3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 .</head><label>2</label><figDesc>The clustering results of various methods on six datasets. The best three results are highlighted in bold. DAC* represents that all the samples are considered for training in each iteration.</figDesc><table>Dataset 
MNIST [16] 
CIFAR-10 [14] 
CIFAR-100 [14] 
STL-10 [5] 
ImageNet-10 [7] 
ImageNet-Dog [7] 

Metric 
NMI 
ARI 
ACC 
NMI 
ARI 
ACC 
NMI 
ARI 
ACC 
NMI 
ARI 
ACC 
NMI 
ARI 
ACC 
NMI 
ARI 
ACC 

K-means [32] </table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported in part by the National Natural Science Foundation of China (NSFC Nos. 91646207, 61403376, 61370039 and 91338202), the Beijing Nature Science Foundation under Grant No. 4162064, and the Youth Innovation Promotion Association CAS.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Locality preserving nonnegative matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1010" to="1015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://github.com/fchollet/keras" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A decision-theoretic generalization of on-line learning and an application to boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Syst. Sci</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="139" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Agglomerative clustering using the concept of mutual nearest neighbourhood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gowda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Krishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="112" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feyereisl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<title level="m">Joint image clustering and labeling by matrix factorization. T-PAMI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1411" to="1424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ensemble clustering using factor graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="131" to="142" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Negative evidences and cooccurences in image retrieval: The benefit of PCA and whitening</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="774" to="787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes. CoRR, abs/1312</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">6114</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Torono</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Master&apos;s Thesis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Self-paced learning for latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1189" to="1197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Sparse autoencoder. CS294A Lecture notes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Correlative multi-label video annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="17" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Joint intermodal and intramodal label transfers for extremely rare or unseen classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>T-PAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno>abs/1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Labelme: A database and web-based tool for image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="157" to="173" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unifying textual and visual cues for content-based image retrieval on the world wide web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cascia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Taycher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVIU</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="86" to="98" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mobile product image search by automatic query object extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="114" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Striving for simplicity: The all convolutional net. CoRR, abs/1412</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">6806</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<ptr target="http://www.deeplearning.net/tutorial/lenet.html#lenet" />
		<title level="m">Theano Development Team. Theano: Deep learning tutorials -convolutional neural networks</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning a parametric embedding by preserving local structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="384" to="391" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Subspace clustering. IEEE Signal Processing Magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="52" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fast approximate k-means via cluster closures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3037" to="3044" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimized cartesian k-means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowl. Data Eng</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="180" to="192" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adaptive densitybased spatial clustering of applications with noise according to data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICMLC</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="445" to="451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Discriminant-em algorithm with application to image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1222" to="1227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="478" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5147" to="5156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Image clustering using local discriminant models and global integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">T-IP</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2761" to="2773" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">General c-means clustering model and its application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="122" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deconvolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2528" to="2535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Self-tuning spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1601" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Stacked what-where auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno>abs/1506.02351</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
