<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T23:12+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adversarially Learned One-Class Classifier for Novelty Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sabokrou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Research in Fundamental Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Khalooei</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Amirkabir University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmood</forename><surname>Fathy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Research in Fundamental Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Adversarially Learned One-Class Classifier for Novelty Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Novelty detection is the process of identifying the observation(s) that differ in some respect from the training observations (the target class). In reality, the novelty class is often absent during training, poorly sampled or not well defined. Therefore, one-class classifiers can efficiently model such problems. However, due to the unavailability of data from the novelty class, training an end-to-end deep network is a cumbersome task. In this paper, inspired by the success of generative adversarial networks for training deep models in unsupervised and semi-supervised settings, we propose an end-to-end architecture for one-class classification. Our architecture is composed of two deep networks, each of which trained by competing with each other while collaborating to understand the underlying concept in the target class, and then classify the testing samples. One network works as the novelty detector, while the other supports it by enhancing the inlier samples and distorting the outliers. The intuition is that the separability of the enhanced inliers and distorted outliers is much better than deciding on the original samples. The proposed framework applies to different related applications of anomaly and outlier detection in images and videos. The results on MNIST and Caltech-256 image datasets, along with the challenging UCSD Ped2 dataset for video anomaly detection illustrate that our proposed method learns the target class effectively and is superior to the baseline and state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Novelty detection is the process of identifying the new or unexplained set of data to determine if they are within the norm (i.e., inliers) or outside of it (i.e., outliers). Novelty refers to the unusual, new observations that do not occur regularly or is simply different from the others. Such problems are especially of great interest in computer vision studies, as they are closely related to outlier detection <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b51">52]</ref>, image denoising <ref type="bibr" target="#b7">[8]</ref>, anomaly detection in images <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b22">23]</ref> and videos <ref type="bibr" target="#b38">[39]</ref>. Novelty detection can be portrayed in the context of one-class classification <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b17">18]</ref>, which aims . The first row of (b) shows some example images, and the second row contains the output of the R network on them, i.e., R(X). As can be seen, R enhanced the inlier samples (even in the presence of noise) but distorted the outliers. Two last rows show the score of D applied to X and R(X), respectively. R(X) is indeed more separable than only using the original input image, X.</p><p>to build classification models when the negative class is absent, poorly sampled or not well defined. As such, the negative class can be considered as the novelty (i.e., outlier or anomaly), while the positive (or target) class is well characterized by instances in the training data.</p><p>To accurately chart the intrinsic geometry of the positive class, the first step is to efficiently represent the data in a way that can entangle more or less the different explanatory factors of variation in the data. Recently, deep learning approaches have gained immense success in representing visual data for various vision-based applications <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>, especially in cases that they are trained in an end-to-end fashion. However, for novelty detection or one-class classification applications, due to unavailability of data from the negative class, training an end-to-end deep network is not straightforward. Some efforts have been made, in recent years, to benefit from deep features in learning one-class classifiers <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b37">38]</ref>, few of which could train an end-to-end feature learning and classification model.</p><p>Inspired by the recent developments in generative adversarial networks (GANs) <ref type="bibr" target="#b13">[14]</ref>, we propose an end-to-end model for one-class classification and apply it to different applications including outlier detection, novelty detection in images and anomaly event detection in videos. The proposed architecture, similar to GANs, comprises two modules, which compete to learn while collaborating with each other for the detection task. The first module (denoted as R) refines the input and gradually injects discriminative material into the learning process to make the positive and novelty samples (i.e., inliers, and outliers) more separable for the detector, the second module (referred to as D).</p><p>These two networks are adversarially and unsupervisedly learned using the training data, which is composed of only the target class. Specifically, R learns to reconstruct the positive samples and tries to fool the detector (i.e., D). Whereas, D learns to distinguish original (positive) samples from the reconstructed ones. In this way, D learns merely the concept characterized by the space of all positive samples, and hence it can be used for distinguishing between positive and novelty classes. On the other hand, R learns to efficiently reconstruct the positive samples, while for negative (or novelty) samples it is unable to reconstruct the input accurately, and hence, for negative samples it acts as a decimator (or informally a distorter). In the testing phase, D operates as the actual novelty detector, while R improves the performance of the detector by adequately reconstructing the positive or target samples and decimating (or distorting) any given negative or novelty samples. <ref type="figure" target="#fig_0">Fig. 1</ref> depicts example inputs and outputs of both R and D networks for a model trained to detect images of Penguins.</p><p>In summary, the main contributions of this paper are as follows: <ref type="formula">(1)</ref> We propose an end-to-end deep network for learning one-class classifier learning. To the best of our knowledge, this article is one of the firsts to introduce an end-to-end network for one-class classification. (2) Almost all approaches based on GANs in the literature <ref type="bibr" target="#b30">[31]</ref> discard either the generator or the discriminator (analogous to R and D, respectively, in our architecture) after training. Only one of the trained models is used, while our setting is more efficient and benefits from both trained modules to collaborate in the testing stage. (3) Our architecture learns the model in the complete absence of any training samples from the novelty class and achieves state-of-the-art performance in different applications, such as outlier detection in images and anomaly event detection in videos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>One-class classification is closely related to rare event detection, outlier detection/removal, and anomaly detection. All these applications share the search procedure for a novel concept, which is scarcely seen in the data and hence can all be encompassed by the umbrella term novelty detection. Consequently, a wide range of real-world applications can be modeled by one-class classifiers. Conventional research often models the target class, and then rejects samples not following this model. Self-representation <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b35">36]</ref> and statistical modeling <ref type="bibr" target="#b26">[27]</ref> are the commonly used approaches for this task. For data representation, low level features <ref type="bibr" target="#b3">[4]</ref>, high level features (e.g., trajectories <ref type="bibr" target="#b28">[29]</ref>), deeply learned features <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">39]</ref> are used in the literature. A brief review of state-of-the-art novelty detection methods especially the ones based on adversarial learning in deep networks is provided in this section.</p><p>Self-Representation. Several previous works show that self-representation is a useful tool for outlier or novelty event detection. For instance, <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b35">36]</ref> proposed self-representation techniques for video anomaly detection and outlier detection through learning a sparse representation model, as a measure for separating inlier and outlier samples. It is assumed that outlier or novel samples are not sparsely represented using the samples from the target class. In some other works (like <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b9">10]</ref>), testing samples are reconstructed using the samples from the target class. The decision if it is an inlier or outlier (novel) is made based on the reconstruction error, i.e., high reconstruction error for a sample indicates that it is more probably an outlier sample. In another work, Liu et al. <ref type="bibr" target="#b23">[24]</ref> proposed to use a low-rank self-representation matrix in place of a sparse representation, penalized by the sum of unsquared self-representation errors. This penalization leads to more robustness against outliers (similar to <ref type="bibr" target="#b1">[2]</ref>). Similarly, auto-encoders are also exploited to model and measure the reconstruction error for the related tasks of outlier removal and video anomaly detection, in <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>Statistical Modeling. More conventional methods tend to model the target class using a statistical approach. For instance, after extracting features from each sample, a distribution function is fit on the samples from the target class, and samples far from this distribution are considered as outliers or novelty (e.g., <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b26">27]</ref>). In another work, Rahmani and Atia <ref type="bibr" target="#b31">[32]</ref> proposed an algorithm termed Coherence Pursuit (CoP) for Robust Principal Component Analysis (RPCA). They assumed that the inlier samples have high correlations and can be spanned in low dimensional subspaces, and hence they have a strong mutual coherence with a large number of data points. As a result, the outliers either do not accord with the low dimensional subspace or form small clusters. Also, a method proposed in <ref type="bibr" target="#b49">[50]</ref>, OutlierPursuit, used convex optimization techniques to solve the PCA problem with robustness to corrupted entries, which led to the develop-ment of many recent methods for PCA with robustness to outliers. Lerman et al. <ref type="bibr" target="#b21">[22]</ref> described a convex optimization problem for detecting the outliers and called it REAPER, which can reliably fit a low-dimensional model to the target class samples.</p><p>Deep Adversarial Learning. In the recent years, GANs <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b40">41]</ref> have shown outstanding success in generating data for learning models. They have also been extended to classification models even in the presence of not enough labeled training data (e.g., in <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b33">34]</ref>). They are based on a two-player game between two different networks, both concurrently trained in an unsupervised fashion. One network is the generator (G), which aims at generating realistic data (e.g., images), while the second network poses as the discriminator (D), and tries to discriminate real data from the data generated by G. One of the different types of GANs, closely related to our work, is the conditional GANs, in which G takes an image X as the input and generates a new image X ′ . Whereas, D tries to distinguish X from X ′ , while G tries to fool D producing more and more realistic images. Very recently Isola et al. <ref type="bibr" target="#b16">[17]</ref> proposed an "Image-to-image translation" framework based on conditional GANs, where both G and D are conditioned on the real data. They showed that a U-Net encoder-decoder <ref type="bibr" target="#b34">[35]</ref> with skip connections could be used as the generator coupled with a patch-based discriminator to transform images with respect to different representations. In a concurrent work, <ref type="bibr" target="#b32">[33]</ref> proposed to learn the generator as a reconstructor of normal events, and hence if it cannot properly reconstruct a chunk of the input frames, that chunk is considered an anomaly. However, in our work, the first module (i.e., R) not only reconstructs the target class, but it also helps to improve the performance for the model on any given testing image, by refining samples belonging to the target class, and decimating/distorting the anomaly or outlier samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Approach</head><p>The proposed one-class classification framework is composed of two main modules: (1) Network R, and (2) Network D. The former acts as a prepossessing and Refinement (or Reconstruction) step, while the latter performs the Discrimination (or Detection). These two networks are learned in an adversarial and unsupervised manner, within an end-to-end setting. In this section, we present a detailed overview of both. The overall schema of the proposed approach is shown in <ref type="figure">Fig. 2</ref>. It can be seen that R reconstructs its input, X, generates X ′ , and tries to fool D so that it speculates that the reconstructed sample is the original data, not a reconstructed sample. On the other hand, D has access to the original set of data and is familiar with their concept. Hence it will reject the reconstructed samples. These two networks play a game, and after the training stage, in which samples from the target class are presented to the model, R  <ref type="figure">Figure 2</ref>. Overview of the proposed structure for one-class classification framework. R and D are two modules of the model, which are adversarially learned. R is optimized to reconstruct samples belonging to the target class, while it works as a decimator function for outlier inputs, whereas D classifies the input data positive (target) and negative (outlier or anomaly). D(R(X)) measures the likelihood of the given input sample belonging to the target class.</p><p>will become an expert to reconstruct the samples from the target class with a minimum error to successfully fool D.</p><p>The training procedure leads to a pair of networks, R and D, which both learn the distribution of the target class. These two modules are trained in a GAN-style adversarial learning framework, forming an end-to-end framework for one-class classification for novelty detection. To make the proposed method more robust against noise and corrupt input samples, a Gaussian noise (denoted by η in <ref type="figure">Fig. 2</ref>) is added to the input training samples and fed to R. Detailed descriptions of each module and the overall training/testing procedures are described in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">R Network Architecture</head><p>It is previously <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b35">36]</ref> investigated that the reconstruction error of an auto-encoder, trained on samples from the target class, is a useful measure for novelty sample detection. Since the auto-encoder is trained to reconstruct target class samples, the reconstruction error for negative (novelty) samples would be high. We use a similar idea, but in contrast, we do not use it for the detection or the discrimination task. Our proposed model uses the reconstructed image to train another network for the discrimination task.</p><p>To implement the R network, we train a decoder-encoder Convolutional Neural Network (CNN) on samples from the target class to map any given input sample to the target concept. As a result, R will efficiently reconstruct the samples that share a similar concept as the trained target class, while for outlier or novelty inputs, it poorly reconstructs them. In other words, R enhances the inliers (samples from the target class), while it destructs or decimates the outliers, making it easier for the discriminator to separate the outliers from the vast pool of inliers. <ref type="figure">Fig. 3</ref> shows the structure of R</p><formula xml:id="formula_0">(5×5×3×64) (5×5×64×128) (5×5×128×256) (5×5×256×512) (5×5×512×256) (5×5×256×128)<label>(5×5×128×64)</label></formula><p>Encoder Decoder <ref type="figure">Figure 3</ref>. R network architecture, composed of encoding (first part) and decoding (second part) layers. The properties of each layer are indicated with four hyperparameters in this order: (first dimension of the kernel × the second dimension of the kernel × the number of input channels × the number of output channels).</p><p>architecture, which includes several convolution layers (as the encoder), followed by several deconvolution layers (for the decoding purpose). For improving the stability of the network similar to <ref type="bibr" target="#b30">[31]</ref>, we do not use any pooling layers in this network. Eventually, R learns the concept shared in the target class to reconstruct its inputs based on that concept. Also, after each convolutional layer, a batch normalization <ref type="bibr" target="#b15">[16]</ref> operation is exploited, which adds stability to our structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">D Network Architecture</head><p>The architecture for D is a sequence of convolution layers, which are trained to eventually distinguish the novel or outlier sample, without any supervision. <ref type="figure" target="#fig_2">Fig. 4</ref> shows the details of this network's architecture. D outputs a scalar value, relative to the likelihood of its input following the distribution spanned by the target class, denoted by p t . Therefore, its output can be considered as a target likelihood score for any given input. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Adversarial Training of R+D</head><p>As mentioned in section 2, Goodfellow et al. <ref type="bibr" target="#b13">[ 14]</ref> introduced an efficient way for adversarial learning of two networks (denoted by Generator (G) and Discriminator (D)), called Generative Adversarial Networks (GANs). GANs aim to generate samples that follow the same distribution as the real data, through adversarial learning of the two networks. G learns to map any random vector, Z from a latent space following a specific distribution, p z , to a data sample that follows the real data distribution (p t in our case), and D tries to discriminate between actual data and the fake data generated by G. Generator and Discriminator are learned in a two-player mini-max game, formulated as:</p><formula xml:id="formula_1">min G max D E X∼pt [log(D(X))] + E Z∼pz [log(1 − D(G(Z)))] .</formula><p>(1)</p><p>In a similar way, we train the R+D neural networks in an adversarial procedure. In contrast to the conventional GAN, instead of mapping the latent space Z to a data sample with the distribution p t , R maps</p><formula xml:id="formula_2">X =(X ∼ p t )+ η ∼N(0,σ 2 I) −→ X ′ ∼ p t ,<label>(2)</label></formula><p>in which η is the added noise sampled from the normal distribution with standard deviation σ, N (0,σ 2 I). From now on, the noise model is denoted by N σ for short. This statistical noise is added to input samples to make R robust to noise and distortions in the input images, in the training stage. As mentioned before, p t is the supposed distribution of the target class. D is aware of p t , as it is exposed to the samples from the target class. Therefore, D explicitly decides if R(X) follows p t or not. Accordingly, R+D can be jointly learned by optimizing the following objective:</p><formula xml:id="formula_3">min R max D E X∼pt [log(D(X))] + EX ∼pt+Nσ [log(1 −D(R(X)))] ,<label>(3)</label></formula><p>Based on the above objective (similar to GAN), network R generates samples with the probability distribution of p t , and as a result its own distribution is given by p r ∼ R(X ∼ p t ; θ r ), where θ r is the parameter of the R network. Therefore, we want to maximize p t (R(X ∼ p t ; θ r )).</p><p>To train the model, we calculate the loss L R+D as the loss function of the joint network R+D. Besides, we need R's output to be close to the original input image. As a result, an extra loss is imposed on the output of R:</p><formula xml:id="formula_4">L R = X − X ′ 2 .<label>(4)</label></formula><p>Therefore, the model is optimized to minimize the loss function:</p><formula xml:id="formula_5">L = L R+D + λL R ,<label>(5)</label></formula><p>where λ&gt;0 is a trade-off hyperparameter that controls the relative importance of the two terms. One of the challenging issues for training R+D is defining an appropriate stopping criterion. Analyzing the loss functions of R and D modules to excerpt a stopping criterion based on is a burdensome task, and hence we use a subjective criterion. The training procedure is stopped when R successfully maps noisy images to clean images carrying the concept of the target class (i.e., favorably fools the D module). Consequently, we have stopped the training of networks, when R can reconstruct its input with minimum error (i.e., X − X ′ 2 &lt;ρ, where ρ is a small positive number).</p><p>After a joint training of the R+D network, the behavior of each single one of them can be interpreted as follows:</p><p>•R (X ∼ p t + η) −→ X ′ ∼ p t , where X − X ′ 2 is minimized. This is because θ r is optimized to reconstruct those inputs that follow the distribution p t . Note that R is trained and operates similar to denoising autoencoders <ref type="bibr" target="#b45">[46]</ref> or, denoising CNNs <ref type="bibr" target="#b10">[11]</ref>, and its output will be a refined version of the input data. See <ref type="figure" target="#fig_0">Figures  1 and 5</ref> for some samples of its reconstructed outputs.</p><p>• For any given outlier or novelty sample (denoted byX) that does not follow p t , R is confused and maps it into a sample,X ′ , with an unknown probability distribution, p ? ,( i.e., R(X ≁ p t + η) −→X ′ ∼ p ? ). In this case, X −X ′ 2 cannot become very small or close to zero. This is because R was not trained on the novelty concept and cannot reconstruct it accordingly (similar to <ref type="bibr" target="#b32">[33]</ref>). Therefore, as a side effect, R decimates the outliers. As an example, <ref type="figure">Fig. 6</ref> shows samples of a different concept being fed to R of a network trained to detect digit "1".</p><p>• We can expect that</p><formula xml:id="formula_6">D(X ′ ∼ p t ) &gt; D(X ′ ≁ p t )</formula><p>, since D is trained to detect samples from the distribution p t .</p><p>• It is interesting to note that in most cases</p><formula xml:id="formula_7">D(R(X ∼ p t )) −D(R(X ≁ p t )) &gt; D(X ∼ p t ) −D(X ≁ p t ).</formula><p>This signifies that the output of R is more separable than original images. It is because of this fact that R supports D for better detection. To further explore this, <ref type="figure" target="#fig_3">Fig. 7</ref> shows the score generated as the output of D for both cases. In some sensitive applications, it is more appropriate to avoid making decisions on difficult cases <ref type="bibr" target="#b4">[5]</ref>, and leave them for human intervention. These hardto-decide cases are known to be in the reject region. As shown in <ref type="figure" target="#fig_3">Fig. 7</ref> the reject region of D(X) is larger than that of D(R(X)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">R+D: One-Class Classification</head><p>In the previous subsection, characteristics of both R and D networks are explained in details. As discussed, D acts as the novelty detector, and benefits the support of R. Hence, the One-Class Classifier (OCC) can be simply formulated by only using the D network (similar to <ref type="bibr" target="#b32">[33]</ref>) as:</p><formula xml:id="formula_8">OCC 1 (X)= Target Class if D(X) &gt;τ, Novelty (Outlier) otherwise,<label>(6)</label></formula><p>where τ is a predefined threshold. Although the above policy for novelty detection works as well as the state-of-the-art methods (explained in details in the Section 4), we further propose to incorporate R in the testing stage. To this end, R(X, θ r ) is used as a refinement step for X, in which θ r is the trained model for the R module. θ r is trained to reconstruct and enhance samples that follow p t (i.e., are from the target class). Consequently, instead of D(X) we use D(R(X)). Eq. <ref type="formula" target="#formula_9">(7)</ref> provides a summary of our proposed once-class classification scheme:</p><formula xml:id="formula_9">OCC 2 (X)= Target Class if D(R(X)) &gt;τ, Novelty (Outlier) otherwise.<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment Results</head><p>In this section, the proposed method is evaluated on three different image and video datasets. The performance results are analyzed in details and are compared with state-of-theart techniques. To show the generality and applicability of the proposed framework for a variety of tasks, we test it for detection of (1) Outlier images, and (2) Video anomalies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup</head><p>All the reported results in this section are from our implementation using the TensorFlow framework <ref type="bibr" target="#b0">[1]</ref>, and Python ran on an NVIDIA TITAN X. The detailed structures of D and R are explained in details in Sections 3.2 and 3.1, respectively. These structures are kept fixed for different tasks, and λ in Eq. <ref type="formula" target="#formula_5">(5)</ref> is set equal to 0.4. The hyperparameters of batch normalization (as in <ref type="bibr" target="#b15">[16]</ref>) are set as ǫ =10 −6 and decay=0.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Outlier Detection</head><p>As discussed earlier, many computer vision applications face considerable amounts of outliers, since they are common in realistic vision-based training sets. On the other hand, machine learning methods often experience considerable performance degradation in the presence gross outliers, if they fail to deal with processing the data contaminated by noise and outliers. Our method can learn the shared concept among all inlier samples, and hence identify the outliers. Similar to <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b46">47]</ref>, we evaluate the performance of our outlier detection method using MNIST 1 <ref type="bibr" target="#b20">[21]</ref>   <ref type="figure">Figure 5</ref>. Examples of the output of R for several inlier and outlier samples from the UCSD Ped2 dataset: R is learned on normal patches. Left and right samples show the inlier (i.e., target) and outlier (i.e., novelty) samples, respectively. As can be seen, the network R enhances its input and shows to be robust to the noise present in its input. First row: Patch contaminated by some Gaussian noise; Second row: Original patches; Third row: The output of R on the noisy samples. <ref type="figure">Figure 6</ref>. Outputs of R trained to detect digit "1" on MNIST dataset. Samples from classes "6" and "7" are given to the model as outliers. R failed to reconstruct them and fundamentally distorted them. In each pair of the images, the first one is the original image and the second one is the output of R. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reject Region</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Outlier Detection Datasets</head><p>MNIST: This dataset <ref type="bibr" target="#b20">[21]</ref> includes 60,000 handwritten digits from "0" to "9". Each of the ten categories of digits is taken as the target class (i.e., inliers), and we simulate outliers by randomly sampling images from other categories with a proportion of 10% to 50%. This experiment is repeated for all of the ten digit categories. Caltech-256: This dataset <ref type="bibr" target="#b14">[15]</ref> contains 256 object categories with a total of 30,607 images. Each category has at least 80 images. Similar to previous works <ref type="bibr" target="#b51">[52]</ref>, we repeat the procedure three times and use images from n ∈{1, 3, 5}</p><p>randomly chosen categories as inliers (i.e., target). The first 150 images of each category are used, if that category has more than 150 images. A certain number of outliers are randomly selected from the "clutter" category, such that each experiment has exactly 50% outliers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Outlier Detection Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Result on MNIST:</head><p>The joint network R+D is trained on images of the target classes, in the absence of outlier samples.</p><p>Following <ref type="bibr" target="#b46">[47]</ref>, we also report the F 1 -score as a measure to evaluate the performance of our method and compare it with others. <ref type="figure">Fig. 8</ref> shows the F 1 -score of our method (and the state-of-the-art methods) as a function of the portion of outlier samples. As can be seen, our method (i.e., D(R(X))) operates more efficient than the other two-state-of-the-art methods (LOF <ref type="bibr" target="#b6">[7]</ref> and DRAE <ref type="bibr" target="#b46">[47]</ref>). Also, it is important to note that with the increase in the number of outliers, our method operates consistently robust and successfully detects the outliers, while the baseline methods fail to detect the outliers as their portion increases. Furthermore, one interesting finding of these results is that, based in <ref type="figure">Fig. 8</ref>, D(X) itself can operate successfully well, and outperform the stateof-the-art methods. Nevertheless, it is even improved more when we incorporate R module, as it modifies the samples (i.e., refines the samples from the target class, and decimates the ones coming from an outlier concept) and helps distinguishability of the samples.</p><p>Result on Caltech-256: In this experiment, similar setup as in <ref type="bibr" target="#b51">[52]</ref> is used, and we compare our method with <ref type="bibr" target="#b51">[52]</ref> and 6 other methods therein designed specifically for detecting outliers, including Coherence Pursuit (CoP) <ref type="bibr" target="#b31">[32]</ref>, OutlierPursuit <ref type="bibr" target="#b49">[50]</ref>, REAPER <ref type="bibr" target="#b21">[22]</ref>, Dual Principal Component Pursuit (DPCP) <ref type="bibr" target="#b44">[45]</ref>, Low-Rank Representation (LRR) <ref type="bibr" target="#b23">[24]</ref>, OutRank <ref type="bibr" target="#b27">[28]</ref>. The results are listed in <ref type="table" target="#tab_1">Table 1</ref>, which are comprised of F 1 -score and area under the ROC curve (AUC). The results of other methods are borrowed from <ref type="bibr" target="#b51">[52]</ref>. This table confirms that our proposed method performs at least as well as others, while in many cases it is superior to  them. As can be seen, both proposed methods (i.e., D(X) and D(R(X))) outperform all other methods in most cases. Interestingly, as we increase the number of inlier classes, from 1 to 3 and 5 (first, second and the last two rows, respectively), our method robustly learns the inlier concept(s).</p><formula xml:id="formula_10">F 1 -Score D(R(X)) D(X) LOF [7] DRAE [47]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Video Anomaly Detection</head><p>Anomaly event detection in videos or visual analysis of suspicious events is a topic of great importance in different computer vision applications. Due to the increased complexity of video processing, detecting abnormal events (i.e., anomaly or novelty events) in videos is even a more burdensome task than image outlier detection. We run our method on a popular video dataset, UCSD <ref type="bibr" target="#b8">[9]</ref> Ped2. The results are reported on a frame-level basis, as we aligned our experimental setup to previous works for comparison purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Anomaly Detection Dataset</head><p>UCSD dataset: This dataset <ref type="bibr" target="#b8">[9]</ref> includes two subsets, Ped1 and Ped2, from two different outdoor scenes, recorded with a static camera at 10 fps and resolutions 158 × 234 and 240 × 360, respectively. The dominant mobile objects in these scenes are pedestrians. Therefore, all other objects (e.g., cars, skateboarders, wheelchairs, or bicycles) are considered as anomalies. We evaluate our algorithm on Ped2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Anomaly Detection Results</head><p>Result on UCSD Ped2: For this experiment, we divide the frames of the video into 2D patches of size 30 × 30. Training patches are only composed of frames with normal behaviors. In the testing phase, test patches are given to the joint network R+D, and the results are recorded. <ref type="figure">Fig. 9</ref> shows examples of the output of R on the testing patches. As it is evident, normal patches (i.e., left part of the figure) are successfully refined and reconstructed by the R network, while the abnormal ones (i.e., the right part of the figure) are distorted and not adequately reconstructed. The last two rows in the figure show the likelihood score identified by our methods (D(X) and D(R(X)), respectively). D(R(X)) shows to yield more distinguishable results, leading to a better model for one-class classification and hence video anomaly detection. It is fascinating to note that one of the </p><formula xml:id="formula_11">D(X) 16% Ours -D(R(X)) 13%</formula><p>most critical dilemmas for video anomaly detection methods is their high false positives. That is, algorithms often detect many of the 'normal' scenes as anomalies. In <ref type="figure">Fig. 9</ref>, three left columns are three tough 'normal' examples, as the human subject is not completely visible in the patch. We deliberately visualized these cases to illustrate how using D(R(X)) can effectively increase the discriminability of the system, compared to only D(X). Similar to <ref type="bibr" target="#b25">[26]</ref>, we also report frame-level Equal Error Rate (EER) of our method and the compared methods. For this purpose, in any frame, if a pixel is detected as an anomaly, that frame is so labeled as 'anomaly.' <ref type="table" target="#tab_2">Table 2</ref> shows the result of our method in comparison to the state-of-the-art. The right column in <ref type="table" target="#tab_2">Table 2</ref> lists the results from methods based on variations of deep-learning. This table confirms that our method is comparable to all these approaches, while we are solving a more general problem that can be used for any outlier, anomaly or novelty detection problem. It is worth noting that other methods (especially Deep-cascade <ref type="bibr" target="#b38">[39]</ref>) benefit from both spatial and temporal complex features, while our method operates on a patch-based basis, considering only spatial features of the frames. Our goal was to illustrate that the proposed method operates at least as well as the state-of-the-art, in a very general setting with no further tuning to the specific problem type. Simply, one can use spatiotemporal features and even further improve the results for anomaly event detection or related tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Discussion</head><p>The experimental results confirmed that R+D detects the novelty samples at least as well as the state-of-the-art or better than them in many cases, but finding the optimal structure and conducting the proper training procedure for these networks can be tedious and cumbersome tasks. The structure used in this paper proved well enough for our applications, while it can still be improved. We observed that achieving better performance is possible by modifying the structure, e.g., by some modification in the size and the order of convolutional layers of R+D, we achieved better results by margins of 0.02 to 0.04 compared to the results reported in <ref type="table" target="#tab_1">Table 1</ref>. Another important point is that it is very critical when to stop the training procedure of the joint network R+D. Stopping the training too early leads to immature learned network weights, while overtraining the networks confuses the R module and yields undesirable outputs. The stopping criterion outlined in Section 3.3 provides a right balance for the maturity of the joint network in understanding the underlying concept in the target class.</p><p>In addition, it is important note is that training a model in absence of the novelty/outlier class can be considered as weak supervision. For many problems this is acceptable, as all the samples we have are often inliers. When dealing with outlier detection problems, we can assume that number samples from the target class is much larger than the outlier samples. However, if we train the model at the presence of small number of outlier samples, the model still works. In a followup experiment, we mixed data from target (90%) and outlier (10%) classes in the training phase of the Ped2 experiment, and observed that the EER only dropped by 1.3%, which is still comparable to the state-of-the-art methods.</p><p>One of the major concerns in GANs is the mode collapse issue <ref type="bibr" target="#b2">[3]</ref>, which often occurs when the generator only learns a portion of real-data distribution and outputs samples from a single mode (i.e., it ignores other modes). For our case, it is a different story as R directly sees all possible samples of the target class data and implicitly learns the manifold spanned by the target data distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we have proposed a general framework for one-class classification and novelty detection in images and videos, trained in an adversarial manner. Specifically, our architecture consists of two modules, Reconstructor and Discriminator. The former learns the concept of a target class to reconstruct images such that the latter is fooled to consider those reconstructed images as real target class images. After training the model, R can reconstruct target class samples correctly, while it distorts and decimates samples that do not have the concept shared among the target class samples. This eventually helps D discriminate the testing samples even better. We have used our models for a variety of related applications including outlier and anomaly detection in images and videos. The results on several datasets demonstrate that the proposed adversarially learned one-class classifier is capable of detecting samples not belonging to the target class (i.e., they are novelty, outliers or anomalies), even though there were no samples from the novelty class during training.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Example outputs of the proposed model, trained to detect Penguins (a), in response to inlier and outlier samples (b). The first row of (b) shows some example images, and the second row contains the output of the R network on them, i.e., R(X). As can be seen, R enhanced the inlier samples (even in the presence of noise) but distorted the outliers. Two last rows show the score of D applied to X and R(X), respectively. R(X) is indeed more separable than only using the original input image, X.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. D network architecture, which determines if its input is from the target class or it is an outlier or novelty. Properties of the layers are denoted similarly to Fig. 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. R+D is trained on inlier samples (digit "1") from MNIST dataset. Top: D(R(X)) scores; Bottom: D(X) scores. The scores are generated on 20 inlier and 20 outlier samples. The red squares indicate inlier samples, while × marks are representatives of the outliers. Reject region for R(X) is larger than that of D(R(X)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 .Figure 9 .</head><label>89</label><figDesc>Figure 8. Comparisons of F1-scores on MNIST dataset for different percentages of outlier samples involved in the experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 .</head><label>1</label><figDesc>Results on the Caltech-256 dataset: Inliers are taken to be images of one, three, or five randomly chosen categories, and outliers are randomly chosen from category 257-clutter. Two first rows: Inliers are from one category of images, with 50% portion of outliers; Two second rows: Inliers are from three categories of images, with 50% portion of outliers; Two last rows: Inliers come from five categories of images, while outliers compose 50% of the samples. The last two columns have the results or our methods, D(X) and D(R(X)), respectively. Note that in each row the best result is typeset in bold and the second best in italic typeface.</figDesc><table>CoP [32] 
REAPER [22] 
OutlierPursuit [50] 
LRR [24] 
DPCP [45] 
R-graph [52] 
Ours D(X) 
Ours D(R(X)) 

AUC 
0.905 
0.816 
0.837 
0.907 
0.783 
0.948 
0.932 
0.942 
F 1 
0.880 
0.808 
0.823 
0.893 
0.785 
0.914 
0.916 
0.928 
AUC 
0.676 
0.796 
0.788 
0.479 
0.798 
0.929 
0.930 
0.938 
F 1 
0.718 
0.784 
0.779 
0.671 
0.777 
0.880 
0.902 
0.913 
AUC 
0.487 
0.657 
0.629 
0.337 
0.676 
0.913 
0.913 
0.923 
F 1 
0.672 
0.716 
0.711 
0.667 
0.715 
0.858 
0.890 
0.905 

10 
20 
30 
40 
50 

0.6 

0.8 

1 

Percentage of outliers (%) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 .</head><label>2</label><figDesc>Frame-level comparisons on Ped2</figDesc><table>Method 
EER 
Method 
EER 
IBC [6] 
13% 
RE [36] 
15% 
MPCCA [19] 30% 
Ravanbakhsh et al. [34] 
13% 
MDT [26] 
24% 
Ravanbakhsh et al. [33] 
14% 
Bertini et al. [4] 
30% 
Dan Xuet al. [48] 
17% 
Dan Xu et al. [49] 20% 
Sabokrou et al. [37] 
19% 
Li et al.[23] 
18.5% Deep-cascade [39] 9% 
Ours -</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This research was in part supported by a grant from IPM (No. CS1396-5-01).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<title level="m">Large-scale machine learning on heterogeneous distributed systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust feature-sample linear discriminant analysis for brain disorders diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-H</forename><surname>Thung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Multi-scale and real-time non-parametric approach for anomaly detection and localization. Computer Vision and Image Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bimbo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seidenari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="320" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Detecting irregularities in images and in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Boiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="31" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lof: identifying density-based local outliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Breunig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM sigmod record</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ucsd pedestrian dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="909" to="926" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sparse reconstruction cost for abnormal event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3449" to="3456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image denoising via cnns: An adversarial approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Divakar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1076" to="1083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Anomaly detection over noisy data using learned probability distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eskin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">One-class novelty detection for seizure analysis from intracranial eeg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vachtsevanos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Litt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1025" to="1044" />
			<date type="published" when="2006-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wardefarley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Caltech-256 object category dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">One-class classification: taxonomy of study and review of techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Madden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Knowledge Engineering Review</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="345" to="374" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Observe locally, infer globally: a space-time mrf for detecting abnormal activities with incremental updates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2921" to="2928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Finding anomalies with generative adversarial networks for a patrolbot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bekele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="12" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Mnist handwritten digit database. AT&amp;T Labs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist" />
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust computation of linear models by convex relaxation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Tropp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of Computational Mathematics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="363" to="410" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Anomaly detection and localization in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="18" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Robust subspace segmentation by low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="663" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Incremental kernel null space discriminant analysis for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="792" to="800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Anomaly detection in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bhalodia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1975" to="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Novelty detection: a reviewpart 1: statistical approaches. Signal processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Markou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="2481" to="2497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Outlier detection using random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Moonesignhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-N</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">18th IEEE International Conference on Tools with Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="532" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Trajectory learning for activity understanding: Unsupervised, multilevel, and long-term adaptive approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2287" to="2301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Network constraints and multiobjective optimization for one-class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Moya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Hush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="463" to="474" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Coherence pursuit: Fast, simple, and robust principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rahmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Atia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Abnormal event detection in videos using generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sangineto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marcenaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Regazzoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Training adversarial discriminators for cross-channel abnormal event detection in crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sangineto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.07680</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and ComputerAssisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Video anomaly detection and localisation based on the sparsity and reconstruction error of auto-encoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hoseini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronics Letters</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="1122" to="1124" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Real-time anomaly detection and localization in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hoseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="56" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Fast and accurate detection and localization of abnormal behavior in crowded scenes. Machine Vision and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Moayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klette</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="965" to="985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deepcascade: Cascading 3d deep neural networks for fast anomaly detection and localization in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1992" to="2004" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deepanomaly: Fully convolutional neural network for fast anomaly detection in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Unsupervised anomaly detection with generative adversarial networks to guide marker discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schlegl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Seeböck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Waldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schmidt-Erfurth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Langs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information Processing in Medical Imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="146" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Dual principal component pursuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Tsakiris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV Workshops</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning discriminative reconstructions for unsupervised outlier removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1511" to="1519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning deep representations of appearance and motion for anomalous event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Video anomaly detection based on a hierarchical activity discovery within spatio-temporal contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="144" to="152" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Robust pca via outlier pursuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Caramanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sanghavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2496" to="2504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Online unsupervised outlier detection using finite mixtures with discounting learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yamanishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-I</forename><surname>Takeuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Milne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="275" to="300" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Provable selfrepresentation based outlier detection in a union of subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
