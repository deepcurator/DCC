<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Mean-Shift Priors for Image Restoration</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siavash</forename><forename type="middle">A</forename><surname>Bigdeli</surname></persName>
							<email>bigdeli@inf.unibe.ch</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Bern</orgName>
								<orgName type="institution" key="instit2">University of Bern</orgName>
								<orgName type="institution" key="instit3">University of Bern</orgName>
								<orgName type="institution" key="instit4">University of Bern</orgName>
								<orgName type="institution" key="instit5">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meiguang</forename><surname>Jin</surname></persName>
							<email>jin@inf.unibe.ch</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Bern</orgName>
								<orgName type="institution" key="instit2">University of Bern</orgName>
								<orgName type="institution" key="instit3">University of Bern</orgName>
								<orgName type="institution" key="instit4">University of Bern</orgName>
								<orgName type="institution" key="instit5">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
							<email>favaro@inf.unibe.ch</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Bern</orgName>
								<orgName type="institution" key="instit2">University of Bern</orgName>
								<orgName type="institution" key="instit3">University of Bern</orgName>
								<orgName type="institution" key="instit4">University of Bern</orgName>
								<orgName type="institution" key="instit5">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zwicker</surname></persName>
							<email>zwicker@cs.umd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Bern</orgName>
								<orgName type="institution" key="instit2">University of Bern</orgName>
								<orgName type="institution" key="instit3">University of Bern</orgName>
								<orgName type="institution" key="instit4">University of Bern</orgName>
								<orgName type="institution" key="instit5">University of Maryland</orgName>
								<address>
									<settlement>College Park</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Mean-Shift Priors for Image Restoration</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>In this paper we introduce a natural image prior that directly represents a Gaussiansmoothed version of the natural image distribution. We include our prior in a formulation of image restoration as a Bayes estimator that also allows us to solve noise-blind image restoration problems. We show that the gradient of our prior corresponds to the mean-shift vector on the natural image distribution. In addition, we learn the mean-shift vector field using denoising autoencoders, and use it in a gradient descent approach to perform Bayes risk minimization. We demonstrate competitive results for noise-blind deblurring, super-resolution, and demosaicing.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Image restoration tasks, such as deblurring and denoising, are ill-posed problems, whose solution requires effective image priors. In the last decades, several natural image priors have been proposed, including total variation <ref type="bibr" target="#b28">[29]</ref>, gradient sparsity priors <ref type="bibr" target="#b11">[12]</ref>, models based on image patches <ref type="bibr" target="#b4">[5]</ref>, and Gaussian mixtures of local filters <ref type="bibr" target="#b24">[25]</ref>, just to name a few of the most successful ideas. See <ref type="figure">Figure 1</ref> for a visual comparison of some popular priors. More recently, deep learning techniques have been used to construct generic image priors.</p><p>Here, we propose an image prior that is directly based on an estimate of the natural image probability distribution. Although this seems like the most intuitive and straightforward idea to formulate a prior, only few previous techniques have taken this route <ref type="bibr" target="#b19">[20]</ref>. Instead, most priors are built on intuition or statistics of natural images (e.g., sparse gradients). Most previous deep learning priors are derived in the context of specific algorithms to solve the restoration problem, but it is not clear how these priors relate to the probability distribution of natural images. In contrast, our prior directly represents the natural image distribution smoothed with a Gaussian kernel, an approximation similar to using a Gaussian kernel density estimate. Note that we cannot hope to use the true image probability distribution itself as our prior, since we only have a finite set of samples from this distribution. We show a visual comparison in <ref type="figure">Figure 1</ref>, where our prior is able to capture the structure of the underlying image, but others tend to simplify the texture to straight lines and sharp edges.</p><p>We formulate image restoration as a Bayes estimator, and define a utility function that includes the smoothed natural image distribution. We approximate the estimator with a bound, and show that the gradient of the bound includes the gradient of the logarithm of our prior, that is, the Gaussian smoothed density. In addition, the gradient of the logarithm of the smoothed density is proportional to the mean-shift vector <ref type="bibr" target="#b7">[8]</ref>, and it has recently been shown that denoising autoencoders (DAEs) learn such a mean-shift vector field for a given set of data samples <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref>. Hence we call our prior a deep mean-shift prior, and our framework is an example of Bayesian inference using deep learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>Our prior BM3D <ref type="bibr" target="#b8">[9]</ref> EPLL <ref type="bibr" target="#b40">[41]</ref> FoE <ref type="bibr" target="#b27">[28]</ref> SF <ref type="bibr" target="#b30">[31]</ref> Figure 1: Visualization of image priors using the method by Shaham et al. <ref type="bibr" target="#b31">[32]</ref>: Our deep mean-shift prior learns complex structures with different curvatures. Other priors prefer simpler structures like lines with small curvature or sharp corners.</p><p>We demonstrate image restoration using our prior for noise-blind deblurring, super-resolution, and image demosaicing, where we solve Bayes estimation using a gradient descent approach. We achieve performance that is competitive with the state of the art for these applications. In summary, the main contributions of this paper are:</p><p>• A formulation of image restoration as a Bayes estimator that leverages the Gaussian smoothed density of natural images as its prior. In addition, the formulation allows us to solve noise-blind restoration problems.</p><p>• An implementation of the prior, which we call deep mean-shift prior, that builds on denoising autoencoders (DAEs). We rely on the observation that DAEs learn a mean-shift vector field, which is proportional to the gradient of the logarithm of the prior.</p><p>• Image restoration techniques based on gradient-descent risk minimization with competitive results for noise-blind image deblurring, super-resolution, and demosaicing. <ref type="bibr" target="#b0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Image Priors. A comprehensive review of previous image priors is outside the scope of this paper. Instead, we refer to the overview by Shaham et al. <ref type="bibr" target="#b31">[32]</ref>, where they propose a visualization technique to compare priors. Our approach is most related to techniques that leverage CNNs to learn image priors. These techniques build on the observation by Venkatakrishnan et al. <ref type="bibr" target="#b32">[33]</ref> that many algorithms that solve image restoration via MAP estimation only need the proximal operator of the regularization term, which can be interpreted as a MAP denoiser <ref type="bibr" target="#b21">[22]</ref>. Venkatakrishnan et al. <ref type="bibr" target="#b32">[33]</ref> build on the ADMM algorithm and propose to replace the proximal operator of the regularizer with a denoiser such as BM3D <ref type="bibr" target="#b8">[9]</ref> or NLM <ref type="bibr" target="#b4">[5]</ref>. Unsurprisingly, this inspired several researchers to learn the proximal operator using CNNs <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b21">22]</ref>. Meinhardt et al. <ref type="bibr" target="#b21">[22]</ref> consider various proximal algorithms including the proximal gradient method, ADMM, and the primal-dual hybrid gradient method, where in each case the proximal operator for the regularizer can be replaced by a neural network. They show that no single method will produce systematically better results than the others.</p><p>In the proximal techniques the relation between the proximal operator of the regularizer and the natural image probability distribution remains unclear. In contrast, we explicitly use the Gaussiansmoothed natural image distribution as a prior, and we show that we can learn the gradient of its logarithm using a denoising autoencoder.</p><p>Romano et al. <ref type="bibr" target="#b26">[27]</ref> designed a prior model that is also implemented by a denoiser, but that does not build on a proximal formulation such as ADMM. Interestingly, the gradient of their regularization term boils down to the residual of the denoiser, that is, the difference between its input and output, which is the same as in our approach. However, their framework does not establish the connection between the prior and the natural image probability distribution, as we do. Finally, Bigdeli and Zwicker <ref type="bibr" target="#b3">[4]</ref> formulate an energy function, where they use a Denoising Autoencoder (DAE) network for the prior, as in our approach, but they do not address the case of noise-blind restoration.</p><p>Noise-and Kernel-Blind Deconvolution. Kernel-blind deconvolution has seen the most effort recently, while we support the fully (noise and kernel) blind setting. Noise-blind deblurring is usually performed by first estimating the noise level and then restoration with the estimated noise. Jin et al. <ref type="bibr" target="#b13">[14]</ref> proposed a Bayes risk formulation that can perform deblurring by adaptively changing the regularization without the need of the noise variance estimate. Zhang et al. <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref> explored a spatially-adaptive sparse prior and scale-space formulation to handle noise-or kernel-blind deconvolution. These methods, however, are tailored specifically to image deconvolution. Also, they only handle the noise-or kernel-blind case, but not fully blind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Bayesian Formulation</head><p>We assume a standard model for image degradation,</p><formula xml:id="formula_0">y = k * ξ + n, n ∼ N (0, σ 2 n ),<label>(1)</label></formula><p>where ξ is the unknown image, k is the blur kernel, n is zero-mean Gaussian noise with variance σ 2 n , and y is the observed degraded image. We restore an estimate x of the unknown image by defining and maximizing an objective consisting of a data term and an image likelihood,</p><formula xml:id="formula_1">argmax x Φ(x) = data(x) + prior(x).<label>(2)</label></formula><p>Our core contribution is to construct a prior that corresponds to the logarithm of the Gaussiansmoothed probability distribution of natural images. We will optimize the objective using gradient descent, and leverage the fact that we can learn the gradient of the prior using a denoising autoencoder (DAE). We next describe how we define our objective by formulating a Bayes estimator in Section 3.1, then explain how we leverage DAEs to obtain the gradient of our prior in Section 3.2, describe our gradient descent approach in Section 3.3, and finally our image restoration applications in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Defining the Objective via a Bayes Estimator</head><p>A typical approach to solve the restoration problem is via a maximum a posteriori (MAP) estimate, where one considers the posterior distribution of the restored image p(x|y) ∝ p(y|x)p(x), derives an objective consisting of a sum of data and prior terms by taking the logarithm of the posterior, and maximizes it (minimizes the negative log-posterior, respectively). Instead, we will compute a Bayes estimator x for the restoration problem by maximizing the posterior expectation of a utility function,</p><formula xml:id="formula_2">Ex[G(x, x)] = G(x, x)p(y|x)p(x)dx<label>(3)</label></formula><p>where G denotes the utility function (e.g., a Gaussian), which encourages its two arguments to be similar. This is a generalization of MAP, where the utility is a Dirac impulse.</p><p>Ideally, we would like to use the true data distribution as the prior p(x). But we only have data samples, hence we cannot learn this exactly. Therefore, we introduce a smoothed data distribution</p><formula xml:id="formula_3">p (x) = E η [p(x + η)] = g σ (η)p(x + η)dη,<label>(4)</label></formula><p>where η has a Gaussian distribution with zero-mean and variance σ 2 , which is represented by the smoothing kernel g σ . The key idea here is that it is possible to estimate the smoothed distribution p (x) or its gradient from sample data. In particular, we will need the gradient of its logarithm, which we will learn using denoising autoencoders (DAEs). We now define our utility function as</p><formula xml:id="formula_4">G(x, x) = g σ (x − x) p (x) p(x) .<label>(5)</label></formula><p>where we use the same Gaussian function g σ with standard deviation σ as introduced for the smoothed distribution p . This penalizes the estimate x if the latent parameterx is far from it. In addition, the term p (x)/p(x) penalizes the estimate if its smoothed density is lower than the true density of the latent parameter. Unlike the utility in Jin et al. <ref type="bibr" target="#b13">[14]</ref>, this approach will allow us to express the prior directly using the smoothed distribution p .</p><p>By inserting our utility function into the posterior expected utility in Equation <ref type="formula" target="#formula_2">(3)</ref> we obtain</p><formula xml:id="formula_5">Ex[G(x, x)] = g σ ( )p(y|x + ) g σ (η)p(x + η)dηd ,<label>(6)</label></formula><p>where the true density p(x) canceled out, as desired, and we introduced the substitution =x − x.</p><p>We finally formulate our objective by taking the logarithm of the expected utility in Equation <ref type="formula" target="#formula_5">(6)</ref>, and introducing a lower bound that will allow us to split Equation (6) into a data term and an image likelihood. By exploiting the concavity of the log function, we apply Jensen's inequality and get our objective Φ(x) as</p><formula xml:id="formula_6">log Ex[G(x, x)] = log g σ ( )p(y|x + ) g σ (η)p(x + η)dηd ≥ g σ ( ) log p(y|x + ) g σ (η)p(x + η)dη d = g σ ( ) log p(y|x + )d Data term data(x) + log g σ (η)p(x + η)dη Image likelihood prior(x) = Φ(x).<label>(7)</label></formula><p>Image Likelihood. We denote the image likelihood as</p><formula xml:id="formula_7">prior(x) = log g σ (η)p(x + η)dη.<label>(8)</label></formula><p>The key observation here is that our prior expresses the image likelihood as the logarithm of the Gaussian-smoothed true natural image distribution p(x), which is similar to a kernel density estimate.</p><p>Data Term. Given that the degradation noise is Gaussian, we see that <ref type="bibr" target="#b13">[14]</ref> data(x) = g σ ( ) log p(y|x</p><formula xml:id="formula_8">+ )d = − |y − k * x| 2 2σ 2 n − M σ 2 2σ 2 n |k| 2 − N log σ n + const,<label>(9)</label></formula><p>where M and N denote the number of pixels in x and y respectively. This will allow us to address noise-blind problems as we will describe in detail in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Gradient of the Prior via Denoising Autoencoders (DAE)</head><p>A key insight of our approach is that we can effectively learn the gradients of our prior in Equation (8) using denoising autoencoders (DAEs). A DAE r σ is trained to minimize <ref type="bibr" target="#b33">[34]</ref> </p><formula xml:id="formula_9">L DAE = E η,x |x − r σ (x + η)| 2 ,<label>(10)</label></formula><p>where the expectation is over all images x and Gaussian noise η with variance σ 2 , and r σ indicates that the DAE was trained with noise variance σ 2 . Note that this is the same loss as in non-parametric least squares estimators <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b19">20]</ref>. Similar to Alain and Bengio <ref type="bibr" target="#b0">[1]</ref>, we parametrize this estimator using neural networks for fast evaluation. They show that the output r σ (x) of the optimal DAE (by assuming unlimited capacity) is related to the true data distribution p(x) as</p><formula xml:id="formula_10">r σ (x) = x − E η [p(x − η)η] E η [p(x − η)] = x − g σ (η)p(x − η)ηdη g σ (η)p(x − η)dη<label>(11)</label></formula><p>where the noise has a Gaussian distribution g σ with standard deviation σ. This is simply a continuous formulation of mean-shift, and g σ corresponds to the smoothing kernel in our prior, Equation <ref type="bibr" target="#b7">(8)</ref>.</p><p>To obtain the relation between the DAE and the desired gradient of our prior, we first rewrite the numerator in Equation <ref type="formula" target="#formula_0">(11)</ref> using the Gaussian derivative definition to remove η, that is</p><formula xml:id="formula_11">g σ (η)p(x − η)ηdη = −σ 2 ∇g σ (η)p(x − η)dη = −σ 2 ∇ g σ (η)p(x − η)dη,<label>(12)</label></formula><p>where we used the Leibniz rule to interchange the ∇ operator with the integral. Plugging this back into Equation <ref type="formula" target="#formula_0">(11)</ref>, we have</p><formula xml:id="formula_12">r σ (x) = x + σ 2 ∇ g σ (η)p(x − η)dη g σ (η)p(x − η)dη = x + σ 2 ∇ log g σ (η)p(x − η)dη.<label>(13)</label></formula><p>One can now see that the DAE error, that is, the difference r σ (x) − x between the output of the DAE and its input, is the gradient of the image likelihood in Equation <ref type="bibr" target="#b7">(8)</ref>. Hence, a main result of our approach is that we can write the gradient of our prior using the DAE error,</p><formula xml:id="formula_13">∇ prior(x) = ∇ log g σ (η)p(x + η)dη = 1 σ 2 r σ (x) − x .<label>(14)</label></formula><p>NB: <ref type="table">Table 1</ref>: Gradient descent steps for non-blind (NB), noise-blind (NA), and kernel-blind (KE) image deblurring. Kernel-blind deblurring involves the steps for (NA) and (KE) to update image and kernel.</p><formula xml:id="formula_14">1. u t = 1 σ 2 n K T (Kx t−1 − y) − ∇prior s L (x t−1 ) 2.ū = µū − αu t 3. x t = x t−1 +ū NA: 1. u t = λ t K T (Kx t−1 − y) − ∇prior s L (x t−1 ) 2.ū = µū − αu t 3. x t = x t−1 +ū KE: 4. v t = λ t x T (K t−1 x t−1 − y) + M σ 2 k t−1 5.v = µ kv − α k v t 6. k t = k t−1 +v</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Stochastic Gradient Descent</head><p>We consider the optimization as minimization of the negative of our objective Φ(x) and refer to it as gradient descent. Similar to Bigdeli and Zwicker <ref type="bibr" target="#b3">[4]</ref>, we observed that the trained DAE is overfitted to noisy images. Because of the large gap in dimensionality between the embedding space and the natural image manifold, the vast majority of training inputs (noisy images) for the DAE lie at a distance very close to σ from the natural image manifold. Hence, the DAE cannot effectively learn mean-shift vectors for locations that are closer than σ to the natural image manifold. In other words, our DAE does not produce meaningful results for input images that do not exhibit noise close to the DAE training σ.</p><p>To address this issue, we reformulate our prior to perform stochastic gradient descent steps that include noise sampling. We rewrite our prior from Equation <ref type="formula" target="#formula_7">(8)</ref> as</p><formula xml:id="formula_15">prior(x) = log g σ (η)p(x + η)dη (15) = log g σ2 (η 2 ) g σ1 (η 1 )p(x + η 1 + η 2 )dη 1 dη 2 (16) ≥ g σ2 (η 2 ) log g σ1 (η 1 )p(x + η 1 + η 2 )dη 1 dη 2 = prior L (x),<label>(17)</label></formula><p>where σ 2 1 + σ 2 2 = σ 2 , we used the fact that two Gaussian convolutions are equivalent to a single convolution with a Gaussian whose variance is the sum of the two, and we applied Jensen's inequality again. This leads to a new lower bound for the prior, which we call prior L (x). Note that the bound proposed by Jin et al. <ref type="bibr" target="#b13">[14]</ref> corresponds to the special case where σ 1 = 0 and σ 2 = σ.</p><p>We address our DAE overfitting issue by using the new lower bound prior L (x) with</p><formula xml:id="formula_16">σ 1 = σ 2 = σ √ 2 . Its gradient is ∇prior L (x) = 2 σ 2 g σ √ 2 (η 2 ) r σ √ 2 (x + η 2 ) − (x + η 2 ) dη 2 .<label>(18)</label></formula><p>In practice, computing the integral over η 2 is not possible at runtime. Instead, we approximate the integral with a single noise sample, which leads to the stochastic evaluation of the gradient as</p><formula xml:id="formula_17">∇prior s L (x) = 2 σ 2 r σ √ 2 (x + η 2 ) − x ,<label>(19)</label></formula><p>where</p><formula xml:id="formula_18">η 2 ∼ N (0, σ 2 2</formula><p>). This addresses the overfitting issue, since it means we add noise each time before we evaluate the DAE. Given the stochastically sampled gradient of the prior, we apply a gradient descent approach with momentum that consists of the following steps:</p><formula xml:id="formula_19">1. u t = −∇ data(x t−1 ) − ∇ prior s L (x t−1 ) 2.ū = µū − αu t 3. x t = x t−1 +ū<label>(20)</label></formula><p>where u t is the update step for x at iteration t,ū is the running step, and µ and α are the momentum and step-size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Image Restoration using the Deep Mean-Shift Prior</head><p>We next describe the detailed gradient descent steps, including the derivatives of the data term, for different image restoration tasks. We provide a summary in <ref type="table">Table 1</ref>. For brevity, we omit the role of downsampling (required for super-resolution) and masking.</p><p>Levin <ref type="bibr" target="#b18">[19]</ref> Berkeley <ref type="bibr">[</ref>  <ref type="table">Table 2</ref>: Average PSNR (dB) for non-blind deconvolution on two datasets (*trained for σ n = 2.55).</p><p>Non-Blind Deblurring (NB). The gradient descent steps for non-blind deblurring with a known kernel and degradation noise variance are given in <ref type="table">Table 1</ref>, top row (NB). Here K denotes the Toeplitz matrix of the blur kernel k.</p><p>Noise-Adaptive Deblurring (NA). When the degradation noise variance σ 2 n is unknown, we can solve Equation <ref type="formula" target="#formula_8">(9)</ref> for the optimal σ 2 n (since it is independent of the prior), which gives</p><formula xml:id="formula_20">σ 2 n = 1 N |y − k * x| 2 + M σ 2 |k| 2 .<label>(21)</label></formula><p>By plugging this back into the equation, we get the following data term</p><formula xml:id="formula_21">data(x) = − N 2 log |y − k * x| 2 + M σ 2 |k| 2 ,<label>(22)</label></formula><p>which is independent of the degradation noise variance σ 2 n . We show the gradient descent steps in <ref type="table">Table 1</ref>, second row (NA), where λ t = N |y − Kx t−1 | 2 + M σ 2 |k| 2 −1 adaptively scales the data term with respect to the prior.</p><p>Noise-and Kernel-Blind Deblurring (NA+KE). Gradient descent in noise-blind optimization includes an intuitive regularization for the kernel. We can use the objective in Equation <ref type="formula" target="#formula_1">(22)</ref> to jointly optimize for the unknown image and the unknown kernel. The gradient descent steps to update the image remain as in <ref type="table">Table 1</ref>, second row (NA), and we take additional steps to update the kernel estimate, as in <ref type="table">Table 1</ref>, third row (KE). Additionally, we project the kernel by applying k t = max(k t , 0) and k t = k t |k t |1 after each step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Results</head><p>Our DAE uses the neural network architecture by Zhang et al. <ref type="bibr" target="#b38">[39]</ref>. We generated training samples by adding Gaussian noise to images from ImageNet <ref type="bibr" target="#b9">[10]</ref>. We experimented with different noise levels and found σ 1 = 11 to perform well for all our deblurring and super-resolution experiments. Unless mentioned, for image restoration we always take 300 iterations with step length α = 0.1 and momentum µ = 0.9. The runtime of our method is linear in the number of pixels, and our implementation takes about 0.2 seconds per iteration for one megapixel on an Nvidia Titan X (Pascal).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Image Deblurring: Non-Blind and Noise-Blind</head><p>In this section we evaluate our method for image deblurring using two datasets. <ref type="table">Table 2</ref> reports the average PSNR for 32 images from the Levin et al. <ref type="bibr" target="#b18">[19]</ref> and 50 images from the Berkeley <ref type="bibr" target="#b1">[2]</ref> segmentation dataset, where 10 images are randomly selected and blurred with 5 kernels as in Jin et al. <ref type="bibr" target="#b13">[14]</ref>. We highlight the best performing PSNR in bold and underline the second best value. The Ground Truth EPLL <ref type="bibr" target="#b40">[41]</ref> DAEP <ref type="bibr" target="#b3">[4]</ref> GradNet 7S <ref type="bibr" target="#b13">[14]</ref> Ours Ours + NA upper half of the table includes non-blind methods for deblurring. EPLL <ref type="bibr" target="#b40">[41]</ref> + NE uses a noise estimation step followed by non-blind deblurring. Noise-blind experiments are denoted by NA for noise adaptivity. We include our results for non-blind (Ours) and noise-blind (Ours + NA). Our noise adaptive approach consistently performs well in all experiments and on average we achieve better results than the state of the art. <ref type="figure">Figure 2</ref> provides a visual comparison of our results. Our prior is able to produce sharp textures while also preserving the natural image structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Image Deblurring: Noise-and Kernel-Blind</head><p>We performed fully blind deconvolution with our method using Levin et al.'s <ref type="bibr" target="#b18">[19]</ref> dataset. In this test, we performed 1000 gradient descent iterations. We used momentum µ = 0.7 and step size α = 0.3 for the unknown image and momentum µ k = 0.995 and step size α k = 0.005 for the unknown kernel. <ref type="figure">Figure 3</ref> shows visual results of fully blind deblurring and performance comparison to state of the art (last column). We compare the SSD error ratio and the number of images in the dataset that achieves error ratios less than a threshold. Results for other methods are as reported by Perrone and Favaro <ref type="bibr" target="#b23">[24]</ref>. Our method can reconstruct all the blurry images in the dataset with errors ratios less than 3.5. Note that our optimization performs end-to-end estimation of the final results and we do not use the common two stage blind deconvolution (kernel estimation, followed by non-blind deconvolution). Additionally our method uses a noise adaptive scheme where we do not assume knowledge of the input noise level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Super-resolution</head><p>To demonstrate the generality of our prior, we perform an additional test with single image superresolution. We evaluate our method on the two common datasets Set5 <ref type="bibr" target="#b2">[3]</ref> and Set14 <ref type="bibr" target="#b35">[36]</ref> for different upsampling scales. Since these tests do not include degradation noise (σ n = 0), we perform our optimization with a rough weight for the prior and decrease it gradually to zero. We compare our method in <ref type="table" target="#tab_2">Table 3</ref>. The upper half of the table represents methods that are specifically trained for super-resolution. SRCNN <ref type="bibr" target="#b10">[11]</ref> and TNRD <ref type="bibr" target="#b6">[7]</ref> have separate models trained for ×2, 3, 4 scales, and we used the model for ×4 to produce the ×5 results. VDSR <ref type="bibr" target="#b15">[16]</ref> and DnCNN-3 <ref type="bibr" target="#b38">[39]</ref> have a single model trained for ×2, 3, 4 scales, which we also used to produce ×5 results. The lower half of the table represents general priors that are not designed specifically for super-resolution. Our method performs on par with state of the art methods over all the upsampling scales.</p><p>Set5 <ref type="bibr" target="#b2">[3]</ref> Set14 <ref type="bibr" target="#b35">[36]</ref>    <ref type="table">Table 4</ref>: Average PSNR (dB) in linear RGB space for demosaicing on the Panasonic dataset <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Demosaicing</head><p>We finally performed a demosaicing experiment on the dataset introduced by Khashabi et al. <ref type="bibr" target="#b14">[15]</ref>. This dataset is constructed by taking RAW images from a Panasonic camera, where the images are downsampled to construct the ground truth data. Due to the down sampling effect, in this evaluation we train a DAE with σ 1 = 3 noise standard deviation. The test dataset consists of 100 noisy images captured by a Panasonic camera using a Bayer color filter array (RGGB). We initialize our method with Matlab's demosaic function <ref type="bibr" target="#b20">[21]</ref>. To get even better initialization, we perform our initial optimization with a large degradation noise estimate (σ n = 2.5) and then perform the optimization with a lower estimate (σ n = 1). We summarize the quantitative results in <ref type="table">Table 4</ref>. Our method is again on par with the state of the art. Additionally, our prior is not trained for a specific color filter array and therefore is not limited to a specific sub-pixel order. <ref type="figure" target="#fig_1">Figure 4</ref> shows a qualitative comparison, where our method produces much smoother results compared to the previous state of the art.</p><p>Ground Truth RTF <ref type="bibr" target="#b14">[15]</ref> Gharbi et al. <ref type="bibr" target="#b12">[13]</ref> SEM <ref type="bibr" target="#b16">[17]</ref> Ours </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>We proposed a Bayesian deep learning framework for image restoration with a generic image prior that directly represents the Gaussian smoothed natural image probability distribution. We showed that we can compute the gradient of our prior efficiently using a trained denoising autoencoder (DAE). Our formulation allows us to learn a single prior and use it for many image restoration tasks, such as noise-blind deblurring, super-resolution, and image demosaicing. Our results indicate that we achieve performance that is competitive with the state of the art for these applications. In the future, we would like to explore generalizing from Gaussian smoothing of the underlying distribution to other types of kernels. We are also considering multi-scale optimization where one would reduce the Bayes utility support gradually to get a tighter bound with respect to maximum a posteriori. Finally, our approach is not limited to image restoration and could be exploited to address other inverse problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Visual comparison of our deconvolution results. Ground Truth Blurred with 1% noise Ours (blind) SSD Error Ratio</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Visual comparison for demosaicing noisy images from the Panasonic data set [15].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Average PSNR (dB) for super-resolution on two datasets. Matlab [21] RTF [15] Gharbi et al. [13] Gharbi et al. [13] f.t. SEM [17</figDesc><table>] Ours 
</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The source code of the proposed method is available at https://github.com/siavashbigdeli/DMSP.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. MJ and PF acknowledge support from the Swiss National Science Foundation (SNSF) on project 200021-153324.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">What regularized auto-encoders learn from the data-generating distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="3743" to="3773" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Contour detection and hierarchical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="898" to="916" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Low-complexity single-image super-resolution based on nonnegative neighbor embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Bevilacqua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aline</forename><surname>Roumy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Guillemot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Line</forename><surname>Alberi-Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference, BMVC 2012</title>
		<meeting><address><addrLine>Surrey, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Image restoration using autoencoding priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjomand</forename><surname>Siavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bigdeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zwicker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.09964</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bartomeu</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2005 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">One network to solve them all-solving linear inverse problems using deep projection models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barnabas</forename><surname>Poczos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aswin C</forename><surname>Bvk Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sankaranarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.09912</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1256" to="1272" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mean shift: A robust approach toward feature space analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dorin</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="603" to="619" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Image denoising with block-matching and 3d filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostadin</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="606414" to="606414" />
		</imprint>
	</monogr>
	<note>Electronic Imaging</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2009 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image super-resolution using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="295" to="307" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Removing camera shake from a single photograph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barun</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="787" to="794" />
			<date type="published" when="2006" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep joint demosaicking and denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaël</forename><surname>Gharbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Chaurasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédo</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">191</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Noise-blind image deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Joint demosaicing and denoising via learned nonparametric random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Jancsary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">W</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4968" to="4981" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Accurate image super-resolution using very deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2016 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1646" to="1654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning joint demosaicing and denoising based on sequential energy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teresa</forename><surname>Klatzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kerstin</forename><surname>Hammernik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Knobelreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Photography (ICCP), 2016 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast image deconvolution using hyper-laplacian priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1033" to="1041" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anat</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédo</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">70</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Natural image denoising: Optimality and inherent bounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anat</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boaz</forename><surname>Nadler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2833" to="2840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">High-quality linear interpolation for demosaicing of bayerpatterned color images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Henrique</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Wei</forename><surname>Malvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cutler</surname></persName>
		</author>
		<idno>iii-485. IEEE</idno>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Meinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Möller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.03488</idno>
		<title level="m">Caner Hazirbas, and Daniel Cremers. Learning proximal operators: Using denoising networks for regularizing inverse imaging problems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An empirical bayes estimator of the mean of a normal population</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koichi Miyasawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bull. Inst. Internat. Statist</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A logarithmic image prior for blind deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Perrone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="172" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image denoising using scale mixtures of gaussians in the wavelet domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Portilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Strela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1338" to="1351" />
			<date type="published" when="2003-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Least squares estimation without priors or supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raphan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="374" to="420" />
			<date type="published" when="2010-11" />
		</imprint>
	</monogr>
	<note>Published online</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The little engine that could: Regularization by denoising (red)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyman</forename><surname>Milanfar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02862</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fields of experts: A framework for learning image priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2005 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="860" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Nonlinear total variation based noise removal algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><forename type="middle">I</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emad</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D: Nonlinear Phenomena</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cascades of regression tree fields for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Jancsary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="677" to="689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Shrinkage fields for effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2774" to="2781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Visualizing image priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamar</forename><forename type="middle">Rott</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Michaeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="136" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Plug-and-play priors for model based reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Singanallur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">A</forename><surname>Venkatakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendt</forename><surname>Bouman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wohlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GlobalSIP</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="945" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning</title>
		<meeting>the 25th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Discriminative transfer learning for general image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Heide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Heidrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Hirsch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.09245</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">On single image scale-up using sparse-representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Zeyde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matan</forename><surname>Protter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Curves and Surfaces</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="711" to="730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Non-uniform camera shake removal using a spatially-adaptive sparse penalty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haichao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wipf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1556" to="1564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Scale adaptive blind deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haichao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3005" to="3013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03981</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Learning deep cnn denoiser prior for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.03264</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">From learning models of natural image patches to whole image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="479" to="486" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
