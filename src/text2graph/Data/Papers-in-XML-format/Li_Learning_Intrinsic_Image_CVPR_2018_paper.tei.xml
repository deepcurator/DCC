<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T23:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Intrinsic Image Decomposition From Watching the World</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengqi</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Snavely</surname></persName>
						</author>
						<title level="a" type="main">Learning Intrinsic Image Decomposition From Watching the World</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>age. During training, the input images interact through our novel loss function (Sec. 5), which evaluates the predicted decompositions jointly for the entire sequence.</p><p>For our network, we use a variant of the U-Net architecture <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b15">16]</ref>  <ref type="figure">(Figure 2</ref>). Our network has one encoder and two decoders, one for log-reflectance and one for logshading, with skip connections for both decoders. Each layer of the encoder consists mainly of a 4 × 4 stride-2 convolutional layer followed by batch normalization <ref type="bibr" target="#b14">[15]</ref> as well as leaky ReLu <ref type="bibr" target="#b13">[14]</ref>. For the two decoders, each layer is composed of a 4 × 4 deconvolutional layer followed by ReLu. In addition to the decoders for reflectance and shading, the network predicts one side output from the innermost feature maps, a single RGB vector for each image corresponding to the predicted illumination color.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Dataset</head><p>To create the BIGTIME dataset, we collected videos and image sequences depicting both indoor and outdoor scenes with varying illumination. While many time-lapse datasets primarily capture outdoor scenes, we explicitly wanted representation from indoor scenes as well. Our indoor sequences were gathered from Youtube, Vimeo, Flickr, Shutterstock, and Boyadzhiev et al. <ref type="bibr" target="#b5">[6]</ref>, and our outdoor sequences were collected from the AMOS <ref type="bibr" target="#b16">[17]</ref> and Time Hallucination <ref type="bibr" target="#b34">[35]</ref> datasets. For each video, we masked out the sky as well as dynamic objects such as pets, people, and cars via automatic semantic segmentation <ref type="bibr" target="#b37">[38]</ref> or manual annotation. We collected 145 sequences from indoor scenes and 50 from outdoor scenes, yielding a total of ∼6,500 training images. Challenges with Internet videos. Most outdoor scenes in our dataset are from time-lapse sequences where the sun moves evenly over time. Many existing algorithms for multiimage intrinsic image decomposition work well on such data. However, we found that indoor image sequences are much more challenging because illumination changes in indoor scenes tend to be less even or continuous compared to outdoor scenes. In particular, we observed that:</p><p>1. most relevant video clips cover a short period of time and do not show large changes in light direction, 2. several video clips are comprised of a light turning on/off in a room, producing a limited number (&lt;8) of valid images with different lighting conditions, and 3. the dynamic range of indoor scenes can be high, with strong sunlight or shadows leading to saturation/clipping that can break intrinsic image algorithms.</p><p>These properties make our dataset even more complex than the IIW and SAW datasets. Several difficult examples are shown in <ref type="figure">Fig. 3</ref>. We found that prior intrinsic image methods designed for image sequences often fail on our indoor videos, as their assumptions tend to hold only for outdoor We applied a state-of-the-art multi-image intrinsic image decomposition estimation algorithm <ref type="bibr" target="#b12">[13]</ref> to our dataset. This method fails to produce decomposition results suitable for training due to strong assumptions that hold primarily for outdoor/laboratory scenes.</p><p>or lab-captured sequences. Example failure cases are shown in <ref type="figure">Fig. 4</ref>. However, as we show in our evaluation, our approach is robust to such strong illumination conditions, and networks trained on BT generalize well to IIW and SAW.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Approach</head><p>In this section, we describe our novel framework for learning reflectance and shading from Internet time-lapse video clips. During training, we formulate the problem as a continuous densely connected conditional random field (dense CRF) and learn a deep neural network to directly predict a decomposition from single views in a feed-forward fashion. Image formation model. Let I denote an input image, and R and S denote the predicted reflectance (albedo) and shading. Assuming an image of a Lambertian scene, we can write the image decomposition in the log domain as:</p><formula xml:id="formula_0">log I = log R + log S + N<label>(1)</label></formula><p>where N models image noise as well as deviations from a Lambertian assumption. In our model, S is a single-channel (grayscale) image, while R is an RGB image. However, modeling S with a single channel assumes white light. In practice, the illumination color can vary across each input video (for instance, red illumination at sunset/sunrise). Hence, we also allow for a colored light in our model:</p><formula xml:id="formula_1">log I = log R + log S + c + N<label>(2)</label></formula><p>where c is a single RGB vector that is added to each element of the left-hand side. For simplicity, we use Eq. 1 in the following sections; without loss of generality, we treat c as being folded into the predicted shading. Each training instance is a stack of m input images with n pixels taken from a fixed viewpoint and varying illumination. We denote such an image sequence by I = I i |i = 1 . . . m , and denote the corresponding predicted reflectances and shadings by R = R i |i = 1 . . . m , and S = S i |i = 1 . . . m , respectively. Additionally, for each image I i we have a binary mask M i indicating which pixels are valid (which we use to exclude saturated pixels, sky, dynamic objects, etc).</p><p>We wish to devise a method for learning single-view intrinsic image decomposition that leverages having multiple views during training. Hence, we propose to combine learning and estimation by encoding our priors into the training loss function. Essentially, we learn a feed-forward predictor for single-image intrinsic images, trained on image sequences with a loss that incorporates these priors, and in particular priors that operate at the sequence level. This loss should also be differentiable and efficient to evaluate, considerations which guide our design below.</p><p>Energy/loss function. During training, we formulate the problem as a dense CRF over an image sequence I, where our goal is to maximize a posterior probability p(R, S|I) = 1 Z(I) exp (−E(R, S, I)), where Z(I) is the partition function. Maximizing p(R, S|I) is equivalent to minimize an energy function E(R, S, I). Because we use a feed-forward network to predict the decomposition, we also use this energy function as our training loss. We define E as:</p><formula xml:id="formula_2">E(R, S, I) =L reconstruct + w 1 L consistency + w 2 L rsmooth + w 3 L ssmooth<label>(3)</label></formula><p>We now describe each term in Eq. 3 in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Image reconstruction loss</head><p>Given an input sequence I, for each image I i ∈ I we expect the predicted reflectance and shading for I i to approximately reconstruct I i via our image formation model. Moreover, since reflectance is constant over time, we should be able to use the reflectance R j predicted for any image I j ∈ I to reconstruct I i , when paired with S i (and masked by the valid image regions indicated by binary masks M i and M j ). This yields a term involving all pairs of images:</p><formula xml:id="formula_3">Lreconstruct = m i=1 m j=1 L i ⊗ M i ⊗ M j ⊗ (log I i − log R j − log S i ) 2 F<label>(4)</label></formula><p>where ⊗ is the Hadamard product. Similar to <ref type="bibr" target="#b9">[10]</ref>, we weight our reconstruction loss by input pixel luminance</p><formula xml:id="formula_4">L i = lum(I i ) 1 8</formula><p>, since dark pixels tend to be noisy, and image differences in dark regions are magnified in log-space.</p><p>We found that including such an all-pairs connected image reconstruction loss improves prediction results, perhaps because it creates more communication between predictions. A direct implementation of this loss takes time O(m 2 n). In Sec. 5.5 we introduce a computational trick that reduces this to O(mn) time, which is key to making training tractable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Reflectance consistency</head><p>We also include a reflectance consistency loss that directly encodes the assumption that the predicted reflectances should be identical across the image sequence:</p><formula xml:id="formula_5">L consistency = m i=1 m j=1 M i ⊗ M j ⊗ (log R i − log R j ) 2 F</formula><p>(5) As above, this can be directly computed in time O(m 2 n), but Sec. 5.5 shows how to reduce this to O(mn).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Dense spatio-temporal reflectance smoothness</head><p>Our reflectance smoothness term L rsmooth is based on the similarity of chromaticity and intensity between pixels. Because we see a sequence of images at training time, we can define a reflectance smoothness term that acts jointly on all of the images in each sequence at once, allowing us to express smoothness in a richer way. Accordingly, we introduce a novel spatio-temporal densely connected reflectance smoothness term that considers the similarity of the predicted reflectance at each pixel in the sequence to all other pixels in the sequence. Our method is inspired by the bilateral-space stereo method of Barron et al. <ref type="bibr" target="#b1">[2]</ref>, but we show how to apply their single-image dense solver to an entire image sequence and how to implement it inside a deep network. We define our smoothness term as:</p><formula xml:id="formula_6">L rsmooth = 1 2 I i ,I j p∈I i q∈I jŴ pq (log R i p − log R j q ) 2<label>(6)</label></formula><p>where p and q indicate pixels in the image sequence, and W is a (bistochastic) weight matrix capturing the affinity between any two pixels p and q. Computing this equation directly is very expensive because it involves all pairs of pixels in the sequence, hence we need a more efficient approach. First, note that ifŴ is a bistochastic matrix, we can rewrite Eq. 6 in the following simplified matrix form:</p><formula xml:id="formula_7">L rsmooth = r ⊤ (I −Ŵ )r<label>(7)</label></formula><p>where r is a stacked vector representation (of length mn) of all of the predicted log-reflectance images in the sequence: </p><formula xml:id="formula_8">r = [r 1 r 2 · · · r m ] ⊤ ,</formula><formula xml:id="formula_9">W pq = exp −(f p − f q ) ⊤ Σ −1 (f p − f q )) (8)</formula><p>where f p and f q are feature vectors for pixels p and q respectively, and Σ is a covariance matrix. We can approximately minimize Eq. 7 in bilateral space by factorizing the Gaussian affinity matrix W ≈ S ⊤B S, wherē</p><formula xml:id="formula_10">B = B 0 B 1 · · · B d + B d B d−1 · · · B 0</formula><p>is a symmetric matrix constructed as a product of sparse matrices representing blur operations in bilateral space, d is the dimension of feature vector f p , and S is a sparse splat/slicing matrix that transforms between image space and bilateral space. Finally, let W = N W N be a bistochastic representation of W , where N is a diagonal matrix that bistochasticizes W <ref type="bibr" target="#b21">[22]</ref>. This bilateral embedding allows us to write the loss in Eq. 7 as:</p><formula xml:id="formula_11">L rsmooth ≈ r ⊤ (I − N S ⊤B SN )r (9)</formula><p>Note that L rsmooth is differentiable and N and S are both sparse matrices that can be computed efficiently. Our final form of L rsmooth (Eq. 9) can be computed in time</p><formula xml:id="formula_12">O((d + 1)mn), rather than O(m 2 n 2 )</formula><p>. We define the feature vector used to compute the affinities in Eq. 8 as</p><formula xml:id="formula_13">f p = [ x p , y p , I p , c 1 , c 2 ]</formula><p>⊤ , where (x p , y p ) is the spatial position of pixel p in the image, I p is the intensity of p, and c 1 = R R+G+B and c 2 = G R+G+B are the first two elements of the L 1 chromaticity of p.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Multi-scale shading smoothness</head><p>In addition to a reflectance smoothness term, our loss also incorporates a shading smoothness term, L ssmooth . This term is summed over each predicted shading image:</p><formula xml:id="formula_14">L ssmooth = m i=1 L ssmooth (S i )</formula><p>, where L ssmooth (S i ) is defined as a weighted L 2 term over neighboring pixels:</p><formula xml:id="formula_15">L ssmooth (S i ) = p∈I i q∈N (p) v pq log S i p − log S i q 2<label>(10)</label></formula><p>where N (p) denotes the 8-connected neighborhood around pixel p, and v pq is a weight on each edge. Our insight is to leverage all of the input images to compute the weights for each individual image. We are inspired by Weiss <ref type="bibr" target="#b36">[37]</ref>, who derives a multi-image intrinsic images algorithm based on median image derivatives over the sequence. Essentially, we expect the median image derivative over the input sequence (in the log domain) to approximate the derivative of the reflectance image. If we denote J pq = log I p − log I q (dropping the image index i for convenience), then this suggests a weight of the form:</p><formula xml:id="formula_16">v med pq = exp −λ med (J pq − median{J pq }) 2<label>(11)</label></formula><p>where median{J pq } is the median value of J pq over the image sequence, and λ med is a parameter defining the strength pq . This weight discourages shading smoothness where the gradient of a particular image is very different from the median (as would happen, e.g., for a shadow boundary).</p><p>We found that v med pq works well as a weight for textureless regions (for instance, it captures the effect of a cast shadow on a flat wall well), but, due to noise present in dark image regions, it does not always capture the desired shading smoothness for textured surfaces. <ref type="figure" target="#fig_1">Figure 5</ref> (bottom) illustrates such a case with a checkerboard pattern on the floor. To address this issue, we define an additional weight v med pq that is normalized by the median derivative:</p><formula xml:id="formula_17">v med pq = exp −λ med J pq − median{J pq } median{J pq } 2<label>(12)</label></formula><p>We combine these weights as follows:</p><formula xml:id="formula_18">v pq = max{v med pq , v med pq } · (1 − median{W pq })<label>(13)</label></formula><p>This final shading smoothness weight is more robust to textured regions while still distinguishing shadow discontinuities. The last factor (1 − median{W pq }) reflects the belief that we should enforce stronger shading smoothness on reflectance edges such as textures and weaker smoothness on regions of constant reflectance. Ideally, our shading smoothness term would be densely connected. However, the median operator is nonlinear and cannot be integrated in a pixel-wise densely connected term. Instead, to introduce longer-range shading constraints, we compute the shading smoothness term at multiple image scales, by repeatedly downsizing each predicted shading image by a factor of two. We set the number of scales to be 4, and each scale l is weighted by a factor 1 l .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">All-pairs weighted least squares (APWLS)</head><p>Direct implementations of the all-pairs image reconstruction and reflectance consistency terms from Sections 5.1 and 5.2 would take O(m 2 n) time. This quadratic complexity would make training intractable for large enough m. Here, we propose a closed-form version of this all-pairs weighted least squares loss (APWLS) that is linear in m. While we apply this tool to our scenario, it can be used in other situations involving all-pairs computation on image sequences.</p><p>In general, suppose each image I i is associated with two matrices P i and Q i and two prediction images X i and Y i . We then can write APWLS as (see supplemental material for a detailed derivation):</p><formula xml:id="formula_19">APWLS = m i=1 m j=1 ||P i ⊗ Q j ⊗ (X i − Y j )|| 2 F (14) =1 ⊤ (Σ Q 2 ⊗ Σ P 2 X 2 + Σ P 2 ⊗ Σ Q 2 Y 2 − 2Σ P 2 Y ⊗ Σ Q 2 X )1<label>(15)</label></formula><p>where Σ Z denotes the sum over all images of the Hadamard product indicated in the subscript Z. Evaluating Eq. 14 requires time O(m 2 n), but rewritten as Eq. 15, just O(mn). We use this derivation to implement our image reconstruction loss L reconstruct (Eq. 15), by making the substitu-</p><formula xml:id="formula_20">tions P i = L i ⊗ M i , Q j = M j , X i = log I i − log S i</formula><p>and Y j = log R j , and our reflectance consistency loss L consistency (Eq. 5) by substituting</p><formula xml:id="formula_21">P i = M i , Q j = M j , X i = log R i and Y j = log R j .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Evaluation</head><p>In this section we evaluate our approach by training solely on our BIGTIME dataset, and testing on two standard datasets, IIW and SAW. The performance of machine learning approaches can suffer from cross-dataset domain shift due to dataset bias. For example, we show that the performance of networks trained on Sintel, MIT, or ShapeNet do not generalize well to IIW and SAW. However, our method, though not trained on IIW or SAW data, can still produce competitive results on both datasets. We also evaluate on the MIT intrinsic images dataset <ref type="bibr" target="#b11">[12]</ref>, which has full ground truth. Rather than using the ground truth during training, we train the network on image sequences provided by the MIT dataset. Training details. We implement our method in PyTorch <ref type="bibr" target="#b0">[1]</ref>. In total, we have 195 image sequences for training. We perform data augmentation via random rotations, flips, and crops. When feeding images into the network, we resize them to 256 × 384, 384 × 256, or 256 × 256 depending on the original aspect ratio. For all evaluations, we train the network from scratch using Adam <ref type="bibr" target="#b20">[21]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Evaluation on IIW</head><p>To evaluate on the IIW dataset, we train our network on BT (without using IIW training data) and directly apply our trained model on the IIW test split provided by <ref type="bibr" target="#b28">[29]</ref>. Numerical comparisons between our method and other optimizationbased and learning-based approaches are shown in  <ref type="table">Table 2</ref>: Results on the SAW test set. Higher is better for AP%. The second column is described in <ref type="table" target="#tab_1">Table 1</ref>. Note that none of the methods use annotations from SAW.</p><p>Our method is competitive with both optimization-based methods <ref type="bibr" target="#b4">[5]</ref> and learning-based methods <ref type="bibr" target="#b39">[40]</ref>. Note that the best WHDR (marked * ) in the table is achieved using CNN classier outputs on pairs of pixels, rather than full image decompositions. In contrast, our results are based on full decompositions. Additionally, as we show in the next subsection, the best performing method (Zhou et al. <ref type="bibr" target="#b39">[40]</ref>) on IIW (which primarily evaluates reflectance) falls behind on SAW (which evaluates shading), suggesting that their method tends to overfit on reflectance. shading accuracy. We also see that networks trained on Sintel, MIT or ShapeNet perform poorly on IIW, likely due to dataset bias.  <ref type="figure">Figure 6</ref>: Qualitative comparisons for intrinsic image decomposition on the IIW/SAW test sets. Our network predictions achieve comparable results to state-of-art intrinsic image decomposition algorithms (Bell et al. <ref type="bibr" target="#b4">[5]</ref> and Zhou et al. <ref type="bibr" target="#b39">[40]</ref>).</p><p>We also perform an ablation study on different configurations of our framework. First, we modify the image reconstruction loss to an alternate loss that considers each image independently, rather than considering all pairs of images in a sequence. Second, we evaluate a modified reflectance smoothness loss that uses local pairwise smoothness (between neighboring pixels) rather than our proposed dense spatio-temporal smoothness. Finally, we try using grayscale shading, rather than our colored shading. The results, shown in the last four rows of <ref type="table" target="#tab_1">Table 1</ref>, demonstrate that our full method can significantly improve reflectance predictions on the IIW test set compared to simpler configurations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Evaluation on SAW</head><p>Next, we test our network on SAW <ref type="bibr" target="#b22">[23]</ref>, again training without using data from SAW. We also propose two improvements to the metric used to evaluate results on SAW:</p><p>First, the original SAW error metric is based on classifying a pixel p as having smooth/nonsmooth shading based on the gradient magnitude of the predicted shading image, ||∇S|| 2 , normalized to the range [0, 1]. Instead, we measure the gradient magnitude in the log domain. We do this because of the scale ambiguity inherent to shading and reflectance, and because it is possible to have very bright values in the shading channel (e.g., due to strong sunlight), and in such cases if we normalize shading to [0, 1] then most of the resulting values will be close to 0. In contrast, computing the gradient magnitude of log shading ||∇ log S|| 2 achieves scale invariance, resulting in fairer comparisons for all methods. As in <ref type="bibr" target="#b22">[23]</ref>, we sweep a threshold τ to create a precision-recall (PR) curve that captures how well each method captures smooth and non-smooth shading.</p><p>Second, Kovacs et al. <ref type="bibr" target="#b22">[23]</ref> apply a 10×10 maximum filter to the shading gradient magnitude image before computing PR curves, because many shadow boundary annotations are not precisely localized. However, this maximum filter can result in degraded performance for smooth shading regions. Instead, we use the max-filtered log-gradient-magnitude image when classifying non-smooth annotations, but use the unfiltered log gradient image when classifying smooth annotations (see supplementary for details).</p><p>All methods, including our own, are trained without use of SAW data. Average precision (AP) scores are shown in <ref type="table">Table 2</ref> (please see the supplementary for full precisionrecall curves). Our method has the best performance among all prior methods we tested, and our full loss outperforms variants with terms removed. In particular, our method outperforms the best optimization-based algorithm <ref type="bibr" target="#b4">[5]</ref> on both IIW and SAW. On the other hand, Zhou et al. <ref type="bibr" target="#b39">[40]</ref> tends to overfit to IIW, as their performance on SAW ranks lower than several other methods. Again, networks trained on Sintel, MIT, and ShapeNet data perform poorly on SAW. <ref type="figure">Figure 6</ref> shows qualitative results from our method and two other state-of-art intrinsic image decomposition algorithms, Zhou et al. <ref type="bibr" target="#b39">[40]</ref> and Bell et al. <ref type="bibr" target="#b4">[5]</ref>, on test images from IIW and SAW. Our results are visually comparable to these methods. One observation is that our shading predictions for dark pixels can be quite dark, leading to reduced contrast in the reflectance images. However, this loss of contrast does not hurt numerical performance. Additionally, like other CNN approaches <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b33">34]</ref>, the direct predictions from our network may not strictly satisfy I = R · S since the  <ref type="table">Table 3</ref>: Results on MIT intrinsics. For all error metrics, lower is better. ST=Sintel dataset and SN=ShapeNet dataset. The second column shows the dataset used for training. GT indicates whether the method uses ground truth for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Qualitative results on IIW and SAW</head><p>two decoders predict R and S simultaneously at test time.</p><p>As future work, it would be interesting to use our predictions as priors for optimization to address these issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Evaluation on MIT intrinsic images</head><p>The MIT intrinsic images dataset <ref type="bibr" target="#b11">[12]</ref> contains 20 objects with ground truth reflectance and shading, as well as an associated image sequence taken from 11 different directional light sources. We use the same training-test split as in Barron et al. <ref type="bibr" target="#b3">[4]</ref>, but instead of training our network on the ground truth provided by the MIT dataset, we train only on the provided image sequences using our learning approach. In this case, we configure our network to produce grayscale shading outputs, since the MIT dataset only contains grayscale shading ground truth images.</p><p>We compare our approach to several supervised learning methods including SIRFS <ref type="bibr" target="#b3">[4]</ref>, Direct Intrinsics (DI) <ref type="bibr" target="#b27">[28]</ref> and Shi et al. <ref type="bibr" target="#b33">[34]</ref>. These prior methods all train using ground truth reflectance and shading images, and additionally DI <ref type="bibr" target="#b27">[28]</ref> and Shi et al. <ref type="bibr" target="#b33">[34]</ref> pretrain on Sintel <ref type="bibr" target="#b6">[7]</ref> and ShapeNet <ref type="bibr" target="#b8">[9]</ref>, respectively. In contrast, we train our network from scratch and only use the provided image sequences during training. We adopt the same metrics as <ref type="bibr" target="#b33">[34]</ref>, including mean square error (MSE), local mean square error (LMSE), and structural dissimilarity index (DSSIM).</p><p>Numerical results are shown in <ref type="table">Table 3</ref> and qualitative comparisons are shown in <ref type="figure" target="#fig_3">Figure 7</ref>. Averaged over reflectance and shading, our results numerically outperform both prior CNN-based supervised learning methods <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b33">34]</ref>. In particular, our albedo estimates are significantly better, while our shading estimates are comparable (slightly better than <ref type="bibr" target="#b27">[28]</ref>, and slightly worse than <ref type="bibr" target="#b33">[34]</ref>). SIRFS has the best numerical results on the MIT, but SIRFS's priors only apply to single objects, and their algorithm performs much more poorly on full images of real-world scenes <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b33">34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We presented a new method for learning intrinsic images, supervised not by ground truth decompositions, but instead by simply observing image sequences with varying illumination over time, and learning to produce decompositions that are consistent with these sequences. Our model can then  <ref type="bibr" target="#b27">[28]</ref>, (e) Shi et al. <ref type="bibr" target="#b33">[34]</ref>, (f) Our method.</p><p>be run on single images, producing competitive results on several benchmarks. Our results illustrate the power of learning decompositions simply from watching large amounts of video. In the future, we plan to combine our approach with other kinds of annotations (IIW, SAW, etc), to measure how well they perform when used together, and to use our outputs as inputs to optimization-based methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Figure 3: Examples of challenging images in our dataset. The first two images depict colorful illumination. The last two images show strong sunlight/shadows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Effect of v med in shading smoothness term. (white = large weight, black = small weight.) Adding the extra v med can help capture smoothness in textured regions such as the pillows in the first row and floor in the second row. The last column shows the final smoothness weight v pq .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>et al. (R) (c) Bell et al. (S) (d) Zhou et al. (R) (e) Zhou et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Qualitative comparisons on the MIT intrinsic test set. Odd-number rows show predicted reflectance; evennumbered rows show predicted shading. (a) Input image, (b) Ground truth (GT), (c) SIRFS [4], (d) Direct Intrinsics (DI) [28], (e) Shi et al. [34], (f) Our method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>where r i is a vector containing the values in log R i . However, now we have a potentially dense affinity matrixŴ ∈ R mn×mn . But we can approximately evaluate this term much more efficiently if the pixel-wise affinities are Gaussian, i.e.,</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>Method 
Training set WHDR% 

Retinex-Color [12] 
-
26.9 
Garces et al. [11] 
-
24.8 
Zhao et al. [39] 
-
23.8 
Bell et al. [5] 
-
20.6 

Narihira et al. [29] 

 *  

IIW 
18.1 

 *  

Zhou et al. [40] 

 *  

IIW 
15.7 

 *  

Zhou et al. [40] 
IIW 
19.9 

DI [28] 
Sintel+MIT 
37.3 

Shi et al. [34] 
ShapeNet 
59.4 

Ours (w/ per-image Lreconstruct) BT 
25.9 
Ours (w/ local L rsmooth ) 
BT 
27.4 
Ours (w/ grayscale S) 
BT 
22.3 
Ours (full method) 
BT 
20.3 

Table 1: Results on the IIW test set. Lower is better for 
the Weighted Human Disagreement Rate (WHDR). The sec-
ond column indicates the training data each learning-based 
method uses; "-" indicates the method is optimization-based. 
 *  indicates WHDR is evaluated based on CNN classifer 
outputs for pairs of pixels rather than full decompositions. 

Method 
Training set AP% 

Retinex-Color [12] 
-
91.93 
Garces et al. [11] 
-
96.89 
Zhao et al. [39] 
-
97.11 
Bell et al. [5] 
-
97.37 

Zhou et al. [40] 
IIW 
96.24 

DI [28] 
Sintel+MIT 95.04 

Shi et al. [34] 
ShapeNet 
86.30 

Ours (w/ local L ssmooth ) BT 
97.03 
Ours (w/o Eq. 12) 
BT 
97.15 
Ours (full method) 
BT 
97.90 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. We thank Jingguang Zhou for his help with data collection. We also thank the anonymous reviewers for their valuable comments. This work was funded by the National Science Foundation through grant IIS-1149393, and by a grant from Schmidt Sciences.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pytorch</surname></persName>
		</author>
		<ptr target="http://pytorch.org" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast bilateral-space stereo for synthetic defocus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4466" to="4474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Intrinsic scene properties from a single RGB-D image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Shape, illumination, and reflectance from shading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1670" to="1687" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Intrinsic images in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">159</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">User-assisted image compositing for photographic lighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Boyadzhiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graphics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A naturalistic open source movie for optical flow evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. on Computer Vision (ECCV)</title>
		<meeting>European Conf. on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A naturalistic open source movie for optical flow evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. on Computer Vision (ECCV)</title>
		<meeting>European Conf. on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="611" to="625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03012</idno>
		<title level="m">An information-rich 3d model repository</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A simple model for intrinsic image decomposition with depth cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="241" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Intrinsic images by clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Garces</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lopez-Moreno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gutierrez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer graphics forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1415" to="1424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ground truth dataset and baseline evaluations for intrinsic image algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Computer Vision (ICCV)</title>
		<meeting>Int. Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2335" to="2342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Photometric ambient occlusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hauagge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wehrwein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2515" to="2522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Computer Vision (ICCV)</title>
		<meeting>Int. Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Machine Learning</title>
		<meeting>Int. Conf. on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5967" to="5976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Consistent temporal variations in many outdoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Roman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Tenenbaum. Self-supervised intrinsic image decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Janner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Yildirim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Intrinsic image decomposition using structure-texture separation and surface normals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. on Computer Vision (ECCV)</title>
		<meeting>European Conf. on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unified depth prediction and intrinsic image decomposition from a single image via joint convolutional neural fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. on Computer Vision (ECCV)</title>
		<meeting>European Conf. on Computer Vision (ECCV)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="143" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A symmetry preserving algorithm for matrix scaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Uçar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="931" to="955" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Shading annotations in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kovacs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="850" to="859" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Intrinsic decomposition of image sequences from local temporal variations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Laffont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Bazin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Computer Vision (ICCV)</title>
		<meeting>Int. Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="433" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Drettakis. Coherent intrinsic images from photo collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Laffont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bousseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Trans. Graphics (SIGGRAPH)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Lightness and retinex theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Land</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Mccann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Josa</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Estimating intrinsic images from image sequences with biased illumination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. on Computer Vision (ECCV)</title>
		<meeting>European Conf. on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="274" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Direct intrinsics: Learning albedo-shading decomposition by convolutional regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Narihira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Computer Vision (ICCV)</title>
		<meeting>Int. Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2992" to="2992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning lightness from human judgement on relative reflectance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Narihira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2965" to="2973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Recovering intrinsic images with a global sparsity prior on reflectance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kiefel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">V</forename><surname>Gehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="765" to="773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Intrinsic image decomposition with non-local texture cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Intrinsic images decomposition using a local and global sparse representation of reflectance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yeo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="697" to="704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning non-lambertian object intrinsics across shapenet categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Data-driven hallucination of different times of day from a single outdoor photo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">200</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Factored time-lapse video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sunkavalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Matusik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rusinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page">101</biblScope>
			<date type="published" when="2007" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deriving intrinsic images from image sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Computer Vision (ICCV)</title>
		<meeting>Int. Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="68" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A closed-form solution to retinex with nonlocal texture constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1437" to="1444" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning data-driven reflectance priors for intrinsic image decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Computer Vision (ICCV)</title>
		<meeting>Int. Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3469" to="3477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning ordinal relationships for mid-level vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Computer Vision (ICCV)</title>
		<meeting>Int. Conf. on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="388" to="396" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
