<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T23:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Associative Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Haeusser</surname></persName>
							<email>haeusser@in.tum.de</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Informatics</orgName>
								<orgName type="institution">TU Munich</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Google, Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Frerix</surname></persName>
							<email>thomas.frerix@tum.de</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Informatics</orgName>
								<orgName type="institution">TU Munich</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Mordvintsev</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Google, Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Informatics</orgName>
								<orgName type="institution">TU Munich</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cremers@tum</forename><surname>De</surname></persName>
						</author>
						<title level="a" type="main">Associative Domain Adaptation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We propose associative domain adaptation, a novel technique for end-to-end   </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Since the publication of LeNet <ref type="bibr" target="#b13">[14]</ref> and AlexNet <ref type="bibr" target="#b12">[13]</ref>, a methodological shift has been observable in the field of computer vision. Deep convolutional neural networks have proved to solve a growing number of problems <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b16">17]</ref>. On the downside, due to a large amount of model parameters, an equally rapidly growing amount of labeled data is needed for training, such as ImageNet <ref type="bibr" target="#b20">[21]</ref>, comprising millions of labeled training examples. This data may be costly to obtain or even nonexistent.</p><p>In this paper, we focus on an approach to train neural networks with a minimum of labeled data: domain adaptation. We refer to domain adaptation as the task to train a model on labeled data from a source domain while minimizing test error on a target domain, for which no labels are available at training time. In order to maximize classification accuracy on an unlabeled target domain, the discrepancy between neural network embeddings of source and target samples (red and blue, respectively) is reduced by an associative loss (→), while minimizing a classification error on the labeled source domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Domain adaptation</head><p>In more formal terms, we consider a source domain D s = {x ∈ C the respective labels, where the target labels {y t i } i=1,...,nt are not available for training. Note that for domain adaption it is assumed that source and target domains are associated with the same label space, while D s and D t are drawn from distributions P s and P t , which are assumed to be different, i.e. the source and target distribution have different joint distributions of data X and labels Y , P s (X, Y ) = P t (X, Y ).</p><p>The value of domain adaptation has even more increased with generative tools producing synthetic datasets. The idea is compelling: rather than labeling vast amounts of realworld data, one renders a similar but synthetic dataset that is automatically labeled. With an effective method for domain adaptation it becomes possible to train models without the need for one single labeled target example at training time.</p><p>In order to combine labeled and unlabeled data for a predictive task, a variety of notions has emerged. To be clear, we explicitly distinguish domain adaptation from related approaches. For semi-supervised learning, labeled source data is leveraged by unlabeled target data drawn from the same distribution, i.e. P s = P t . In transfer learning, not only source and target domain are drawn from different distributions, also their label spaces are generally different. An example of supervised transfer learning is training a neural network on a source domain and subsequently fine-tuning the model on a labeled target domain for a different task <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b4">5]</ref>.</p><p>The problem of domain adaptation was theoretically studied in <ref type="bibr" target="#b1">[2]</ref>, relating source and target error with a statistical similarity measure of the respective domains. Their results suggest that a good domain adaptation method should be based on features that are as similar as possible for source and target domain (assimilation), while reducing the prediction error in the source domain as much as possible (discrimination). These effects are opposing each other since source and target domains are drawn from different distributions. This can be formulated as a cost function that consists of two terms:</p><formula xml:id="formula_0">L = L classification + L sim ,<label>(1)</label></formula><p>Here, the classification loss, L classification encourages discrimination between different classes, maximizing the margin between clusters of embeddings that belong to the same class. We define the second term as a generic similarity loss L sim , which enforces statistically similar latent representations.</p><p>Intuitively, for similar latent representations of the source and target domain, the target class labels can be more accurately inferred from the labeled source samples.</p><p>In the following, we show how previous methods approached this optimization and then propose a new loss for L sim .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Related work</head><p>Several works have approached the problem of domain adaptation. Here, we mainly focus on methods that are based on deep learning, as these have proved to be powerful learning systems and are closest to our scheme.</p><p>The CORAL method <ref type="bibr" target="#b23">[24]</ref> explicitly forces the covariance of the target data onto the source data (assimilation). The authors then apply supervised training to this transformed source domain with original labels (discrimination). This idea is extended to second order statistics of features in deep neural networks in <ref type="bibr" target="#b24">[25]</ref>.</p><p>Building on the idea of adversarial training <ref type="bibr" target="#b9">[10]</ref>, the authors of <ref type="bibr" target="#b8">[9]</ref> propose an architecture in which a class label and a domain label predictor are built on top of a general feature extractor. While the class label predictor is supposed to correctly classify the labeled training examples (discrimination), the domain label predictor for all training samples is used in a way to make the feature distributions similar (assimilation). The authors of <ref type="bibr" target="#b2">[3]</ref> use an adversarial approach to train for similarity in data space instead of feature space. Their training scheme is closer to standard generative adversarial networks <ref type="bibr" target="#b9">[10]</ref>, however, it does not only condition on noise, but also on an image from the source domain.</p><p>Within the paradigm of training for domain invariant features, one popular metric is the maximum mean discrepancy (MMD) <ref type="bibr" target="#b10">[11]</ref>. This measure is the distance between the mean embeddings of two probability distributions in a reproducing kernel Hilbert space H k with a characteristic kernel k. More precisely, the mean embedding of a distribution P in H k is the unique element</p><formula xml:id="formula_1">µ k (P) ∈ H k such that E x∼P [f (x)] = f (x), µ k (P) H k , ∀f ∈ H k .</formula><p>The MMD distance between source and target domain then</p><formula xml:id="formula_2">reads d MMD (P s , P t ) = ||µ k (P s ) − µ k (P t )|| H k .</formula><p>In practice, this distance is computed via the kernel trick <ref type="bibr" target="#b30">[31]</ref>, which leads to an algorithm with quadratic runtime in the number of samples. Linear time estimators have previously been proposed <ref type="bibr" target="#b14">[15]</ref>.</p><p>Most works, which explicitly minimize latent feature discrepancy, use MMD in some variant. That is, they use MMD as L sim in order to achieve assimilation as defined above. The authors of <ref type="bibr" target="#b14">[15]</ref> propose the Deep Adaptation Network architecture. Exploiting that learned features transition from general to specific within the network, they train the first layers of a CNN commonly for source and target domain, then train individual task-specific layers while minimizing the multiple kernel maximum mean discrepancies between these layers.</p><p>The technique of task-specific but coupled layers is further explored in <ref type="bibr" target="#b19">[20]</ref> and <ref type="bibr" target="#b3">[4]</ref>. The authors of <ref type="bibr" target="#b19">[20]</ref> propose to individually train source and target domains while the network parameters of each layer are regularized to be linear transformations of each other. In order to train for domain invariant features, they minimize the MMD of the embedding layer. On the other hand, the authors of <ref type="bibr" target="#b3">[4]</ref> maintain a shared representation of both domains and private representations of each individual domain in their Domain Separation architecture.</p><p>As becomes evident in these works, the MMD minimizes domain discrepancy in some abstract space and requires a choice of kernels with appropriate hyperparameters, such as the standard deviation of the Gaussian kernel. In this work, we propose a different loss for L sim which is more intuitive in embedding space, less computationally complex and better suitable to obtain effective embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Contribution</head><p>We propose the association loss L assoc as an alternative discrepancy measure (L sim ) within the domain adaptation paradigm described in Section 1.1. The reasoning behind our approach is the following: Ultimately, we want to minimize the classification error on the target domain D t . This is not directly possible since no labels are available at training time. Therefore, we minimize the classification error on the source domain D s as a proxy while enforcing representations of D t to have similar statistics to those of D s . This is accomplished by enforcing associations <ref type="bibr" target="#b11">[12]</ref> between feature representations of D t with those of D s that are in the same class. Therefore, in contrast to MMD as L sim , this approach also leverages knowledge about labels of the source domain and hence avoids unwanted assimilation across class clusters. The implementation is simple yet powerful as we show in Section 2. It works with any existing architecture and, unlike most deep learning approaches for domain adaptation, does not introduce a structural and almost no computational overhead. In fact, we used the same generic and simple architecture for all our experiments, each of which achieved state-of-the-art results.</p><p>In summary, our contributions are:</p><p>• A straightforward training schedule for domain adaptation with neural networks.</p><p>• An integration of our approach into the prevailing domain adaptation formalism and a detailed comparison with the most commonly used explicit L sim : the maximum mean discrepancy (MMD).</p><p>• A simple implementation that works with arbitrary architectures 1 .</p><p>• Extensive experiments on various benchmarks for domain adaptation that outperform related deep learning methods.</p><p>• A detailed analysis demonstrating that associative domain adaptation results in effective embeddings in terms of classifying target domain samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Associative domain adaptation</head><p>We start from the approach of learning by association <ref type="bibr" target="#b11">[12]</ref> which is geared towards semi-supervised training. Labeled and unlabeled data are related by associating their embeddings, i.e. features of a neural network's last layer before the softmax layer. Our work generalizes this approach for domain adaptation. For the new task, we identify labeled data with the source domain and unlabeled data with the target domain. Specifically, for</p><formula xml:id="formula_3">x s i ∈ D s , x t i ∈ D t and the embedding map φ : R N0 → R N L−1 of an L-layer neural 1 https://git.io/vyzrl network, denote by A i . . = φ(x s i ), B j . . = φ(x t j</formula><p>) the respective embeddings of source and target domain. Then, similarity is measured by the embedding vectors' dot product as</p><formula xml:id="formula_4">M ij = A i , B j .</formula><p>If one considers transitions between the parts ({A i }, {B j }) of a bipartite graph, the intuition is that transitions are more probable if embeddings are more similar. This is formalized by the transition probability from embedding A i to embedding B j :</p><formula xml:id="formula_5">P ab ij = P(B j |A i ) . . = exp(M ij ) j ′ exp(M ij ′ ) .<label>(2)</label></formula><p>The basis of associative similarity is the two-step roundtrip probability of an imaginary random walker starting from an embedding A i of the labeled source domain and returning to another embedding A j via the (unlabeled) target domain embeddings B, P aba ij</p><formula xml:id="formula_6">. . = P ab P ba ij .<label>(3)</label></formula><p>The authors of <ref type="bibr" target="#b11">[12]</ref> observed that higher order round trips do not improve performance. The two-step probabilities are forced to be similar to the uniform distribution over the class labels via a cross-entropy loss term called the walker loss,</p><formula xml:id="formula_7">L walker . . = H T, P aba ,<label>(4)</label></formula><p>where</p><formula xml:id="formula_8">T ij . . = 1/|A i | class(A i ) = class(A j ) 0 else<label>(5)</label></formula><p>This means that all association cycles within the same class are forced to have equal probability. The walker loss by itself could be minimized by only visiting target samples that are easily associated, skipping difficult examples. This would lead to poor generalization to the target domain. Therefore, a regularizer is necessary such that each target sample is visited with equal probability. This is the function of the visit loss. It is defined by the cross entropy between the uniform distribution over target samples and the probability of visiting some target sample starting in any source sample,</p><formula xml:id="formula_9">L visit . . = H(V, P visit ) ,<label>(6)</label></formula><p>where P visit j</p><formula xml:id="formula_10">. . = xi∈Ds P ab ij , V j . . = 1 |B| .<label>(7)</label></formula><p>Note that this formulation assumes that the class distribution is the same for source and target domain. If this is not the case, using a low weight for L visit may yield better results.</p><p>Together, these terms form a loss that enforces associations between similar embeddings of both domains,</p><formula xml:id="formula_11">L assoc = β 1 L walker + β 2 L visit ,<label>(8)</label></formula><p>where β i is a weight factor. At the same time, the network is trained to minimize the prediction error on the labeled source data via a softmax cross-entropy loss term, L classification . The overall neural network loss for our training scheme is given by</p><formula xml:id="formula_12">L = L classification + αL assoc .<label>(9)</label></formula><p>We want to emphasize once more the essential motivation for our approach: The association loss enforces similar embeddings (assimilation) for the source and target samples, while the classification loss minimizes the prediction error of the source data (discrimination). Without L assoc , we have the case of a neural network that is trained conventionally <ref type="bibr" target="#b12">[13]</ref> on the source domain only. As we show in this work, the (scheduled) addition of L assoc during training allows to incorporate unlabeled data from a different domain improving the effectiveness of embeddings for classification. Adding L assoc enables an arbitrary neural network to be trained for domain adaptation. The neural network learning algorithm is then able to model the shift in distribution between source and target domain. More formally, if L assoc is minimized, associated embeddings from both source and target domain become more similar in terms of their dot product.</p><p>In contrast to MMD, L assoc incorporates knowledge about source domain classes and hence prevents the case that source and target domain embeddings are statistically similar, but not class discriminative. We demonstrate this experimentally in Section 3.4.</p><p>We emphasize that not every semi-supervised training method can be adapted for domain adaptation in this manner. It is necessary that the method explicitly models the shift between the source and target distributions, in order to reduce the discrepancy between both domains, which is accomplished by L assoc .</p><p>In this respect, associative domain adaptation parallels the approaches mentioned in Section 1.2. As we demonstrate experimentally in the next section, L assoc is employed as a compact, intuitive and effective training signal for assimilation yielding superior performance on all tested benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Domain adaptation benchmarks</head><p>In order to evaluate and compare our method, we chose common domain adaptation tasks, for which previous results are reported. Examples for the respective datasets are shown in <ref type="table">Table 1</ref>.  <ref type="table">Table 1</ref>: Dataset samples for our domain adaptation tasks. For three randomly chosen classes, the first row depicts a source sample, the second row a target sample. The datasets vary in difficulty due to differences in color space, variance of transformation or number of classes.</p><p>MNIST → MNIST-M We used the MNIST <ref type="bibr" target="#b13">[14]</ref> dataset as labeled source and generated the unlabeled MNIST-M target as described in <ref type="bibr" target="#b8">[9]</ref>. Background patches from the color photo BSDS500 dataset <ref type="bibr" target="#b0">[1]</ref> were randomly extracted. Then the absolute value of the difference of each color channel with the MNIST image was taken. This yields a color image, which can be easily identified by a human, but is significantly more difficult for a machine compared to MNIST due to two additional color channels and more nuanced noise. The single channel of the MNIST images was replicated three times to match those of the MNIST-M images (RGB). The image size is 28 × 28 pixels. This is the only setting where we used data augmentation: We randomly inverted MNIST images since they are always white on black, unlike MNIST-M.</p><p>Synth → SVHN The Street View House Numbers (SVHN) dataset <ref type="bibr" target="#b18">[19]</ref> contains house number signs extracted from Google Street View. We used the variant Format 2 where images (32 × 32 pixels) are already cropped. Still, multiple digits can appear in one image. As a labeled source domain we use the Synthetic Digits dataset provided by the authors of <ref type="bibr" target="#b8">[9]</ref>, which expresses a varying number of fonts and properties (background, orientation, position, stroke color, blur) that aim to mimic the distribution in SVHN.</p><p>SVHN → MNIST MNIST images were resized with bilinear interpolation to 32 × 32 pixels and extended to three channels in order to match the shape of SVHN.</p><p>Synthetic Signs → GTSRB The Synthetic Signs dataset was provided by the authors of <ref type="bibr" target="#b17">[18]</ref> and consists of 100,000 images that were generated by taking common street signs from Wikipedia and applying various artificial transformations. The German Traffic Signs Recognition Benchmark (GTSRB) <ref type="bibr" target="#b22">[23]</ref> provides 39,209 (training set) and 12,630 (test set) cropped images of German traffic signs. The images vary in size and were resized with bilinear interpolation to match the Synthetic Signs images' size of 40 × 40 pixels. Both datasets contain images from 43 different classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Training setup 3.2.1 Associative domain adaptation</head><p>Our formulation of associative domain adaptation is implemented 2 as a custom loss function that can be added to any existing neural network architecture. Results obtained by neural network learning algorithms often highly depend 2 https://git.io/vyzrl on the complexity of a specifically tuned architecture. Since we wanted to make the effect of our approach as transparent as possible, we chose the following generic convolutional neural network architecture for all our experiments:</p><formula xml:id="formula_13">C(32, 3) → C(32, 3) → P (2) → C(64, 3) → C(64, 3) → P (2) → C(128, 3) → C(128, 3) → P (2) → F C(128)</formula><p>Here, C(n, k) stands for a convolutional layer with n kernels of size k × k and stride 1. P (k) denotes a max-pooling layer with window size k × k and stride 1. F C(n) is a fully connected layer with n output units. The size of the embeddings is 128. An additional fully connected layer maps these embeddings to logits, which are the input to a softmax cross-entropy loss for classification, L classification .</p><p>The detailed hyperparameters for each experiment can be found in the supplementary material. The most important hyperparameters are the following:</p><p>Learning rate We chose the same initial learning rate (τ = 1e −4 ) for all experiments, which was reduced by a factor of 0.33 in the last third of the training time. All trainings converged in less than 20k iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mini-batch sizes</head><p>It is important to ensure that a minibatch represents all classes sufficiently, in order not to introduce a bias. For the labeled mini-batch, we explicitly Method Domains (source → target) MNIST → MNIST-M Syn. Digits → SVHN SVHN → MNIST Syn. Signs → GTSRB Transf. Repr. <ref type="bibr" target="#b21">[22]</ref> 13  <ref type="table">Table 2</ref>: Domain adaptation. Errors (%) on the target test sets (lower is better). Source only and target only refer to training only on the respective dataset (supervisedly <ref type="bibr" target="#b11">[12]</ref>, without domain adaptation) and evaluating on the target dataset. In the DA MMD setting, we replaced L assoc with MMD. The metric coverage is reported in parentheses, where available (cf. Section 3.3). We used the same network architecture for all our experiments and achieve state of the art results on all benchmarks. The row "DA assoc fixed params † " reports results from 10 runs (± standard deviation) with an arbitrary choice of fixed hyper parameters (β 2 = 0.5, delay = 500 steps and batch size = 100) for all four domain pairs. The row below shows our results after individual hyper parameter optimization. No labels of the target domain were used at training time.</p><p>sample a number of examples per class. For the unlabeled mini-batch we chose the same overall size as for the labeled one, usually around 10-100 times the number of classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss weights</head><p>The only loss weight that we actively chose is the one for L visit , β 2 . As was shown in <ref type="bibr" target="#b11">[12]</ref>, this loss acts as a regularizer. Since it assumes the same class distribution on both domains, the weight needs to be lowered if the assumption does not hold. We experimentally chose a suitable weight.</p><p>Delay of L assoc We observed that convergence is faster if we first train the network only with the classification loss, L classification , and then add the association loss, L assoc , after a number of iterations. This is implemented by defining α <ref type="figure">(Equation 8</ref>) as a step function. This procedure is intuitive, as the transfer of label information from source to target domain is most effective when the network has already learned some class structure and the embeddings are not random anymore.</p><p>Hyper parameter tuning We are aware that hyper parameter tuning can sometimes obscure the actual effect of a proposed method. In particular, we want to discuss the effect of small batch sizes on our algorithm. For the association loss to work properly, all classes must be represented in a mini-batch, which places a restriction on small batch sizes, when the number of classes is large. To further investigate this hyperparameter we ran the same architecture with an arbitrary choice of fixed hyper parameters and smaller batch size (β 2 = 0.5, delay = 500 steps and batch size = 100) for all four domain pairs and report the mean and standard deviation of 10 runs in the row "DA assoc fixed params † ". In all cases except for the traffic signs, these runs outperform previous methods. The traffic sign setup is special because there are 4.3× more classes and with larger batches more classes are expected to be present in the unlabeled batch. When we removed the batch size constraint, we achieved a test error of 6.55 ± 0.59, which outperforms state of the art for the traffic signs.</p><p>Hardware All experiments were carried out on an NVIDIA Titan X (Pascal). Each experiment took less than 120 minutes until convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Domain adaptation with MMD</head><p>In order to compare our setup and the proposed L assoc , we additionally ran all experiments described above with MMD instead of L assoc . We performed the same hyperparameter search for α and report the respectively best test errors. We used the open source implementation including hyperparameters from <ref type="bibr" target="#b25">[26]</ref>. This setup is referred to as DA MMD .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Evaluation</head><p>All reported test errors are evaluated on the target domain. To assess the quality of domain adaptation, we provide results trained on source and target only (SO and TO, respectively) as in <ref type="bibr" target="#b11">[12]</ref>, for associative domain adaptation (DA assoc ) and for the same architecture with MMD instead of L assoc . Besides the absolute accuracy, an informative metric is coverage of the gap between TO and SO by DA,</p><formula xml:id="formula_14">DA − SO T O − SO ,</formula><p>as it is a measure of how much label information is successfully transferred from the source to the target domain. In order to assess a method's performance on domain adaptation, one should always consider both coverage and absolute error on the target test set since a high coverage could also stem from poor performance in the SO or TO setting.</p><p>Where available, we report the coverage of other methods (with respect to their own performance on SO and TO). <ref type="table">Table 2</ref> shows the results of our experiments. In all four popular domain adaptation settings our method performs best. On average, our approach improves the performance by 87.17 % compared to training on source only (coverage). In order to make our results as comparable as possible, we used a generic architecture that was not handcrafted for the respective tasks (cf. Section 3.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Analysis of the embedding quality</head><p>As described in Section 1, a good intuition for the formalism of domain adaptation is the following. On the one hand, the latent features should cluster in embedding space, if they belong to the same class (assimilation). On the other hand, these clusters should separate well in order to facilitate classification (discrimination).</p><p>We claim that our proposed L assoc is well suited for this task compared with maximum mean discrepancy. We use four points to support this claim:</p><p>• t-SNE visualizations show that employing L assoc produces embeddings that cluster better compared to MMD.</p><p>• L assoc simultaneously reduces the maximum mean discrepancy (MMD) in most cases.</p><p>• Lower MMD values do not imply lower target test errors in these settings.</p><p>• In all cases, the target domain test error of our approach is lower compared to training with an MMD loss.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Qualitative evaluation: t-SNE embeddings</head><p>A popular method to visualize high-dimensional data in 2D is t-SNE <ref type="bibr" target="#b15">[16]</ref>. We are interested in the distribution of embeddings for source and target domain when we employ our training scheme. <ref type="figure">Figure 2</ref> shows such visualizations. We always plotted embeddings of the target domain test set.</p><p>The embeddings are obtained with networks trained semisupervisedly <ref type="bibr" target="#b11">[12]</ref> on the source domain only (SO), with our proposed associative domain adaptation (DA assoc ) and with MMD instead of L assoc (DA MMD , cf. Section 3.2).</p><p>In the SO setting, samples from the source domain fall into clusters as expected. Samples from the target domain are more scattered. For DA assoc , samples from both domains cluster well and become separable. For DA MMD , the resulting distributions are similar, but not visibly class discriminative.</p><p>For completeness, however, we explicitly mention that t-SNE embeddings are obtained via a non-linear, stochastic optimization procedure that depends on the choice of parameters like the perplexity ( <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b31">32]</ref>). We therefore interpret these plots only qualitatively and infer that associative domain adaptation learns consistent embeddings for source and target domain that cluster well with observable margins.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Quantitative evaluation: MMD values</head><p>While t-SNE plots provide qualitative insights into the latent feature representation of a learning algorithm, we want to complement this with a quantitative evaluation and compute the discrepancy in embedding space for target and source domains. We estimated the MMD with a Gaussian RBF kernel using the TensorFlow implementation provided by the authors of <ref type="bibr" target="#b25">[26]</ref>. The results are shown in <ref type="table" target="#tab_2">Table 3</ref>. In parentheses we copied the test accuracies on the respective target domains from <ref type="table">Table 2</ref>.</p><p>We observe that DA MMD yields the lowest maximum mean discrepancy, as expected, since this training setup explicitly minimizes this quantity. At the same time, DA assoc also reduces this metric in most cases. Interestingly though, for the setup SVHN → MNIST, we actually obtain a particularly high MMD. Nevertheless, the test error of the network trained with DA assoc is one of the best results. We ascribe this to the fact that MMD enforces domain invariant feature representations regardless of the source labels, whereas L assoc takes into account the labels of associated source samples, resulting in better separation of the clusters and higher similarity within the same class. Consequently, DA assoc achieves lower test error on the target domain, which is the actual goal of domain adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>We have introduced a novel, intuitive domain adaptation scheme for neural networks termed associative domain adaptation that generalizes a recent approach for semisupervised learning <ref type="bibr" target="#b11">[12]</ref> to the domain adaptation setting. The key idea is to optimize a joint loss function combining the classification loss on the source domain with an association loss that imposes consistency of source and target embeddings. The implementation is simple, works with arbitrary architectures in an end-to-end manner and introduces no significant additional computational and structural complexity. We have demonstrated the capabilities of associative domain adaptation on various benchmarks and achieved state-of-the-art results for all our experiments. Finally, we quantitatively and qualitatively examined how well our approach reduces the discrepancy between network embeddings from the source and target domain. We have observed that, compared to explicitly modelling the maximum mean discrepancy as a cost function, the proposed association loss results in embeddings that are more effective for classification in the target domain, the actual goal of domain adaptation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Associative domain adaptation. In order to maximize classification accuracy on an unlabeled target domain, the discrepancy between neural network embeddings of source and target samples (red and blue, respectively) is reduced by an associative loss (→), while minimizing a classification error on the labeled source domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>Left: After training on source only. Middle: after training with associative domain adaptation (DA assoc ). Right: after training with MMD loss (DA MMD ). While the target samples are diffuse when embedded with the source only trained network, the class label information is successfully inferred after associative domain adaptation. When the network is trained with an MMD loss, the resulting distributions are similar, but less visibly class discriminative. Domains (source → target) MNIST → MNIST-M Syn. Digits → SVHN SVHN → MNIST Syn. Signs → GTSRB</figDesc><table>Figure 2: t-SNE embeddings with perplexity 35 of 1,000 test samples for Synthetic Digits (source, red) and SVHN (target, 
blue). Source only 
0.1234 (35.96) 
0.1010 (15.68) 
0.0739 (30.71) 
0.0466 (4.59) 
DA assoc 
0.0504 (10.53) 
0.0415 (8.14) 
0.2112 (2.40) 
0.0459 (2.34) 
DA MMD 
0.0233 (22.90) 
0.0166 (19.29) 
0.0404 (34.06) 
0.0145 (12.85) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Maximum mean discrepancy (MMD) between embeddings of source and target domain, obtained with a network trained supervisedly on source only (SO), for the domain adaptation setting with L assoc (DA assoc ) and with an MMD loss (DA MMD ). Numbers in parentheses are test errors on the target domain from Table 2. Associative domain adaptation also reduces the MMD in some cases. Lower MMD values do not correlate with lower test errors. In fact, even though the MMD for training with the associative loss is higher compared with training with the MMD loss, our approach achieves lower test errors.</figDesc><table></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Contour detection and hierarchical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="898" to="916" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="151" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Unsupervised pixel-level domain adaptation with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.05424</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Domain separation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="343" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference in Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Flownet: Learning optical flow with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ilg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hausser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hazirbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Van Der Smagt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2758" to="2766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Depth map prediction from a single image using a multi-scale deep network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Puhrsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2366" to="2374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised visual domain adaptation using subspace alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sebban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2960" to="2967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Domainadversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A kernel two-sample test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="723" to="773" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning by association -a versatile semi-supervised training method for neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haeusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mordvintsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference of Neural Information Processing Systems</title>
		<meeting>the 25th International Conference of Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ilg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hausser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4040" to="4048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evaluation of traffic sign recognition methods trained on synthetically generated data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moiseev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Konev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chigorin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Konushin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Advanced Concepts for Intelligent Vision Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="576" to="583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS workshop on deep learning and unsupervised feature learning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2011</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Beyond sharing weights for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozantsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06432</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning transferrable representations for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">O</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2110" to="2118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The German Traffic Sign Recognition Benchmark: A multi-class classification competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stallkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schlipsing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salmen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Joint Conference on Neural Networks</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1453" to="1460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Return of frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2016 Workshops</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Generative models and model criticism via optimized maximum mean discrepancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Strathmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramdas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.04488</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep neural networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2553" to="2561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deeppose: Human pose estimation via deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1653" to="1660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<title level="m">Adversarial discriminative domain adaptation. Nips</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The Nature of Statistical Learning Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Springer-Verlag New York, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">How to use t-sne effectively. Distill</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vigas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Johnson</surname></persName>
		</author>
		<ptr target="http://distill.pub/2016/misread-tsne.7" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">How transferable are features in deep neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
