<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A-NICE-MC: Adversarial Training for MCMC</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Song</surname></persName>
							<email>tsong@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengjia</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
							<email>ermon@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Stanford University</orgName>
								<orgName type="institution" key="instit2">Stanford University</orgName>
								<orgName type="institution" key="instit3">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A-NICE-MC: Adversarial Training for MCMC</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Existing Markov Chain Monte Carlo (MCMC) methods are either based on generalpurpose and domain-agnostic schemes, which can lead to slow convergence, or problem-specific proposals hand-crafted by an expert. In this paper, we propose A-NICE-MC, a novel method to automatically design efficient Markov chain kernels tailored for a specific domain. First, we propose an efficient likelihood-free adversarial training method to train a Markov chain and mimic a given data distribution. Then, we leverage flexible volume preserving flows to obtain parametric kernels for MCMC. Using a bootstrap approach, we show how to train efficient Markov chains to sample from a prescribed posterior distribution by iteratively improving the quality of both the model and the samples. Empirical results demonstrate that A-NICE-MC combines the strong guarantees of MCMC with the expressiveness of deep neural networks, and is able to significantly outperform competing methods such as Hamiltonian Monte Carlo.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Variational inference (VI) and Monte Carlo (MC) methods are two key approaches to deal with complex probability distributions in machine learning. The former approximates an intractable distribution by solving a variational optimization problem to minimize a divergence measure with respect to some tractable family. The latter approximates a complex distribution using a small number of typical states, obtained by sampling ancestrally from a proposal distribution or iteratively using a suitable Markov chain (Markov Chain Monte Carlo, or MCMC).</p><p>Recent progress in deep learning has vastly advanced the field of variational inference. Notable examples include black-box variational inference and variational autoencoders <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref>, which enabled variational methods to benefit from the expressive power of deep neural networks, and adversarial training <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, which allowed the training of new families of implicit generative models with efficient ancestral sampling. MCMC methods, on the other hand, have not benefited as much from these recent advancements. Unlike variational approaches, MCMC methods are iterative in nature and do not naturally lend themselves to the use of expressive function approximators <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. Even evaluating an existing MCMC technique is often challenging, and natural performance metrics are intractable to compute <ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref>. Defining an objective to improve the performance of MCMC that can be easily optimized in practice over a large parameter space is itself a difficult problem <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>To address these limitations, we introduce A-NICE-MC, a new method for training flexible MCMC kernels, e.g., parameterized using (deep) neural networks. Given a kernel, we view the resulting Markov Chain as an implicit generative model, i.e., one where sampling is efficient but evaluating the (marginal) likelihood is intractable. We then propose adversarial training as an effective, likelihoodfree method for training a Markov chain to match a target distribution. First, we show it can be used in a learning setting to directly approximate an (empirical) data distribution. We then use the approach to train a Markov Chain to sample efficiently from a model prescribed by an analytic expression (e.g., a Bayesian posterior distribution), the classic use case for MCMC techniques. We leverage flexible volume preserving flow models <ref type="bibr" target="#b13">[14]</ref> and a "bootstrap" technique to automatically design powerful domain-specific proposals that combine the guarantees of MCMC and the expressiveness of neural networks. Finally, we propose a method that decreases autocorrelation and increases the effective sample size of the chain as training proceeds. We demonstrate that these trained operators are able to significantly outperform traditional ones, such as Hamiltonian Monte Carlo, in various domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Notations and Problem Setup</head><p>A sequence of continuous random variables {x t } 1 t=0 , x t 2 R n , is drawn through the following Markov chain:</p><formula xml:id="formula_0">x 0 ⇠ ⇡ 0 x t+1 ⇠ T ✓ (x t+1 |x t )</formula><p>where T ✓ (·|x) is a time-homogeneous stochastic transition kernel parametrized by ✓ 2 ⇥ and ⇡ 0 is some initial distribution for x 0 . In particular, we assume that T ✓ is defined through an implicit generative model f ✓ (·|x, v), where v ⇠ p(v) is an auxiliary random variable, and f ✓ is a deterministic transformation (e.g., a neural network). Let ⇡ t ✓ denote the distribution for x t . If the Markov chain is both irreducible and positive recurrent, then it has an unique stationary distribution ⇡ ✓ = lim t!1 ⇡ t ✓ . We assume that this is the case for all the parameters ✓ 2 ⇥.</p><formula xml:id="formula_1">Let p d (x) be a target distribution over x 2 R</formula><p>n , e.g, a data distribution or an (intractable) posterior distribution in a Bayesian inference setting. Our objective is to find a T ✓ such that:</p><p>1. Low bias: The stationary distribution is close to the target distribution (minimize |⇡ ✓ p d |).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Efficiency:</head><formula xml:id="formula_2">{⇡ t ✓ } 1 t=0 converges quickly (minimize t such that |⇡ t ✓ p d | &lt; ).</formula><p>3. Low variance: Samples from one chain {x t } 1 t=0 should be as uncorrelated as possible (minimize autocorrelation of {x t } 1 t=0 ).</p><p>We think of ⇡ ✓ as a stochastic generative model, which can be used to efficiently produce samples with certain characteristics (specified by p d ), allowing for efficient Monte Carlo estimates. We consider two settings for specifying the target distribution. The first is a learning setting where we do not have an analytic expression for p d (x) but we have access to typical samples {s i } m i=1 ⇠ p d ; in the second case we have an analytic expression for p d (x), possibly up to a normalization constant, but no access to samples. The two cases are discussed in Sections 3 and 4 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Adversarial Training for Markov Chains</head><p>Consider the setting where we have direct access to samples from p d (x). Assume that the transition kernel T ✓ (x t+1 |x t ) is the following implicit generative model:</p><formula xml:id="formula_3">v ⇠ p(v) x t+1 = f ✓ (x t , v)<label>(1)</label></formula><p>Assuming a stationary distribution ⇡ ✓ (x) exists, the value of ⇡ ✓ (x) is typically intractable to compute. The marginal distribution ⇡ t ✓ (x) at time t is also intractable, since it involves integration over all the possible paths (of length t) to x. However, we can directly obtain samples from ⇡ t ✓ , which will be close to ⇡ ✓ if t is large enough (assuming ergodicity). This aligns well with the idea of generative adversarial networks (GANs), a likelihood free method which only requires samples from the model. Generative Adversarial Network (GAN) <ref type="bibr" target="#b3">[4]</ref> is a framework for training deep generative models using a two player minimax game. A generator network G generates samples by transforming a noise variable z ⇠ p(z) into G(z). A discriminator network D(x) is trained to distinguish between "fake" samples from the generator and "real" samples from a given data distribution p d . Formally, this defines the following objective (Wasserstein GAN, from <ref type="bibr" target="#b14">[15]</ref>)</p><formula xml:id="formula_4">min G max D V (D, G) = min G max D E x⇠p d [D(x)] E z⇠p(z) [D(G(z))]<label>(2)</label></formula><p>In our setting, we could assume p d (x) is the empirical distribution from the samples, and choose z ⇠ ⇡ 0 and let G ✓ (z) be the state of the Markov Chain after t steps, which is a good approximation of ⇡ ✓ if t is large enough. However, optimization is difficult because we do not know a reasonable t in advance, and the gradient updates are expensive due to backpropagation through the entire chain.   Therefore, we propose a more efficient approximation, called Markov GAN (MGAN):</p><formula xml:id="formula_5">min ✓ max D E x⇠p d [D(x)] Ex ⇠⇡ b ✓ [D(x)] (1 )E x d ⇠p d ,x⇠T m ✓ (x|x d ) [D(x)]<label>(3)</label></formula><p>where 2 (0, 1), b 2 N + , m 2 N + are hyperparameters,x denotes "fake" samples from the generator and T m ✓ (x|x d ) denotes the distribution of x when the transition kernel is applied m times, starting from some "real" sample x d .</p><p>We use two types of samples from the generator for training, optimizing ✓ such that the samples will fool the discriminator:</p><formula xml:id="formula_6">1. Samples obtained after b transitionsx ⇠ ⇡ b ✓ , starting from x 0 ⇠ ⇡ 0 .</formula><p>2. Samples obtained after m transitions, starting from a data sample</p><formula xml:id="formula_7">x d ⇠ p d .</formula><p>Intuitively, the first condition encourages the Markov Chain to converge towards p d over relatively short runs (of length b). The second condition enforces that p d is a fixed point for the transition operator. <ref type="bibr" target="#b0">1</ref> Instead of simulating the chain until convergence, which will be especially time-consuming if the initial Markov chain takes many steps to mix, the generator would run only (b + m)/2 steps on average. Empirically, we observe better training times by uniformly sampling b from [1, B] and m from [1, M] respectively in each iteration, so we use B and M as the hyperparameters for our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Example: Generative Model for Images</head><p>We experiment with a distribution p d over images, such as digits (MNIST) and faces (CelebA). In the experiments, we parametrize f ✓ to have an autoencoding structure, where the auxiliary variable v ⇠ N (0, I) is directly added to the latent code of the network serving as a source of randomness:</p><formula xml:id="formula_8">z = encoder ✓ (x t ) z 0 = ReLU(z + v) x t+1 = decoder ✓ (z 0 )<label>(4)</label></formula><p>where is a hyperparameter we set to 0.1. While sampling is inexpensive, evaluating probabilities according to T ✓ (·|x t ) is generally intractable as it would require integration over v. The starting distribution ⇡ 0 is a factored Gaussian distribution with mean and standard deviation being the mean and standard deviation of the training set. We include all the details, which ares based on the DCGAN <ref type="bibr" target="#b15">[16]</ref> architecture, in Appendix E.1. All the models are trained with the gradient penalty objective for Wasserstein GANs <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b14">15]</ref>, where = 1/3, B = 4 and M = 3.</p><p>We visualize the samples generated from our trained Markov chain in <ref type="figure" target="#fig_0">Figures 1 and 3</ref>, where each row shows consecutive samples from the same chain (we include more images in Appendix F) From <ref type="figure" target="#fig_0">Figure 1</ref> it is clear that x t+1 is related to x t in terms of high-level properties such as digit identity (label). Our model learns to find and "move between the modes" of the dataset, instead of generating a single sample ancestrally. This is drastically different from other iterative generative models trained with maximum likelihood, such as Generative Stochastic Networks (GSN, <ref type="bibr" target="#b17">[18]</ref>) and Infusion Training (IF, <ref type="bibr" target="#b18">[19]</ref>), because when we train T ✓ (x t+1 |x t ) we are not specifying a particular target for x t+1 . In fact, to maximize the discriminator score the model (generator) may choose to generate some x t+1 near a different mode.</p><p>To further investigate the frequency of various modes in the stationary distribution, we consider the class-to-class transition probabilities for MNIST. We run one step of the transition operator starting from real samples where we have class labels y 2 {0, . . . , 9}, and classify the generated samples with a CNN. We are thus able to quantify the transition matrix for labels in <ref type="figure" target="#fig_1">Figure 2</ref>. Results show that class probabilities are fairly uniform and range between 0.09 and 0.11.</p><p>Although it seems that the MGAN objective encourages rapid transitions between different modes, it is not always the case. In particular, as shown in <ref type="figure" target="#fig_2">Figure 3</ref>, adding residual connections <ref type="bibr" target="#b19">[20]</ref> and highway connections <ref type="bibr" target="#b20">[21]</ref> to an existing model can significantly increase the time needed to transition between modes. This suggests that the time needed to transition between modes can be affected by the architecture we choose for f ✓ (x t , v). If the architecture introduces an information bottleneck which forces the model to "forget" x t , then x t+1 will have higher chance to occur in another mode; on the other hand, if the model has shortcut connections, it tends to generate x t+1 that are close to x t . The increase in autocorrelation will hinder performance if samples are used for Monte Carlo estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Adversarial Training for Markov Chain Monte Carlo</head><p>We now consider the setting where the target distribution p d is specified by an analytic expression:</p><formula xml:id="formula_9">p d (x) / exp( U (x))<label>(5)</label></formula><p>where U (x) is a known "energy function" and the normalization constant in Equation (5) might be intractable to compute. This form is very common in Bayesian statistics <ref type="bibr" target="#b21">[22]</ref>, computational physics <ref type="bibr" target="#b22">[23]</ref> and graphics <ref type="bibr" target="#b23">[24]</ref>. Compared to the setting in Section 3, there are two additional challenges:</p><p>1. We want to train a Markov chain such that the stationary distribution ⇡ ✓ is exactly p d ; 2. We do not have direct access to samples from p d during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Exact Sampling Through MCMC</head><p>We use ideas from the Markov Chain Monte Carlo (MCMC) literature to satisfy the first condition and guarantee that {⇡ t ✓ } 1 t=0 will asymptotically converge to p d . Specifically, we require the transition operator T ✓ (·|x) to satisfy the detailed balance condition:</p><formula xml:id="formula_10">p d (x)T ✓ (x 0 |x) = p d (x 0 )T ✓ (x|x 0 )<label>(6)</label></formula><p>for all x and x 0 . This condition can be satisfied using Metropolis-Hastings (MH), where a sample x 0 is first obtained from a proposal distribution g ✓ (x 0 |x) and accepted with the following probability:</p><formula xml:id="formula_11">A ✓ (x 0 |x) = min ✓ 1, p d (x 0 ) p d (x) g ✓ (x|x 0 ) g ✓ (x 0 |x) ◆ = min ✓ 1, exp(U (x) U (x 0 )) g ✓ (x|x 0 ) g ✓ (x 0 |x) ◆<label>(7)</label></formula><p>Therefore, the resulting MH transition kernel can be expressed as</p><formula xml:id="formula_12">T ✓ (x 0 |x) = g ✓ (x 0 |x)A ✓ (x 0 |x) (if x 6 = x 0 )</formula><p>, and it can be shown that p d is stationary for T ✓ (·|x) <ref type="bibr" target="#b24">[25]</ref>.</p><p>The idea is then to optimize for a good proposal g ✓ (x 0 |x). We can set g ✓ directly as in Equation (1) (if f ✓ takes a form where the probability g ✓ can be computed efficiently), and attempt to optimize the MGAN objective in Eq. (3) (assuming we have access to samples from p d , a challenge we will address later). Unfortunately, Eq. <ref type="formula" target="#formula_11">(7)</ref> is not differentiable -the setting is similar to policy gradient optimization in reinforcement learning. In principle, score function gradient estimators (such as REINFORCE <ref type="bibr" target="#b25">[26]</ref>) could be used in this case; in our experiments, however, this approach leads to extremely low acceptance rates. This is because during initialization, the ratio g ✓ (x|x 0 )/g ✓ (x 0 |x) can be extremely low, which leads to low acceptance rates and trajectories that are not informative for training. While it might be possible to optimize directly using more sophisticated techniques from the RL literature, we introduce an alternative approach based on volume preserving dynamics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Hamiltonian Monte Carlo and Volume Preserving Flow</head><p>To gain some intuition to our method, we introduce Hamiltonian Monte Carlo (HMC) and volume preserving flow models <ref type="bibr" target="#b26">[27]</ref>. HMC is a widely applicable MCMC method that introduces an auxiliary "velocity" variable v to g ✓ (x 0 |x). The proposal first draws v from p(v) (typically a factored Gaussian distribution) and then obtains (x 0 , v 0 ) by simulating the dynamics (and inverting v at the end of the simulation) corresponding to the Hamiltonian</p><formula xml:id="formula_13">H(x, v) = v &gt; v/2 + U (x)<label>(8)</label></formula><p>where x and v are iteratively updated using the leapfrog integrator (see <ref type="bibr" target="#b26">[27]</ref>). The transition from</p><formula xml:id="formula_14">(x, v) to (x 0 , v 0</formula><p>) is deterministic, invertible and volume preserving, which means that</p><formula xml:id="formula_15">g ✓ (x 0 , v 0 |x, v) = g ✓ (x, v|x 0 , v 0 )<label>(9)</label></formula><p>MH acceptance <ref type="formula" target="#formula_11">(7)</ref> is computed using the distribution p(</p><formula xml:id="formula_16">x, v) = p d (x)p(v)</formula><p>, where the acceptance probability is p(</p><formula xml:id="formula_17">x 0 , v 0 )/p(x, v) since g ✓ (x 0 , v 0 |x, v)/g ✓ (x, v|x 0 , v 0 ) = 1.</formula><p>We can safely discard v 0 after the transition since x and v are independent.</p><p>Let us return to the case where the proposal is parametrized by a neural network; if we could satisfy Equation 9 then we could significantly improve the acceptance rate compared to the "REINFORCE" setting. Fortunately, we can design such an proposal by using a volume preserving flow model <ref type="bibr" target="#b13">[14]</ref>.</p><p>A flow model <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref>] defines a generative model for x 2 R n through a bijection f : h ! x, where h 2 R n have the same number of dimensions as x with a fixed prior p H (h) (typically a factored Gaussian). In this form, p X (x) is tractable because</p><formula xml:id="formula_18">p X (x) = p H (f 1 (x)) det @f 1 (x) @x 1 (10)</formula><p>and can be optimized by maximum likelihood.</p><p>In the case of a volume preserving flow model f , the determinant of the Jacobian @f (h) @h is one. Such models can be constructed using additive coupling layers, which first partition the input into two parts, y and z, and then define a mapping from (y, z) to (y 0 , z</p><formula xml:id="formula_19">0 ) as: y 0 = y z 0 = z + m(y)<label>(11)</label></formula><p>where m(·) can be a complex function. By stacking multiple coupling layers the model becomes highly expressive. Moreover, once we have the forward transformation f , the backward transformation f 1 can be easily derived. This family of models are called Non-linear Independent Components Estimation (NICE) <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">A NICE Proposal</head><p>HMC has two crucial components. One is the introduction of the auxiliary variable v, which prevents random walk behavior; the other is the symmetric proposal in Equation <ref type="formula" target="#formula_15">(9)</ref>, which allows the MH step to only consider p(x, v). In particular, if we simulate the Hamiltonian dynamics (the deterministic part of the proposal) twice starting from any (x, v) (without MH or resampling v), we will always return to (x, v).</p><p>Auxiliary variables can be easily integrated into neural network proposals. However, it is hard to obtain symmetric behavior. If our proposal is deterministic, then f ✓ (f ✓ (x, v)) = (x, v) should hold for all (x, v), a condition which is difficult to achieve 2 . Therefore, we introduce a proposal which satisfies Equation (9) for any ✓, while preventing random walk in practice by resampling v after every MH step.</p><p>Our proposal considers a NICE model f ✓ (x, v) with its inverse f 1 ✓ , where v ⇠ p(v) is the auxiliary variable. We draw a sample x 0 from the proposal g ✓ (x 0 , v 0 |x, v) using the following procedure:</p><formula xml:id="formula_20">1. Randomly sample v ⇠ p(v) and u ⇠ Uniform[0, 1]; 2. If u &gt; 0.5, then (x 0 , v 0 ) = f ✓ (x, v); f f 1 High "high" acceptance "low" acceptance U (x, v) Low U (x, v) p(x, v)</formula><p>Figure 4: Sampling process of A-NICE-MC. Each step, the proposal executes f ✓ or f 1 ✓ . Outside the high probability regions f ✓ will guide x towards p d (x), while MH will tend to reject f 1 ✓ . Inside high probability regions both operations will have a reasonable probability of being accepted.</p><formula xml:id="formula_21">3. If u  0.5, then (x 0 , v 0 ) = f 1 ✓ (x, v).</formula><p>We call this proposal a NICE proposal and introduce the following theorem. Theorem 1. For any (x, v) and</p><formula xml:id="formula_22">(x 0 , v 0 ) in their domain, a NICE proposal g ✓ satisfies g ✓ (x 0 , v 0 |x, v) = g ✓ (x, v|x 0 , v 0 )</formula><p>Proof. In Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Training A NICE Proposal</head><p>Given any NICE proposal with f ✓ , the MH acceptance step guarantees that p d is a stationary distribution, yet the ratio p(x 0 , v 0 )/p(x, v) can still lead to low acceptance rates unless ✓ is carefully chosen. Intuitively, we would like to train our proposal g ✓ to produce samples that are likely under p(x, v).</p><p>Although the proposal itself is non-differentiable w.r.t. x and v, we do not require score function gradient estimators to train it. In fact, if f ✓ is a bijection between samples in high probability regions, then f 1 ✓ is automatically also such a bijection. Therefore, we ignore f 1 ✓ during training and only train f ✓ (x, v) to reach the target distribution p(</p><formula xml:id="formula_23">x, v) = p d (x)p(v). For p d (x)</formula><p>, we use the MGAN objective in Equation <ref type="formula" target="#formula_5">(3)</ref>; for p(v), we minimize the distance between the distribution for the generated v 0 (tractable through Equation <ref type="formula" target="#formula_3">(10)</ref>) and the prior distribution p(v) (which is a factored Gaussian):</p><formula xml:id="formula_24">min ✓ max D L(x; ✓, D) + L d (p(v), p ✓ (v 0 ))<label>(12)</label></formula><p>where L is the MGAN objective, L d is an objective that measures the divergence between two distributions and is a parameter to balance between the two factors; in our experiments, we use KL divergence for L d and = 1 3 .</p><p>Our transition operator includes a trained NICE proposal followed by a Metropolis-Hastings step, and we call the resulting Markov chain Adversarial NICE Monte Carlo (A-NICE-MC). The sampling process is illustrated in <ref type="figure">Figure 4</ref>. Intuitively, if (x, v) lies in a high probability region, then both f ✓ and f 1 ✓ should propose a state in another high probability region. If (x, v) is in a low-probability probability region, then f ✓ would move it closer to the target, while f 1 ✓ does the opposite. However, the MH step will bias the process towards high probability regions, thereby suppressing the randomwalk behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Bootstrap</head><p>The main remaining challenge is that we do not have direct access to samples from p d in order to train f ✓ according to the adversarial objective in Equation <ref type="formula" target="#formula_3">(12)</ref>, whereas in the case of Section 3, we have a dataset to get samples from the data distribution.</p><p>In order to retrieve samples from p d and train our model, we use a bootstrap process <ref type="bibr" target="#b32">[33]</ref> where the quality of samples used for adversarial training should increase over time. We obtain initial samples by running a (possibly) slow mixing operator T ✓0 with stationary distribution p d starting from an arbitrary initial distribution ⇡ 0 . We use these samples to train our model f ✓i , and then use it to obtain new samples from our trained transition operator T ✓i ; by repeating the process we can obtain samples of better quality which should in turn lead to a better model.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Reducing Autocorrelation by Pairwise Discriminator</head><p>An important metric for evaluating MCMC algorithms is the effective sample size (ESS), which measures the number of "effective samples" we obtain from running the chain. As samples from MCMC methods are not i.i.d., to have higher ESS we would like the samples to be as independent as possible (low autocorrelation). In the case of training a NICE proposal, the objective in Equation (3) may lead to high autocorrelation even though the acceptance rate is reasonably high. This is because the coupling layer contains residual connections from the input to the output; as shown in Section 3.1, such models tend to learn an identity mapping and empirically they have high autocorrelation.</p><p>We propose to use a pairwise discriminator to reduce autocorrelation and improve ESS. Instead of scoring one sample at a time, the discriminator scores two samples (x 1 , x 2 ) at a time. For "real data" we draw two independent samples from our bootstrapped samples; for "fake data" we draw</p><formula xml:id="formula_25">x 2 ⇠ T m ✓ (·|x 1 )</formula><p>such that x 1 is either drawn from the data distribution or from samples after running the chain for b steps, and x 2 is the sample after running the chain for m steps, which is similar to the samples drawn in the original MGAN objective.</p><p>The optimal solution would be match both distributions of x 1 and x 2 to the target distribution. Moreover, if x 1 and x 2 are correlated, then the discriminator should be able distinguish the "real" and "fake" pairs, so the model is forced to generate samples with little autocorrelation. More details are included in Appendix D. The pairwise discriminator is conceptually similar to the minibatch discrimination layer <ref type="bibr" target="#b33">[34]</ref>; the difference is that we provide correlated samples as "fake" data, while <ref type="bibr" target="#b33">[34]</ref> provides independent samples that might be similar.</p><p>To demonstrate the effectiveness of the pairwise discriminator, we show an example for the image domain in <ref type="figure" target="#fig_3">Figure 5</ref>, where the same model with shortcut connections is trained with and without pairwise discrimination (details in Appendix E.1); it is clear from the variety in the samples that the pairwise discriminator significantly reduces autocorrelation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Code for reproducing the experiments is available at https://github.com/ermongroup/a-nice-mc.</p><p>To demonstrate the effectiveness of A-NICE-MC, we first compare its performance with HMC on several synthetic 2D energy functions: ring (a ring-shaped density), mog2 (a mixture of 2 Gaussians) mog6 (a mixture of 6 Gaussians), ring5 (a mixture of 5 distinct rings). The densities are illustrated in <ref type="figure" target="#fig_4">Figure 6</ref> (Appendix E.2 has the analytic expressions). ring has a single connected component of high-probability regions and HMC performs well; mog2, mog6 and ring5 are selected to demonstrate cases where HMC fails to move across modes using gradient information. A-NICE-MC performs well in all the cases.</p><p>We use the same hyperparameters for all the experiments (see Appendix E.4 for details). In particular, we consider f ✓ (x, v) with three coupling layers, which update v, x and v respectively. This is to ensure that both x and v could affect the updates to x 0 and v 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How does A-NICE-MC perform?</head><p>We evaluate and compare ESS and ESS per second (ESS/s) for both methods in <ref type="table" target="#tab_0">Table 1</ref>. For ring, mog2, mog6, we report the smallest ESS of all the dimensions  (as in <ref type="bibr" target="#b34">[35]</ref>); for ring5, we report the ESS of the distance between the sample and the origin, which indicates mixing across different rings. In the four scenarios, HMC performed well only in ring; in cases where modes are distant from each other, there is little gradient information for HMC to move between modes. On the other hand, A-NICE-MC is able to freely move between the modes since the NICE proposal is parametrized by a flexible neural network.</p><formula xml:id="formula_26">(a) E[ p x 2 1 + x 2 2 ] (b) Std[ p x 2 1 + x 2 2 ]<label>(c)</label></formula><p>We use ring5 as an example to demonstrate the results. We assume ⇡ 0 (x) = N (0, 2 I) as the initial distribution, and optimize through maximum likelihood. Then we run both methods, and use the resulting particles to estimate p d . As shown in <ref type="figure" target="#fig_5">Figures 7a and 7b</ref>, HMC fails and there is a large gap between true and estimated statistics. This also explains why the ESS is lower than 1 for HMC for ring5 in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>Another reasonable measurement to consider is Gelman's R hat diagnostic <ref type="bibr" target="#b35">[36]</ref>, which evaluates performance across multiple sampled chains. We evaluate this over the rings5 domain (where the statistics is the distance to the origin), using 32 chains with 5000 samples and 1000 burn-in steps for each sample. HMC gives a R hat value of 1.26, whereas A-NICE-MC gives a R hat value of 1.002 <ref type="bibr" target="#b3">4</ref> . This suggest that even with 32 chains, HMC does not succeed at estimating the distribution reasonably well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Does training increase ESS?</head><p>We show in <ref type="figure" target="#fig_6">Figure 8</ref> that in all cases ESS increases with more training iterations and bootstrap rounds, which also indicates that using the pairwise discriminator is effective at reducing autocorrelation.</p><p>Admittedly, training introduces an additional computational cost which HMC could utilize to obtain more samples initially (not taking parameter tuning into account), yet the initial cost can be amortized thanks to the improved ESS. For example, in the ring5 domain, we can reach an ESS of 121.54 in approximately 550 seconds (2500 iterations on 1 thread CPU, bootstrap included). If we then sample from the trained A-NICE-MC, it will catch up with HMC in less than 2 seconds.</p><p>Next, we demonstrate the effectiveness of A-NICE-MC on Bayesian logistic regression, where the posterior has a single mode in a higher dimensional space, making HMC a strong candidate for the task. However, in order to achieve high ESS, HMC samplers typically use many leap frog steps and require gradients at every step, which is inefficient when r x U (x) is computationally expensive. A-NICE-MC only requires running f ✓ or f 1 ✓ once to obtain a proposal, which is much cheaper computationally. We consider three datasets -german (25 covariates, 1000 data points), heart (14 covariates, 532 data points) and australian (15 covariates, 690 data points) -and evaluate the lowest ESS across all covariates (following the settings in <ref type="bibr" target="#b34">[35]</ref>), where we obtain 5000 samples after 1000  Although HMC outperforms A-NICE-MC in terms of ESS, the NICE proposal is less expensive to compute than the HMC proposal by almost an order of magnitude, which leads to higher ESS per second (see <ref type="table" target="#tab_1">Table 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>To the best of our knowledge, this paper presents the first likelihood-free method to train a parametric MCMC operator with good mixing properties. The resulting Markov Chains can be used to target both empirical and analytic distributions. We showed that using our novel training objective we can leverage flexible neural networks and volume preserving flow models to obtain domain-specific transition kernels. These kernels significantly outperform traditional ones which are based on elegant yet very simple and general-purpose analytic formulas. Our hope is that these ideas will allow us to bridge the gap between MCMC and neural network function approximators, similarly to what "black-box techniques" did in the context of variational inference <ref type="bibr" target="#b0">[1]</ref>.</p><p>Combining the guarantees of MCMC and the expressiveness of neural networks unlocks the potential to perform fast and accurate inference in high-dimensional domains, such as Bayesian neural networks. This would likely require us to gather the initial samples through other methods, such as variational inference, since the chances for untrained proposals to "stumble upon" low energy regions is diminished by the curse of dimensionality. Therefore, it would be interesting to see whether we could bypass the bootstrap process and directly train on U (x) by leveraging the properties of flow models. Another promising future direction is to investigate proposals that can rapidly adapt to changes in the data. One use case is to infer the latent variable of a particular data point, as in variational autoencoders. We believe it should be possible to utilize meta-learning algorithms with data-dependent parametrized proposals.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Visualizing samples of ⇡ 1 to ⇡ 50 (each row) from a model trained on the MNIST dataset. Consecutive samples can be related in label (red box), inclination (green box) or width (blue box).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: T ✓ (y t+1 |y t ). Figure 3: Samples of ⇡ 1 to ⇡ 30 from models (top: without shortcut connections; bottom: with shortcut connections) trained on the CelebA dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 2: T ✓ (y t+1 |y t ). Figure 3: Samples of ⇡ 1 to ⇡ 30 from models (top: without shortcut connections; bottom: with shortcut connections) trained on the CelebA dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Left: Samples from a model with shortcut connections trained with ordinary discriminator. Right: Samples from the same model trained with a pairwise discriminator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Densities of ring, mog2, mog6 and ring5 (from left to right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: (a-b) Mean absolute error for estimating the statistics in ring5 w.r.t. simulation length. Averaged over 100 chains. (c-d) Density plots for both methods. When the initial distribution is a Gaussian centered at the origin, HMC overestimates the densities of the rings towards the center.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: ESS with respect to the number of training iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 :</head><label>1</label><figDesc>Performance of MCMC samplers as measured by Effective Sample Size (ESS).</figDesc><table>Higher is 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc>ESS and ESS per second for Bayesian logistic regression tasks.burn-in samples. For HMC we use 40 leap frog steps and tune the step size for the best ESS possible. For A-NICE-MC we use the same hyperparameters for all experiments (details in Appendix E.5).</figDesc><table>ESS 
A-NICE-MC 
HMC 

german 
926.49 
2178.00 
heart 
1251.16 
5000.00 
australian 
1015.75 
1345.82 

ESS/s 
A-NICE-MC 
HMC 

german 
1289.03 
216.17 
heart 
3204.00 
1005.03 
australian 
1857.37 
289.11 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="31">st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We provide a more rigorous justification in Appendix B.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The cycle consistency loss (as in CycleGAN [31]) introduces a regularization term for this condition; we added this to the REINFORCE objective but were not able to achieve satisfactory results.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The results are not very sensitive to changes in ; we also tried Maximum Mean Discrepancy (MMD, see [32] for details) and achieved similar results.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">For R hat values, the perfect value is 1, and 1.1-1.2 would be regarded as too high.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was funded by Intel Corporation, TRI, FLI and NSF grants 1651565, 1522054, 1733686. The authors would like to thank Daniel Lévy for discussions on the NICE proposal proof, Yingzhen Li for suggestions on the training procedure and Aditya Grover for suggestions on the implementation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Black box variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="814" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.4082</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Learning in implicit generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.03483</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Markov chain monte carlo and variational inference: Bridging the gap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1218" to="1226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Variational mcmc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">De</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Højen-Sørensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence</title>
		<meeting>the Seventeenth conference on Uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Measuring sample quality with stein&apos;s method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gorham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mackey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="226" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Measuring sample quality with diffusions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gorham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Vollmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mackey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.06972</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Measuring sample quality with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gorham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mackey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.01717</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Designing fast absorbing markov chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="849" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adaptive mcmc with bayesian optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mahendran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hamze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N. De</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AISTATS</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="751" to="760" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fastest mixing markov chain on a graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diaconis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM review</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="667" to="689" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Nice: Non-linear independent components estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8516</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Wasserstein gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00028</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Deep generative stochastic networks trainable by backprop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Thibodeau-Laufer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning to generate samples from noise through infusion training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Honari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Highway networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Reversible jump markov chain monte carlo computation and bayesian model determination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="page" from="711" to="732" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Manifold exploration: a markov chain monte carlo technique for rendering scenes with difficult specular transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marschner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">58</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A guide to Monte Carlo simulations in statistical physics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Landau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Binder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Monte carlo sampling methods using markov chains and their applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">K</forename><surname>Hastings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="109" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Handbook of Markov Chain Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="113" to="162" />
		</imprint>
	</monogr>
	<note>Mcmc using hamiltonian dynamics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.05770</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Improving variational inference with inverse autoregressive flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04934</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Flow-gan: Bridging implicit and prescribed learning in generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08868</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10593</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generative moment matching networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1718" to="1727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">An introduction to the bootstrap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2226" to="2234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Riemann manifold langevin and hamiltonian monte carlo methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Girolami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Calderhead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="214" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">General methods for monitoring convergence of iterative simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational and graphical statistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="434" to="455" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The no-u-turn sampler: adaptively setting path lengths in hamiltonian monte carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1593" to="1623" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
