<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T23:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Proximal Operators: Using Denoising Networks for Regularizing Inverse Imaging Problems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Meinhardt</surname></persName>
							<email>tim.meinhardt@in.tum.de</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Siegen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Moeller</surname></persName>
							<email>michael.moeller@uni-siegen.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caner</forename><surname>Hazirbas</surname></persName>
							<email>hazirbas@cs.tum.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Siegen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
							<email>cremers@tum.de</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Siegen</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Technical University of Munich</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Proximal Operators: Using Denoising Networks for Regularizing Inverse Imaging Problems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Many important problems in image processing and computer vision can be phrased as linear inverse problems where the desired quantity u cannot be observed directly but needs to be determined from measurements f that relate to u via a linear operator A, i.e. f = Au + n for some noise n. In almost all practically relevant applications the solution is very sensitive to the input data, and the underlying continuous problem is ill-posed. A classical but powerful general CNN <ref type="figure">Figure 1</ref>: We propose to exploit the recent advances in convolutional neural networks for image denoising for general inverse imaging problems by replacing the proximal operator in optimization algorithms with such a network. Changing the image reconstruction task, e.g. from deblurring to demosaicking, merely changes the data fidelity term such that the same network can be used over a wide range of applications without requiring any retraining.</p><p>approach to obtain stable and faithful reconstructions is to use a regularization and determine the estimated solutionû via an energy minimization problem of the form u = argmin u H f (Au) + R(u).</p><p>(1)</p><p>In the above, H f is a fidelity measure that relates the data f to the estimated true solution u, e.g. H f (Au) = Au − f 2 and R is a regularization function that introduces a-priori information on the expected solution. Recently, the computer vision research community has had great success in replacing the explicit modeling of energy functions in Equation (1) by parameterized functions G that directly map the input data f to a solutionû = G(f ). Powerful architectures are so-called deep networks that parameterize G by several layers of linear operations followed by certain nonlinearities, e.g. rectified linear units. The free parameters of G are learned by using large amounts of training data and fitting the parameters to the ground truth data via a large-scale optimization problem.</p><p>Deep networks have had a big impact in many fields of computer vision. Starting from the first large-scale applications of convolutional neural networks (CNNs), e.g. ImageNet classification <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b16">17]</ref>, deep networks have recently been extended to high dimensional inverse problems such as image denoising <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b46">47]</ref>, deblurring <ref type="bibr" target="#b43">[44]</ref>, superresolution <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>, optical flow estimation <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b27">28]</ref>, image demosaicking <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21]</ref>, or inpainting <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b44">45]</ref>. In many cases, the performance of deep networks can be further improved when the prediction of the network is postprocessed with an energy minimization method, e.g. optical flow <ref type="bibr" target="#b15">[16]</ref> and stereo matching (disparity estimation) <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>While learning based methods yield powerful representations and are efficient in the evaluation of the network for given input data f , their training is often difficult. A sufficient amount of training data needs to be acquired in such a way that it generalizes well enough to the test data the network is finally used for. Furthermore, the final performance often depends on a required training and network architecture expertise which includes weight regularization <ref type="bibr" target="#b24">[25]</ref>, dropout <ref type="bibr" target="#b36">[37]</ref>, batch normalization <ref type="bibr" target="#b18">[19]</ref>, or the introduction of "shortcuts" <ref type="bibr" target="#b16">[17]</ref>. Finally, while it is very quick and easy to change the linear operator A in variational methods like Equation (1), learning based methods require a costly training as soon as the operator A changes. The latter motivates the idea to combine the advantages of energy minimization methods that are flexible to changes of the data term with the powerful representation of natural images that can be obtained via deep learning.</p><p>It was observed in <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b17">18]</ref> that modern convex optimization algorithms for solving Equation (1) merely depend on the proximal operator of the regularization R, which motivated the authors to replace this step by general designed denoising algorithms such as the non-local means (NLM) <ref type="bibr" target="#b2">[3]</ref> or BM3D <ref type="bibr" target="#b6">[7]</ref> algorithms. Upon preparation of this manuscript we additionally found the ArXiv report <ref type="bibr" target="#b29">[30]</ref> which extends the ideas of <ref type="bibr" target="#b39">[40]</ref> and offers a detailed theoretical analysis on solving linear inverse problems by turning them into a chain of denoising steps. For the sake of completeness, we have to mention methods such as <ref type="bibr" target="#b40">[41]</ref> who apply the contrary approach and use variational methods as boilerplate models to design their network architecture.</p><p>In this paper we exploit the power of learned image denoising networks by using them to replace the proximal operators in convex optimization algorithms as illustrated in <ref type="figure">Figure 1</ref>. Our contributions are:</p><p>• We demonstrate that using a fixed denoising network as a proximal operator in the primal-dual hybrid gradient (PDHG) method yields state-of-the-art results close to the performance of methods that trained a problem-specific network.</p><p>• We analyze the possibility to use different optimization algorithms for incorporating neural networks and show that the fixed points of the resulting algorithmic schemes coincide.</p><p>• We provide new insights about how the final result is influenced by the algorithm's step size parameter and the denoising strength of the neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Classical variational methods exploiting Equation (1), use regularization functions that are designed to suppress noise while preserving important image features. One of the most famous examples is the total variation (TV) <ref type="bibr" target="#b32">[33]</ref> which penalizes the norm of the gradient of an image and has been shown to preserve image discontinuities.</p><p>An interesting observation is that typical convex optimization methods for Equation (1) merely require the evaluation of the proximal operator of the regularization functional R,</p><formula xml:id="formula_0">prox R (b) = argmin u 1 2 u − b 2 2 + R(u).<label>(2)</label></formula><p>The interpretation of the proximal operator as a denoising of b motivated the authors of <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b17">18]</ref> to replace the proximal operator of R by a powerful denoising method such as NLM or BM3D. Theoretical results including conditions under which the alternating directions method of multipliers (ADMM) with a custom proximal operator converges were presented in <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b4">5]</ref>. Techniques using customized proximal operators have recently been explored in several applications, e.g. Poisson denoising <ref type="bibr" target="#b30">[31]</ref>, bright field electron tomography <ref type="bibr" target="#b35">[36]</ref>, super-resolution <ref type="bibr" target="#b1">[2]</ref>, or hyperspectral image sharpening <ref type="bibr" target="#b37">[38]</ref>. Interestingly, the aforementioned works all focused on patch-based denoising methods as proximial operators. While <ref type="bibr" target="#b38">[39]</ref> included a learning of a Gaussian mixture model of patches, we propose to use deep convolutional denoising networks as proximal operators, and analyze their behavior numerically as well as theoretically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Learned proximal operators</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Motivation via MAP estimates</head><p>A common strategy to motivate variational methods like Equation <ref type="bibr" target="#b0">(1)</ref> are maximum a-posteriori probability (MAP) estimates. One desires to maximize the conditional probability p(u|f ) that u is the true solution given that f is the observed data. One applies Bayes rule, and minimizes the negative logarithm of the resulting expression to find</p><formula xml:id="formula_1">arg max u p(u|f ) = arg min u − log p(f |u)p(u) p(f )<label>(3)</label></formula><p>= arg min</p><formula xml:id="formula_2">u (− log(p(f |u)) − log(p(u))) .<label>(4)</label></formula><p>In the light of MAP estimates, the data term is well described by the forward operator A and the assumed noise model. For example, if the observed data f differs from the true data Au by Gaussian noise of variance σ 2 , it holds</p><formula xml:id="formula_3">that p(f |u) = exp(− Au−f 2 2 2σ 2</formula><p>), which naturally yields a squared ℓ 2 norm as a data fidelity term. Therefore, having a good estimate on the forward operator A and the underlying noise model seems to make "learning the data term" obsolete.</p><p>A much more delicate term is the regularization, which -in the framework of MAP estimates -corresponds to the negative logarithm of the probability of observing u as an image. Assigning a probability to any possible R n×m matrix that could represent an image, seems extremely difficult by simple, hand-crafted measures. Although penalties like the TV are well-motivated in a continuous setting, the norm of the gradient cannot fully capture the likelihood of complex natural images. Hence, the regularization is the perfect candidate to be replaced by learning-based techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Algorithms for learned proximal operators</head><p>Motivated by MAP estimates "learning the probability p(u) of natural images", seems to be a very attractive strategy. As learning p(u) directly appears to be difficult from a practical point of view, we instead exploit the observation of <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b17">18]</ref> that many convex optimization algorithms for Equation <ref type="bibr" target="#b0">(1)</ref> only require the proximal operator of the regularization.</p><p>For instance, applying a proximal gradient (PG) method to the minimization problem in Equation (1) yields the update equation</p><formula xml:id="formula_4">u k+1 = prox τ R u k − τ A * ∇H f (Au k ) .<label>(5)</label></formula><p>Since a proximal operator can be interpreted as a Gaussian denoiser in a MAP sense, an interesting idea is to replace the above proximal operator of the regularizer by a neural network G, i.e.</p><formula xml:id="formula_5">u k+1 = G u k − τ A * ∇H f (Au k ) .<label>(6)</label></formula><p>Instead of the proximal gradient method in Equation <ref type="formula" target="#formula_4">(5)</ref>, the plug-and-play priors considered in <ref type="bibr" target="#b39">[40]</ref> utilize the ADMM algorithm leading to update equations of the form</p><formula xml:id="formula_6">u k+1 =prox 1 γ (H f •A) v k+1 − 1 γ y k ,<label>(7)</label></formula><formula xml:id="formula_7">v k+1 =prox 1 γ R u k + 1 γ y k ,<label>(8)</label></formula><formula xml:id="formula_8">y k+1 =y k + γ(u k+1 − v k+1 ),<label>(9)</label></formula><p>and consider replacing the proximal operator in Equation (8) by a general denoising method such as NLM or BM3D. Replacing Equation (8) by a neural network can be motivated equally.</p><p>Finally, the authors of <ref type="bibr" target="#b17">[18]</ref> additionally consider a purely primal formulation of the primal-dual hybrid gradient method (PDHG) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b3">4]</ref>. For Equation (1) such a method amounts to update equations of the form</p><formula xml:id="formula_9">z k+1 =z k + γAū k − γprox 1 γ H f 1 γ z k + Aū k ,<label>(10)</label></formula><formula xml:id="formula_10">y k+1 =y k + γū k − γprox 1 γ R 1 γ y k +ū k ,<label>(11)</label></formula><formula xml:id="formula_11">u k+1 =u k − τ A T z k+1 − τ y k+1 ,<label>(12)</label></formula><formula xml:id="formula_12">u k+1 =u k+1 + θ(u k+1 − u k ),<label>(13)</label></formula><p>if prox H f •A is difficult to compute, or otherwise</p><formula xml:id="formula_13">y k+1 =y k + γū k − γprox 1 γ R 1 γ y k +ū k ,<label>(14)</label></formula><formula xml:id="formula_14">u k+1 =prox τ (H f •A) (u k − τ y k+1 ),<label>(15)</label></formula><formula xml:id="formula_15">u k+1 =u k+1 + θ(u k+1 − u k ).<label>(16)</label></formula><p>In both variants of the PDHG method shown above, linear operators in the regularization (such as the gradient in case of TV regularization) can further be decoupled from the computation of the remaining proximity operator. From now on we will refer to <ref type="formula" target="#formula_9">(10)</ref>- <ref type="formula" target="#formula_1">(13)</ref> as PDHG1 and to <ref type="formula" target="#formula_2">(14)</ref>- <ref type="formula" target="#formula_5">(16)</ref> as PDHG2. Again, the authors of <ref type="bibr" target="#b17">[18]</ref> considered replacing the proximal operator in update Equation <ref type="bibr" target="#b10">(11)</ref> or Equation <ref type="formula" target="#formula_2">(14)</ref> by a BM3D or NLM denoiser, which -again -motivates replacing such a designed algorithm by a learned network G, i.e.</p><formula xml:id="formula_16">y k+1 = y k + γū k − γ G 1 γ y k +ū k .<label>(17)</label></formula><p>A natural question is which of the algorithms PG, ADMM, PDHG1, or PDHG2 should be used together with a denoising neural network? The convergence of any of the four algorithms can only be guaranteed for sufficiently friendly convex functions, or in some nonconvex settings under specific additional assumptions. The latter is an active field of research such that analyzing the convergence even beyond nonconvex functions goes beyond the scope of this paper. We refer the reader to <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b4">5]</ref> for some results on the convergence of ADMM with customized proximal operators. We will refer to the proposed method as an algorithmic scheme in order to indicate that a proximal operator has been replaced by a denoising network. Despite this heuristics, our numerical experiments as well as previous publications indicate that the modified iterations remain stable and converge in a wide variety of cases. Therefore, we investigate the fixed-points of the considered schemes. Interestingly, the following remark shows that the set of fixedpoints does not differ for different algorithms. </p><formula xml:id="formula_17">u * = G u * − tA T ∇H f (Au * )<label>(18)</label></formula><p>with * ∈ {PG, ADMM, PDHG1, PDHG2} and t = τ for PG and PDHG2, and t = 1 γ for ADMM and PDHG1.</p><p>Proof. See supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Parameters for learned proximal operators</head><p>One key question when replacing a proximity operator of the form prox 1 γ R by a Gaussian denoising operator, is the relation between the step size γ and the noise standard deviation σ used for the denoiser. Note that prox 1 γ R can be interpreted as a MAP estimate for removing zeromean Gaussian noise with standard-deviation σ = √ γ (as also shown in <ref type="bibr" target="#b39">[40]</ref>). Therefore, the authors of <ref type="bibr" target="#b17">[18]</ref> used the PDHG algorithm with a BM3D method as a proximal operator in Equation <ref type="formula" target="#formula_2">(14)</ref> and adopted the BM3D denoising strength according to the relation σ = √ γ. While algorithms like BM3D allow to easily choose the denoising strength, a neural network is less flexible as an expensive training is required for each choice of denoising strength. An interesting insight can be gained by using the algorithmic scheme arising from the PDHG2 algorithm with stepsize τ = c γ for some constant c, and the proximity operator of the regularization being replaced by an arbitrary function G. In the case of convex optimization, i.e. the original PDHG2 algorithm, the constant c resembles the stability condition that τ γ has to be smaller than the squared norm of the involved linear operator. After using G instead of the proximal mapping, the resulting algorithmic scheme becomes</p><formula xml:id="formula_18">y k+1 =y k + γū k − γ G 1 γ y k +ū k ,<label>(19)</label></formula><formula xml:id="formula_19">u k+1 =prox c γ (H f •A) (u k − c γ y k+1 ),<label>(20)</label></formula><formula xml:id="formula_20">u k+1 =u k+1 + θ(u k+1 − u k ).<label>(21)</label></formula><p>We can draw the following simple conclusion:</p><formula xml:id="formula_21">Proposition 3.2.</formula><p>Consider the algorithmic scheme given by Equations (19)- <ref type="bibr" target="#b20">(21)</ref>. Then any choice of γ &gt; 0 is equivalent to γ = 1 with a newly weighted data fidelity term</p><formula xml:id="formula_22">H f = 1 γ H f .</formula><p>In other words, changing the step size γ merely changes the data fidelity parameter.</p><p>Proof. We divide Equation <ref type="bibr" target="#b18">(19)</ref> by γ and defineỹ</p><formula xml:id="formula_23">k = 1 γ y k .</formula><p>The resulting algorithm becomes</p><formula xml:id="formula_24">y k+1 =ỹ k +ū k − G ỹ k +ū k ,<label>(22)</label></formula><formula xml:id="formula_25">u k+1 =prox c(H f •A) (u k − cỹ k+1 ),<label>(23)</label></formula><formula xml:id="formula_26">u k+1 =u k+1 + θ(u k+1 − u k ),<label>(24)</label></formula><p>which yields the assertion.</p><p>We'd like to point out that Proposition 3.2 states the equivalence of the update equations. For the iterates to coincide one additionally needs the initialization y 0 = 0. Interestingly, similar results can be obtained for any of the four schemes discussed above. As a conclusion, the specific choice of the step sizes τ and σ does not matter, as they simply rescale the data fidelity term, which should have a free tuning parameter anyway.</p><p>Besides the step sizes τ and σ, an interesting question is how the denoising strength of a neural network G relates to the data fidelity parameter. In analogy to MAP estimates above, one could expect that increasing the standard deviation σ of the noise the network is trained on by a factor of a, requires the increase of the data fidelity parameter by a factor of a 2 in order to obtain equally optimal results. To test such an hypothesis we run several different deconvolution experiments with the same input data, but different neural networks which all differ by the standard deviation σ they have been trained on. We use a data fidelity term of the form α 2 Au−f 2 2 for a blur operator A, and data fidelity parameter α. We then run an exhaustive search for the best parameter α maximizing the PSNR value for each of the different neural networks. The first plot of <ref type="figure">Figure 2</ref> illustrates the optimal data fidelity parameter α as a function of the standard deviation σ the corresponding neural network has been trained on. Interestingly, the dependence of the optimal α on σ indeed seems to be well approximated by a parabola, as illustrated by the dashed blue line representing the curve α = p σ 2 for an optimal p. It is important to note that while in the convex optimization setting a rescaling of both, regularization and data fidelity parameter, does not change the final result at all, the results obtained at each of the data points shown in the first part of <ref type="figure">Figure 2</ref> do differ as illustrated in the second plot. While a network trained on very small noise did not give good results, a sufficiently large standard deviation gives good results over a large range of training noise level σ.</p><p>Please also note that similar choices (data fidelity parameter and strength of the denoising algorithm) have to be made for any other custom denoising algorithm: As discussed above, the authors of <ref type="bibr" target="#b17">[18]</ref> proposed to make the BM3D denoising strength step size depended. <ref type="bibr" target="#b29">[30]</ref> also considers the use of neural networks as proximal operators, but similar to <ref type="bibr" target="#b17">[18]</ref>, the authors of <ref type="bibr" target="#b29">[30]</ref> try to make the denoising strength step size dependent. However, since the denoising Deblurring PSNR</p><p>Optimal PSNR vs. trained &lt; <ref type="figure">Figure 2</ref>: The same deconvolution experiment was run with denoising networks trained on noise with different standard deviations σ as proximal operators. The first plot shows the optimal data fidelity parameter α as a function of σ and the dashed blue curve is the best quadratic fit. It verifies the expected theoretical quadratic relation between the data fidelity parameter and denoising strength. The second plot shows the corresponding achieved PSNR values (for optimally tuned data fidelity parameters) as a function of σ. We can see that the PSNR is quite stable over a large range of sufficiently large denoising strengths.</p><p>strength of a neural network cannot be adapted as easily as for the BM3D algorithm, the authors rely on the assumption that a rescaling of the input data which is fed into the network allows to adapt the denoising strength. Instead we propose to rather fix the denoising strength, which -according to Proposition 3.2 -then allows us to fix the algorithm step size γ = 1 and control the smoothness of the final result by adapting the data fidelity parameter. This avoids the problem of the aforementioned approaches that the internal step size parameter γ of the algorithmic scheme influences the result and therefore becomes a (difficult-to-tune) hyperparameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Numerical implementation 4.1. Algorithmic framework and prior stacking</head><p>In the following section we describe how we implemented the proposed algorithmic scheme with a neural network replacing a proximal operator.</p><p>According to Remark 3.1 the potential fixed-points of any of the schemes are the same. In comparison to the PG method, the PDHG algorithm has the advantage that it can easily combine learned (neural network) priors (which have no associated cost function term and thus are referred to as implicit priors) with explicitly modeled priors that can be tailored to specific applications -a fact that has first been exploited by the authors of <ref type="bibr" target="#b17">[18]</ref> in a technique termed prior stacking, which we utilize in our experiments as well.</p><p>A combination, or stacking, of different priors can easily be achieved in the PDHG algorithm by introducing multiple variables: If we consider all variables in their vectorized form, our final algorithmic scheme is given by</p><formula xml:id="formula_27">z k+1 =z k + γDū k − γprox β γ J 1 γ z k + Dū k ,<label>(25)</label></formula><formula xml:id="formula_28">y k+1 =y k + γū k − γG 1 γ y k +ū k ,<label>(26)</label></formula><formula xml:id="formula_29">u k+1 =prox τ α(H f •A) (u k − τ y k+1 − τ D T z k+1 ),<label>(27)</label></formula><formula xml:id="formula_30">u k+1 =2u k+1 − u k ,<label>(28)</label></formula><p>where D is an arbitrary linear operator (e.g. the discretized gradient in the case of TV regularization), J an additional regularization (e.g. J(Du) = Du 2,1 for the TV), β is a regularization parameter, α is the data fidelity parameter, and we use (H f •A)(u) = 1 2 Au−f 2 2 for a linear operator A. We now have two variables z and y, which implement the network G and an additional regularization J, where the regularization J may again consist of multiple priors. For more details on prior stacking we refer the reader to <ref type="bibr" target="#b17">[18]</ref>.</p><p>Please note that our result of Proposition 3.2 can easily be extended to the above algorithm, where an arbitrary γ = Consequently, we again only have to optimize for the data fidelity and regularization parameters unless one considers even the product c = τ γ of the step sizes as a free parameter. For the sake of clarity and similarity to the convex optimization case, we decided not to pursue this direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Deep convolutional denoising network</head><p>In order to make our denoising network benefit from the recent advances in learning based problem solving we use an end-to-end trained deep convolutional neural network (CNN). Our network architecture of choice is similar to DnCNN-S <ref type="bibr" target="#b46">[47]</ref> and composed of 17 convolution layers with a kernel size of 3×3 each of which is followed by a rectified linear unit (ReLU). Input of the network is either a gray-scale or a color image depending on the application. We use the training pipeline identical to <ref type="bibr" target="#b46">[47]</ref> with the Adam optimization algorithm <ref type="bibr" target="#b19">[20]</ref> and train our network for removing Gaussian noise of a fixed standard deviation σ. Table 1 demonstrates the superior performance of our learned denoising operator in comparison with general denoising algorithms such as NLM and BM3D on a range of different </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Evaluation</head><p>The general idea of using neural networks instead of proximal operators applies to any image reconstruction task. We demonstrate the effectiveness of this approach on the exemplary problems of image deconvolution and Bayer demosaicking. It is important to note that we keep the neural network fixed throughout the entire numerical evaluation. In particular, the network has neither been specifically trained for deconvolution nor for demosaicking, but only on removing Gaussian noise with a fixed noise standard deviation of σ f = 0.02.</p><p>For a direct comparison we follow the experimental setup of <ref type="bibr" target="#b17">[18]</ref>, but reimplemented the problems using the problem agnostic modeling language for image optimization problems ProxImaL <ref type="bibr" target="#b13">[14]</ref>. For the denoising network we used the graph computation framework TensorFlow <ref type="bibr" target="#b0">[1]</ref> which made the integration simple and flexible. <ref type="bibr" target="#b0">1</ref> Since our approach stands in direct comparison to <ref type="bibr" target="#b17">[18]</ref>, we have to mention that we were not able to reproduce their results with our implementation. This is likely due to them replacing the proximal operator with an improved but not released version of BM3D which was even further refined for the case of demosaicking. In this paper, our main goal is to compare our approach with the framework of <ref type="bibr" target="#b17">[18]</ref> as methods that are not tailored to a specific problem but provide solutions for any linear inverse problem. Therefore, we use the publicly available BM3D implementation, perform a grid search over all free parameters, and denote the obtained results in our evaluation by FlexISP * . The latter allows us to investigate to what extend the advantage in denoising performance shown in <ref type="table" target="#tab_0">Table 1</ref> transfers to general inverse problems. Of course, approaches that are tailored to a specific problem, e.g. by training a specialized network, will likely yield superior performance. FlexISP * applies the same step size related denoising approach as <ref type="bibr" target="#b17">[18]</ref>, but in contrast to <ref type="bibr" target="#b17">[18]</ref> we observed a notable effect of the choice of γ and therefore included it in the parameter optimization. We set the same residual-based stopping criterion as well as a maximum number of 30 PDHG iterations for FlexISP * and our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Demosaicking</head><p>We evaluated our performance on noise-free demosaicking of the Bayer filtered McMaster color image dataset, <ref type="bibr" target="#b47">[48]</ref>. Besides our denoising network, we use the cross-channel and total variation prior as additional explicit regularizations J in Equation <ref type="formula" target="#formula_0">(25)</ref> as also done in <ref type="bibr" target="#b17">[18]</ref>. For FlexISP * as well as for our method we optimized in an exhaustive grid search for the data fidelity parameter α as well as for the regularization parameters β T V and β Cross . <ref type="figure" target="#fig_4">Figure 4</ref> compares our average debayering quality with multiple state-of-the-art algorithms, and <ref type="figure" target="#fig_3">Figure 3</ref> gives a visual impression of the demosaicking quality of the corresponding algorithms for two example images. As we can see, the proposed method achieves a very high average PSNR value and is only surpassed by <ref type="bibr" target="#b14">[15]</ref> who specifically trained a deep demosaicking CNN. Comparing our approach with FlexISP * , the advantage of about 1dB in PSNR values of our network over BM3D on image denoising carried over to the inverse problem of demosaicking.</p><p>To justify our choice of a fixed σ f we investigate the robustness of our approach to different choices of denoising networks. <ref type="table" target="#tab_3">Table 2</ref> illustrates the results of our method for differently trained networks, and also shows the optimal parameters found by our grid search. While we can see that the PSNRs do vary by about 1.1dB, it is encouraging to see that the average PSNR remains above 36dB for a wide range of differently trained networks. A little less conclusive are the optimal parameters found by our grid search. They merely seem to indicate that explicit priors should be used less if the denoising network is trained on larger noise levels. We also tested completely omitting explicit priors, which decreased the average performance by about 0.4dB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Deconvolution</head><p>For evaluating the deconvolution performance, we use the benchmark introduced by <ref type="bibr" target="#b33">[34]</ref>, which consists of 5 different experiments with different Gaussian noise and different blur kernels applied to 11 standard test images. Exper-  To illustrate the differences in reconstruction quality we added zoomed in residual images. Apart from FlexISP * and our result, all other images are taken from <ref type="bibr" target="#b17">[18]</ref>.  The results of all methods except CNN, FlexISP * and ours are copied from the same comparison in <ref type="bibr" target="#b17">[18]</ref>. As expected the deep CNN from <ref type="bibr" target="#b14">[15]</ref> which was specifically trained on demosaicking outperforms our approach. Nevertheless the results show that using a powerful denoising network as a proximal operator yields substantial results.</p><formula xml:id="formula_31">S O L C A H D S A D L M M S E S S D L D I N L M L D I N A T D C R A W P S C N N F le x IS P * O u r</formula><p>iments a -c, d and e each apply a Gaussian, squared and motion blurring, respectively. <ref type="table" target="#tab_5">Table 3</ref> compares our average results over all test images with eight state-of-the-art deblurring methods, and <ref type="figure">Figure 5</ref> gives a visual impression of the corresponding results for two example images within experiments a and e. Apart from FlexISP * and our method, all other results are taken from <ref type="bibr" target="#b17">[18]</ref>. For FlexISP * and our method, we used the TV as an explicit additional prior and optimized individual parameter sets for each experiment. However, while FlexISP * benefits from a separately optimized stepsize γ, our method applies the same neural network for all experiments. Nevertheless, our overall performance is on par with the other methods.</p><p>Particularly remarkable is the fact that the MLP approach  <ref type="table" target="#tab_5">IDD-BM3D IDD-BM3D IDD-BM3D IDD-BM3D IDD-BM3D  IDD-BM3D  IDD-BM3D  IDD-BM3D  IDD-BM3D  IDD-BM3D  IDD-BM3D  IDD-BM3D  IDD-BM3D IDD-BM3D IDD-BM3D IDD-BM3D IDD-</ref>   <ref type="bibr" target="#b33">[34]</ref>. All reported values except FlexISP * and ours were taken from <ref type="bibr" target="#b17">[18]</ref>. Note that we used exactly the same denoising network (σ = 0.02) for all experiments opposed to MLP, which trained specialized neural networks removing the different corruptions of experiments a-e separately. We conclude that only very little performance has to be scarified when combining a generic but powerful denoising network with the flexibility of energy minimization algorithms. parably small difference in PSNR value. Therefore, a detailed understanding for which problems and in what sense the performance of a denoising algorithm can be fully transferred to an inverse problem when the algorithm is used as a proximal operator remains an open question for future research.</p><p>Due to the efficiency of the neural network, the average runtime of our approach for image deconvolution was ≈2.5s in comparison to ≈4s of FlexISP * yielding a significant relative improvement of 37.5%. In both cases the denoising operator was evaluated on the GPU.</p><p>We again study the robustness of the proposed approach to networks trained on different noise levels. The second plot of <ref type="table" target="#tab_5">Table 3</ref> shows the optimal PSNR values attained with networks that have been trained on different standard deviations σ. As we can see the PSNRs remain very stable over a large range of different σ indicating the robustness toward the specific network that is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper we studied the use of denoising neural networks as proximal operators in energy minimization algorithms. We showed that four different algorithms using neural networks as proximal operators have the same potential fixed-points. Moreover, the particular choice of step size in the PDHG algorithm merely rescales the data fidelity (and other possible regularization) parameters. Interestingly, the noise level the neural network is trained on behaves very much like a regularization parameter derived from MAP estimates and reveals a quadratic relation between the standard deviation σ and the data fidelity parameter.</p><p>For our numerical experiments we proposed to combine the PDHG algorithm with a DnCNN-S denoising network <ref type="bibr" target="#b46">[47]</ref> as a proximal operator and the prior stacking approach of <ref type="bibr" target="#b17">[18]</ref>. Our reconstruction results and robustness tests on the exemplary problems of demosaicking and deblurring indicate that one can obtain state-of-the-art results with a fixed neural network.</p><p>We expect that this concept can significantly ease the need for problem-specific retraining of classical deep learning approaches and additionally even allows to benefit from learned natural image priors for problems where training data is not available.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Remark 3 . 1 .</head><label>31</label><figDesc>Consider replacing the proximal operator of R in the PG, ADMM, PDHG1, and PDHG2 methods by an arbitrary continuous function G. Then the fixed-point equa- tions of all four resulting algorithmic schemes are equiva- lent, and yield</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>with c (usually) denoting the operator norm [I, −D T ] 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Visual comparison of different demosaicking methods on two example images of the McMaster color image data set. To illustrate the differences in reconstruction quality we added zoomed in residual images. Apart from FlexISP * and our result, all other images are taken from [18].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Average PSNR results in [dB] for demosaicking the McMaster color image dataset. The results of all methods except CNN, FlexISP * and ours are copied from the same comparison in [18]. As expected the deep CNN from [15] which was specifically trained on demosaicking outperforms our approach. Nevertheless the results show that using a powerful denoising network as a proximal operator yields substantial results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 :</head><label>1</label><figDesc>Average PSNRs in [dB] for 11 test images for dif- ferent standard deviations σ of the Gaussian noise in a com- parison of NLM, BM3D, and our denoising networks using the DnCNN-S architecture proposed in [47]. We used the same test images as in our deconvolution experiments.</figDesc><table>σ 
Noisy NLM [3] BM3D [7] DnCNN-S 
0.02 33.99 
35.49 
36.77 
37.80 
0.03 30.47 
32.73 
34.14 
35.26 
0.04 27.99 
31.04 
32.49 
33.52 
0.05 26.06 
29.79 
31.16 
32.15 
0.06 24.50 
28.94 
30.13 
31.13 
0.07 23.19 
28.27 
29.22 
30.20 
0.08 22.08 
27.52 
28.57 
29.48 
0.09 21.00 
26.94 
27.89 
28.81 
0.10 20.14 
26.37 
27.41 
28.10 

σ. It should be noted that each σ requires an individually 
trained DnCNN-S. Although we used different noise levels 
than the one presented in [47], our results have similar mar-
gins to BM3D indicating that our trained networks represent 
state-of-the-art denoising methods. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>The table shows the optimal parameters for the 
data fidelity parameter α, the TV regularization β T V and the 
cross channel prior β Cross when denoising networks trained 
on Gaussian noise with different standard deviation σ are 
used. Below the parameters we show the average PSNR 
values in [dB] obtained on the McMaster color image data 
set. Considering the results of competing methods shown 
in Figure 4, different denoising networks yield quite good 
demosaicking performance on a wide range of different σ. 

σ 
Reconstruction PSNR in [dB] 
α 
β T V 
β Cross 

0.001 
36.05 
4000 
0.1 
0.05 

0.01 
36.74 
100 
0.01 
0.0 

0.02 
37.12 
90 
0.01 
0.0 

0.03 
36.39 
12 
0.0 
0.0 

0.05 
36.08 
800 
0.0 
0.01 

form [34] trained a network (including the different linear 
operators) on each of the five experiments separately. It is 
encouraging to see that an energy minimization algorithm 
with a generic denoising network as a proximal operator 
yields results similar to the specialized networks in experi-
ments a -d and even outperformed the latter on the problem 
e of removing motion blurs. 

When comparing to the FlexISP 
 *  results it is interesting 
to see that the performance advantage our denoising net-
works have over BM3D on plain denoising did not fully 
carry over to the deconvolution problem, yielding a com-</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head></head><label></label><figDesc>FlexISP* FlexISP* FlexISP* FlexISP* FlexISP*FlexISP* FlexISP* FlexISP* FlexISP* FlexISP*Visual comparison of different deconvolution methods on two out of 11 standard test images. The images Boat and Barbara were each corrupted with Gaussian noise (σ = 0.04, σ = 0.01) and a Gaussian blur (experiment a) as well as a motion blur (experiment e), respectively. Apart from FlexISP * and our result, all other images are taken from [18].</figDesc><table>BM3D 

24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 
24.60 dB 

MLP MLP MLP MLP MLP 
MLP 
MLP 
MLP 
MLP 
MLP 
MLP 
MLP 
MLP MLP MLP MLP MLP 

24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 
24.44 dB 

FlexISP* 
FlexISP* 
FlexISP* 
FlexISP* 
FlexISP* 
FlexISP* 
FlexISP* 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 
24.41 dB 

Ours Ours Ours Ours Ours 
Ours 
Ours 
Ours 
Ours 
Ours 
Ours 
Ours 
Ours Ours Ours Ours Ours 

17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
17.56 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.73 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
29.15 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.69 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.53 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
30.59 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 
31.67 dB 

Figure 5: </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc>Average PSNR results in [dB] for image decon- volution on a set of 11 standard grayscale images over 5 experiments with different blur kernels and noise levels as detailed in</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head></head><label></label><figDesc>DEB-BM3D [8] 24.19 26.30 21.48 22.20 28.26 24.49 IDD-BM3D [9] 24.68 27.13 21.99 22.69 29.41 25.18 FoE [32] 24.07 26.56 21.61 22.04 28.83 24.62 MLP [34] 24.76 27.23 22.20 22.75 29.42 25.27 FlexISP * [18] 24.32 26.84 21.99 22.53 29.30 25.00 Ours 24.51 27.08 21.83 21.96 30.17 25.11</figDesc><table>Deblurring method 
Reconstruction PSNR in [dB] 
a 
b 
c 
d 
e 
AVG 
EPLL [49] 
24.04 26.64 21.36 21.04 29.25 24.47 
IRLS [26] 
24.09 26.51 21.72 21.91 28.33 24.51 
LUT [23] 
24.17 26.60 21.73 22.07 28.17 24.55 
Ours, σ=0.01 
24.25 27.01 21.57 21.52 28.78 24.63 
Ours, σ=0.04 
24.56 27.10 21.95 22.40 30.35 25.27 
Ours, σ=0.06 
24.62 27.14 22.03 22.58 30.26 25.33 
Ours, σ=0.09 
24.57 27.13 21.98 22.60 29.96 25.25 
Ours, σ=0.2 
24.48 26.63 22.00 22.35 25.80 24.25 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Our code is available at https://github.com/tum-vision/ learn_prox_ops.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. M.M. and D.C. acknowledge the support of the German Research Foundation (DFG) via the research training group GRK 1564 Imaging New Modalities and the ERC Consolidator Grant "3D-Reloaded", respectively.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<title level="m">Tensorflow: Large-scale machine learning on heterogeneous systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Turning a denoiser into a super-resolver using plug and play priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brifman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Non-Local Means Denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Processing On Line</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A first-order primal-dual algorithm for convex problems with applications to imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision (JMIV)</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Plug-and-play admm for image restoration: Fixed-point convergence and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">A</forename><surname>Elgendy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Computational Imaging</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A deep visual correspondence embedding model for stereo matching costs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Video denoising by sparse 3d transform-domain collaborative filtering. European Signal Processing Conference (EUSIPCO)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image restoration by sparse 3d transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Image Processing</title>
		<editor>J. T. Astola, K. O. Egiazarian, and E. R. Dougherty</editor>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bm3d frames and variational image deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Danielyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning a deep convolutional network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image super-resolution using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">FlowNet: Learning Optical Flow with Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ilg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Häusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hazirbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Van Der Smagt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A general framework for a class of first order primal-dual algorithms for convex optimization in imaging science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences (SIIMS)</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">ProxImaL: Efficient Image Optimization using Proximal Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">F</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R.-K</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">G</forename><surname>Heidrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep joint demosaicking and denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gharbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chaurasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2016" />
			<publisher>TOG</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep discrete flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision (ACCV)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Flexisp: A flexible camera image processing framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rouf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pajk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Heidrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pulli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Special Interest Group on Computer Graphics</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning joint demosaicing and denoising based on sequential energy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Klatzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hammernik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Knobelreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computational Photography (ICCP)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mask-specific inpainting with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition (GCPR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast image deconvolution using hyper-laplacian priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A simple weight decay can improve generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hertz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deconvolution using natural image priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient deep learning for stereo matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ilg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hausser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An algorithm for minimizing the piecewise smooth MumfordShah functional</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02862</idno>
	</analytic>
	<monogr>
		<title level="m">The Little Engine that Could: Regularization by Denoising (RED)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
	<note>to appear in</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Poisson inverse problems by the plug-and-play scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Communication and Image Representation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fields of experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Nonlinear total variation based noise removal algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A machine learning approach for non-blind image deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Plug-and-play priors for bright field electron tomography and sparse interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sreehari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Venkatakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wohlberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>Buzzard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Drummy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Bouman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Imaging</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning (JMLR)</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Sharpening hyperspectral images using plug-and-play priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Teodoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Latent Variable Analysis and Signal Separation</title>
		<editor>P. Tichavský, M. Babaie-Zadeh, O. J. Michel, and N. Thirion-Moreau</editor>
		<meeting><address><addrLine>LVA ICA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Image restoration and reconstruction using variable splitting and class-adapted image priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Teodoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A T</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Plug-and-Play Priors for Model Based Reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Venkatakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Bouman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wohlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Global Conference on Signal and Information Processing</title>
		<imprint>
			<publisher>GlobalSIP</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Proximal deep structured models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A multilayer neural network for image demosaicking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Image denoising and inpainting with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep convolutional neural network for image deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.07539</idno>
		<title level="m">Semantic image inpainting with perceptual and contextual losses</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Stereo matching by training a convolutional neural network to compare image patches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zbontar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Machine Learning (JMLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3142" to="3155" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Color Demosaicking by Local Directional Interpolation and Nonlocal Adaptive Thresholding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Electronic Imaging</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">From learning models of natural image patches to whole image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
