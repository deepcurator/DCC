<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T22:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Generative ConvNets via Multi-grid Modeling and Sampling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqi</forename><surname>Gao</surname></persName>
							<email>ruiqigao@ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Lu</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Amazon</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junpei</forename><surname>Zhou</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Zhejiang University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><forename type="middle">Nian</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Generative ConvNets via Multi-grid Modeling and Sampling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This paper studies the problem of learning energy-based generative ConvNet models <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b14">15]</ref> of images. The model is in the form of a Gibbs distribution where the energy function is defined by a bottom-up convolutional neural network (ConvNet or CNN). It can be derived from the commonly used discriminative ConvNet <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b20">21]</ref> as a direct consequence of the Bayes rule <ref type="bibr" target="#b3">[4]</ref>, but unlike the discriminative ConvNet, the generative ConvNet is endowed with the gift of imagination in that it can generate images by sampling from the probability distribution of the model. As a result, the generative ConvNet can be learned in an unsupervised setting without requiring class labels. The learned model can be used as a * Equal contributions. prior model for image processing. It can also be turned into a discriminative ConvNet for classification.</p><p>The maximum likelihood learning of the energy-based generative ConvNet model follows an "analysis by synthesis" scheme: we sample the synthesized examples from the current model, usually by Markov chain Monte Carlo (MCMC), and then update the model parameters based on the difference between the observed training examples and the synthesized examples. The probability distribution or the energy function of the learned model is likely to be multi-modal if the training data are highly varied. The MCMC may have difficulty traversing different modes and may take a long time to converge. A simple and popular modification of the maximum likelihood learning is the contrastive divergence (CD) learning <ref type="bibr" target="#b9">[10]</ref>, where for each observed training example, we obtain a corresponding synthesized example by initializing a finite-step MCMC from the observed example. Such a method can be scaled up to large training datasets using mini-batch training. However, the synthesized examples may be far from fair samples of the current model, thus resulting in bias of the learned model parameters. A modification of CD is persistent CD <ref type="bibr" target="#b41">[42]</ref>, where the MCMC is still initialized from the observed example at the initial learning epoch. However, in each subsequent learning epoch, the finite-step MCMC is initialized from the synthesized example of the previous epoch. Running persistent chains may make the synthesized examples less biased by the observed examples, although the persistent chains may still have difficulty traversing different modes of the learned model.</p><p>To address the above challenges under the constraint of finite budget MCMC, we propose a multi-grid method to learn the energy-based generative ConvNet models at multiple scales or grids. Specifically, for each training image, we obtain its multi-grid versions by repeated down-scaling. Our method learns a separate generative ConvNet model at each grid. Within each iteration of our learning algorithm, for each observed training image, we generate the corresponding synthesized images at multiple grids. Specifically, we initialize the finite-step MCMC sampling from the minimal 1 × 1 version of the training image, and the synthesized image at each grid serves to initialize the finite-step MCMC that samples from the model of the subsequent finer grid. See <ref type="figure" target="#fig_0">Fig. 1</ref> for an illustration, where we sample images sequentially at 3 grids, with 30 steps of the Langevin dynamics at each grid. After obtaining the synthesized images at the multiple grids, the models at the multiple grids are updated separately and simultaneously based on the differences between the synthesized images and the observed training images at different grids.</p><p>The advantages of the proposed method are as follows.</p><p>(1) The finite-step MCMC is initialized from the 1 × 1 version of the observed image, instead of the original observed image. Thus the synthesized image is much less biased by the observed image compared to the original CD.</p><p>(2) The learned models at coarser grids are expected to be smoother than the models at finer grids. Sampling the models at increasingly finer grids sequentially is like a simulated annealing process <ref type="bibr" target="#b18">[19]</ref> that helps the MCMC to mix.</p><p>(3) Unlike the original CD or persistent CD, the learned models are equipped with a fixed budget MCMC to generate new synthesized images from scratch, because we only need to initialize the MCMC by sampling from the onedimensional histogram of the 1 × 1 version of the training images.</p><p>We show that the proposed method can learn realistic models of images. The learned models can be used for image processing such as image inpainting. The learned feature maps can be used for subsequent tasks such as classification.</p><p>The contributions of our paper are as follows. We propose a multi-grid method for learning energy-based generative ConvNet models. We show empirically that the proposed method outperforms the original CD, persistent CD, as well as the single-grid learning. More importantly, we show that a small budget MCMC is capable of generating diverse and realistic patterns. The deep energy-based models have not received the attention they deserve in the recent literature because of the reliance on MCMC sampling. It is our hope that this paper will stimulate further research on designing efficient MCMC algorithms for learning deep energy-based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Our method is related to CD <ref type="bibr" target="#b9">[10]</ref> for training energybased models. In general, both the data distribution of the observed training examples and the learned model distribution can be multi-modal, and the data distribution can be even more multi-modal than the model distribution. The finite-step MCMC of CD initialized from the data distribution may only explore local modes around the training examples, thus the finite-step MCMC may not get close to the model distribution. This can also be the case with persistent CD <ref type="bibr" target="#b41">[42]</ref>. In contrast, our method initializes the finite-step MCMC from the minimal 1 × 1 version of the original image, and the sampling of the model at each grid is initialized from the image sampled from the model at the previous coarser grid. The model distribution at the coarser grid is expected to be smoother than the model distribution at the finer grid, and the coarse to fine MCMC is likely to generate varied samples from the learned models. As a result, the learned models obtained by our method can be closer to maximum likelihood estimate than the original CD.</p><p>The multi-grid Monte Carlo method originated from statistical physics <ref type="bibr" target="#b8">[9]</ref>. The motivation for multi-grid Monte Carlo is that reducing the scale or resolution leads to a smoother or less multi-modal distribution. Our work is perhaps the first to apply the multi-grid sampling to the learning of deep energy-based models. The difference between our method and the multi-grid MCMC in statistical physics is that in the latter, the distribution of the lower resolution is obtained from the distribution of the higher resolution. In our work, the models at different grids are learned from training images at different resolutions directly and separately.</p><p>Besides energy-based generative ConvNet model, another popular deep generative model is the generator network or implicit generative model which maps the latent vector that follows a simple prior distribution to the image via a top-down ConvNet. The model is usually trained together with an assisting model such as an inferential model as in the variational auto-encoder (VAE) <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b30">31]</ref>, or a discriminative model as in the generative adversarial networks (GAN) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b36">37]</ref>. The focus of this paper is on training deep energy-based models, without resorting to a different class of models, so that we do not need to be concerned with the mismatch between the two different classes of models.</p><p>Our learning method is based on maximum likelihood. Recently, building on the early work of <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">22]</ref> have developed an introspective learning method to learn the energy-based model, where the energy function is discriminatively learned. It is possible to apply multi-grid learning and sampling to their method.</p><p>We would like to emphasize that this paper is not another paper on GAN. This paper seeks to answer the following question: Whether it is possible to learn the deep energybased probabilistic models from big datasets by maximum likelihood type of algorithms, without relying on an extra network such as an implicit generative network? We believe this is a fundamental question, especially because an energy-based model corresponds directly to a discriminative classifier (see subsection 3.2). Our paper answers this question in affirmative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Generative ConvNet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">The model</head><p>Let Y be the image defined on a squared (or rectangle) grid. We use p θ (Y ) to denote the probability distribution of Y with parameter θ . The energy-based generative ConvNet model is as follows <ref type="bibr" target="#b44">[45]</ref>:</p><formula xml:id="formula_0">p θ (Y ) = 1 Z(θ ) exp [ f θ (Y )] p 0 (Y ),<label>(1)</label></formula><p>where p 0 (Y ) is the reference distribution such as Gaussian white noise p 0 (Y ) ∝ exp − Y 2 /2σ 2 (or a uniform distribution within a bounded range). f θ (Y ) is defined by a bottom-up ConvNet whose parameters are denoted by θ . The normalizing constant</p><formula xml:id="formula_1">Z(θ ) = exp [ f θ (Y )] p 0 (Y )dY is analytically intractable. p θ can be written in the form of an energy-based model: p θ (Y ) = 1 Z(θ ) exp[−E θ (Y )]. The energy function is E θ (Y ) = 1 2σ 2 Y 2 − f θ (Y ).<label>(2)</label></formula><p>The local energy minima <ref type="bibr" target="#b12">[13]</ref> satisfy an auto-encoder [45]</p><formula xml:id="formula_2">Y σ 2 = ∂ ∂Y f θ (Y ).</formula><p>The learned model is likely to be multimodal if the training data are highly varied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Correspondence to discriminative ConvNet</head><p>Model (1) corresponds to a classifier in the following sense <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b14">15]</ref>. Suppose there are K categories,</p><formula xml:id="formula_3">p θ k (Y ), for k = 1, ..., K, in addition to the background cat- egory p 0 (Y ). The ConvNets f θ k (Y ) for k = 1, .</formula><p>.., K may share common lower layers. Let ρ k be the prior probability of category k, k = 0, ..., K. Then the posterior probability for classifying an example Y to the category k is a softmax multi-class classifier</p><formula xml:id="formula_4">Pr(k|Y ) = exp( f θ k (Y ) + b k ) ∑ K k=0 exp( f θ k (Y ) + b k ) ,<label>(3)</label></formula><p>where </p><formula xml:id="formula_5">b k = log(ρ k /ρ 0 ) − log Z(θ k ), and for k = 0, f θ 0 (Y ) = 0, b 0 = 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Maximum likelihood</head><p>While the discriminative ConvNet must be learned in a supervised setting, the generative ConvNet model p θ (Y ) in (1) can be learned from unlabeled data by maximum likelihood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Learning and sampling</head><p>Suppose we observe training examples {Y i , i = 1, ..., n} from an unknown data distribution P data (Y ). The maximum likelihood learning seeks to maximize the log-likelihood function</p><formula xml:id="formula_6">L(θ ) = 1 n ∑ n i=1 log p θ (Y i ).<label>(4)</label></formula><p>If the sample size n is large, the maximum likelihood estimator minimizes the Kullback-Leibler divergence</p><formula xml:id="formula_7">KL(P data p θ ) from the data distribution P data to the model distribution p θ . The gradient of L(θ ) is L ′ (θ ) = 1 n ∑ n i=1 ∂ ∂ θ f θ (Y i ) − E θ ∂ ∂ θ f θ (Y ) ,<label>(5)</label></formula><p>where E θ denotes the expectation with respect to p θ (Y ). The key to the above identity is that</p><formula xml:id="formula_8">∂ ∂ θ log Z(θ ) = E θ [ ∂ ∂ θ f θ (Y )].</formula><p>The expectation in equation <ref type="formula" target="#formula_7">(5)</ref> is analytically intractable and has to be approximated by MCMC, such as the Langevin dynamics <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b6">7]</ref>, which iterates the following step:</p><formula xml:id="formula_9">Y τ+∆τ = Y τ − ∆τ 2 ∂ ∂Y E θ (Y τ ) + √ ∆τZ τ = Y τ − ∆τ 2 Y τ σ 2 − ∂ ∂Y f θ (Y τ ) + √ ∆τZ τ ,<label>(6)</label></formula><p>where τ indexes the time of the Langevin dynamics, ∆τ is the step size, and Z τ ∼ N(0, I) is Gaussian white noise. Let the distribution of Y τ be p τ , then KL(p τ ||p θ ) → 0 monotonically as τ → ∞ according to the second law of thermodynamics <ref type="bibr" target="#b2">[3]</ref>. KL(p τ ||p θ ) can be decomposed into energy and entropy. The gradient descent part of the Langevin dynamics reduces the energy, while the Brownian motion part increases the entropy. A Metropolis-Hastings step may be added to correct for the finite step size ∆τ. We have also implemented Hamiltonian Monte Carlo (HMC) for sampling the generative ConvNet <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b3">4]</ref>.</p><p>We can runñ parallel chains of the Langevin dynamics according to <ref type="bibr" target="#b5">(6)</ref> to obtain the synthesized examples</p><formula xml:id="formula_10">{Ỹ i , i = 1, ...,ñ}. The Monte Carlo approximation to L ′ (θ ) is L ′ (θ ) ≈ 1 n ∑ n i=1 ∂ ∂ θ f θ (Y i ) − 1 n ∑˜n i=1 ∂ ∂ θ f θ (Ỹ i ) (7) = ∂ ∂ θ 1 n ∑˜n i=1 E θ (Ỹ i ) − 1 n ∑ n i=1 E θ (Y i ) ,</formula><p>which is used to update θ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Contrastive divergence</head><p>The MCMC sampling of p θ may take a long time to converge, especially if the learned p θ is multi-modal, which is often the case because P data is usually multi-modal. In order to learn from large datasets, we can only afford small budget MCMC, i.e., within each learning iteration, we can only run MCMC for a small number of steps. To meet such a challenge, <ref type="bibr" target="#b9">[10]</ref> proposed the contrastive divergence (CD) method, where within each learning iteration, we initialize the finite-step MCMC from each Y i in the current training batch to obtain a synthesized exampleỸ i . The parameters are then updated according to the learning gradient <ref type="bibr" target="#b6">(7)</ref>.</p><p>Let M θ be the transition kernel of the finite-step MCMC that samples from p θ (Y ). For any probability distribution p(Y ) and any Markov transition kernel M,</p><formula xml:id="formula_11">let M p(Y ′ ) = p(Y )M(Y,Y ′ )</formula><p>dY denote the marginal distribution obtained after running M starting from p. The learning gradient of CD approximately follows the gradient of the difference between two Kullback-Leibler (KL) divergences:</p><formula xml:id="formula_12">KL(P data p θ ) − KL(M θ P data p θ ),<label>(8)</label></formula><p>thus the name "contrastive divergence". If M θ P data is close to p θ , then the second divergence is small, and the CD estimate is close to maximum likelihood which minimizes the first divergence. However, it is likely that P data and the learned p θ are multi-modal. It is expected that p θ is smoother than P data , i.e., P data is "colder" than p θ in the language of simulated annealing <ref type="bibr" target="#b18">[19]</ref>. If P data is different from p θ , it is unlikely that M θ P data becomes much closer to p θ due to the trapping of local modes. This may lead to bias in the CD estimate. A persistent version of CD <ref type="bibr" target="#b41">[42]</ref> is to initialize the MCMC from the observed Y i in the beginning, and then in each learning epoch, the MCMC is initialized from the synthesizedỸ i obtained in the previous epoch. The persistent CD may still face the challenge of traversing and exploring different local energy minima.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Modified and adversarial CDs</head><p>This subsection explains modifications of CD, including methods based on an additional generator network. It can be skipped in the first reading.</p><p>The original CD initializes MCMC sampling from the data distribution P data . We may modify it by initializing MCMC sampling from a given distribution P 0 , in the hope that M θ P 0 is closer to p θ than M θ P data . The learning gradient approximately follows the gradient of</p><formula xml:id="formula_13">KL(P data p θ ) − KL(M θ P 0 p θ ).<label>(9)</label></formula><p>That is, we run a finite-step MCMC from a given initial distribution P 0 , and use the resulting samples as synthesized examples to approximate the expectation in (5). The approximation can be made more accurate using annealed importance sampling <ref type="bibr" target="#b31">[32]</ref>. Following the idea of simulated annealing, P 0 should be a "smoother" distribution than p θ (the extreme case is to start from white noise P 0 ). Unlike persistent CD, here the finite-step MCMC is non-persistent, sometimes also referred to as "cold start", where the MCMC is initialized from a given P 0 within each learning iteration, instead of from the examples synthesized by the previous learning epoch. The cold start version is easier to implement for mini-batch learning.</p><p>With the multi-grid method (to be introduced in the next section), at each grid, P 0 is the distribution of the images generated by the previous coarser grid. At the smallest grid, P 0 is the one-dimensional histogram of the 1 × 1 versions of the training images.</p><p>Another possibility is to recruit a generator network q α (Y ) as an approximated direct sampler <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b4">5]</ref>, so that p θ and q α can be jointly learned by the adversarial CD:</p><formula xml:id="formula_14">min p θ max q α [KL(P data p θ ) − KL(q α p θ )] .<label>(10)</label></formula><p>That is, the learning of p θ is modified CD with q α supplying synthesized examples, and the learning of q α is based on min q α KL(q α p θ ), which is a variational approximation. The adversarial CD is related to Wasserstein GAN <ref type="bibr" target="#b0">[1]</ref>, except that the former regularizes the entropy of the generator, while the latter regularizes the critic.</p><p>[44] also studied the problem of joint learning of the energy-based model and the generator model. The learning of the energy-based model is based on the modified CD:</p><formula xml:id="formula_15">KL(P data p θ ) − KL(M θ q α p θ ),<label>(11)</label></formula><p>with q α taking the role of P 0 , whereas the learning of the generator is based on how M θ q α modifies q α , and is accomplished by a t+1 = arg min α KL(M θ q α t q α ), i.e., q α accumulates MCMC transitions to be close to the stationary distribution of M θ , which is p θ . In this paper, we shall not consider recruiting a generator network, so that we do not need to worry about the mismatch between the generator model and the energy-based model. In other words, instead of relying on a learned approximate direct sampler, we endeavor to develop small budget MCMC for sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Multi-grid modeling and sampling</head><p>We propose a multi-grid method for learning and sampling generative ConvNet models.  i } according to equation <ref type="bibr" target="#b6">(7)</ref>. Algorithm 1 provides the details of the multi-grid method.</p><p>In the above sampling scheme, p (0) can be sampled directly because it is a one-dimensional histogram. Each p (s) is expected to be smoother than p (s+1) . Thus the sampling scheme is similar to simulated annealing, where we run finite-step MCMC through a sequence of probability distributions that are increasingly multi-modal (or cold), in the hope of reaching and exploring major modes of the model distributions. The learning process then shifts these major modes toward the observed examples, while sharpening these modes along the way, in order to memorize the observed examples with these major modes of the model distributions.</p><p>Let P </p><formula xml:id="formula_16">For s = 1, ..., S, update θ (s) t+1 = θ (s) t + γ t L ′ (θ (s) t ), with step size γ t , where L ′ (θ (s)</formula><p>t ) is computed according to equation <ref type="formula">(7)</ref>. <ref type="bibr">6:</ref> Let t ← t + 1. θ (s) . The learning gradient of the multi-grid method at grid s approximately follows the gradient of the difference between two KL divergences:  </p><formula xml:id="formula_17">KL P (s) data p (s) θ (s) − KL M (s) θ (s) P (s) θ (s−1) p (s) θ (s) .<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>Project page: The code and more results can be found at http://www.stat.ucla.edu/˜ruiqigao/ multigrid/main.html.</p><p>We learn the models at 3 grids: 4 × 4, 16 × 16 and 64 × 64, which we refer to as grid1, grid2 and grid3, respectively. That is, we set S = 3 (number of grids), d = 4 (reducing each 4 × 4 block to a pixel in the down-scaling operation).</p><p>We conduct qualitative and quantitative experiments to evaluate our method with respect to several baseline methods. The first baseline is the single-grid method: starting from a 1 × 1 image, we directly up-scale it to 64 × 64 and sample a 64 × 64 image using a single generative ConvNet. The other two baselines are CD1 (running 1 step Langevin dynamics from the observed images) and persistent CD. Both CD baselines initialize the MCMC sampling from the observed images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Implementation details</head><p>The training images are resized to 64 × 64. Since the models of the three grids act on images of different scales, we design a specific ConvNet structure per grid: grid1 has a 3-layer network with 5 × 5 stride 2 filters at the first layer and 3 × 3 stride 1 filters at the next two layers; grid2 has a 4-layer network with 5 × 5 stride 2 filters at the first layer and 3 × 3 stride 1 filters at the next three layers; grid3 has a 3-layer network with 5 × 5 stride 2 filters at the first layer, 3 × 3 stride 2 filters at the second layer, and 3 × 3 stride 1 filters at the third layer. Numbers of channels are 96−128−256 at grid1 and grid3, and 96−128−256−512 at grid2. A fully-connected layer with 1 channel output is added on top of every grid to get the value of f θ (Y ). Batch normalization <ref type="bibr" target="#b13">[14]</ref> and leaky ReLU activations are applied after every convolution. At each iteration, we run l = 30 steps of the Langevin dynamics for each grid with √ ∆τ = 0.3. All networks are trained simultaneously with mini-batches of size 100 and an initial learning rate of 0.3. Learning rate is decayed logarithmically every 10 iterations.</p><p>For CD1, persistent CD and the single-grid method, we follow the same setting as the multi-grid method except that for persistent CD and the single-grid method, we set the Langevin steps to 90 to maintain the same MCMC budget as the multi-grid method. We use the same network structure of grid3 for these baseline methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Synthesis</head><p>We learn multi-grid models from five datasets: CelebA <ref type="bibr" target="#b26">[27]</ref>, Large-scale Scene Understanding (LSUN) <ref type="bibr" target="#b40">[41]</ref>, CIFAR-10 <ref type="bibr" target="#b19">[20]</ref>, Street View Housing Numbers (SVHN) <ref type="bibr" target="#b33">[34]</ref> and MIT places205 <ref type="bibr" target="#b46">[47]</ref>. In the CelebA dataset, we randomly sample 10,000 images for training. <ref type="figure" target="#fig_6">Fig. 2</ref> show synthesized images generated by models learned from CelebA dataset. We also show synthesized images generated by models learned by DCGAN <ref type="bibr" target="#b36">[37]</ref> and the single-grid method. CD1 and persistent CD cannot synthesize realistic images, thus we do not bother to show their synthesis results. Compared with the single-grid method, images generated by the multi-grid method are more realistic. The results from multi-grid models are comparable to the results from DCGAN. <ref type="figure" target="#fig_7">Fig. 3</ref> shows synthesized images from models learned from the LSUN bedrooms dataset, which Observed DCGAN single-grid method multi-grid method  contains more than 3 million training images. The SVHN dataset consists of color images of house numbers collected by Google Street View. The training set consists of 73,257 images and the testing set has 26,032 images. We learn the models in the unsupervised manner. MIT places205 contains images of 205 scene categories. We learn from a sin-gle category. Please refer to the supplementary materials for synthesized results by models learned from SVHN dataset and several categories of MIT places205 dataset.  CIFAR-10 includes various object categories and has 50,000 training examples. <ref type="figure" target="#fig_8">Fig. 4</ref> shows the synthesized images generated by models learned by the multi-grid method conditional on each category. In this experiment, we run 40 steps of the Langevin dynamics for each grid, and in the final synthesis after learning, we disable the noise term in the Langevin dynamics, which slightly improves the synthesis quality. We evaluate the quality of synthesized images quantitatively using the average inception score <ref type="bibr" target="#b39">[40]</ref> in <ref type="table" target="#tab_2">Table 1</ref>. The multi-grid method gets comparable inception score as DCGAN as reported in <ref type="bibr" target="#b25">[26]</ref>.</p><p>To check the diversity of Langevin dynamics sampling, we synthesize images by initializing the Langevin dynamics from the same 1 × 1 image. As shown in <ref type="figure" target="#fig_9">Fig. 5</ref>, after 90 steps of Langevin dynamics, the sampled images from the same 1 × 1 image are different from each other.  To evaluate the features learned by the multi-grid method, we perform a semi-supervised classification experiment by following the same procedure outlined in <ref type="bibr" target="#b36">[37]</ref>. That is, we use the multi-grid method as a feature extractor. We first train a multi-grid model on the combination of SVHN training and testing sets in an unsupervised way. Then we train a regularized L2-SVM on the learned representations of grid 3. For fair comparison, we adopt the discriminator structure of <ref type="bibr" target="#b36">[37]</ref> for grid 3, which has 4 convolutional layers of 5 × 5 filters with 64, 128, 256 and 512 channels respectively. The features from all the convolutional layers are max pooled and concatenated to form a 15,360-dimensional vector. We randomly sample 1000, 2000 and 4000 labeled examples from the training dataset to train the SVM and test on the testing dataset. Within the same setting, we compare the learned features of the multi-grid method with the single-grid method, persistent CD <ref type="bibr" target="#b41">[42]</ref>, one-step CD <ref type="bibr" target="#b9">[10]</ref>, Wasserstein GAN <ref type="bibr" target="#b0">[1]</ref>, deep directed generative models <ref type="bibr" target="#b15">[16]</ref> and DCGAN <ref type="bibr" target="#b36">[37]</ref>. <ref type="table" target="#tab_3">Table 2</ref> shows the classification results, indicating that the multi-grid method learns strong features.</p><p>Next we try to combine the learned features of three grids together. Specifically, we build a two-layer classification CNN on top of the top layer feature maps of three grids. The first layer is a 3 × 3 stride 1 convolutional layer with 64 channels operated separately on the feature maps of the three grids. Then the outputs from the three grids are concatenated to form a 34,624-dimensional vector. A fullyconnected layer is added on top of the vector. We train this classifier using 1000, 2000 and 4000 labeled examples that are randomly sampled from the training set. As shown in <ref type="table">Table 3</ref>, our method achieves a test error rate of 19.73% for 1, 000 labeled images. For comparison, we train a classification network from scratch with the same structure (three networks as used in the multi-grid method plus two layers for classification) on the same labeled training data. It has a significantly higher error rate of 39.04% for 1, 000 labeled training images. Our method also outperforms some methods that are specifically designed for semi-supervised learning, such as DGN <ref type="bibr" target="#b16">[17]</ref>, virtual adversarial <ref type="bibr" target="#b29">[30]</ref> and auxiliary deep generative model <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Image inpainting</head><p>We further test our method on image inpainting. In this task, we try to learn the conditional distribution p θ (Y M |YM) by our models, where M consists of pixels to be masked, andM consists of pixels not to be masked. In the training stage, we randomly place the mask on each training image, but we assume Y M is observed in training. We follow the same learning and sampling algorithm as in Algorithm 1, except that in the sampling step (i.e., step 4 in Algorithm 1), in each Langevin step, only the masked part of the image is updated, and the unmasked part remains fixed as observed. This is a generalization of the pseudo-likelihood estimation <ref type="bibr" target="#b1">[2]</ref>, which corresponds to the case where M consists of one pixel. It can also be considered a form of associative memory <ref type="bibr" target="#b12">[13]</ref>. After learning p θ (Y M |YM) from the fully observed training images, we then use it to inpaint the masked testing images, where the masked parts are not observed.  We use 10,000 face images randomly sampled from CelebA dataset to train the model. We set the mask size at 32 × 32 for training. During training, the size of the mask is fixed but the position is randomly selected for each training image. Another 1,000 face images are randomly selected from CelebA dataset for testing. We find that during the testing, the mask does not need to be restricted to 32 × 32 square mask. So we test three different shapes of masks: 1) 32 × 32 square mask, 2) doodle mask with approximately 25% missing pixels, and 3) pepper and salt mask with approximately 60% missing pixels. <ref type="figure" target="#fig_10">Fig. 6</ref> shows some inpainting examples. We perform quantitative evaluations using two metrics: 1) reconstruction error measured by the per pixel difference and 2) peak signal-to-noise ratio (PSNR). Metrics are computed between the inpainting results obtained by different methods and the original face images on the masked pixels. We compare with persistent CD, CD1 and the single-grid method. We also compare with the ContextEncoder <ref type="bibr" target="#b35">[36]</ref> (CE). We re-train the CE model on 10,000 training face images for fair comparison. As our tested masks are not in the image center, we use the "inpaintRandom" version of the CE code and randomly place a 32 × 32 mask in each image during training. The results are shown in <ref type="table" target="#tab_4">Table 4</ref>. It shows that the multi-grid method works well for the inpainting task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>This paper seeks to address the fundamental question of whether we can learn energy-based generative ConvNet models purely by themselves without recruiting extra networks such as generator networks. This question is important both conceptually and practically because the energybased generative ConvNet models correspond directly to discriminative ConvNet classifiers. Being able to learn and sample from such models also provides us a valuable alternative to GAN methods, by relieving us from the concerns with issues such as mismatch between two different classes of models, as well as instability in learning.</p><p>To answer the above question, we propose a multi-grid method for learning energy-based generative ConvNet models. Our work seeks to facilitate the learning of such models by developing small budget MCMC initialized from a simple distribution for sampling from the learned models. We show that our method can learn realistic models of images and the learned models can be useful for tasks such as image processing and classification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Synthesized images at multi-grids. From left to right: 4× 4 grid, 16 × 16 grid and 64 × 64 grid. Synthesized image at each grid is obtained by 30 step Langevin sampling initialized from the synthesized image at the previous coarser grid, beginning with the 1 × 1 grid.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>For an image Y , let (Y (s) , s = 0, ..., S) be the multi-grid versions of Y , with Y (0) being the minimal 1 × 1 version of Y , and Y (S) = Y . For each Y (s) , we can divide the image grid into squared blocks of d × d pixels. We can reduce each d × d block into a single pixel by averaging the intensity values of the d × d pixels. Such a down-scaling operation maps Y (s) to Y (s−1) . Conversely, we can also define an up-scaling operation, by expanding each pixel of Y (s−1) into a d × d block of con- stant intensity to obtain an up-scaled versionŶ (s) of Y (s−1) . The up-scaledŶ (s) is not identical to the original Y (s) be- cause the high resolution details are lost. The mapping from Y (s) to Y (s−1) is a linear projection onto a set of orthogonal basis vectors, each of which corresponds to a d × d block. The up-scaling operation is a pseudo-inverse of this linear mapping. In general, d does not even need to be an integer (e.g., d = 1.5) for the existence of the linear mapping and its pseudo-inverse. Let p (s) θ (s) (Y (s) ) be the energy-based generative ConvNet model at grid s. p (0) can be simply modeled by a one- dimensional histogram of Y (0) pooled from the 1 × 1 ver- sions of the training images. Within each learning iteration, for each training image Y i in the current learning batch, we initialize the finite- step MCMC from the 1 × 1 image Y (0) i . For s = 1, ..., S, we sample from the current p</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>θ</head><label></label><figDesc>(s) (Y (s) ) by running l steps of the Langevin dynamics from the up-scaled version of Y (s−1) i sampled at the previous coaser grid. After that, for s = 1, ..., S, we update the model parameters θ (s) based on the difference between the synthesized {Ỹ (s) i } and the ob- served {Y (s)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>i</head><label></label><figDesc>be the data distribution of {Y (s) i }. Let p (s) θ (s) be the model at grid s. Let P (s) θ (s−1) be the up-scaled version of the model p (s−1) θ (s−1) . Specifically, let Y (s−1) ∼ p (s−1) θ (s−1) be a ran-, s = 1, ..., S, i = 1, ..., n}, (2) number of Langevin steps l, (3) number of learning iterations T . Output: (1) estimated parameters (θ (s) , s = 1, ..., S), (2) synthesized examples {Ỹ (s) i , s = 1, ..., S, i = 1, ..., n}. 1: Let t ← 0, initialize θ (s) , s = 1, ..., S.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>7: until t = T dom example at grid s − 1, and letŶ (s) be the up-scaled ver- sion of Y (s−1) , then P (s) θ (s−1) is the distribution ofŶ (s) . Let M (s) θ (s) be the Markov transition kernel of l-step Langevin dynamics that samples p (s)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Synthesized images from models learned from the CelebA dataset. From left to right: observed images, images synthesized by DCGAN [37], single-grid method and multi-grid method. CD1 and persistent CD cannot synthesize realistic images and their results are not shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Synthesized images generated by the multi-grid models learned from the LSUN bedrooms dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Synthesized images generated by the multi-grid models learned from the CIFAR-10 dataset. Each row illustrates a category, and the multi-grid models are learned conditional on the category. From top to bottom: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Synthesized images by initializing the Langevin dynamics sampling from the same 1 × 1 image. Each block of 4 images are generated from the same 1 × 1 image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Inpainting examples on CelebA dataset. In each block from left to right: the original image, masked input, inpainted image by the multi-grid method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>θ (s) by creating details at the current resolution. If we use the original CD by initializing MCMC from Pdata , and we may not expect the resulting distribution to be close to the target p</figDesc><table>P 

(s) 

θ (s−1) is smoother than p 

(s) 

θ (s) , and M 

(s) 

θ (s) will evolve P 

(s) 

θ (s−1) to 
a distribution close to p 

(s) 

(s) 

data , then we are sampling a multi-modal (cold) dis-
tribution p 

(s) 

θ (s) by initializing from a presumably even more 
multi-modal (or colder) distribution P 

(s) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 .</head><label>1</label><figDesc>Inception scores on CIFAR-10.</figDesc><table>Real images 
DCGAN 
multi-grid method 
Inception score 
11.237 
6.581 
6.565 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 2 .</head><label>2</label><figDesc>Classification error of L2-SVM trained on the features learned from SVHN.</figDesc><table>Test error rate with # of labeled images 1,000 2,000 4,000 
Persistent CD [42] 
45.74 39.47 34.18 
One-step CD [10] 
44.38 35.87 30.45 
Wasserstein GAN [1] 
43.15 38.00 32.56 
Deep directed generative models [16] 44.99 34.26 27.44 
DCGAN[37] 
38.59 32.51 29.37 
single-grid method 
36.69 30.87 25.60 
multi-grid method 
30.23 26.54 22.83 

Table 3. Classification error of CNN classifier trained on the fea-
tures of three grids learned from SVHN. 

Test error rate with # of labeled images 1,000 2,000 4,000 
DGN [17] 
36.02 
-
-
Virtual adversarial [30] 
24.63 
-
-
Auxiliary deep generative model [29] 
22.86 
-
-
Supervised CNN with the same structure 39.04 22.26 15.24 
multi-grid method + CNN classifier 
19.73 15.86 12.71 

6.3. Unsupervised feature learning for classfication 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 4 .</head><label>4</label><figDesc>Quantitative evaluations for three types of masks. Lower values of error are better. Higher values of PSNR are better. PCD, CD1, SG, CE and MG indicate persistent CD, one-step CD, single- grid method, ContextEncoder and multi-grid method, respectively.</figDesc><table>Mask 
PCD 
CD1 
SG 
CE 
MG 
Mask 
0.056 
0.081 
0.066 
0.045 
0.042 
Error 
Doodle 
0.055 
0.078 
0.055 
0.050 
0.045 
Pepper 
0.069 
0.084 
0.054 
0.060 
0.036 
Mask 
12.81 
12.66 
15.97 
17.37 
16.42 
PSNR 
Doodle 
12.92 
12.68 
14.79 
15.40 
16.98 
Pepper 
14.93 
15.00 
15.36 
17.04 
19.34 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>The work is supported by DARPA SIMPLEX N66001-15-C-4035, ONR MURI N00014-16-1-2007, DARPA ARO W911NF-16-1-0579, and DARPA N66001-17-2-4029. We thank Erik Nijkamp for his help with writing and coding.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
<note type="report_type">Wasserstein gan. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Spatial interaction and the statistical analysis of lattice systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Besag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="192" to="236" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Elements of information theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-N</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6296</idno>
		<title level="m">Generative modeling of convolutional neural networks</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Calibrating energy-based generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Almahairi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.01691</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep generative image models using a laplacian pyramid of adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1486" to="1494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Riemann manifold langevin and hamiltonian monte carlo methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Girolami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Calderhead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="214" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multigrid monte carlo method. conceptual foundations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Sokal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review D</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">2035</biblScope>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised discovery of nonlinear structure using contrastive backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="725" to="731" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural networks and physical systems with emergent collective computational abilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
		<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="2554" to="2558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Introspective classification with convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lazarow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Deep directed generative models with energy-based probability estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03439</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="3581" to="3589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Optimization by simulated annealing. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Gelatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Introspective neural networks for generative modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lazarow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2774" to="2783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A tutorial on energy-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning deep energy models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.00797</idno>
	</analytic>
	<monogr>
		<title level="m">Contrastive divergence vs. amortized mle</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3730" to="3738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning FRAME models using CNN filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.05473</idno>
		<title level="m">Auxiliary deep generative models</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distributional smoothing by virtual adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">stat</title>
		<imprint>
			<biblScope unit="volume">1050</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Neural variational inference and learning in belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1791" to="1799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Annealed importance sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Mcmc using hamiltonian dynamics. Handbook of Markov Chain Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS workshop on deep learning and unsupervised feature learning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2011</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning deep energy models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1105" to="1112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Context encoders: Feature learning by inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2536" to="2544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Construction of a largescale image dataset using deep learning with humans in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">Y Y Z S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S J</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.03365</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Training restricted boltzmann machines using approximations to the likelihood gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tieleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1064" to="1071" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning generative models via discriminative approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.09408</idno>
		<title level="m">Cooperative training of descriptor and generator networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A theory of generative convnet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Synthesizing dynamic patterns by spatial-temporal generative convnet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7093" to="7101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning deep features for scene recognition using places database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="487" to="495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Grade: Gibbs reaction and diffusion equitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="847" to="854" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
