<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T23:17+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pairwise Confusion for Fine-Grained Visual Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhimanyu</forename><surname>Dubey</surname></persName>
							<email>dubeya@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otkrist</forename><surname>Gupta</surname></persName>
							<email>otkrist@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Guo</surname></persName>
							<email>peiguo@cs.byu.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Brigham Young University</orgName>
								<address>
									<postCode>84602</postCode>
									<settlement>Provo</settlement>
									<region>UT</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Raskar</surname></persName>
							<email>raskar@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Farrell</surname></persName>
							<email>farrell@cs.byu.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Brigham Young University</orgName>
								<address>
									<postCode>84602</postCode>
									<settlement>Provo</settlement>
									<region>UT</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Naik</surname></persName>
							<email>naik@mit.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Harvard University</orgName>
								<address>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Pairwise Confusion for Fine-Grained Visual Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract. Fine-Grained Visual Classification (FGVC) datasets contain small sample sizes, along with significant intra-class variation and interclass similarity. While prior work has addressed intra-class variation using localization and segmentation techniques, inter-class similarity may also affect feature learning and reduce classification performance. In this work, we address this problem using a novel optimization procedure for the end-to-end neural network training on FGVC tasks. Our procedure, called Pairwise Confusion (PC) reduces overfitting by intentionally introducing confusion in the activations. With PC regularization, we obtain state-ofthe-art performance on six of the most widely-used FGVC datasets and demonstrate improved localization ability. PC is easy to implement, does not need excessive hyperparameter tuning during training, and does not add significant overhead during test time.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Fine-Grained Visual Classification (FGVC) task focuses on differentiating between hard-to-distinguish object classes, such as species of birds, flowers, or animals; and identifying the makes or models of vehicles. FGVC datasets depart from conventional image classification in that they typically require expert knowledge, rather than crowdsourcing, for gathering annotations. FGVC datasets contain images with much higher visual similarity than those in large-scale visual classification (LSVC). Moreover, FGVC datasets have minute inter-class visual differences in addition to the variations in pose, lighting and viewpoint found in LSVC <ref type="bibr" target="#b0">[1]</ref>. Additionally, FGVC datasets often exhibit long tails in the data distribution, since the difficulty of obtaining examples of different classes may vary. This combination of small, non-uniform datasets and subtle inter-class differences makes FGVC challenging even for powerful deep learning algorithms.</p><p>Most of the prior work in FGVC has focused on tackling the intra-class variation in pose, lighting, and viewpoint using localization techniques <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>, and by augmenting training datasets with additional data from the Web <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>However, we observe that prior work in FGVC does not pay much attention to the problems that may arise due to the inter-class visual similarity in the feature extraction pipeline. Similar to LSVC tasks, neural networks for FGVC tasks are typically trained with cross-entropy loss <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>. In LSVC datasets such as ImageNet <ref type="bibr" target="#b9">[10]</ref>, strongly discriminative learning using the cross-entropy loss is successful in part due to the significant inter-class variation (compared to intraclass variation), which enables deep networks to learn generalized discriminatory features with large amounts of data.</p><p>We posit that this formulation may not be ideal for FGVC, which shows smaller visual differences between classes and larger differences within each class than LSVC. For instance, if two samples in the training set have very similar visual content but different class labels, minimizing the cross-entropy loss will force the neural network to learn features that distinguish these two images with high confidence-potentially forcing the network to learn sample-specific artifacts for visually confusing classes in order to minimize training error. We suspect that this effect would be especially pronounced in FGVC, since there are fewer samples from which the network can learn generalizable class-specific features.</p><p>Based on this hypothesis, we propose that introducing confusion in output logit activations during training for an FGVC task will force the network to learn slightly less discriminative features, thereby preventing it from overfitting to sample-specific artifacts. Specifically, we aim to confuse the network, by minimizing the distance between the predicted probability distributions for random pairs of samples from the training set. To do so, we propose Pairwise Confusion (PC) <ref type="bibr" target="#b3">4</ref> , a pairwise algorithm for training convolutional neural networks (CNNs) end-to-end for fine-grained visual classification.</p><p>In Pairwise Confusion, we construct a Siamese neural network trained with a novel loss function that attempts to bring class conditional probability distributions closer to each other. Using Pairwise Confusion with a standard network architecture like DenseNet <ref type="bibr" target="#b10">[11]</ref> or ResNet <ref type="bibr" target="#b11">[12]</ref> as a base network, we obtain state-of-the-art performance on six of the most widely-used fine-grained recognition datasets, improving over the previous-best published methods by 1.86% on average. In addition, PC-trained networks show better localization performance as compared to standard networks. Pairwise Confusion is simple to implement, has no added overhead in training or prediction time, and provides performance improvements both in FGVC tasks and other tasks that involve transfer learning with small amounts of training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Fine-Grained Visual Classification: Early FGVC research focused on methods to train with limited labeled data and traditional image features. Yao et al. <ref type="bibr" target="#b12">[13]</ref> combined strongly discriminative image patches with randomization techniques to prevent overfitting. Yao et al. <ref type="bibr" target="#b13">[14]</ref> subsequently utilized template matching to avoid the need for a large number of annotations. Recently, improved localization of the target object in training images has been shown to be useful for FGVC <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>. Zhang et al. <ref type="bibr" target="#b14">[15]</ref> utilize part-based Region-CNNs <ref type="bibr" target="#b17">[18]</ref> to perform finer localization. Spatial Transformer Networks <ref type="bibr" target="#b1">[2]</ref> show that learning a content-based affine transformation layer improves FGVC performance. Pose-normalized CNNs have also been shown to be effective at FGVC <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. Model ensembling and boosting has also improved performance on FGVC <ref type="bibr" target="#b20">[21]</ref>. Lin et al. <ref type="bibr" target="#b0">[1]</ref> introduced Bilinear Pooling, which combines pairwise local feature sets and improves classification performance. Bilinear Pooling has been extended by Gao et al. <ref type="bibr" target="#b15">[16]</ref> using a compact bilinear representation and Cui et al. <ref type="bibr" target="#b8">[9]</ref> using a general Kernel-based pooling framework that captures higher-order interactions of features.</p><p>Pairwise Learning: Chopra et al. <ref type="bibr" target="#b21">[22]</ref> introduced a Siamese neural network for handwriting recognition. Parikh and Grauman <ref type="bibr" target="#b22">[23]</ref> developed a pairwise ranking scheme for relative attribute learning. Subsequently, pairwise neural network models have become common for attribute modeling <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>Learning from Label Confusion: Our method aims to improve classification performance by introducing confusion within the output labels. Prior work in this area includes methods that utilize label noise (e.g., <ref type="bibr" target="#b27">[28]</ref>) and data noise (e.g., <ref type="bibr" target="#b28">[29]</ref>) in training. Krause et al. <ref type="bibr" target="#b5">[6]</ref> utilized noisy training data for FGVC. Neelakantan et al. <ref type="bibr" target="#b29">[30]</ref> added noise to the gradient during training to improve generalization performance in very deep networks. Szegedy et al. <ref type="bibr" target="#b30">[31]</ref> introduced label-smoothing regularization for training deep Inception models.</p><p>In this paper, we bring together concepts from pairwise learning and label confusion and take a step towards solving the problems of overfitting and samplespecific artifacts when training neural networks for FGVC tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>FGVC datasets in computer vision are orders of magnitude smaller than LSVC datasets and contain greater imbalance across classes (see <ref type="table" target="#tab_0">Table 1</ref>). Moreover, the samples of a class are not accurately representative of the complete variation in the visual class itself. The smaller dataset size can result in overfitting when training deep neural architectures with large number of parameters-even with preliminary layers being frozen. In addition, the training data may not be completely representative of the real-world data, with issues such as more abundant sampling for certain classes. For example, in FGVC of birds, certain species from geographically accessible areas may be overrepresented in the training dataset. As a result, the neural network may learn to latch on to sample-specific artifacts in the image, instead of learning a versatile representation for the target object. We aim to solve both of these issues in FGVC (overfitting and sample-specific artifacts) by bringing the different class-conditional probability distributions closer together and confusing the deep network, subsequently reducing its prediction over-confidence, thus improving generalization performance.</p><p>Let us formalize the idea of "confusing" the conditional probability distributions. Consider the conditional probability distributions for two input images x 1 and x 2 , which can be given by p θ (y|x 1 ) and p θ (y|x 2 ) respectively. For a classification problem with N output classes, each of these distributions is an N-dimensional vector, with each element i denoting the belief of the classifier in class y i given input x. If we wish to confuse the class outputs of the classifier for the pair x 1 and x 2 , we should learn parameters θ that bring these conditional probability distributions "closer" under some distance metric, that is, make the predictions for x 1 and x 2 similar.</p><p>While KL-divergence might seem to be a reasonable choice to design a loss function for optimizing the distance between conditional probability distributions, in Section 3.1, we show that it is infeasible to train a neural network when using KL-divergence as a regularizer. Therefore, we introduce the Euclidean Distance between distributions as a metric for confusion in Sections 3.2 and 3.3 and describe neural network training with this metric in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Symmetric KL-divergence or Jeffrey's Divergence</head><p>The most prevalent method to measure dissimilarity of one probability distribution from another is to use the Kullback-Liebler (KL) divergence. However, the standard KL-divergence cannot serve our purpose owing to its asymmetric nature. This could be remedied by using the symmetric KL-divergence, defined for two probability distributions P, Q with mass functions p(·), q(·) (for events u ∈ U):</p><formula xml:id="formula_0">D J (P, Q) u∈U p(u) · log p(u) q(u) + q(u) · log q(u) p(u) = D KL (P ||Q) + D KL (Q||P ) (1)</formula><p>This symmetrized version of KL-divergence, known as Jeffrey's divergence <ref type="bibr" target="#b39">[40]</ref>, is a measure of the average relative entropy between two probability distributions <ref type="bibr" target="#b40">[41]</ref>. For our model parameterized by θ, for samples x 1 and x 2 , the Jeffrey's divergence can be written as:</p><formula xml:id="formula_1">D J (p θ (y|x 1 ), p θ (y|x 2 )) = N i=1 (p θ (y i |x 1 ) − p θ (y i |x 2 )) · log p θ (y i |x 1 ) p θ (y i |x 2 )<label>(2)</label></formula><p>Jeffrey's divergence satisfies all of our basic requirements of a symmetric divergence metric between probability distributions, and therefore could be included as a regularizing term while training with cross-entropy, to achieve our desired confusion. However, when we learn model parameters using stochastic gradient descent (SGD), it can be difficult to train, especially if our distributions P, Q have mass concentrated on different events. This can be seen in Equation 2. Consider Jeffrey's divergence with N = 2 classes, and that x 1 belongs to class 1, and x 2 belongs to class 2. If the model parameters θ are such that it correctly identifies both x 1 and x 2 by training using cross-entropy loss, p θ (y 1 |x 1 ) = 1 − δ 1 and p θ (y 2 |x 2 ) = 1 − δ 2 , where 0 &lt; δ 1 , δ 2 &lt; 1 2 (since the classifier outputs correct predictions for the input images), we can show:</p><formula xml:id="formula_2">D J (p θ (y|x 1 ), p θ (y|x 2 )) ≥ (1 − δ 1 − δ 2 ) · (2 log(1 − δ 1 − δ 2 ) − log(δ 1 δ 2 )) (3)</formula><p>Please see the supplementary material for an expanded proof.</p><p>As training progresses with these labels, the cross-entropy loss will motivate the values of δ 1 and δ 2 to become closer to zero (but never equaling zero, since the probability outputs p θ (y|x 1 ), p θ (y|x 2 ) are the outputs from a softmax). As (δ 1 , δ 2 ) → (0 + , 0 + ), the second term − log(δ 1 δ 2 ) on the R.H.S. of inequality (3) typically grows whereas (1 − δ 1 − δ 2 ) approaches 1, which makes D J (p θ (y|x 1 ), p θ (y|x 2 )) larger as the predictions get closer to the true labels. In practice, we see that training with D J (p θ (y|x 1 ), p θ (y|x 2 )) as a regularizer term diverges, unless a very small regularizing parameter is chosen, which removes the effect of regularization altogether.</p><p>A natural question that can arise from this analysis is that cross-entropy training itself involves optimizing KL-divergence between the target label distribution and the model's predictions, however no such divergence occurs. This is because cross-entropy involves only one direction of the KL-divergence, and the target distribution has all the mass concentrated at one event (the correct label). Since (x log x)| x=0 = 0, for predicted label vector y ′ with correct label class c, this simplifies the cross-entropy error L CE (p θ (y|x), y ′ ) to be:</p><formula xml:id="formula_3">L CE (p θ (y|x), y ′ ) = − N i=1 y ′ i log( p θ (y i |x) y ′ i ) = − log(p θ (y c |x)) ≥ 0<label>(4)</label></formula><p>This formulation does not diverge as the model trains, i.e. p θ (y c |x) → 1. In some cases where label noise is added to the label vector (such as label smoothing <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b41">42]</ref>), the label noise is a fixed constant and not approaching zero (as in the case of Jeffery's divergence between model predictions) and is hence feasible to train. Thus, Jeffrey's Divergence or symmetric KL-divergence, while a seemingly natural choice, cannot be used to train a neural network with SGD. This motivates us to look for an alternative metric to measure "confusion" between conditional probability distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Euclidean Distance as Confusion</head><p>Since the conditional probability distribution over N classes is an element within R N on the unit simplex, we can consider the Euclidean distance to be a metric of "confusion" between two conditional probability distributions. Analogous to the previous setting, we define the Euclidean Confusion D EC (·, ·) for a pair of inputs x 1 , x 2 with model parameters θ as:</p><formula xml:id="formula_4">D EC (p θ (y|x 1 ), p θ (y|x 2 )) = N i=1 (p θ (y i |x 1 ) − p θ (y i |x 2 )) 2 = p θ (y|x 1 ) − p θ (y|x 2 ) 2 2</formula><p>(5) Unlike Jeffrey's Divergence, Euclidean Confusion does not diverge when used as a regularization term with cross-entropy. However, to verify this unconventional choice for a distance metric between probability distributions, we prove some properties that relate Euclidean Confusion to existing divergence measures. Lemma 1. On a finite probability space, the Euclidean Confusion D EC (P, Q) is a lower bound for the Jeffrey's Divergence D J (P, Q) for probability measures P, Q.</p><p>Proof. This follows from Pinsker's Inequality and the relationship between ℓ 1 and ℓ 2 norms. Complete proof is provided in the supplementary material.</p><p>By Lemma 1, we can see that the Euclidean Confusion is a conservative estimate for Jeffrey's divergence, the earlier proposed divergence measure. For finite probability spaces, the Total Variation Distance D TV (P, Q) 2 = 1 2 P − Q 1 is also a measure of interest. However, due to its non-differentiable nature, it is unsuitable for our case. Nevertheless, we can relate the Euclidean Confusion and Total Variation Distance by the following result.</p><p>Lemma 2. On a finite probability space, the Euclidean Confusion D EC (P, Q) is bounded by 4D TV (P, Q) 2 for probability measures P, Q.</p><p>Proof. This follows directly from the relationship between ℓ 1 and ℓ 2 norms. Complete proof is provided in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Euclidean Confusion for Point Sets</head><p>In a standard classification setting with N classes, we consider a training set with m = N i=1 m i training examples, where m i denotes the number of training samples for class i. For this setting, we can write the total Euclidean Confusion between points of classes i and j as the average of the Euclidean Confusion between all pairs of points belonging to those two classes. For simplicity of notation, let us denote the set of conditional probability distributions of all training points belonging to class i for a model parameterized by θ as</p><formula xml:id="formula_5">S i = {p θ (y|x i 1 ), p θ (y|x i 2 ), ..., p θ (y|x i mi )}.</formula><p>Then, for a model parameterized by θ, the Euclidean Confusion is given by:</p><formula xml:id="formula_6">D EC (Si, Sj; θ) 1 mimj m i ,m j u,v D EC (p θ (y|x i u ), p θ (y|x j v ))<label>(6)</label></formula><p>We can simplify this equation by assuming an equal number of points n per class:</p><formula xml:id="formula_7">D EC (S i , S j ; θ) = 1 n 2 n,n u,v p θ (y|x i u ) − p θ (y|x j v ) 2 2<label>(7)</label></formula><p>This form of the Euclidean Confusion between the two sets of points gives us an interesting connection with another popular distance metric over probability distributions, known as the Energy Distance <ref type="bibr" target="#b42">[43]</ref>.</p><p>Introduced by Gabor Szekely <ref type="bibr" target="#b42">[43]</ref>, the Energy Distance D EN (F, G) between two cumulative probability distribution functions F and G with random vectors X and Y in R N can be given by</p><formula xml:id="formula_8">D EN (F, G) 2 2E X − Y − E X − X ′ − E Y − Y ′ ≥ 0<label>(8)</label></formula><p>where (X, X ′ , Y, Y ′ ) are independent, and X ∼ F,</p><formula xml:id="formula_9">X ′ ∼ F, Y ∼ G, Y ′ ∼ G.</formula><p>If we consider the sets S i and S j , with a uniform probability of selecting any of the n points in each of these sets, then we obtain the following results.</p><p>Lemma 3. For sets S i , S j and D EC (S i , S j ; θ) as defined in Equation <ref type="formula" target="#formula_7">(7)</ref>:</p><formula xml:id="formula_10">1 2 D EN (S i , S j ; θ) 2 ≤ D EC (S i , S j ; θ)</formula><p>where D EN (S i , S j ; θ) is the Energy Distance under Euclidean norm between S i and S j (parameterized by θ), and random vectors are selected with uniform probability in both S i and S j .</p><p>Proof. This follows from the definition of Energy Distance with uniform probability of sampling. Complete proof is provided in the supplementary material.</p><p>Corollary 1. For sets S i , S j and D EC (S i , S j ; θ) as defined in Equation <ref type="formula" target="#formula_7">(7)</ref>, we have:</p><formula xml:id="formula_11">D EC (S i , S i ; θ) + D EC (S j , S j ; θ) ≤ 2D EC (S i , S j ; θ)</formula><p>with equality only when S i = S j .</p><p>Proof. This follows from the fact that the Energy Distance D EN (S i , S j ; θ) is 0 only when S i = S j . The complete version of the proof is included in the supplement.</p><p>With these results, we restrict the behavior of Euclidean Confusion within two well-defined conventional probability distance measures, the Jeffrey's divergence and Energy Distance. One might consider optimizing the Energy Distance directly, due to its similar formulation and the fact that we uniformly sample points during training with SGD. However, the Energy Distance additionally includes the two terms that account for the negative of the average all-pairs distances between points in S i and S j respectively, which we do not want to maximize, since we do not wish to push points within the same class further apart. Therefore, we proceed with our measure of Euclidean Confusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Learning with Gradient Descent</head><p>We proceed to learn parameters θ * for a neural network, with the following learning objective function for a pair of input points, motivated by the formulation  <ref type="figure">Fig. 1</ref>. CNN training pipeline for Pairwise Confusion (PC). We employ a Siamese-like architecture, with individual cross entropy calculations for each branch, followed by a joint energy-distance minimization loss. We split each incoming batch of samples into two mini-batches, and feed the network pairwise samples.</p><p>of Euclidean Confusion:</p><formula xml:id="formula_12">θ * = arg min θ N,N n,n i=1,j =i u,v L CE (p θ (y|x i u ), y i u )+L CE (p θ (y|x j v ), y j v )+ λ n 2 D EC (p θ (y|x j v ), p θ (y|x i u ))<label>(9)</label></formula><p>This objective function can be explained as: for each point in the training set, we randomly select another point from a different class and calculate the individual cross-entropy losses and Euclidean Confusion until all pairs have been exhausted. For each point in the training dataset, there are n·(N − 1) valid choices for the other point, giving us a total of n 2 ·N ·(N − 1) possible pairs. In practice, we find that we do not need to exhaust all combinations for effective learning using gradient descent, and in fact we observe that convergence is achieved far before all observations are observed. We simplify our formulation instead by using the following procedure described in Algorithm 1.</p><p>Training Procedure: As described in Algorithm 1, our learning procedure is a slightly modified version of the standard SGD. We randomly permute the training set twice, and then for each pair of points in the training set, add Euclidean Confusion only if the samples belong to different classes. This form of sampling approximates the exhaustive Euclidean Confusion, with some points with regular gradient descent, which in practice does not alter the performance. Moreover, convergence is achieved after only a fraction of all the possible pairs are observed. Formally, we wish to model the conditional probability distribution p θ (y|x) over the p classes for function f (x; θ) = p θ (y|x) parameterized by model parameters θ. Given our optimization procedure, we can rewrite the total loss for a pair of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Training Using Euclidean Confusion</head><p>Training data D, Test dataD, parameters θ, hyperparametersθ for epoch</p><formula xml:id="formula_13">∈ [0,max epochs]) do D1 ⇐ shuffle(D) D2 ⇐ shuffle(D) for i ∈ [0,num batches] do L batch = 0 for (d1, d2) ∈ batch i of (D1, D2) do γ ⇐ 1 if label(d1) = label(d2), 0 otherwise L pair ⇐ L CE (d1; θ) + L CE (d2; θ) + λ · γ · D EC (d1, d2; θ) L batch ⇐ L batch + L pair end for θ ⇐ Backprop(L batch , θ,θ) end for θ ⇐ ParameterUpdate(epoch,θ) end for</formula><p>points x 1 , x 2 with model parameters θ as: <ref type="bibr" target="#b9">(10)</ref> where, γ(y 1 , y 2 ) = 1 when y i = y j , and 0 otherwise. We denote training with this general architecture with the term Pairwise Confusion or PC for short. Specifically, we train a Siamese-like neural network <ref type="bibr" target="#b21">[22]</ref> with shared weights, training each network individually using cross-entropy, and add the Euclidean Confusion loss between the conditional probability distributions obtained from each network <ref type="figure">(Figure 1</ref>). During training, we split an incoming batch of training samples into two parts, and evaluating cross-entropy on each sub-batch identically, followed by a pairwise loss term calculated for corresponding pairs of samples across batches. During testing, only one branch of the network is active, and generates output predictions for the input image.</p><formula xml:id="formula_14">L pair (x1, x2, y1, y2; θ) = 2 i=1 [L CE (p θ (y|xi), yi)] + λγ(y1, y2)D EC (p θ (y|x1), p θ (y|x2))</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN Architectures</head><p>We experiment with VGGNet <ref type="bibr" target="#b43">[44]</ref>, GoogLeNet <ref type="bibr" target="#b41">[42]</ref>, ResNets <ref type="bibr" target="#b11">[12]</ref>, and DenseNets <ref type="bibr" target="#b10">[11]</ref> as base architectures for the Siamese network trained with PC to demonstrate that our method is insensitive to the choice of source architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Details</head><p>We perform all experiments using Caffe <ref type="bibr" target="#b44">[45]</ref> or PyTorch <ref type="bibr" target="#b45">[46]</ref> over a cluster of NVIDIA Titan X, Tesla K40c and GTX 1080 GPUs. Our code and models are available at github.com/abhimanyudubey/confusion. Next, we provide brief descriptions of the various datasets used in our paper. <ref type="table">Table 2</ref>. Pairwise Confusion (PC) obtains state-of-the-art performance on six widelyused fine-grained visual classification datasets (A-F). Improvement over the baseline model is reported as (∆). All results averaged over 5 trials.</p><p>(A) CUB-200-2011 Method Top-1 ∆ Gao et al. <ref type="bibr" target="#b15">[16]</ref> 84.00 -STN <ref type="bibr" target="#b1">[2]</ref> 84.10 -Zhang et al. <ref type="bibr" target="#b46">[47]</ref> 84.50 -Lin et al. <ref type="bibr" target="#b7">[8]</ref> 85.80 -Cui et al. <ref type="bibr" target="#b8">[9]</ref> 86.  <ref type="bibr" target="#b47">[48]</ref> 86.80 -Lin et al. <ref type="bibr" target="#b7">[8]</ref> 92.00 -Cui et al. <ref type="bibr" target="#b8">[9]</ref> 92.  These datasets contain (i) large visual diversity in each class <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b36">37]</ref>, (ii) visually similar, often confusing samples belonging to different classes, and (iii) a large variation in the number of samples present per class, leading to greater class imbalance than LSVC datasets like ImageNet <ref type="bibr" target="#b9">[10]</ref>. Additionally, some of these datasets have densely annotated part information available, which we do not utilize in our experiments. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Fine-Grained Visual Classification</head><p>We first describe our results on the six FGVC datasets from <ref type="table">Table 2</ref>. In all experiments, we average results over 5 trials per experiment-after choosing the best value of hyperparameter λ. Please see the supplementary material for mean and standard deviation values for all experiments.</p><p>1. Fine-tuning from Baseline Models: We fine-tune from three baseline models using the PC optimization procedure: ResNet-50 <ref type="bibr" target="#b11">[12]</ref>, Bilinear CNN <ref type="bibr" target="#b0">[1]</ref>, and DenseNet-161 <ref type="bibr" target="#b10">[11]</ref>. As <ref type="table">Tables 2-(A-F)</ref> show, PC obtains substantial improvement across all datasets and models. For instance, a baseline DenseNet-161 architecture obtains an average accuracy of 84.21%, but PC-DenseNet-161 obtains an accuracy of 86.87%, an improvement of 2.66%. On NABirds, we obtain improvements of 4.60% and 3.42% over baseline ResNet-50 and DenseNet-161 architectures. 2. Combining PC with Specialized FGVC models: Recent work in FGVC has proposed several novel CNN designs that take part-localization into account, such as bilinear pooling techniques <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b8">9]</ref> and spatial transformer networks <ref type="bibr" target="#b1">[2]</ref>. We train a Bilinear CNN <ref type="bibr" target="#b0">[1]</ref> with PC, and obtain an average improvement of 1.7% on the 6 datasets.</p><p>We note two important aspects of our analysis: <ref type="formula">(1)</ref> we do not compare with ensembling and data augmentation techniques such as Boosted CNNs <ref type="bibr" target="#b20">[21]</ref> and Krause, et al. <ref type="bibr" target="#b5">[6]</ref> since prior evidence indicates that these techniques invariably improve performance, and <ref type="formula" target="#formula_1">(2)</ref> we evaluate a single-crop, single-model evaluation without any part-or object-annotations, and perform competitively with methods that use both augmentations. Choice of Hyperparameter λ: Since our formulation requires the selection of a hyperparameter λ, it is important to study the sensitivity of classification performance to the choice of λ. We conduct this experiment for four different models: GoogLeNet <ref type="bibr" target="#b41">[42]</ref>, ResNet-50 <ref type="bibr" target="#b11">[12]</ref> and VGGNet-16 <ref type="bibr" target="#b43">[44]</ref> and Bilinear-CNN <ref type="bibr" target="#b0">[1]</ref> on the CUB-200-2011 dataset. PC's performance is not very sensitive to the choice of λ <ref type="figure" target="#fig_2">(Figure 2</ref> and Supplementary Tables S1-S5). For all six datasets, the λ value is typically between the range <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20]</ref>. On Bilinear CNN, setting λ = 10 for all datasets gives average performance within 0.08% compared to the reported values in <ref type="table">Table 2</ref>. In general, PC obtains optimum performance in the range of 0.05N and 0.15N , where N is the number of classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Additional Experiments</head><p>Since our method aims to improve classification performance in FGVC tasks by introducing confusion in output logit activations, we would expect to see a larger improvement in datasets with higher inter-class similarity and intra-class variation. To test this hypothesis, we conduct two additional experiments.</p><p>In the first experiment, we construct two subsets of ImageNet-1K <ref type="bibr" target="#b9">[10]</ref>. The first dataset, ImageNet-Dogs is a subset consisting only of species of dogs (117 classes and 116K images). The second dataset, ImageNet-Random contains randomly selected classes from ImageNet-1K. Both datasets contain equal number of classes (117) and images (116K), but ImageNet-Dogs has much higher interclass similarity and intra-class variation, as compared to ImageNet-Random. To test repeatability, we construct 3 instances of Imagenet-Random, by randomly choosing a different subset of ImageNet with 117 classes each time. For both experiments, we randomly construct a 80-20 train-val split from the training data to find optimal λ by cross-validation, and report the performance on the unseen ImageNet validation set of the subset of chosen classes. In <ref type="table" target="#tab_3">Table 3</ref>, we compare the performance of training from scratch with-and without-PC across three models: GoogLeNet, ResNet-50, and DenseNet-161. As expected, PC obtains a larger gain in classification accuracy (1.45%) on ImageNet-Dogs as compared to the ImageNet-Random dataset(0.54% ± 0.28).</p><p>In the second experiment, we utilize the CIFAR-10 and CIFAR-100 datasets, which contain the same number of total images. CIFAR-100 has 10× the number of classes and 10% of images per class as CIFAR-10 and contains larger inter-class similarity and intra-class variation. We train networks on both datasets from scratch using default train-test splits ( <ref type="table" target="#tab_3">Table 3)</ref>. As expected, we obtain larger average gains of 1.77% on CIFAR-100, as compared to 0.20% on CIFAR-10. Additionally, when training with λ = 10 on the entire ImageNet dataset, we obtain a top-1 accuracy of 76.28% (compared to a baseline of 76.15%), which is a smaller improvement, which is in line with what we would expect for a large-scale image classification problem with large inter-class variation.</p><p>Moreover, while training with PC, we observe that the rate of convergence is always similar to or faster than training without PC. For example, a GoogLeNet trained on CUB-200-2011 <ref type="figure" target="#fig_2">(Figure 2</ref>(right) above) shows that PC converges to higher validation accuracy faster than normal training using identical learning rate schedule and batch size. Note that the training accuracy is reduced when training with PC, due to the regularization effect. In sum, classification problems that have large intra-class variation and high inter-class similarity benefit from optimization with pairwise confusion. The improvement is even more prominent when training data is limited. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Improvement in Localization Ability</head><p>Recent techniques for improving classification performance in fine-grained recognition are based on summarizing and extracting dense localization information in images <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Since our technique increases classification accuracy, we wish to understand if the improvement is a result of enhanced CNN localization abilities due to PC. To measure the regions the CNN localizes on, we utilize Gradient-Weighted Class Activation Mapping (Grad-CAM) <ref type="bibr" target="#b52">[53]</ref>, a method that provides a heatmap of visual saliency as produced by the network. We perform both quantitative and qualitative studies of localization ability of PC-trained models. Overlap in Localized Regions: To quantify the improvement in localization due to PC, we construct bounding boxes around object regions obtained from Grad-CAM, by thresholding the heatmap values at 0.5, and choosing the largest box returned. We then calculate the mean IoU (intersection-over-union) of the bounding box with the provided object bounding boxes for the CUB-200-2011 dataset. We compare the mean IoU across several models, with and without PC. As summarized in <ref type="table">Table 4</ref>, we observe an average 3.4% improvement across five different networks, implying better localization accuracy. Change in Class-Activation Mapping: To qualitatively study the improvement in localization due to PC, we obtain samples from the CUB-200-2011 dataset and visualize the localization regions returned from Grad-CAM for both the baseline and PC-trained VGG-16 model. As shown in <ref type="figure" target="#fig_3">Figure 3</ref>, PC models provide tighter, more accurate localization around the target object, whereas sometimes the baseline model has localization driven by image artifacts. <ref type="figure" target="#fig_3">Figure 3</ref>-(a) has an example of the types of distractions that are often present in FGVC images (the cartoon bird on the right). We see that the baseline VGG-16 network pays For all cases, we consistently observe a tighter and more accurate localization with PC, whereas the baseline VGG-16 network often latches on to artifacts, even while making correct predictions.</p><p>significant attention to the distraction, despite making the correct prediction. With PC, we find that the attention is limited almost exclusively to the correct object, as desired. Similarly for <ref type="figure" target="#fig_3">Figure 3</ref>-(b), we see that the baseline method latches on to the incorrect bird category, which is corrected by the addition of PC.</p><p>In <ref type="figure" target="#fig_3">Figures 3-(c-d)</ref>, we see that the baseline classifier makes incorrect decisions due to poor localization, mistakes that are resolved by PC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we introduce Pairwise Confusion (PC), an optimization procedure to improve generalizability in fine-grained visual classification (FGVC) tasks by encouraging confusion in output activations. PC improves FGVC performance for a wide class of convolutional architectures while fine-tuning. Our experiments indicate that PC-trained networks show improved localization performance which contributes to the gains in classification accuracy. PC is easy to implement, does not need excessive tuning during training, and does not add significant overhead during test time, in contrast to methods that introduce complex localizationbased pooling steps that are often difficult to implement and train. Therefore, our technique should be beneficial to a wide variety of specialized neural network models for applications that demand for fine-grained visual classification or learning from limited labeled data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Wildlife Species Classification: We experiment with several widely-used FGVC datasets. The Caltech-UCSD Birds (CUB-200-2011) dataset [33] has 5,994 training and 5,794 test images across 200 species of North-American birds. The NABirds dataset [35] contains 23,929 training and 24,633 test images across over 550 visual categories, encompassing 400 species of birds, including separate classes for male and female birds in some cases. The Stanford Dogs dataset [37] has 20,580 images across 120 breeds of dogs around the world. Finally, the Flowers-102 dataset [32] consists of 1,020 training, 1,020 validation and 6,149 test images over 102 flower types. 2. Vehicle Make/Model Classification: We experiment with two common vehicle classification datasets. The Stanford Cars dataset [34] contains 8,144 training and 8,041 test images across 196 car classes. The classes represent variations in car make, model, and year. The Aircraft dataset is a set of 10,000 images across 100 classes denoting a fine-grained set of airplanes of different varieties [36].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (left) Variation of test accuracy on CUB-200-2011 with logarithmic variation in hyperparameter λ. (right) Convergence plot of GoogLeNet on CUB-200-2011.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Pairwise Confusion (PC) obtains improved localization performance, as demonstrated here with Grad-CAM heatmaps of the CUB-200-2011 dataset images (left) with a VGGNet-16 model trained without PC (middle) and with PC (right). The objects in (a) and (b) are correctly classified by both networks, and (c) and (d) are correctly classified by PC, but not the baseline network (VGG-16). For all cases, we consistently observe a tighter and more accurate localization with PC, whereas the baseline VGG-16 network often latches on to artifacts, even while making correct predictions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 .</head><label>1</label><figDesc>A comparison of fine-grained visual classification (FGVC) datasets with large- scale visual classification (LSVC) datasets. FGVC datasets are significantly smaller and noisier than LSVC datasets.</figDesc><table>Dataset 
num. samples 
classes per class 
Flowers-102 [32] 
102 
10 
CUB-200-2011 [33] 200 
29.97 
Cars [34] 
196 
41.55 
NABirds [35] 
550 
43.5 
Aircrafts [36] 
100 
100 
Stanford Dogs [37] 120 
100 

Dataset 
num. samples 
classes per class 
CIFAR-100 [38] 100 
500 
ImageNet [10] 
1000 
1200 
CIFAR-10 [38] 
10 
5000 
SVHN [39] 
10 
7325.7 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 .</head><label>3</label><figDesc>Experiments with ImageNet and CIFAR show that datasets with large intra- class variation and high inter-class similarity benefit from optimization with Pairwise Confusion. Only the mean accuracy over 3 Imagenet-Random experiments is shown.Table 4. Pairwise Confusion (PC) improves localization performance in fine-grained visual classification tasks. On the CUB-200-2011 dataset, PC obtains an average improvement of 3.4% in Mean Intersection-over-Union (IoU) for Grad-CAM bounding boxes for each of the five baseline models.</figDesc><table>Network 
ImageNet-Random ImageNet-Dogs CIFAR-10 
CIFAR-100 
Baseline 
PC 
Baseline PC Baseline PC Baseline PC 
GoogLeNet [42] 
71.85 
72.09 
62.35 64.17 86.63 87.02 73.35 76.02 
ResNet-50 [12] 
82.01 
82.65 
73.81 75.92 93.17 93.46 72.16 73.14 
DenseNet-161 [11] 78.34 
79.10 
70.15 71.44 95.15 95.08 78.60 79.56 

Method 
GoogLeNet VGG-16 ResNet-50 DenseNet-161 Bilinear-CNN 
Mean IoU (Baseline) 
0.29 
0.31 
0.32 
0.34 
0.37 
Mean IoU (PC) -Ours 
0.35 
0.34 
0.35 
0.37 
0.39 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Implementation available at https://github.com/abhimanyudubey/confusion.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements: We would like to thank Dr. Ashok Gupta for his guidance on bird recognition, and Dr. Sumeet Agarwal, Spandan Madan and Ishaan Grover for their feedback at various stages of this work. RF and PG were supported in part by the National Science Foundation under Grant No. IIS1651832, and AD, OG, RR and NN acknowledge the generous support of the MIT Media Lab Consortium.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bilinear cnn models for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roychowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1449" to="1457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Spatial transformer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2017" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Weakly supervised fine-grained categorization with part-based image representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1713" to="1725" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fine-grained recognition without part annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5546" to="5555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fine-grained pose prediction, normalization, and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations Workshops</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The unreasonable effectiveness of noisy data for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Duerig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="301" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fine-grained categorization and dataset bootstrapping using deep metric learning with humans in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06772</idno>
		<title level="m">Improved bilinear pooling with cnns</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<title level="m">Kernel pooling for convolutional neural networks. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<title level="m">Imagenet: A large-scale hierarchical image database. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Combining randomization and discrimination for fine-grained image categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1577" to="1584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A codebook-free and annotation-free approach for fine-grained image categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bradski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3466" to="3473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Part-based r-cnns for fine-grained category detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="834" to="849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Beijbom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<title level="m">Compact bilinear pooling. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="317" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mining discriminative triplets of patches for fine-grained classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bird species categorization using pose normalized deep convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Pose pooling kernels for sub-category recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Vision and Pattern Recognition</title>
		<imprint>
			<biblScope unit="page" from="3665" to="3672" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moghimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saberian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Boosted convolutional neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<title level="m">Relative attributes. IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="503" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Modeling image virality with pairwise spatial transformer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.07914</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Souri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Noury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<title level="m">Deep relative attributes. Asian Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="118" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep learning the city: Quantifying urban perception at a global scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Hidalgo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="196" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<title level="m">End-to-end localization and ranking for relative attributes. European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="753" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<title level="m">Training deep neural networks on noisy labels with bootstrapping</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Adding gradient noise improves learning for very deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06807</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automated flower classification over a large number of classes. Indian Conference on Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Nilsback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphics &amp; Image Processing</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="722" to="729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<title level="m">The caltech-ucsd birds-200-2011 dataset</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision Workshops</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="554" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Building a bird recognition app and large scale dataset with citizen scientists: The fine print in fine-grained dataset collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="595" to="604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.5151</idno>
		<title level="m">Fine-grained visual classification of aircraft</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Novel dataset for fine-grained image categorization: Stanford dogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jayadevaprakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision Workshops on Fine-Grained Visual Categorization</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">The cifar-10 dataset otkrist</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<title level="m">Reading digits in natural images with unsupervised feature learning. NIPS workshop on deep learning and unsupervised feature learning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">The theory of probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jeffreys</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>OUP</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">On information and sufficiency. The annals of mathematical statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Leibler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1951" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<title level="m">Going deeper with convolutions. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Energy statistics: A class of statistics based on distances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Székely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Rizzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of statistical planning and inference</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1249" to="1272" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM international conference on Multimedia</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Tensors and Dynamic neural networks in Python with strong GPU acceleration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paskze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<ptr target="https://github.com/pytorchAccessed" />
		<imprint>
			<date type="published" when="2017-01-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Picking deep filter responses for fine-grained image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1134" to="1142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Hierarchical joint cnn-based models for fine-grained cars recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Cloud Computing and Security</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="337" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Generalized orderless pooling performs implicit salient matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Denzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Low-rank bilinear pooling for fine-grained classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7025" to="7034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Efficient object detection and segmentation for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Angelova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="811" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">CNN features offthe-shelf: An astounding baseline for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharif Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Grad-cam: Why did you say that? visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02391</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
