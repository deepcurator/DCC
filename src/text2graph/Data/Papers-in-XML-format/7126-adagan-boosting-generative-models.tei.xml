<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:41+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AdaGAN: Boosting Generative Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Tolstikhin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">MPI for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">MPI for Intelligent Systems</orgName>
								<orgName type="institution">MPI for Intelligent Systems Tübingen</orgName>
								<address>
									<settlement>Tübingen, Tübingen</settlement>
									<country>Germany, Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly Google</surname></persName>
							<email>sylvaingelly@google.com</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">MPI for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">MPI for Intelligent Systems</orgName>
								<orgName type="institution">MPI for Intelligent Systems Tübingen</orgName>
								<address>
									<settlement>Tübingen, Tübingen</settlement>
									<country>Germany, Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brain</forename><surname>Zürich</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">MPI for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">MPI for Intelligent Systems</orgName>
								<orgName type="institution">MPI for Intelligent Systems Tübingen</orgName>
								<address>
									<settlement>Tübingen, Tübingen</settlement>
									<country>Germany, Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Switzerland</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">MPI for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">MPI for Intelligent Systems</orgName>
								<orgName type="institution">MPI for Intelligent Systems Tübingen</orgName>
								<address>
									<settlement>Tübingen, Tübingen</settlement>
									<country>Germany, Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><forename type="middle">Bousquet</forename><surname>Google</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">MPI for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">MPI for Intelligent Systems</orgName>
								<orgName type="institution">MPI for Intelligent Systems Tübingen</orgName>
								<address>
									<settlement>Tübingen, Tübingen</settlement>
									<country>Germany, Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brain</forename><surname>Zürich</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">MPI for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">MPI for Intelligent Systems</orgName>
								<orgName type="institution">MPI for Intelligent Systems Tübingen</orgName>
								<address>
									<settlement>Tübingen, Tübingen</settlement>
									<country>Germany, Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Switzerland</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">MPI for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">MPI for Intelligent Systems</orgName>
								<orgName type="institution">MPI for Intelligent Systems Tübingen</orgName>
								<address>
									<settlement>Tübingen, Tübingen</settlement>
									<country>Germany, Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl-Johann</forename><surname>Simon-Gabriel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">MPI for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">MPI for Intelligent Systems</orgName>
								<orgName type="institution">MPI for Intelligent Systems Tübingen</orgName>
								<address>
									<settlement>Tübingen, Tübingen</settlement>
									<country>Germany, Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">MPI for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">MPI for Intelligent Systems</orgName>
								<orgName type="institution">MPI for Intelligent Systems Tübingen</orgName>
								<address>
									<settlement>Tübingen, Tübingen</settlement>
									<country>Germany, Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AdaGAN: Boosting Generative Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Generative Adversarial Networks (GAN) are an effective method for training generative models of complex data such as natural images. However, they are notoriously hard to train and can suffer from the problem of missing modes where the model is not able to produce examples in certain regions of the space. We propose an iterative procedure, called AdaGAN, where at every step we add a new component into a mixture model by running a GAN algorithm on a re-weighted sample. This is inspired by boosting algorithms, where many potentially weak individual predictors are greedily aggregated to form a strong composite predictor. We prove analytically that such an incremental procedure leads to convergence to the true distribution in a finite number of steps if each step is optimal, and convergence at an exponential rate otherwise. We also illustrate experimentally that this procedure addresses the problem of missing modes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Imagine we have a large corpus, containing unlabeled pictures of animals, and our task is to build a generative probabilistic model of the data. We run a recently proposed algorithm and end up with a model which produces impressive pictures of cats and dogs, but not a single giraffe. A natural way to fix this would be to manually remove all cats and dogs from the training set and run the algorithm on the updated corpus. The algorithm would then have no choice but to produce new animals and, by iterating this process until there's only giraffes left in the training set, we would arrive at a model generating giraffes (assuming sufficient sample size). At the end, we aggregate the models obtained by building a mixture model. Unfortunately, the described meta-algorithm requires manual work for removing certain pictures from the unlabeled training set at every iteration.</p><p>Let us turn this into an automatic approach, and rather than including or excluding a picture, put continuous weights on them. To this end, we train a binary classifier to separate "true" pictures of the original corpus from the set of "synthetic" pictures generated by the mixture of all the models trained so far. We would expect the classifier to make confident predictions for the true pictures of animals missed by the model (giraffes), because there are no synthetic pictures nearby to be confused with them. By a similar argument, the classifier should make less confident predictions for the true pictures containing animals already generated by one of the trained models (cats and dogs). For each picture in the corpus, we can thus use the classifier's confidence to compute a weight which we use for that picture in the next iteration, to be performed on the re-weighted dataset.</p><p>The present work provides a principled way to perform this re-weighting, with theoretical guarantees showing that the resulting mixture models indeed approach the true data distribution. <ref type="bibr" target="#b0">1</ref> ALGORITHM 1 AdaGAN, a meta-algorithm to construct a "strong" mixture of T individual generative models (f.ex. GANs), trained sequentially.</p><p>Input: Training sample SN := {X1, . . . , XN }. Output: Mixture generative model G = GT .</p><p>Train vanilla GAN G1 = GAN(SN , W1) with a uniform weight W1 = (1/N, . . . , 1/N ) over the training points for t = 2, . . . , T do #Choose the overall weight of the next mixture component βt = ChooseMixtureWeight(t) #Update the weight of each training example Wt = UpdateTrainingWeights(Gt−1, SN , βt) #Train t-th "weak" component generator G Before discussing how to build the mixture, let us consider the question of building a single generative model. A recent trend in modelling high dimensional data such as natural images is to use neural networks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. One popular approach are Generative Adversarial Networks (GAN) <ref type="bibr" target="#b1">[2]</ref>, where the generator is trained adversarially against a classifier, which tries to differentiate the true from the generated data. While the original GAN algorithm often produces realistically looking data, several issues were reported in the literature, among which the missing modes problem, where the generator converges to only one or a few modes of the data distribution, thus not providing enough variability in the generated data. This seems to match the situation described earlier, which is why we will most often illustrate our algorithm with a GAN as the underlying base generator. We call it AdaGAN, for Adaptive GAN, but we could actually use any other generator: a Gaussian mixture model, a VAE <ref type="bibr" target="#b0">[1]</ref>, a WGAN <ref type="bibr" target="#b2">[3]</ref>, or even an unrolled <ref type="bibr" target="#b3">[4]</ref> or mode-regularized GAN <ref type="bibr" target="#b4">[5]</ref>, which were both already specifically developed to tackle the missing mode problem. Thus, we do not aim at improving the original GAN or any other generative algorithm. We rather propose and analyse a meta-algorithm that can be used on top of any of them. This meta-algorithm is similar in spirit to AdaBoost in the sense that each iteration corresponds to learning a "weak" generative model (e.g., GAN) with respect to a re-weighted data distribution. The weights change over time to focus on the "hard" examples, i.e. those that the mixture has not been able to properly generate so far.</p><p>Related Work Several authors <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref> have proposed to use boosting techniques in the context of density estimation by incrementally adding components in the log domain. This idea was applied to GANs in <ref type="bibr" target="#b7">[8]</ref>. A major downside of these approaches is that the resulting mixture is a product of components and sampling from such a model is nontrivial (at least when applied to GANs where the model density is not expressed analytically) and requires techniques such as Annealed Importance Sampling <ref type="bibr" target="#b8">[9]</ref> for the normalization.</p><p>When the log likelihood can be computed, <ref type="bibr" target="#b9">[10]</ref> proposed to use an additive mixture model. They derived the update rule via computing the steepest descent direction when adding a component with infinitesimal weight. However, their results do not apply once the weight β becomes non-infinitesimal. In contrast, for any fixed weight of the new component our approach gives the overall optimal update (rather than just the best direction) for a specified f -divergence. In both theories, improvements of the mixture are guaranteed only if the new "weak" learner is still good enough (see Conditions 10&amp;11) Similarly, <ref type="bibr" target="#b10">[11]</ref> studied the construction of mixtures minimizing the Kullback divergence and proposed a greedy procedure for doing so. They also proved that under certain conditions, finite mixtures can approximate arbitrary mixtures at a rate 1/k where k is the number of components in the mixture when the weight of each newly added component is 1/k. These results are specific to the Kullback divergence but are consistent with our more general results.</p><p>An additive procedure similar to ours was proposed in <ref type="bibr" target="#b11">[12]</ref> but with a different re-weighting scheme, which is not motivated by a theoretical analysis of optimality conditions. On every new iteration the authors run GAN on the k training examples with maximal values of the discriminator from the last iteration.</p><p>Finally, many papers investigate completely different approaches for addressing the same issue by directly modifying the training objective of an individual GAN. For instance, <ref type="bibr" target="#b4">[5]</ref> add an autoencoding cost to the training objective of GAN, while <ref type="bibr" target="#b3">[4]</ref> allow the generator to "look few steps ahead" when making a gradient step.</p><p>The paper is organized as follows. In Section 2 we present our main theoretical results regarding iterative optimization of mixture models under general f -divergences. In Section 2.4 we show that if optimization at each step is perfect, the process converges to the true data distribution at exponential rate (or even in a finite number of steps, for which we provide a necessary and sufficient condition). Then we show in Section 2.5 that imperfect solutions still lead to the exponential rate of convergence under certain "weak learnability" conditions. These results naturally lead to a new boosting-style iterative procedure for constructing generative models. When used with GANs, it results in our AdaGAN algorithm, detailed in Section 3 . Finally, we report initial empirical results in Section 4, where we compare AdaGAN with several benchmarks, including original GAN and uniform mixture of multiple independently trained GANs. Part of new theoretical results are reported without proofs, which can be found in appendices.</p><p>2 Minimizing f -divergence with Mixtures</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preliminaries and notations</head><p>Generative Density Estimation In density estimation, one tries to approximate a real data distribution P d , defined over the data space X , by a model distribution P model . In the generative approach one builds a function G : Z → X that transforms a fixed probability distribution P Z (often called the noise distribution) over a latent space Z into a distribution over X . Hence P model is the pushforward of P Z , i.e. P model (A) = P Z (G −1 (A)). With this approach it is in general impossible to compute the density dP model (x) and the log-likelihood of the training data under the model, but one can easily sample from P model by sampling from P Z and applying G. Thus, to construct G, instead of comparing P model directly with P d , one compares their samples. To do so, one uses a similarity measure D(P model P d ) which can be estimated from samples of those distributions, and thus approximately minimized over a class G of functions.</p><p>f -Divergences In order to measure the agreement between the model distribution and the true distribution we will use an f -divergence defined in the following way:</p><formula xml:id="formula_0">D f (Q P ) := f dQ dP (x) dP (x)<label>(1)</label></formula><p>for any pair of distributions P, Q with densities dP , dQ with respect to some dominating reference measure µ (we refer to Appendix D for more details about such divergences and their domain of definition). Here we assume that f is convex, defined on (0, ∞), and satisfies f (1) = 0. We will denote by F the set of such functions. <ref type="bibr" target="#b1">2</ref> As demonstrated in <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>, several commonly used symmetric f -divergences are Hilbertian metrics, which in particular means that their square root satisfies the triangle inequality. This is true for the Jensen-Shannon divergence <ref type="bibr" target="#b2">3</ref> , the Hellinger distance and the Total Variation among others. We will denote by F H the set of functions f such that D f is a Hilbertian metric.</p><p>GAN and f -divergences The original GAN algorithm <ref type="bibr" target="#b1">[2]</ref> optimizes the following criterion:</p><formula xml:id="formula_1">min G max D E P d [log D(X)] + E P Z [log(1 − D(G(Z)))] ,<label>(2)</label></formula><p>where D and G are two functions represented by neural networks. This optimization is performed on a pair of samples (a training sample from P d and a "fake" sample from P Z ), which corresponds to approximating the above criterion by using the empirical distributions. In the non-parametric limit for D, this is equivalent to minimizing the Jensen-Shannon divergence <ref type="bibr" target="#b1">[2]</ref>. This point of view can be generalized to any other f -divergence <ref type="bibr" target="#b12">[13]</ref>. Because of this strong connection between adversarial 2 Examples of f -divergences include the Kullback-Leibler divergence (obtained for f (x) = x log x) and Jensen-Shannon divergence (f (x) = −(x + 1) log x+1 2 + x log x). Other examples can be found in <ref type="bibr" target="#b12">[13]</ref>. For further details we refer to Section 1.3 of <ref type="bibr" target="#b13">[14]</ref> and <ref type="bibr" target="#b14">[15]</ref>.</p><p>3 which means such a property can be used in the context of the original GAN algorithm.</p><p>training of generative models and minimization of f -divergences, we cast the results of this section into the context of general f -divergences.</p><p>Generative Mixture Models In order to model complex data distributions, it can be convenient to use a mixture model of the following form:</p><formula xml:id="formula_2">P T model := T i=1 α i P i , where α i ≥ 0, i α i = 1</formula><p>, and each of the T components is a generative density model. This is natural in the generative context, since sampling from a mixture corresponds to a two-step sampling, where one first picks the mixture component (according to the multinomial distribution with parameters α i ) and then samples from it. Also, this allows to construct complex models from simpler ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Incremental Mixture Building</head><p>We restrict ourselves to the case of f -divergences and assume that, given an i.i.d. sample from any unknown distribution P , we can construct a simple model Q ∈ G which approximately minimizes</p><formula xml:id="formula_3">4 min Q∈G D f (Q P ).<label>(3)</label></formula><p>Instead of modelling the data with a single distribution, we now want to model it with a mixture of distributions P i ,where each P i is obtained by a training procedure of the form <ref type="formula" target="#formula_3">(3)</ref> with (possibly) different target distributions P for each i. A natural way to build a mixture is to do it incrementally:</p><p>we train the first model P 1 to minimize D f (P 1 P d ) and set the corresponding weight to α 1 = 1, leading to P 1 model = P 1 . Then after having trained t components P 1 , . . . , P t ∈ G we can form the (t + 1)-st mixture model by adding a new component Q with weight β as follows:</p><formula xml:id="formula_4">P t+1 model := t i=1 (1 − β)α i P i + βQ.<label>(4)</label></formula><p>where β ∈ [0, 1] and Q ∈ G is computed by minimizing:</p><formula xml:id="formula_5">min Q D f ((1 − β)P g + βQ P d ),<label>(5)</label></formula><p>where we denoted P g := P t model the current generative mixture model before adding the new component. We do not expect to find the optimal Q that minimizes (5) at each step, but we aim at constructing some Q that slightly improves our current approximation of P d , i.e. such that for c &lt; 1</p><formula xml:id="formula_6">D f ((1 − β)P g + βQ P d ) ≤ c · D f (P g P d ) .<label>(6)</label></formula><p>This greedy approach has a significant drawback in practice. As we build up the mixture, we need to make β decrease (as P t model approximates P d better and better, one should make the correction at each step smaller and smaller). Since we are approximating (5) using samples from both distributions, this means that the sample from the mixture will only contain a fraction β of examples from Q. So, as t increases, getting meaningful information from a sample so as to tune Q becomes harder and harder (the information is "diluted"). To address this issue, we propose to optimize an upper bound on (5) which involves a term of the form D f (Q R) for some distribution R, which can be computed as a re-weighting of the original data distribution P d . This procedure is reminiscent of the AdaBoost algorithm <ref type="bibr" target="#b17">[18]</ref>, which combines multiple weak predictors into one strong composition. On each step AdaBoost adds new predictor to the current composition, which is trained to minimize the binary loss on the re-weighted training set. The weights are constantly updated to bias the next weak learner towards "hard" examples, which were incorrectly classified during previous stages.</p><p>In the following we will analyze the properties of (5) and derive upper bounds that provide practical optimization criteria for building the mixture. We will also show that under certain assumptions, the minimization of the upper bound leads to the optimum of the original criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Upper Bounds</head><p>We provide two upper bounds on the divergence of the mixture in terms of the divergence of the additive component Q with respect to some reference distribution R.</p><p>Lemma 1 Given two distributions P d , P g and some β ∈ [0, 1], then, for any Q and R, and f ∈ F H :</p><formula xml:id="formula_7">D f ((1 − β)P g + βQ P d ) ≤ βD f (Q R) + D f ((1 − β)P g + βR P d ) .<label>(7)</label></formula><p>If, more generally, f ∈ F, but βdR ≤ dP d , then:</p><formula xml:id="formula_8">D f ((1 − β)P g + βQ P d ) ≤ βD f (Q R) + (1 − β)D f P g P d − βR 1 − β .<label>(8)</label></formula><p>We can thus exploit those bounds by introducing some well-chosen distribution R and then minimizing them with respect to Q. A natural choice for R is a distribution that minimizes the last term of the upper bound (which does not depend on Q). Our main result indicates the shape of the distributions minimizing the right-most terms in those bounds.</p><p>Theorem 1 For any f -divergence D f , with f ∈ F and f differentiable, any fixed distributions P d , P g , and any β ∈ (0, 1], the minimizer of (5) over all probability distributions P has density dQ *</p><formula xml:id="formula_9">β (x) = 1 β (λ * dP d (x) − (1 − β)dP g (x)) + = dP d β λ * − (1 − β) dP g dP d + .<label>(9)</label></formula><p>for the unique λ *</p><formula xml:id="formula_10">∈ [β, 1] satisfying dQ * β = 1. Also, λ * = 1 if and only if P d ((1 − β)dP g &gt; dP d ) = 0, which is equivalent to βdQ * β = dP d − (1 − β)dP g .</formula><p>Theorem 2 Given two distributions P d , P g and some β ∈ (0, 1], assume P d (dP g = 0) &lt; β. Let f ∈ F. The problem</p><formula xml:id="formula_11">min Q:βdQ≤dP d D f P g P d − βQ 1 − β</formula><p>has a solution with the density dQ †</p><formula xml:id="formula_12">β (x) = 1 β dP d (x) − λ † (1 − β)dP g (x) + for the unique λ † ≥ 1 that satisfies dQ † β = 1.</formula><p>Surprisingly, in both Theorems 1 and 2, the solutions do not depend on the choice of the function f , which means that the solution is the same for any f -divergence <ref type="bibr" target="#b4">5</ref> . Note that λ * is implicitly defined by a fixed-point equation. In Section 3 we will show how it can be computed efficiently in the case of empirical distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Convergence Analysis for Optimal Updates</head><p>In previous section we derived analytical expressions for the distributions R minimizing last terms in upper bounds <ref type="bibr" target="#b7">(8)</ref> and <ref type="formula" target="#formula_7">(7)</ref>. Assuming Q can perfectly match R, i.e. D f (Q R) = 0, we are now interested in the convergence of the mixture (4) to the true data distribution</p><formula xml:id="formula_13">P d when Q = Q D f P g P d − βQ † β 1 − β ≤ D f (P g P d ) and D f (1 − β)P g + βQ † β P d ≤ (1 − β)D f (P g P d ).</formula><p>Imagine repeatedly adding T new components to the current mixture P g , where on every step we use the same weight β and choose the components described in Theorem 1. In this case Lemma 2 guarantees that the original objective value D f (P g P d ) would be reduced at least to</p><formula xml:id="formula_14">(1 − β) T D f (P g P d )</formula><p>. <ref type="bibr" target="#b4">5</ref> in particular, by replacing f with f • (x) := xf (1/x), we get the same solution for the criterion written in the other direction. Hence the order in which we write the divergence does not matter and the optimal solution is optimal for both orders.</p><p>This exponential rate of convergence, which at first may look surprisingly good, is simply explained by the fact that Q * β depends on the true distribution P d , which is of course unknown. Lemma 2 also suggests setting β as large as possible since we assume we can compute the optimal mixture component (which for β = 1 is P d ). However, in practice we may prefer to keep β relatively small, preserving what we learned so far through P g : for instance, when P g already covered part of the modes of P d and we want Q to cover the remaining ones. We provide further discussions on choosing β in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Weak to Strong Learnability</head><p>In practice the component Q that we add to the mixture is not exactly Q * β or Q † β , but rather an approximation to them. In this section we show that if this approximation is good enough, then we retain the property (6) (exponential improvements).</p><p>Looking again at Lemma 1 we notice that the first upper bound is less tight than the second one. Indeed, take the optimal distributions provided by Theorems 1 and 2 and plug them back as R into the upper bounds of Lemma 1. Also assume that Q can match R exactly, i.e. D f (Q R) = 0. In this case both sides of <ref type="formula" target="#formula_7">(7)</ref> are equal to D f ((1 − β)P g + βQ * β P d ), which is the optimal value for the original objective <ref type="bibr" target="#b4">(5)</ref>. On the other hand, <ref type="bibr" target="#b7">(8)</ref> does not become an equality and the r.h.s. is not the optimal one for (5). However, earlier we agreed that our aim is to reach the modest goal (6) and next we show that this is indeed possible.Corollaries 1 and 2 provide sufficient conditions for strict improvements when we use the upper bounds <ref type="formula" target="#formula_8">(8)</ref> and <ref type="formula" target="#formula_7">(7)</ref> respectively.</p><formula xml:id="formula_15">Corollary 1 Given P d , P g , and some β ∈ (0, 1], assume P d dPg dP d = 0 &lt; β. Let Q † β be as defined in Theorem 2. If Q is such that D f (Q Q † β ) ≤ γD f (P g P d ) (10) for γ ∈ [0, 1], then D f ((1 − β)P g + βQ P d ) ≤ (1 − β(1 − γ))D f (P g P d ).</formula><p>Corollary 2 Let f ∈ F H . Take any β ∈ (0, 1], P d , P g , and let Q * β be as defined in Theorem 1. If Q is such that</p><formula xml:id="formula_16">D f (Q Q * β ) ≤ γD f (P g P d ) (11) for some γ ∈ [0, 1], then D f ((1 − β)P g + βQ P d ) ≤ C γ,β · D f (P g P d ) , where C γ,β = √ γβ + √ 1 − β 2</formula><p>is strictly smaller than 1 as soon as γ &lt; β/4 (and β &gt; 0).</p><p>Conditions 10 and 11 may be compared to the "weak learnability" condition of AdaBoost. As long as our weak learner is able to solve the surrogate problem (3) of matching respectively Q † β or Q * β accurately enough, the original objective <ref type="formula" target="#formula_5">(5)</ref> is guaranteed to decrease as well. It should be however noted that Condition 11 with γ &lt; β/4 is perhaps too strong to call it "weak learnability". Indeed, as already mentioned before, the weight β is expected to decrease to zero as the number of components in the mixture distribution P g increases. This leads to γ → 0, making it harder to meet Condition 11. This obstacle may be partially resolved by the fact that we will use a GAN to fit Q, which corresponds to a relatively rich <ref type="bibr" target="#b5">6</ref> class of models G in (3). In other words, our weak learner is not so weak. On the other hand, Condition 10 of Corollary 1 is milder. No matter what γ ∈ [0, 1] and β ∈ (0, 1] are, the new component Q is guaranteed to strictly improve the objective functional. This comes at the price of the additional condition P d (dP g /dP d = 0) &lt; β, which asserts that β should be larger than the mass of true data P d missed by the current model P g . We argue that this is a rather reasonable condition: if P g misses many modes of P d we would prefer assigning a relatively large weight β to the new component Q. However, in practice, both Conditions 10 and 11 are difficult to check. A rigorous analysis of situations when they are guaranteed is a direction for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">AdaGAN</head><p>We now describe the functions ChooseMixtureWeight and UpdateTrainingWeights of Algorithm 1. The complete AdaGAN meta-algorithm with the details of UpdateTrainingWeight and ChooseMixtureWeight, is summarized in Algorithm 3 of Appendix A.</p><p>UpdateTrainingWeights At each iteration we add a new component Q to the current mixture P g with weight β. The component Q should approach the "optimal target" Q * β provided by <ref type="bibr" target="#b8">(9)</ref> in Theorem 1. This distribution depends on the density ratio dP g /dP d , which is not directly accessible, but it can be estimated using adversarial training. Indeed, we can train a separate mixture discriminator D M to distinguish between samples from P d and samples from the current mixture P g . It is known <ref type="bibr" target="#b12">[13]</ref> that for an arbitrary f -divergence, there exists a corresponding function h such that the values of the optimal discriminator D M are related to the density ratio by</p><formula xml:id="formula_17">dP g dP d (x) = h D M (x) .<label>(12)</label></formula><p>We can replace dP g (x)/dP d (x) in <ref type="formula" target="#formula_9">(9)</ref> with h D M (x) . For the Jensen-Shannon divergence, used by the original GAN algorithm, h(z) = 1−z z . In practice, when we compute dQ * β on the training sample S N = (X 1 , . . . , X N ), each example X i receives weight</p><formula xml:id="formula_18">w i = 1 βN λ * − (1 − β)h(d i ) + , where d i = D M (X i ) .<label>(13)</label></formula><p>The only remaining task is to determine λ * . As the weights w i in (13) must sum to 1, we get:</p><formula xml:id="formula_19">λ * = β i∈I(λ * ) p i   1 + (1 − β) β i∈I(λ * ) p i h(d i )  <label>(14)</label></formula><p>where</p><formula xml:id="formula_20">I(λ) := {i : λ &gt; (1 − β)h(d i )}. To find I(λ * ), we sort h(d i ) in increasing order: h(d 1 ) ≤ . . . ≤ h(d N ). Then I(λ * )</formula><p>is a set consisting of the first k indices. We then successively test all k-s until the λ given by <ref type="bibr" target="#b13">(14)</ref> </p><formula xml:id="formula_21">verifies (1 − β)h(d k ) &lt; λ ≤ (1 − β)h(d k+1 )</formula><p>. This procedure is guaranteed to converge by Theorem 1. It is summarized in Algorithm 2 of Appendix A ChooseMixtureWeight For every β there is an optimal re-weighting scheme with weights given by <ref type="bibr" target="#b12">(13)</ref>. If the GAN could perfectly approximate its target Q * β , then choosing β = 1 would be optimal, because Q * 1 = P d . But in practice, GANs cannot do that. So we propose to choose β heuristically by imposing that each generator of the final mixture model has same weight. This yields β t = 1/t, where t is the iteration index. Other heuristics are proposed in Appendix B, but did not lead to any significant difference.</p><p>The optimal discriminator In practice it is of course hard to find the optimal discriminator D M achieving the global maximum of the variational representation for the f-divergence and verifying <ref type="bibr" target="#b11">(12)</ref>. For the JS-divergence this would mean that D M is the classifier achieving minimal expected crossentropy loss in the binary classification between P g and P d . In practice, we observed that the reweighting (13) leads to the desired property of emphasizing at least some of the missing modes as long as D M distinguishes reasonably between data points already covered by the current model P g and those which are still missing. We found an early stopping (while training D M ) sufficient to achieve this. In the worst case, when D M overfits and returns 1 for all true data points, the reweighting simply leads to the uniform distribution over the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We ran AdaGAN 7 on toy datasets, for which we can interpret the missing modes in a clear and reproducible way, and on MNIST, which is a high-dimensional dataset. The goal of these experiments was not to evaluate the visual quality of individual sample points, but to demonstrate that the re-weighting scheme of AdaGAN promotes diversity and effectively covers the missing modes.</p><p>Toy Datasets Our target distribution is a mixture of isotropic Gaussians over R 2 . The distances between the means are large enough to roughly avoid overlaps between different Gaussian components. We vary the number of modes to test how well each algorithm performs when there are fewer or more expected modes. We compare the baseline GAN algorithm with AdaGAN variations, and with other meta-algorithms that all use the same underlying GAN procedure. For details on these algorithms and on the architectures of the underlying generator and discriminator, see Appendix B.</p><p>To evaluate how well the generated distribution matches the target distribution, we use a coverage metric C. We compute the probability mass of the true data "covered" by the model P model . More precisely, we compute C := P d (dP model &gt; t) with t such that P model (dP model &gt; t) = 0.95. This metric is more interpretable than the likelihood, making it easier to assess the difference in performance of the algorithms. To approximate the density of P model we use a kernel density estimation, where the bandwidth is chosen by cross validation. We repeat the run 35 times with the same parameters (but different random seeds). For each run, the learning rate is optimized using a grid search on a validation set. We report the median over those multiple runs, and the interval corresponding to the 5% and 95% percentiles. <ref type="figure" target="#fig_2">Figure 2</ref> summarizes the performance of algorithms as a function of the number of iterations T . Both the ensemble and the boosting approaches significantly outperform the vanilla GAN and the "best of T " algorithm. Interestingly, the improvements are significant even after just one or two additional iterations (T = 2 or 3). Our boosting approach converges much faster. In addition, its variance is much lower, improving the likelihood that a given run gives good results. On this setup, the vanilla GAN approach has a significant number of catastrophic failures (visible in the lower bounds of the intervals). Further empirical results are available in Appendix B, where we compared AdaGAN variations to several other baseline meta-algorithms in more details <ref type="table">(Table 1</ref>) and combined AdaGAN with the unrolled GANs (UGAN) <ref type="bibr" target="#b3">[4]</ref>  <ref type="figure">(Figure 3)</ref>. Interestingly, <ref type="figure">Figure 3</ref> shows that AdaGAN ran with UGAN outperforms the vanilla UGAN on the toy datasets, demonstrating the advantage of using AdaGAN as a way to further improve the mode coverage of any existing GAN implementations. Experiments correspond to the data distribution with 5 modes. Each blue point is the median over 35 runs. Green intervals are defined by the 5% and 95% percentiles (see Section 4). Iteration 0 is equivalent to one vanilla GAN. The left plot corresponds to taking the best generator out of T runs. The middle plot is an "ensemble" GAN, simply taking a uniform mixture of T independently trained GAN generators. The right plot corresponds to our boosting approach (AdaGAN), with β t = 1/t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MNIST and MNIST3</head><p>We ran experiments both on the original MNIST and on the 3-digit MNIST (MNIST3) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b3">4]</ref> dataset, obtained by concatenating 3 randomly chosen MNIST images to form a 3-digit number between 0 and 999. According to <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b3">4]</ref>, MNIST contains 10 modes, while MNIST3 contains 1000 modes, and these modes can be detected using the pre-trained MNIST classifier. We combined AdaGAN both with simple MLP GANs and DCGANs <ref type="bibr" target="#b18">[19]</ref>. We used T ∈ {5, 10}, tried models of various sizes and performed a reasonable amount of hyperparameter search.</p><p>Similarly to <ref type="bibr" target="#b3">[4,</ref><ref type="bibr">Sec 3.3</ref>.1] we failed to reproduce the missing modes problem for MNIST3 reported in <ref type="bibr" target="#b4">[5]</ref> and found that simple GAN architectures are capable of generating all 1000 numbers. The authors of <ref type="bibr" target="#b3">[4]</ref> proposed to artificially introduce the missing modes again by limiting the generators' flexibility. In our experiments, GANs trained with the architectures reported in <ref type="bibr" target="#b3">[4]</ref> were often generating poorly looking digits. As a result, the pre-trained MNIST classifier was outputting random labels, which again led to full coverage of the 1000 numbers. We tried to threshold the confidence of the pre-trained classifier, but decided that this metric was too ad-hoc. For MNIST we noticed that the re-weighted distribution was often concentrating its mass on digits having very specific strokes: on different rounds it could highlight thick, thin, vertical, or diagonal digits, indicating that these traits were underrepresented in the generated samples (see <ref type="figure" target="#fig_2">Figure 2</ref>). This suggests that AdaGAN does a reasonable job at picking up different modes of the dataset, but also that there are more than 10 modes in MNIST (and more than 1000 in MNIST3). It is not clear how to evaluate the quality of generative models in this context.</p><p>We also tried to use the "inversion" metric discussed in Section 3.4.1 of <ref type="bibr" target="#b3">[4]</ref>. For MNIST3 we noticed that a single GAN was capable of reconstructing most of the training points very accurately both visually and in the 2 -reconstruction sense. The "inversion" metric tests whether the trained model can generate certain examples or not, but unfortunately it does not take into account the probabilities of doing so.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We studied the problem of minimizing general f -divergences with additive mixtures of distributions. The main contribution of this work is a detailed theoretical analysis, which naturally leads to an iterative greedy procedure. On every iteration the mixture is updated with a new component, which minimizes f -divergence with a re-weighted target distribution. We provided conditions under which this procedure is guaranteed to converge to the target distribution at an exponential rate. While our results can be combined with any generative modelling techniques, we focused on GANs and provided a boosting-style algorithm AdaGAN. Preliminary experiments show that AdaGAN successfully produces a mixture which iteratively covers the missing modes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Coverage C of the true data by the model distribution P T model , as a function of iterations T . Experiments correspond to the data distribution with 5 modes. Each blue point is the median over 35 runs. Green intervals are defined by the 5% and 95% percentiles (see Section 4). Iteration 0 is equivalent to one vanilla GAN. The left plot corresponds to taking the best generator out of T runs. The middle plot is an "ensemble" GAN, simply taking a uniform mixture of T independently trained GAN generators. The right plot corresponds to our boosting approach (AdaGAN), with β t = 1/t.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Digits from the MNIST dataset corresponding to the smallest (left) and largest (right) weights, obtained by the AdaGAN procedure (see Section 3) in one of the runs. Bold digits (left) are already covered and next GAN will concentrate on thin (right) digits.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that the term "mixture" should not be interpreted to imply that each component models only one mode: the models to be combined into a mixture can themselves cover multiple modes.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">One example of such a setting is running GANs.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">The hardness of meeting Condition 11 of course largely depends on the class of models G used to fit Q in (3). For now we ignore this question and leave it for future research.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">Code available online at https://github.com/tolstikhin/adagan</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gan</forename><surname>Wasserstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02163</idno>
		<title level="m">Unrolled generative adversarial networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanran</forename><surname>Tong Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.02136</idno>
		<title level="m">Mode regularized generative adversarial networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Self supervised boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="665" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning generative models via discriminative approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Boosted generative models. ICLR 2017 conference submission</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Annealed importance sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="139" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Boosting density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saharon</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eran</forename><surname>Segal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="641" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mixture density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="603" to="618" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van De Weijer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.00991</idno>
		<title level="m">Ensembles of generative adversarial networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Training generative neural samplers using variational divergence minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryota</forename><surname>Tomioka. F-Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Statistical Decision Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-J</forename><surname>Miescke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Information, divergence and risk for binary experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="731" to="817" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Jensen-shannon divergence and hilbert space embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bent</forename><surname>Fuglede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flemming</forename><surname>Topsoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Information Theory</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="31" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hilbertian metrics and positive definite kernels on probability measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="136" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A decision-theoretic generalization of on-line learning and an application to boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="139" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
