<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Numerics of GANs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Mescheder</surname></persName>
							<email>lars.mescheder@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Autonomous Vision Group MPI Tübingen</orgName>
								<orgName type="laboratory" key="lab2">Machine Intelligence and Perception Group Microsoft Research</orgName>
								<orgName type="laboratory" key="lab3">Autonomous Vision Group MPI</orgName>
								<address>
									<settlement>Tübingen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
							<email>sebastian.nowozin@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Autonomous Vision Group MPI Tübingen</orgName>
								<orgName type="laboratory" key="lab2">Machine Intelligence and Perception Group Microsoft Research</orgName>
								<orgName type="laboratory" key="lab3">Autonomous Vision Group MPI</orgName>
								<address>
									<settlement>Tübingen</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
							<email>andreas.geiger@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Autonomous Vision Group MPI Tübingen</orgName>
								<orgName type="laboratory" key="lab2">Machine Intelligence and Perception Group Microsoft Research</orgName>
								<orgName type="laboratory" key="lab3">Autonomous Vision Group MPI</orgName>
								<address>
									<settlement>Tübingen</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Numerics of GANs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>In this paper, we analyze the numerics of common algorithms for training Generative Adversarial Networks (GANs). Using the formalism of smooth two-player games we analyze the associated gradient vector field of GAN training objectives. Our findings suggest that the convergence of current algorithms suffers due to two factors: i) presence of eigenvalues of the Jacobian of the gradient vector field with zero real-part, and ii) eigenvalues with big imaginary part. Using these findings, we design a new algorithm that overcomes some of these limitations and has better convergence properties. Experimentally, we demonstrate its superiority on training common GAN architectures and show convergence on GAN architectures that are known to be notoriously hard to train.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Generative Adversarial Networks (GANs) <ref type="bibr" target="#b9">[10]</ref> have been very successful in learning probability distributions. Since their first appearance, GANs have been successfully applied to a variety of tasks, including image-to-image translation <ref type="bibr" target="#b11">[12]</ref>, image super-resolution <ref type="bibr" target="#b12">[13]</ref>, image in-painting <ref type="bibr" target="#b26">[27]</ref> domain adaptation <ref type="bibr" target="#b25">[26]</ref>, probabilistic inference <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b7">8]</ref> and many more.</p><p>While very powerful, GANs are known to be notoriously hard to train. The standard strategy for stabilizing training is to carefully design the model, either by adapting the architecture <ref type="bibr" target="#b20">[21]</ref> or by selecting an easy-to-optimize objective function <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b10">11]</ref>.</p><p>In this work, we examine the general problem of finding local Nash-equilibria of smooth games. We revisit the de-facto standard algorithm for finding such equilibrium points, simultaneous gradient ascent. We theoretically show that the main factors preventing the algorithm from converging are the presence of eigenvalues of the Jacobian of the associated gradient vector field with zero real-part and eigenvalues with a large imaginary part. The presence of the latter is also one of the reasons that make saddle-point problems more difficult than local optimization problems. Utilizing these insights, we design a new algorithm that overcomes some of these problems. Experimentally, we show that our algorithm leads to stable training on many GAN architectures, including some that are known to be hard to train.</p><p>Our technique is orthogonal to strategies that try to make the GAN-game well-defined, e.g. by adding instance noise <ref type="bibr" target="#b23">[24]</ref> or by using the Wasserstein-divergence <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11]</ref>: while these strategies try to ensure the existence of Nash-equilibria, our paper deals with their computation and the numerical difficulties that can arise in practice. <ref type="bibr">31st</ref> Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.</p><p>In summary, our contributions are as follows:</p><p>• We identify the main reasons why simultaneous gradient ascent often fails to find local Nash-equilibria.</p><p>• By utilizing these insights, we design a new, more robust algorithm for finding Nashequilibria of smooth two-player games.</p><p>• We empirically demonstrate that our method enables stable training of GANs on a variety of architectures and divergence measures.</p><p>The proofs for the theorems in this paper can be found the supplementary material. <ref type="bibr" target="#b0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In this section we first revisit the concept of Generative Adversarial Networks (GANs) from a divergence minimization point of view. We then introduce the concept of a smooth (non-convex) two-player game and define the terminology used in the rest of the paper. Finally, we describe simultaneous gradient ascent, the de-facto standard algorithm for finding Nash-equilibria of such games, and derive some of its properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Divergence Measures and GANs</head><p>Generative Adversarial Networks are best understood in the context of divergence minimization: assume we are given a divergence function D, i.e. a function that takes a pair of probability distributions as input, outputs an element from [0, ∞] and satisfies D(p, p) = 0 for all probability distributions p. Moreover, assume we are given some target distribution p 0 from which we can draw i.i.d. samples and a parametric family of distributions q θ that also allows us to draw i.i.d. samples. In practice q θ is usually implemented as a neural network that acts on a hidden code z sampled from some known distribution and outputs an element from the target space. Our goal is to findθ that minimizes the divergence D(p 0 , q θ ), i.e. we want to solve the optimization problem</p><formula xml:id="formula_0">min θ D(p 0 , q θ ).<label>(1)</label></formula><p>Most divergences that are used in practice can be represented in the following form <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b3">4]</ref>:</p><formula xml:id="formula_1">D(p, q) = max f ∈F E x∼q [g 1 (f (x))] − E x∼p [g 2 (f (x))]<label>(2)</label></formula><p>for some function class F ⊆ X → R and convex functions g 1 , g 2 : R → R. Together with (1), this leads to mini-max problems of the form</p><formula xml:id="formula_2">min θ max f ∈F E x∼q θ [g 1 (f (x))] − E x∼p0 [g 2 (f (x))] .<label>(3)</label></formula><p>These divergences include the Jensen-Shannon divergence <ref type="bibr" target="#b9">[10]</ref>, all f-divergences <ref type="bibr" target="#b15">[16]</ref>, the Wasserstein divergence <ref type="bibr" target="#b3">[4]</ref> and even the indicator divergence, which is 0 if p = q and ∞ otherwise.</p><p>In practice, the function class F in (3) is approximated with a parametric family of functions, e.g. parameterized by a neural network. Of course, when minimizing the divergence w.r.t. this approximated family, we no longer minimize the correct divergence. However, it can be verified that taking any class of functions in (3) leads to a divergence function for appropriate choices of g 1 and g 2 . Therefore, some authors call these divergence functions neural network divergences <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Smooth Two-Player Games</head><p>A differentiable two-player game is defined by two utility functions f (φ, θ) and g(φ, θ) defined over a common space (φ, θ) ∈ Ω 1 × Ω 2 . Ω 1 corresponds to the possible actions of player 1, Ω 2 corresponds to the possible actions of player 2. The goal of player 1 is to maximize f , whereas player 2 tries to maximize g. In the context of GANs, Ω 1 is the set of possible parameter values for the generator, whereas Ω 2 is the set of possible parameter values for the discriminator. We call a game a zero-sum game if f = −g. Note that the derivation of the GAN-game in Section 2.1 leads to a zero-sum game, </p><formula xml:id="formula_3">v φ ← ∇ φ f (θ, φ) 3: v θ ← ∇ θ g(θ, φ) 4: φ ← φ + hv φ 5:</formula><p>θ ← θ + hv θ 6: end while whereas in practice people usually employ a variant of this formulation that is not a zero-sum game for better convergence <ref type="bibr" target="#b9">[10]</ref>.</p><p>Our goal is to find a Nash-equilibrium of the game, i.e. a pointx = (φ,θ) given by the two conditions</p><formula xml:id="formula_4">φ ∈ argmax φ f (φ,θ) andθ ∈ argmax θ g(φ, θ).<label>(4)</label></formula><p>We call a point (φ,θ) a local Nash-equilibrium, if (4) holds in a local neighborhood of (φ,θ).</p><p>Every differentiable two-player game defines a vector field</p><formula xml:id="formula_5">v(φ, θ) = ∇ φ f (φ, θ) ∇ θ g(φ, θ) .<label>(5)</label></formula><p>We call v the associated gradient vector field to the game defined by f and g.</p><p>For the special case of zero-sum two-player games, we have g = −f and thus</p><formula xml:id="formula_6">v (φ, θ) = ∇ 2 φ f (φ, θ) ∇ φ,θ f (φ, θ) −∇ φ,θ f (φ, θ) −∇ 2 θ f (φ, θ) .<label>(6)</label></formula><p>As a direct consequence, we have the following: Lemma 1. For zero-sum games, v (x) is negative (semi-)definite if and only if</p><formula xml:id="formula_7">∇ 2 φ f (φ, θ) is negative (semi-)definite and ∇ 2 θ f (φ, θ) is positive (semi-)definite.</formula><p>Corollary 2. For zero-sum games, v (x) is negative semi-definite for any local Nash-equilibrium x. Conversely, ifx is a stationary point of v(x) and v (x) is negative definite, thenx is a local Nash-equilibrium.</p><p>Note that Corollary 2 is not true for general two-player games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Simultaneous Gradient Ascent</head><p>The de-facto standard algorithm for finding Nash-equilibria of general smooth two-player games is Simultaneous Gradient Ascent (SimGA), which was described in several works, for example in <ref type="bibr" target="#b21">[22]</ref> and, more recently also in the context of GANs, in <ref type="bibr" target="#b15">[16]</ref>. The idea is simple and is illustrated in Algorithm 1. We iteratively update the parameters of the two players by simultaneously applying gradient ascent to the utility functions of the two players. This can also be understood as applying the Euler-method to the ordinary differential equation</p><formula xml:id="formula_8">d dt x(t) = v(x(t)),<label>(7)</label></formula><p>where v(x) is the associated gradient vector field of the two-player game.</p><p>It can be shown that simultaneous gradient ascent converges locally to a Nash-equilibrium for a zero-sum game, if the Hessian of both players is negative definite <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b21">22]</ref> and the learning rate is small enough. Unfortunately, in the context of GANs the former condition is rarely met. We revisit the properties of simultaneous gradient ascent in Section 3 and also show a more subtle property, namely that even if the conditions for the convergence of simultaneous gradient ascent are met, it might require extremely small step sizes for convergence if the Jacobian of the associated gradient vector field has eigenvalues with large imaginary part.  when discretizing the gradient flow with step size h, the eigenvalues of the Jacobian at a fixed point are projected into the unit ball along rays from 1. However, this is only possible if the eigenvalues lie in the left half plane and requires extremely small step sizes h if the eigenvalues are close to the imaginary axis. The proposed method moves the eigenvalues to the left in order to make the problem better posed, thus allowing the algorithm to converge for reasonable step sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Convergence Theory</head><p>In this section, we analyze the convergence properties of the most common method for training GANs, simultaneous gradient ascent <ref type="bibr" target="#b1">2</ref> . We show that two major failure causes for this algorithm are eigenvalues of the Jacobian of the associated gradient vector field with zero real-part as well as eigenvalues with large imaginary part.</p><p>For our theoretical analysis, we start with the following classical theorem about the convergence of fixed-point iterations: Then there is an open neighborhood U ofx so that for all x 0 ∈ U , the iterates F (k) (x 0 ) converge tox. The rate of convergence is at least linear. More precisely, the error</p><formula xml:id="formula_9">F (k) (x 0 ) −x is in O(|λ max | k ) for k → ∞</formula><p>where λ max is the eigenvalue of F (x) with the largest absolute value.</p><p>Proof. See <ref type="bibr" target="#b5">[6]</ref>, Proposition 4.4.1.</p><p>In numerics, we often consider functions of the form</p><formula xml:id="formula_10">F (x) = x + h G(x)<label>(8)</label></formula><p>for some h &gt; 0. Finding fixed points of F is then equivalent to finding solutions to the nonlinear equation G(x) = 0 for x. For F as in <ref type="formula" target="#formula_10">(8)</ref>, the Jacobian is given by</p><formula xml:id="formula_11">F (x) = I + h G (x).<label>(9)</label></formula><p>Note that in general neither F (x) nor G (x) are symmetric and can therefore have complex eigenvalues.</p><p>The following Lemma gives an easy condition, when a fixed point of F as in <ref type="formula" target="#formula_10">(8)</ref> satisfies the conditions of Proposition 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 4.</head><p>Assume that A ∈ R n×n only has eigenvalues with negative real-part and let h &gt; 0. Then the eigenvalues of the matrix I + h A lie in the unit ball if and only if</p><formula xml:id="formula_12">h &lt; 1 | (λ)| 2 1 + (λ) (λ) 2 (10)</formula><note type="other">for all eigenvalues λ of A. Corollary 5. If v (x) only has eigenvalues with negative real-part at a stationary pointx, then Algorithm 1 is locally convergent tox for h &gt; 0 small enough. Equation 10</note><p>shows that there are two major factors that determine the maximum possible step size h: (i) the maximum value of (λ) and (ii) the maximum value q of | (λ)/ (λ)|. Note that as q goes to infinity, we have to choose h according to O(q −2 ) which can quickly become extremely small. This is visualized in <ref type="figure" target="#fig_1">Figure 1</ref>: if G (x) has an eigenvalue with small absolute real part but big imaginary part, h needs to be chosen extremely small to still achieve convergence. Moreover, even if we make h small enough, most eigenvalues of F (x) will be very close to 1, which leads by Proposition 3 to very slow convergence of the algorithm. This is in particular a problem of simultaneous gradient ascent for two-player games (in contrast to gradient ascent for local optimization), where the Jacobian G (x) is not symmetric and can therefore have non-real eigenvalues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Consensus Optimization</head><p>In this section, we derive the proposed method and analyze its convergence properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Derivation</head><p>Finding stationary points of the vector field v(x) is equivalent to solving the equation v(x) = 0. In the context of two-player games this means solving the two equations ∇ φ f (φ, θ) = 0 and ∇ θ g(φ, θ) = 0.</p><p>A simple strategy for finding such stationary points is to minimize L(x) = 2 and in practice, we found it did not work well.</p><p>We therefore consider a modified vector field w(x) that is as close as possible to the original vector field v(x), but at the same time still minimizes L(x) (at least locally). A sensible candidate for such a vector field is</p><formula xml:id="formula_14">w(x) = v(x) − γ∇L(x)<label>(12)</label></formula><p>for some γ &gt; 0. A simple calculation shows that the gradient ∇L(x) is given by</p><formula xml:id="formula_15">∇L(x) = v (x) T v(x).<label>(13)</label></formula><p>This vector field is the gradient vector field associated to the modified two-player game given by the two modified utility functions</p><formula xml:id="formula_16">f (φ, θ) = f (φ, θ) − γL(φ, θ) andg(φ, θ) = g(φ, θ) − γL(φ, θ).<label>(14)</label></formula><p>The regularizer L(φ, θ) encourages agreement between the two players. Therefore we call the resulting algorithm Consensus Optimization (Algorithm 2). <ref type="bibr">3 4 3</ref> This algorithm requires backpropagation through the squared norm of the gradient with respect to the weights of the network. This is sometimes called double backpropagation and is for example supported by the deep learning frameworks Tensorflow <ref type="bibr" target="#b0">[1]</ref> and PyTorch <ref type="bibr" target="#b18">[19]</ref>. <ref type="bibr" target="#b3">4</ref> As was pointed out by Ferenc Huzsár in one of his blog posts on www.inference.vc, naively implementing this algorithm in a mini-batch setting leads to biased estimates of L(x). However, the bias goes down linearly with the batch size, which justifies the usage of consensus optimization in a mini-batch setting. Alternatively, it is possible to debias the estimate by subtracting a multiple of the sample variance of the gradients, see the supplementary material for details. </p><formula xml:id="formula_17">v φ ← ∇ φ (f (θ, φ) − γL(θ, φ)) 3: v θ ← ∇ θ (g(θ, φ) − γL(θ, φ)) 4: φ ← φ + hv φ 5:</formula><p>θ ← θ + hv θ 6: end while</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Convergence</head><p>For analyzing convergence, we consider a more general algorithm than in Section 4.1 which is given by iteratively applying a function F of the form</p><formula xml:id="formula_18">F (x) = x + h A(x)v(x).<label>(15)</label></formula><p>for some step size h &gt; 0 and an invertible matrix A(x) to x. Consensus optimization is a special case of this algorithm for A(x) = I − γ v (x) T . We assume that 1 γ is not an eigenvalue of v (x) T for any x, so that A(x) is indeed invertible. Lemma 6. Assume h &gt; 0 and A(x) invertible for all x. Thenx is a fixed point of (15) if and only if it is a stationary point of v. Moreover, ifx is a stationary point of v, we have</p><formula xml:id="formula_19">F (x) = I + hA(x)v (x).<label>(16)</label></formula><p>Lemma 7. Let A(x) = I − γv (x) T and assume that v (x) is negative semi-definite and invertible 5 . Then A(x)v (x) is negative definite.</p><p>As a consequence of Lemma 6 and Lemma 7, we can show local convergence of our algorithm to a local Nash equilibrium: Corollary 8. Let v(x) be the associated gradient vector field of a two-player zero-sum game and A(x) = I − γv (x) T . Ifx is a local Nash-equilibrium, then there is an open neighborhood U ofx so that for all x 0 ∈ U , the iterates F (k) (x 0 ) converge tox for h &gt; 0 small enough.</p><p>Our method solves the problem of eigenvalues of the Jacobian with (approximately) zero real-part. As the next Lemma shows, it also alleviates the problem of eigenvalues with a big imaginary-to-realpart-quotient:</p><p>Lemma 9. Assume that A ∈ R n×n is negative semi-definite. Let q(γ) be the maximum of</p><formula xml:id="formula_20">| (λ)| | (λ)|</formula><p>(possibly infinite) with respect to λ where λ denotes the eigenvalues of A − γA T A and (λ) and (λ) denote their real and imaginary part respectively. Moreover, assume that A is invertible with |Av| ≥ ρ|v| for ρ &gt; 0 and let c = min</p><formula xml:id="formula_21">v∈S(C n ) |v T (A + A T )v| |v T (A − A T )v| (17)</formula><p>where S(C n ) denotes the unit sphere in C n . Then</p><formula xml:id="formula_22">q(γ) ≤ 1 c + 2ρ 2 γ .<label>(18)</label></formula><p>Lemma 9 shows that the imaginary-to-real-part-quotient can be made arbitrarily small for an appropriate choice of γ. According to Proposition 3, this leads to better convergence properties near a local Nash-equilibrium.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Mixture of Gaussians In our first experiment we evaluate our method on a simple 2D-example where our goal is to learn a mixture of 8 Gaussians with standard deviations equal to 10 −2 and modes </p><formula xml:id="formula_23">v (x) w (x)</formula><p>Before training After training <ref type="figure" target="#fig_2">Figure 3</ref>: Empirical distribution of eigenvalues before and after training using consensus optimization. The first column shows the distribution of the eigenvalues of the Jacobian v (x) of the unmodified vector field v(x). The second column shows the eigenvalues of the Jacobian w (x) of the regularized vector field w(x) = v(x) − γ∇L(x) used in consensus optimization. We see that v (x) has eigenvalues close to the imaginary axis near the Nash-equilibrium. As predicted theoretically, this is not the case for the regularized vector field w(x). For visualization purposes, the real part of the spectrum of w (x) before training was clipped.</p><p>uniformly distributed around the unit circle. While simplistic, algorithms training GANs often fail to converge even on such simple examples without extensive fine-tuning of the architecture and hyper parameters <ref type="bibr" target="#b14">[15]</ref>.</p><p>For both the generator and critic we use fully connected neural networks with 4 hidden layers and 16 hidden units in each layer. For all layers, we use RELU-nonlinearities. We use a 16-dimensional Gaussian prior for the latent code z and set up the game between the generator and critic using the utility functions as in <ref type="bibr" target="#b9">[10]</ref>. To test our method, we run both SimGA and our method with RMSProp and a learning rate of 10 −4 for 20000 steps. For our method, we use a regularization parameter of γ = 10.</p><p>The results produced by SimGA and our method for 0, 5000, 10000 and 20000 iterations are depicted in <ref type="figure" target="#fig_5">Figure 2</ref>. We see that while SimGA jumps around the modes of the distribution and fails to converge , our method converges smoothly to the target distribution (shown in red). <ref type="figure" target="#fig_2">Figure 3</ref> shows the empirical distribution of the eigenvalues of the Jacobian of v(x) and the regularized vector field w(x). It can be seen that near the Nash-equilibrium most eigenvalues are indeed very close to the  <ref type="figure">Figure 4</ref>: Samples generated from a model where both the generator and discriminator are given as in <ref type="bibr" target="#b20">[21]</ref>, but without batch-normalization. For celebA, we also use a constant number of filters in each layer and add additional RESNET-layers. Comparison of the inception score over time which was computed using 6400 samples. We see that on this architecture both methods have comparable rates of convergence and consensus optimization achieves slightly better end results.</p><p>imaginary axis and that the proposed modification of the vector field used in consensus optimization moves the eigenvalues to the left.</p><p>CIFAR-10 and CelebA In our second experiment, we apply our method to the cifar-10 and celebAdatasets, using a DC-GAN-like architecture <ref type="bibr" target="#b20">[21]</ref> without batch normalization in the generator or the discriminator. For celebA, we additionally use a constant number of filters in each layer and add additional RESNET-layers. These architectures are known to be hard to optimize using simultaneous (or alternating) gradient ascent <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b3">4]</ref>. <ref type="figure">Figure 4a</ref> and 4b depict samples from the model trained with our method. We see that our method successfully trains the models and we also observe that unlike when using alternating gradient ascent, the generator and discriminator losses remain almost constant during training. This is illustrated in <ref type="figure" target="#fig_7">Figure 5</ref>. For a quantitative evaluation, we also measured the inception-score <ref type="bibr" target="#b22">[23]</ref> over time <ref type="figure" target="#fig_7">(Figure 5c</ref>), showing that our method compares favorably to a DC-GAN trained with alternating gradient ascent. The improvement of consensus optimization over alternating gradient ascent is even more significant if we use 4 instead of 3 convolutional layers, see <ref type="figure" target="#fig_1">Figure 11</ref> in the supplementary material for details.</p><p>Additional experimental results can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>While we could prove local convergence of our method in Section 4, we believe that even more insights can be gained by examining global convergence properties. In particular, our analysis from Section 4 cannot explain why the generator and discriminator losses remain almost constant during training.</p><p>Our theoretical results assume the existence of a Nash-equilibrium. When we are trying to minimize an f-divergence and the dimensionality of the generator distribution is misspecified, this might not be the case <ref type="bibr" target="#b2">[3]</ref>. Nonetheless, we found that our method works well in practice and we leave a closer theoretical investigation of this fact to future research.</p><p>In practice, our method can potentially make formerly instable stationary points of the gradient vector field stable if the regularization parameter is chosen to be high. This may lead to poor solutions. We also found that our method becomes less stable for deeper architectures, which we attribute to the fact that the gradients can have very different scales in such architectures, so that the simple L2-penalty from Section 4 needs to be rescaled accordingly.</p><p>Our method can be regarded as an approximation to the implicit Euler method for integrating the gradient vector field. It can be shown that the implicit Euler method has appealing stability properties <ref type="bibr" target="#b6">[7]</ref> that can be translated into convergence theorems for local Nash-equilibria. However, the implicit Euler method requires the solution of a nonlinear equation in each iteration. Nonetheless, we believe that further progress can be made by finding better approximations to the implicit Euler method.</p><p>An alternative interpretation is to view our method as a second order method. We hence believe that further progress can be made by revisiting second order optimization methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b17">18]</ref> in the context of saddle point problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Work</head><p>Saddle point problems do not only arise in the context of training GANs. For example, the popular actor-critic models <ref type="bibr" target="#b19">[20]</ref> in reinforcement learning are also special cases of saddle-point problems.</p><p>Finding a stable algorithm for training GANs is a long standing problem and multiple solutions have been proposed. Unrolled GANs <ref type="bibr" target="#b14">[15]</ref> unroll the optimization with respect to the critic, thereby giving the generator more informative gradients. Though unrolling the optimization was shown to stabilize training, it can be cumbersome to implement and in addition it also results in a big model. As was recently shown, the stability of GAN-training can be improved by using objectives derived from the Wasserstein-1-distance (induced by the Kantorovich-Rubinstein-norm) instead of f-divergences <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11]</ref>. While Wasserstein-GANs often provide a good solution for the stable training of GANs, they require keeping the critic optimal, which can be time-consuming and can in practice only be achieved approximately, thus violating the conditions for theoretical guarantees. Moreover, some methods like Adversarial Variational Bayes <ref type="bibr" target="#b13">[14]</ref> explicitly prescribe the divergence measure to be used, thus making it impossible to apply Wasserstein-GANs. Other approaches that try to stabilize training, try to design an easy-to-optimize architecture <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b20">21]</ref> or make use of additional labels <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>In contrast to all the approaches described above, our work focuses on stabilizing training on a wide range of architecture and divergence functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this work, starting from GAN objective functions we analyzed the general difficulties of finding local Nash-equilibria in smooth two-player games. We pinpointed the major numerical difficulties that arise in the current state-of-the-art algorithms and, using our insights, we presented a new algorithm for training generative adversarial networks. Our novel algorithm has favorable properties in theory and practice: from the theoretical viewpoint, we showed that it is locally convergent to a Nashequilibrium even if the eigenvalues of the Jacobian are problematic. This is particularly interesting for games that arise in the context of GANs where such problems are common. From the practical viewpoint, our algorithm can be used in combination with any GAN-architecture whose objective can be formulated as a two-player game to stabilize the training. We demonstrated experimentally that our algorithm stabilizes the training and successfully combats training issues like mode collapse. We believe our work is a first step towards an understanding of the numerics of GAN training and more general deep learning objective functions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>how our method alle- viates the problem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Images showing how the eigenvalues of A are projected into the unit circle and what causes problems: when discretizing the gradient flow with step size h, the eigenvalues of the Jacobian at a fixed point are projected into the unit ball along rays from 1. However, this is only possible if the eigenvalues lie in the left half plane and requires extremely small step sizes h if the eigenvalues are close to the imaginary axis. The proposed method moves the eigenvalues to the left in order to make the problem better posed, thus allowing the algorithm to converge for reasonable step sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Proposition 3 .</head><label>3</label><figDesc>Let F : Ω → Ω be a continuously differential function on an open subset Ω of R n and letx ∈ Ω be so that 1. F (x) =x, and 2. the absolute values of the eigenvalues of the Jacobian F (x) are all smaller than 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>x. Unfor- tunately, this can result in unstable stationary points of v or other local minima of 1 2 v(x)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of Simultaneous Gradient Ascent and Consensus optimization on a circular mixture of Gaussians. The images depict from left to right the resulting densities of the algorithm after 0, 5000, 10000 and 20000 iterations as well as the target density (in red).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: (a) and (b): Comparison of the generator and discriminator loss on a DC-GAN architecture with 3 convolutional layers trained on cifar-10 for consensus optimization (without batchnormalization) and alternating gradient ascent (with batch-normalization). We observe that while alternating gradient ascent leads to highly fluctuating losses, consensus optimization successfully stabilizes the training and makes the losses almost constant during training. (c): Comparison of the inception score over time which was computed using 6400 samples. We see that on this architecture both methods have comparable rates of convergence and consensus optimization achieves slightly better end results.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The code for all experiments in this paper is available under https://github.com/LMescheder/ TheNumericsOfGANs.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">A similar analysis of alternating gradient ascent, a popular alternative to simultaneous gradient ascent, can be found in the supplementary material.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Note that v (x) is usually not symmetric and therefore it is possible that v (x) is negative semi-definite and invertible but not negative-definite.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by Microsoft Research through its PhD Scholarship Programme.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<idno>abs/1603.04467</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Natural gradient works efficiently in learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shun-Ichi Amari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="276" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Towards principled methods for training generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<idno>abs/1701.04862</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gan</forename><surname>Wasserstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corr</surname></persName>
		</author>
		<idno>abs/1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generalization and equilibrium in generative adversarial nets (gans)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-11" />
			<biblScope unit="page" from="224" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Constrained optimization and Lagrange multiplier methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dimitri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bertsekas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Academic press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Numerical methods for ordinary differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John Charles</forename><surname>Butcher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Adversarial feature learning. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno>abs/1605.09782</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Adversarially learned inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishmael</forename><surname>Vincent Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Mastropietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Courville</surname></persName>
		</author>
		<idno>abs/1606.00704</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-12-08" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<idno>abs/1704.00028</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno>abs/1611.07004</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Huszar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">P</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Shi</surname></persName>
		</author>
		<idno>abs/1609.04802</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adversarial variational bayes: Unifying variational autoencoders and generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><forename type="middle">M</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-11" />
			<biblScope unit="page" from="2391" to="2400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Unrolled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<idno>abs/1611.02163</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">f-gan: Training generative neural samplers using variational divergence minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryota</forename><surname>Tomioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-05" />
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Conditional image synthesis with auxiliary classifier gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-11" />
			<biblScope unit="page" from="2642" to="2651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Natural gradient revisited. CoRR, abs/1301</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3584</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Pytorch</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Connecting generative adversarial networks and actor-critic methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno>abs/1610.01945</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno>abs/1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Characterization and computation of local nash equilibria in continuous games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><forename type="middle">J</forename><surname>Ratliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Burden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">51st Annual Allerton Conference on Communication, Control, and Computing</title>
		<meeting><address><addrLine>Allerton; Allerton Park &amp; Retreat Center, Monticello, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10-02" />
			<biblScope unit="page" from="917" to="924" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-05" />
			<biblScope unit="page" from="2226" to="2234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Amortised MAP inference for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Casper Kaae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huszár</surname></persName>
		</author>
		<idno>abs/1610.04490</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tijmen</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno>abs/1702.05464</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Semantic image inpainting with perceptual and contextual losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teck-Yian</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
		<idno>abs/1607.07539</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
