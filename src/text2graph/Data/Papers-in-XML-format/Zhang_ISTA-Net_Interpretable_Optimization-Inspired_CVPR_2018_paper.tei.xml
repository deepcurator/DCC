<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-04T23:16+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ISTA-Net: Interpretable Optimization-Inspired Deep Network for Image Compressive Sensing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
							<email>jian.zhang@kaust.edu.sa</email>
							<affiliation key="aff0">
								<orgName type="institution">King Abdullah University of Science and Technology (KAUST)</orgName>
								<address>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
							<email>bernard.ghanem@kaust.edu.sa</email>
							<affiliation key="aff0">
								<orgName type="institution">King Abdullah University of Science and Technology (KAUST)</orgName>
								<address>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ISTA-Net: Interpretable Optimization-Inspired Deep Network for Image Compressive Sensing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>From much fewer acquired measurements than determined by Nyquist sampling theory, Compressive Sensing (CS) theory demonstrates that a signal can be reconstructed with high probability when it exhibits sparsity in some transform domain <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11]</ref>. This novel acquisition strategy is much more hardware-friendly and it enables image or video capturing with a sub-Nyquist sampling rate <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b23">24]</ref>. In addition, by exploiting the redundancy inherent to a signal, CS conducts sampling and compression at the same time, which greatly alleviates the need for high transmission bandwidth and large storage space, enabling low-cost <ref type="figure">Figure 1</ref>. CS reconstruction results produced by our proposed ISTA-Net method and a recent network-based CS reconstruction method (ReconNet <ref type="bibr" target="#b20">[21]</ref>), when the CS ratio is 25%. ISTA-Net clearly produces a higher fidelity reconstruction.</p><p>on-sensor data compression. CS has been applied in many practical applications, including but not limited to singlepixel imaging <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b32">33]</ref>, accelerating magnetic resonance imaging (MRI) <ref type="bibr" target="#b25">[26]</ref>, wireless tele-monitoring <ref type="bibr" target="#b49">[50]</ref> and cognitive radio communication <ref type="bibr" target="#b35">[36]</ref>.</p><p>Mathematically, the purpose of CS reconstruction is to infer the original signal x ∈ R N from its randomized C-S measurements y = Φx ∈ R M . Here, Φ ∈ R M ×N is a linear random projection (matrix). Because M ≪ N , this inverse problem is typically ill-posed, whereby the CS ratio is defined as M N . In this paper, we mainly focus on CS reconstruction of natural images. However, it is worth noting that our proposed framework can be easily extended to videos and other types of data.</p><p>In the past decade, a great deal of image CS reconstruction methods have been developed <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21]</ref>. Most traditional methods exploit some structured sparsity as an image prior and then solve a sparsity-regularized optimization problem in an iterative fashion <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b27">28]</ref>. Based on some well-studied image formation models and intrinsic image properties, these methods enjoy the advantages of strong convergence and theoretical analysis in most cases. However, they usually suffer from high computational complexity, and they are also faced with the challenges of choosing optimal transforms and tuning parameters in their solvers. Fueled by the powerful learning ability of deep networks, several deep network-based image CS re- <ref type="figure" target="#fig_0">Figure 2</ref>. Illustration of our proposed ISTA-Net framework. Specifically, ISTA-Net is composed of Np phases, and each phase strictly corresponds to one iteration in ISTA. The forward transform F (k) is designed as a combination of two linear convolutional operators separated by a rectified linear unit (ReLU), and the backward transform F (k) is designed to exhibit a structure symmetric to that of F <ref type="bibr">(k)</ref> . Note that F (k) and F (k) satisfy the symmetry constraint F (k) • F (k) = I, where I is the identity operator. N f denotes the number of feature maps.</p><p>construction algorithms have been recently proposed to directly learn the inverse mapping from the CS measurement domain to the original signal domain <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b14">15]</ref>. Compared to optimization-based algorithms, these non-iterative algorithms dramatically reduce time complexity, while achieving impressive reconstruction performance. However, existing network-based CS algorithms are trained as a black box, with limited insights from the CS domain.</p><p>In this paper, we design a novel deep architecture, dubbed ISTA-Net, by mapping the traditional ISTA <ref type="bibr" target="#b3">[4]</ref> for optimizing a general ℓ 1 norm CS reconstruction model into a deep network. In particular, ISTA-Net is composed of a fixed number of phases, each of which strictly corresponds to an ISTA-like iteration, as illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>. Rather than traditional linear transforms, nonlinear learnable and sparsifying transforms are adopted in ISTA-Net, and an efficient and effective strategy to solve the proximal mapping of the nonlinear transform is developed. All the parameters involved in ISTA-Net (e.g. nonlinear transforms, shrinkage thresholds, step sizes, etc.) are learned end-to-end using back-propagation. Moreover, borrowing more insights from the compression realm, an enhanced version, dubbed ISTA-Net + , is derived from ISTA-Net by sparsifying natural images explicitly in the residual domain. Interestingly, the skip connections introduced by ISTA-Net + further facilitate the network training. In fact, the proposed ISTA-Nets can be viewed as an attempt to bridge the gap between the two aforementioned categories of CS methods. Contributions. The main contributions of this paper are summarized as follows: 1) We develop a novel ISTA-Net, which adopts the structure of ISTA update steps to design a learnable deep network manifestation, where all parameters are discriminately learned instead of being hand-crafted or fixed. By learning sparsifying transforms in the residual domain, an enhanced version ISTA-Net + is derived to further improve CS performance. As such, ISTA-Nets enjoy the advantages of fast and accurate reconstruction with welldefined interpretability.</p><p>2) The proximal mapping problem associated to a nonlinear sparsifying transform is solved in a general and efficient way, which actually enables mapping other optimization algorithms into deep network form.</p><p>3) Extensive experiments on natural image and MRI CS reconstruction clearly show that ISTA-Net significantly outperforms the state-of-the-art, while maintaining attractive computational complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>We generally group existing CS reconstruction methods of images into two categories: traditional optimizationbased CS methods and recent network-based CS methods. In what follows, we give a brief review of both and focus on the specific methods most relevant to our own.</p><p>Optimization-based CS reconstruction: Given the linear measurements y, traditional image CS methods usually reconstruct the original image x by solving the following (generally convex) optimization problem:</p><formula xml:id="formula_0">min x 1 2 Φx − y 2 2 + λ Ψx 1 ,<label>(1)</label></formula><p>where Ψx denotes the transform coefficients of x with respect to some transform Ψ and the sparsity of the vector Ψx is encouraged by the ℓ 1 norm with λ being the (generally pre-defined) regularization parameter. Since natural images are typically non-stationary, the classic fixed domains (e.g. DCT, wavelet <ref type="bibr" target="#b30">[31]</ref>, and gradient domain <ref type="bibr" target="#b21">[22]</ref>) usually result in poor reconstruction performance. Many works incorporate additional prior knowledge about transform coefficients (e.g. statistical dependencies <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b50">51]</ref>, structure <ref type="bibr" target="#b12">[13]</ref>, etc.) into the CS reconstruction framework. Furthermore, some elaborate priors ex-ploiting the non-local self-similarity properties of natural images have been proposed to improve CS reconstruction <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b51">52]</ref>. <ref type="bibr">Metzler et al.</ref> propose to integrate the welldefined BM3D denoiser into the approximate message passing (AMP) framework for CS reconstruction <ref type="bibr" target="#b27">[28]</ref>. Quite recently, some fast and effective convolutional neural network (CNN) denoisers are trained and integrated into the half quadratic splitting (HQS) <ref type="bibr" target="#b48">[49]</ref> and the alternating direction method of multipliers (ADMM) <ref type="bibr" target="#b6">[7]</ref> to solve image inverse problems. However, all these traditional image CS methods require hundreds of iterations to solve Eq. (1) by means of various iterative solvers, which inevitably gives rise to high computational cost thus restricting the application of CS. In addition, the selected image prior (e.g. optimal transform) or the optimization parameters (e.g. step size and regularization parameter) are usually hand-crafted and quite challenging to pre-define.</p><p>Network-based CS reconstruction: Inspired by the powerful learning capability of deep networks <ref type="bibr" target="#b41">[42]</ref> and its success in computer vision tasks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b24">25]</ref>  <ref type="bibr" target="#b20">[21]</ref>. Mousavi and Baraniuk recently propose an all-convolutional network for image CS reconstruction <ref type="bibr" target="#b28">[29]</ref>. A main feature of network-based image CS methods is that they are non-iterative, which dramatically reduces time complexity as compared with their optimizationbased counterparts. However, this is done with either fullyconnected or repetitive convolutional layers. We believe that their lack of structural diversity, which originates from the absence of CS domain specific insights inherent to optimization-based methods, is the bottleneck for further performance improvement.</p><p>The tremendous success of deep learning for many image processing applications has also led researchers to consider relating iterative optimization methods to neural networks <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b31">32]</ref>. For instance, in the context of sparse coding, Grefor and LeCun propose a fast algorithm to calculate good approximations of optimal sparse codes by introducing the Learned ISTA (LISTA), in which two matrices in classical ISTA are learned instead of using pre-computed ones <ref type="bibr" target="#b11">[12]</ref>. Mark et al. extend approximate message passing (AMP) algorithms to so-called Learned AMP networks for solving sparse linear inverse problems <ref type="bibr" target="#b4">[5]</ref>. Relying on LISTA, some sparse-coding based networks for image super-resolution and deblocking are proposed <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b22">23]</ref>. For image denoising and deconvolution, Schmidt and Roth propose to learn the linear filters and shrinkage functions under the framework of half-quadratic optimization <ref type="bibr" target="#b34">[35]</ref>. Chen et al. propose a trainable reaction diffusion model by learning several parameterized linear filters and influence functions for image denoising and deblocking <ref type="bibr" target="#b7">[8]</ref>. In the context of CS for sparse signals, Kamilov and Mansour propose to learn the optimal thresholding functions for ISTA based on a B-spline decomposition <ref type="bibr" target="#b16">[17]</ref>.</p><p>Recently, Yang et al. propose a so-called ADMM-Net architecture by reformulating ADMM for CS magnetic resonance imaging (CS-MRI) using deep networks <ref type="bibr" target="#b43">[44]</ref>. Although both ADMM-Net and our proposed ISTA-Net have similar inspirations, they are quite different. In fact, there are two main differences between both methods. First, ADMM-Net is specifically designed and developed for CS-MRI based on ADMM, while our ISTA-Net is much more general, since it works well for both general CS and CS-MRI based on ISTA. Second, ADMM-Net only utilizes several linear filters, while ISTA-Net goes beyond that to adopt nonlinear transforms to more effectively sparsify natural images and develops an efficient strategy for solving their proximal mapping problems. The detailed comparison with ADMM-Net for CS-MRI can be found in Section 5.3.</p><p>In a nutshell, the proposed ISTA-Net can be essentially viewed as a significant extension of LISTA <ref type="bibr" target="#b11">[12]</ref>, from the sparse coding problem to general CS reconstruction. Compared with traditional optimization-based CS methods, ISTA-Net is able to learn its optimal parameters, i.e. thresholds, step sizes as well as nonlinear transforms, without hand-crafted settings. In addition, ISTA-Net has the same computational complexity as several iterations of traditional ISTA, which is more than 100 times faster than existing methods of this category. Compared with network-based C-S methods, ISTA-Net borrows insights from traditional optimization methods to allow for interpretability in its network design and it utilizes the structural diversity originating from the CS domain. Extensive experiments demonstrate that ISTA-Net significantly outperforms the existing optimization-based and network-based CS methods, even when compared against methods that are designed for a specific domain (e.g. CS-MRI).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed ISTA-Net for Compressive Sensing</head><p>In this section, we first briefly review traditional ISTA optimization for image CS reconstruction, and then elaborate on the design of our proposed ISTA-Net.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Traditional ISTA for CS</head><p>The iterative shrinkage-thresholding algorithm (ISTA) is a popular first order proximal method, which is well suited for solving many large-scale linear inverse problems.</p><p>Specifically, ISTA solves the CS reconstruction problem in Eq. <ref type="formula" target="#formula_0">(1)</ref> by iterating between the following update steps:</p><formula xml:id="formula_1">r (k) = x (k−1) − ρΦ ⊤ (Φx (k−1) − y),<label>(2)</label></formula><formula xml:id="formula_2">x (k) = arg min x 1 2 x − r (k) 2 2 + λ Ψx 1 .<label>(3)</label></formula><p>Here, k denotes the ISTA iteration index, and ρ is the step size. Eq. <ref type="formula" target="#formula_1">(2)</ref> is trivial, while Eq. <ref type="formula" target="#formula_2">(3)</ref> is actually a special case of the so-called proximal mapping, i.e. prox λφ (r (k) ), when φ(x) = Ψx 1 . Formally, the proximal mapping of regularizer φ denoted by prox λφ (r) is defined as prox λφ (r) = arg min</p><formula xml:id="formula_3">x 1 2 ||x − r|| 2 2 + λφ(x).<label>(4)</label></formula><p>Solving prox λφ (r) in an efficient and effective way is critical for ISTA <ref type="bibr" target="#b46">[47]</ref>, as well as for other optimization methods, such as ADMM <ref type="bibr" target="#b2">[3]</ref> and AMP <ref type="bibr" target="#b27">[28]</ref>. For example, when φ(x) = Wx 1 (W is wavelet transform matrix), we have prox λφ (r) = W ⊤ sof t(Wr, λ) due to the orthogonality of W. However, it remains non-trivial to obtain x (k) in Eq. <ref type="formula" target="#formula_2">(3)</ref> for a more complex non-orthogonal (or even nonlinear) transform Ψ. In addition, ISTA usually requires many iterations to obtain a satisfactory result, suffering from extensive computation. The optimal transform Ψ and all the parameters such as ρ and λ are pre-defined (do not change with k), and very challenging to tune apriori.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">ISTA-Net Framework</head><p>By taking full advantage of the merits of ISTA-based and network-based CS methods, the basic idea of ISTA-Net is to map the previous ISTA update steps to a deep network architecture that consists of a fixed number of phases, each of which corresponds to one iteration in traditional ISTA.</p><p>In order to improve reconstruction performance and increase network capacity and instead of the hand-crafted transform Ψ in Eq. (1), ISTA-Net adopts a general nonlinear transform function to sparsify natural images, denoted by F(·), whose parameters are learnable. In particular and inspired by the powerful representation power of CNN <ref type="bibr" target="#b8">[9]</ref> and its universal approximation property <ref type="bibr" target="#b13">[14]</ref>, we propose to design F(·) as a combination of two linear convolutional operators (without bias terms) separated by a rectified linear unit (ReLU). As illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>, the first convolutional operator in F(·) corresponds to N f filters (each of size 3 × 3 in our experiments) and the second convolutional operator corresponds to another set of N f filters (each of size 3 × 3 × N f in our experiments). In our implementation, we set N f = 32 by default. Obviously, F(·) can also be equivalently formulated in matrix form as F(x) = BReLU (Ax), where A and B correspond to the above two convolutional operators, respectively. With its learnable and nonlinear characteristics, F(·) is expected to be able to achieve a richer representation for natural images.</p><p>Replacing Ψ in Eq. (1) with F(·), we obtain the following sparsity-inducing regularization problem with a nonlinear transform:</p><formula xml:id="formula_4">min x 1 2 Φx − y 2 2 + λ F(x) 1 .<label>(5)</label></formula><p>By solving Eq. (5) using ISTA, Eq. <ref type="formula" target="#formula_1">(2)</ref> is unchanged while Eq. (3) becomes</p><formula xml:id="formula_5">x (k) = arg min x 1 2 x − r (k) 2 2 + λ F(x) 1 .<label>(6)</label></formula><p>In the following, we argue that the above two steps Eq. <ref type="formula" target="#formula_1">(2)</ref> and Eq. (6) in the k-th ISTA iteration both admit efficient solutions, and we cast them into two separate modules in the k-th phase of ISTA-Net, namely the r (k) module and the x (k) module, as illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>• r (k) Module: It corresponds to Eq. <ref type="formula" target="#formula_1">(2)</ref> and is used to generate the immediate reconstruction result r (k) . Note that</p><formula xml:id="formula_6">Φ ⊤ (Φx (k−1) − y)</formula><p>is essentially the gradient of the datafidelity term</p><formula xml:id="formula_7">1 2 Φx −y 2 2 , computed at x (k−1)</formula><p>. To preserve the ISTA structure while increasing network flexibility, we allow the step size ρ to vary across iterations (while it is fixed in traditional ISTA), so the output of this module with input x (k−1) is finally defined as:</p><formula xml:id="formula_8">r (k) = x (k−1) − ρ (k) Φ ⊤ (Φx (k−1) − y).<label>(7)</label></formula><p>• x (k) Module: It aims to compute x (k) according to Eq. (6) with input r (k) . Note that Eq. <ref type="formula" target="#formula_5">(6)</ref> is actually the proximal mapping prox λF (r (k) ) associated with the nonlinear transform F(·). In this paper, we propose to solve prox λF (r (k) ) efficiently in two steps, which is also one of our main contributions.</p><p>First, note that r (k) is the immediate reconstruction result of x (k) at the k-th iteration. In the context of image inverse problems, one general and reasonable assumption is that each element of (x (k) − r (k) ) follows an independent normal distribution with common zero mean and variance σ 2 <ref type="bibr" target="#b45">[46]</ref>. Here, we also make this assumption, and then we further prove the following theorem:</p><p>Theorem 1 Let X 1 , ..., X n be independent normal random variables with common zero mean and variance</p><formula xml:id="formula_9">σ 2 . If X = [X 1 , ..., X n ]</formula><p>⊤ and given any matrices A ∈ R m×n and B ∈ R s×m , define a new random variable Theorem 1 can be easily extended to a normal distribution. Suppose that r (k) and F(r (k) ) are the mean values of x and F(x) respectively, then we can make the following <ref type="figure">Figure 3</ref>. Illustration of the k-th phase of the proposed ISTA-Net</p><formula xml:id="formula_10">Y = BReLU (A X) = B max(0, A X). Then, E[ Y − E[ Y ] 2 2 ] and E[ X − E[ X] 2 2 ] are linearly related, i.e. E[ Y − E[ Y ] 2 2 ] = αE[ X − E[ X]</formula><formula xml:id="formula_11">+ . D (k) , G (k) , H (k) , H (k) are learnable linear convolutional operators.</formula><p>approximation based on Theorem 1:</p><formula xml:id="formula_12">F(x) − F(r (k) ) 2 2 ≈ α x − r (k) 2 2 ,<label>(8)</label></formula><p>where α is a scalar that is only related to the parameters of F(·). By incorporating this linear relationship into Eq. <ref type="formula" target="#formula_5">(6)</ref>, we obtain the following optimization:</p><formula xml:id="formula_13">x (k) = arg min x 1 2 F(x) − F (r (k) ) 2 2 + θ F (x) 1,<label>(9)</label></formula><p>where λ and α are merged into one parameter θ, i.e. θ = λα. Therefore, we get a closed-form version of F(x (k) ):</p><formula xml:id="formula_14">F(x (k) ) = sof t(F(r (k) ), θ).<label>(10)</label></formula><p>Second, motivated by the invertible characteristics of the wavelet transform that leads to a closed-form solution for Eq. (3), we introduce the left inverse of F(·), denoted by F(·) such that F • F = I, where I is the identity operator. Specifically, F(·) is designed to exhibit a structure symmetric to that of F(·), so it is also modeled as two linear convolutional operators separated by a ReLU operator, as shown in <ref type="figure" target="#fig_0">Figure 2</ref>. Because F(·) and F(·) are both learnable, we will enforce the symmetry constraint F • F = I by incorporating it into the loss function during network training. Therefore, x (k) can be efficiently computed in closed-form as:</p><formula xml:id="formula_15">x (k) = F(sof t(F(r (k) ), θ)).<label>(11)</label></formula><p>It is worth emphasizing that θ, as a shrinkage threshold, is a learnable parameter in this module. Similarly, to increase network capacity, we do not constrain that F(·), F(·), and θ be the same at each phase. That is, each phase of ISTA-Net has its own <ref type="figure" target="#fig_0">Figure 2</ref>. Therefore, with all the learnable parameters, the output x (k) in this module should be updated as: <ref type="figure" target="#fig_0">Figure 2</ref> clearly illustrates how Eq. (6) with the closedform solution in Eq. <ref type="formula" target="#formula_0">(12)</ref> is mapped into a deep network in the k-th phase of ISTA-Net. Parameters in ISTA-Net: Each module in each phase of ISTA-Net strictly corresponds to the updates steps in an ISTA iteration. The learnable parameter set in ISTA-Net, denoted by Θ, includes the step size ρ (k) in the r (k) module, the parameters of the forward and backward transforms F (k) (·) and F (k) (·), and the shrinkage threshold θ (k) in the</p><formula xml:id="formula_16">{F (k) (·), F (k) (·), θ (k) }, as illustrat- ed in</formula><formula xml:id="formula_17">x (k) = F (k) (sof t(F (k) (r (k) ), θ (k) )).<label>(12)</label></formula><formula xml:id="formula_18">x (k) module. As such, Θ = {ρ (k) , θ (k) , F (k) , F (k) } Np k=1 ,</formula><p>where N p is the total number of ISTA-Net phases. All these parameters will be learned as neural network parameters. Initialization: Like traditional ISTA, ISTA-Net also requires an initialization denoted by x (0) in <ref type="figure" target="#fig_0">Figure 2</ref>. Instead of random values, we propose to directly use a linear mapping to compute the initialization. Specifically, given the training data pairs that include the image blocks and their corresponding CS measurements, i.e. {(y i ,</p><formula xml:id="formula_19">x i )} N b i=1 with x i ∈ R N , y i ∈ R M</formula><p>, the linear mapping matrix, denoted by Q init , can be computed by solving a least squares problem:</p><formula xml:id="formula_20">Q init = arg min Q QY−X 2 F = XY ⊤ (YY ⊤ ) −1 . Here, X = [x 1 , ..., x N b ], and Y = [y 1 , ..., y N b ].</formula><p>Hence, given any input CS measurement y, its corresponding ISTA-Net initialization x (0) is computed as:</p><formula xml:id="formula_21">x (0) = Q init y.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Loss Function Design</head><p>Given the training data pairs {(y i ,</p><formula xml:id="formula_22">x i )} N b i=1</formula><p>, ISTA-Net first takes the CS measurement y i as input and generates the reconstruction result, denoted by x (Np) i , as output. We seek to reduce the discrepancy between x i and x (Np) i while satisfying the symmetry constraint F (k) • F (k) = I ∀k = 1, . . . , N p . Therefore, we design the end-to-end loss function for ISTA-Net as follows:</p><formula xml:id="formula_23">L total (Θ) = L discrepancy + γL constraint ,<label>(13)</label></formula><p>with:</p><formula xml:id="formula_24">L discrepancy = 1 N b N N b i=1 x (Np) i − xi 2 2 Lconstraint = 1 N b N N b i=1 Np k=1 F (k) (F (k) (xi)) − xi 2 2 ,</formula><p>where N p , N b , N , and γ are the total number of ISTA-Net phases, the total number of training blocks, the size of each block x i , and the regularization parameter, respectively. In our experiments, γ is set to 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Enhanced Version: ISTA-Net</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+</head><p>Motivated by the fact that the residuals of natural images and videos are more compressible <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b36">37]</ref>, an enhanced version, dubbed ISTA-Net + , is derived from ISTA-Net to further improve CS performance. Starting from Eq. (6), we assume that</p><formula xml:id="formula_25">x (k) = r (k) + w (k) + e (k)</formula><p>, where e (k) stands for some noise and w (k) represents some missing highfrequency component in r (k) , which can be extracted by a linear operator R(·) from and G corresponds to 1 filter (with size 3×3×N f ). By modeling F = H • D, where H consists of two linear convolutional operators and one ReLU, as illustrated in <ref type="figure">Figure 3</ref>, we can replace F in Eq. <ref type="formula" target="#formula_13">(9)</ref> with H • D to obtain:</p><formula xml:id="formula_26">x (k) , i.e. w (k) = R(x (k) ). Fur- thermore, R(·) is defined as R = G • D,</formula><formula xml:id="formula_27">min x 1 2 ||H(D(x)) − H(D(r (k) ))|| 2 2 + θ||H(D(x))||1. (14)</formula><p>By exploiting the approximation used in Eq. <ref type="formula" target="#formula_13">(9)</ref> and following the same strategy as in ISTA-Net, we define the left inverse of H as H, which has a structure symmetric to that of H and satisfies the symmetry constraint H • H = I. Thus, the closed form of the ISTA-Net + update for x (k) is:</p><formula xml:id="formula_28">x (k) = r (k) + G( H(sof t(H(D(r (k) )), θ))).<label>(15)</label></formula><p>Similar to ISTA-Net, each phase of ISTA-Net + also has its own learnable parameters, and the k-th phase of ISTA-Net + is illustrated in <ref type="figure">Figure 3</ref>. Hence, the learnable parameter set Θ + of ISTA-Net</p><formula xml:id="formula_29">+ is Θ + = {ρ (k) , θ (k) , D (k) , G (k) , H (k) , H (k) } Np k=1</formula><p>. The loss function of ISTA-Net + is analogously designed by incorporating the constraints H (k) • H (k) = I into Eq. (13).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head><p>For fair comparison, we use the same set of 91 images as in <ref type="bibr" target="#b20">[21]</ref> for training. Following common practices in previous CS work, we generate the training data pairs</p><formula xml:id="formula_30">{(y i , x i )} N b i=1</formula><p>by first extracting the luminance component of 88,912 randomly cropped image blocks (each of size 33×33), i.e. N b =88,912 and N =1,089. Then, for a given C-S ratio, the corresponding measurement matrix Φ ∈ R M ×N is constructed by generating a random Gaussian matrix and then orthogonalizing its rows, i.e. ΦΦ ⊤ = I, where I is the identity matrix. Applying y i = Φx i yields the set of CS measurements, where x i is the vectorized version of an image block. We use TensorFlow <ref type="bibr" target="#b0">[1]</ref> to implement and train the ISTA-Nets separately for a range of CS ratios {1%, 4%, 10%, 25%, 30%, 40%, 50%}. To train the networks, we use Adam optimization <ref type="bibr" target="#b18">[19]</ref> with a learning rate of 0.0001 (200 epochs), and a batch size of 64. All the experiments are performed on a workstation with Intel Core i7-6820 CPU and GTX1060 GPU. Training ISTA-Nets with phase number N p =9 roughly takes 10 hours. For testing, we utilize two widely used benchmark datasets: Set11 <ref type="bibr" target="#b20">[21]</ref> and BSD68 <ref type="bibr" target="#b26">[27]</ref>, which have 11 and 68 gray images, respectively. The reconstruction results are reported as the average Peak Signal-to-Noise Ratio (PSNR) over the test images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">ISTA-Net vs. ISTA-Net</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+</head><p>To demonstrate the superiority of ISTA-Net + over ISTANet, we compare them in two aspects: performance and convergence. <ref type="figure" target="#fig_1">Figure 4 (top)</ref> shows the average PSNR curves for the testing set (Set11) with respect to different phase numbers, when the CS ratio is 25%. We observe that both PSNR curves increase as phase number N p increases; however, the curves are almost flat when N p ≥ 9. Thus, considering the tradeoff between network complexity and reconstruction performance, we set the default phase number N p =9 for both ISTA-Net and ISTA-Net + in the rest of the experiments. Clearly, ISTA-Net + achieves about 1 d-B gain over ISTA-Net when N p =9. Furthermore, <ref type="figure" target="#fig_1">Figure 4</ref> (bottom) plots the average PSNR curves for Set11 with respect to different numbers of epochs during training, when the CS ratio is 25% and N p =9. Both ISTA-Nets get higher PSNR when trained for a larger number of epochs, but ISTA-Net + achieves faster training convergence and better reconstruction performance on the test set (Set11). Due to limited space, please refer to supplementary material for the filters that are learned by ISTA-Nets.</p><p>We attribute the superiority of ISTA-Net + over ISTANet to two factors. First, ISTA-Net + explicitly sparsifies the images in the residual domain, leading to a sparser representation as compared to ISTA-Net. Second, the skip connections introduced by ISTA-Net + coincide with the central idea of the popular ResNet <ref type="bibr" target="#b12">[13]</ref> architecture, which facilitates the training of deeper networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Comparison with State-of-the-Art Methods</head><p>We compare our proposed ISTA-Net and ISTA-Net + with five recent and state-of-the-art image CS methods, namely TVAL3 <ref type="bibr" target="#b21">[22]</ref>, D-AMP <ref type="bibr" target="#b27">[28]</ref>, IRCNN <ref type="bibr" target="#b48">[49]</ref>, SDA <ref type="bibr" target="#b29">[30]</ref>, and ReconNet <ref type="bibr" target="#b20">[21]</ref> 1 . The first three are optimization-based methods, while the last two are network-based methods. The average PSNR reconstruction performance on Set11 with respect to seven CS ratios are summarized in <ref type="table" target="#tab_1">Table 1</ref>. For fair comparison and following the evaluation strategy of <ref type="bibr" target="#b20">[21]</ref>, all the competing methods reconstruct each image block from its CS measurement independently. From Table 1, we observe that SDA and ReconNet work better at  extremely low CS ratios of 1% and 4%, while traditional optimization-based methods perform better at higher CS ratios. However, ISTA-Net and ISTA-Net + outperform all the existing methods by a large margin across all the CS ratios. This clearly demonstrates that they combine the merits of both categories of CS methods. As expected, ISTA-Net + performs better than ISTA-Net. The last two columns in <ref type="table" target="#tab_1">Table 1</ref> is a run-time analysis of all the competing methods. These results indicate that the proposed ISTA-Nets produce consistently better reconstruction results, while remaining computationally attractive. In <ref type="figure" target="#fig_2">Figure 5</ref>, we show the reconstructions of all seven methods of the Butterfly image when the CS ratio is 25%. The proposed ISTA-Net + is able to reconstruct more details and sharper edges.</p><p>To further validate the generalizability of our ISTA-Nets, we also compare them to network-based methods SDA and ReconNet on the larger BSD68 dataset. As shown in <ref type="table" target="#tab_2">Table  2</ref>, ISTA-Net + achieves the best performance, while ISTANet registers second best among all five CS ratios. ISTANets outperform SDA and ReconNet, especially at higher CS ratios. In addition, it is worth emphasizing that a pretrained ISTA-Net or ISTA-Net + using one CS measurement matrix Φ can be directly used for any new measurement matrix with the same CS ratio as Φ, avoiding training new network from scratch. The only difference is that we need to recalculate the initialization matrix Q init for the new mea- surement matrix, which usually takes less than 1 second. Please refer to supplementary material for more results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Comparison with ADMM-Net for CS-MRI</head><p>To demonstrate the generality of ISTA-Net + , we directly extend ISTA-Net + to the specific problem of CS MRI reconstruction, which aims at reconstructing MR images from a small number of under-sampled data in k-space. In this application and following common practices, we set the sampling matrix Φ in Eq. (1) to Φ = PF, where P is an under-sampling matrix and F is the discrete Fourier transform. In this case, we compare against ADMM-Net <ref type="bibr" target="#b43">[44]</ref> 2 , which is a network-based method inspired by ADMM and specifically designed for the CS-MRI domain. It is worthwhile to note that ADMM-Net cannot be trivially extended to other CS domains, since it imposes a specific structure to the sampling matrix Φ. Utilizing the same training and   <ref type="table" target="#tab_3">Table 3</ref> for CS ratios of 20%, 30%, 40% and 50%. It is clear that ISTA-Nets outperform ADMM-Net not only in terms of reconstruction but also in terms of runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Ablation Studies and Discussions</head><p>This section mainly focuses on the nonlinearity and flexibility of the proposed ISTA-Nets. In what follows, we analyze ISTA-Net + with N p =9 phases.</p><p>• Linear vs. Nonlinear Transforms: The nonlinearity of ISTA-Net + is introduced by the ReLU operator in H</p><p>and H (k) , as shown in <ref type="figure">Figure 3</ref>. To evaluate the impact of the nonlinearity, we train ISTA-Net + models with ReLU (nonlinear transforms) and without ReLU (linear transforms). <ref type="figure" target="#fig_3">Figure 6</ref> plots the average PSNR curves for each ISTANet + variant on Set11 throughout training. Note that parameter N f , the number of feature maps in H (k) and H (k) , is set to 8 or 16 in this experiment. It is clear that the nonlinearity introduced by the ReLU is critical for high fidelity C-S reconstruction performance. In addition, when N f &gt; 30, experiments indicate that ISTA-Net + without ReLU is significantly less stable in training than ISTA-Net + with Re-LU, which still performs well. We conclude that the nonlinearity plays an important role in facilitating satisfaction of the symmetry constraint, improving network stability, and learning a suitable transform possible for CS.</p><p>• Shared vs. Unshared: As described previously, each phase of ISTA-Net + (N f =32) has three types of parameters with their dimensionality listed in parentheses: step size ρ (k) (1), threshold θ (k) (1), and transform T (k) = {D (k) , G (k) , H (k) , H (k) } (32 × 3 × 3 + 32 × 3 × 3 × 32 × 2 + 32 × 3 × 3 × 32 × 2 + 1 × 3 × 3 × 32 = 37440). The flexibility of ISTA-Net + indicates that the same type of parameters in different phases do not need to be the same. To demonstrate the impact of this flexibility, we train several variants of ISTA-Net + , where we vary the parameters that are shared among the phases. A summary of the average PSNR results on Set11 at a 25% CS ratio is reported in <ref type="table">Table 4</ref>. Obviously, the default unshared ISTANet + (most flexible with largest number of parameters) achieves the best performance, while the variant of ISTANet + that shares all parameters (ρ (k) , θ (k) , T (k) ) in all its phases (least flexible with smallest number of parameters) obtains the worst performance. When only (ρ (k) , T (k) ) or (θ (k) , T (k) ) are shared, these ISTA-Net + variants register 0.75dB and 0.55dB gains over he variant with all shared parameters. Interestingly, the ISTA-Net + variant with only shared transforms T (k) obtains very competitive PSNR results compared to the unshared variant. This indicates that further compression in ISTA-Net + parameters is possible, with limited affect on reconstruction performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>Inspired by the Iterative Shrinkage-Thresholding Algorithm (ISTA), we propose a novel structured deep network for image compressive sensing (CS) reconstruction, dubbed ISTA-Net, as well as, its enhanced version ISTA-Net + . The proposed ISTA-Nets have well-defined interpretability, and make full use of the merits of both optimization-based and network-based CS methods. All the parameters in ISTANets are discriminately learned end-to-end. Extensive experiments show that ISTA-Nets greatly improve upon the results of state-of-the-art CS methods, while maintaining a fast runtime. Since the developed strategy to solve the proximal mapping problem associated to a nonlinear sparsifying transform is quite general and efficient, one direction of interest is to design deep networks based on other optimization inspirations, such as FISTA <ref type="bibr" target="#b3">[4]</ref>. The other direction of our future work is to extend ISTA-Nets for other image inverse problems, such as deconvolution and inpainting.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2 2</head><label>2</label><figDesc>], where α is only a function of A and B. (Please refer to the supplementary material for the proof and more details.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. PSNR comparison between ISTA-Net and ISTA-Net +</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Comparison of seven CS reconstruction methods (including our ISTA-Net and ISTA-Net + ), when applied to the Butterfly image in Set11 (CS ratio is 25%).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. PSNR (dB) comparison between two versions of ISTANet + : with and without ReLU (when N f =8 and N f =16).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>, several deep network-based image CS reconstruction algorithms have re- cently been proposed [30, 15, 21, 29]. Mousavi et al. first propose to apply a stacked denoising auto-encoder (SDA) to learn the representation from training data and to recon- struct test data from their CS measurements [30]. Adler et al. and Iliadis et al. separately propose to utilize fully- connected neural networks for image and video CS recon- struction [2, 15]. Kulkarni et al. further develop a CNN- based CS algorithm, dubbed ReconNet, which learns to regress an image block (output) from its CS measuremen- t (input)</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 .</head><label>1</label><figDesc>Average PSNR (dB) performance comparisons on Set11 with different CS ratios. The best performance is labeled in bold and the second best is underlined. Note that the last two columns is a run-time analysis of all the competing methods, showing the average time to reconstruct a 256 × 256 image and the corresponding frames-per-second (FPS).</figDesc><table>Algorithm 
CS Ratio 
Time 
CPU/GPU 

FPS 
CPU/GPU 
50% 
40% 
30% 
25% 
10% 
4% 
1% 

TVAL3 [22] 
33.55 31.46 29.23 27.92 22.99 18.75 16.43 
3.135s/---
0.32/--
D-AMP [28] 
35.92 33.56 30.39 28.46 22.64 18.40 
5.21 
51.21s/---
0.02/--
IRCNN [49] 
36.23 34.06 31.18 30.07 24.02 17.56 
7.70 
---/68.42s 
--/0.015 
SDA [30] 
28.95 27.79 26.63 25.34 22.65 20.12 17.29 
--/0.0032s 
--/312.5 
ReconNet [21] 31.50 30.58 28.74 25.60 24.28 20.63 17.27 
---/0.016s 
--/62.5 

ISTA-Net 
37.43 35.36 32.91 31.53 25.80 21.23 17.30 
0.923s/0.039s 
1.08/25.6 
ISTA-Net 

+ 

38.07 36.06 33.82 32.57 26.64 21.31 17.34 
1.375s/0.047s 
0.73/21.3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 .</head><label>2</label><figDesc>Average PSNR (dB) performance comparison of various network-based algorithms on the BSD68 dataset.34.01 32.21 30.34 25.33 22.17</figDesc><table>Algorithm 
CS Ratio 
50% 
40% 
30% 
10% 
4% 

SDA [30] 
28.35 27.41 26.38 23.12 21.32 
ReconNet [21] 29.86 29.08 27.53 24.15 21.66 
ISTA-Net 
33.60 31.85 29.93 25.02 22.12 
ISTA-Net 

+ 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 .</head><label>3</label><figDesc>Average PSNR (dB) comparison between ADMM-Net [44] and our proposed ISTA-Nets for CS-MRI.38.73 40.89 42.52 44.09 0.1437s Table 4. Average PSNR (dB) performance with different shared types of ISTA-Net + . Shared Type Number of Parameters PSNRtesting brain medical images as ADMM-Net, the CS-MRI results of ISTA-Nets with N p =11 phases are summarized in</figDesc><table>Algorithm 
CS Ratio 
Time 
20% 
30% 
40% 
50% 
GPU 

ADMM-Net 37.17 39.84 41.56 43.00 0.9535s 
ISTA-Net 
38.30 40.52 42.12 43.60 0.1246s 
ISTA-Net 

+ 

Shared ρ 
(k) , θ 
(k) , T 

(k) 

(37440+1+1)=37,442 
31.53 
Shared ρ 
(k) , T 

(k) 

(37440+1)+1*9=37,450 
32.28 
Shared θ 
(k) , T 

(k) 

(37440+1)+1*9=37,450 
32.08 
Shared T 

(k) 

37440+(1+1)*9=37,458 
32.36 

Unshared (default) 
(37440+1+1)*9=336,978 
32.57 

</table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We use the source code made publicly available by the authors of T-VAL3 [22], D-AMP [28], IRCNN [49], and ReconNet [21] and implement SDA [30] ourselves, since its source code is not available.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/yangyan92/Deep-ADMM-Net</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. This work was supported by the King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research. The first author would like to sincerely thank Adel Bibi for his helpful discussion.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A deep learning approach to block-based compressed sensing of images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boublil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zibulevsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01519</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An augmented lagrangian approach to the constrained optimization formulation of imaging inverse problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Afonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="681" to="695" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A fast iterative shrinkagethresholding algorithm for linear inverse problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="183" to="202" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">AMPinspired deep networks for sparse linear inverse problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Borgerding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schniter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rangan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="4293" to="4308" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Near-optimal signal recovery from random projections: Universal encoding strategies?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5406" to="5425" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">One network to solve them allsolving linear inverse problems using deep projection models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H R</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Póczos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V K V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On learning optimized reaction diffusion processes for effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning a deep convolutional network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="184" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Compressive sensing via nonlocal low-rank regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3618" to="3632" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Single-pixel imaging via compressive sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Duarte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Davenport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Takbar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Laska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">F</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Baraniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="83" to="91" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning fast approximations of sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="399" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploiting structure in wavelet-based bayesian compressive sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3488" to="3497" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multilayer feedforward networks are universal approximators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stinchcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks</title>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="359" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep fullyconnected networks for video compressive sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iliadis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Spinoulas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Katsaggelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Signal Processing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="9" to="18" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep convolutional neural network for inverse problems in imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Froustey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Unser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4509" to="4522" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning optimal nonlinearities for iterative thresholding algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">S</forename><surname>Kamilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mansour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="747" to="751" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Compressed sensing using a gaussian scale mixtures model in wavelet domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Nadar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bilgin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIP</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3365" to="3368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">ImageNet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">ReconNet: non-iterative reconstruction of images from compressively sensed measurements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kerviche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ashok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="449" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An efficient augmented lagrangian method with applications to total variation minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Optimization and Applications</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="507" to="530" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Robust single image super-resolution via deep networks with sparse prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3194" to="3207" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Imaging with nature: Compressive imaging using a multiply scattering medium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Liutkus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Martina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Popoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chardon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lerosey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Daudet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Carron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Sparse mri: The application of compressed sensing for rapid mr imaging. Magnetic Resonance in Medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lustig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Pauly</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="1182" to="1195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<editor>ICCV. IEEE</editor>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">From denoising to compressed sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maleki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Baraniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="5117" to="5144" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Learning to invert: Signal recovery via deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Baraniuk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A deep learning approach to structured signal recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Baraniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Allerton Conference on Communication, Control, and Computing (Allerton)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1336" to="1343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Block compressed sensing of images using directional transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Fowler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIP</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="3021" to="3024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Atgv-net: accurate depth super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rüther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="268" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Adaptive basis scan by wavelet prediction for single-pixel imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rousset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ducros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Valentini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dandrea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Peyrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Imaging</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="46" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Csmuvi: Video compressive sensing for spatial-multiplexing cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Studer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Baraniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCP</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Shrinkage fields for effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2774" to="2781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Application of compressive sensing in cognitive radio communications: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lagunas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chatzinotas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ottersten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communication Surveys &amp; Tutorials</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1838" to="1860" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Overview of the high efficiency video coding (HEVC) standard</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ohm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wiegand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1649" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The JPEG still picture compression standard</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Wallace</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on consumer electronics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="xviii" to=" xxxiv" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Proximal deep structured models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="865" to="873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">D3: Deep dual-domain based fast restoration of JPEG-compressed images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2764" to="2772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep networks for image super-resolution with sparse prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="370" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Image denoising and inpainting with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="341" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Maximal sparsity with deep networks? In NIPS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4340" to="4348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep ADMM-Net for compressive sensing MRI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Image compressive sensing recovery using adaptively learned sparsifying basis via l0 minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="114" to="126" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Group-based sparse representation for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3336" to="3351" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Structural group sparse representation for image compressive sensing recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Compression Conference (DCC)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="331" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Image compressive sensing recovery via collaborative sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Emerging and Selected Topics in Circuits and Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="380" to="391" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Learning deep CNN denoiser prior for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Compressed sensing for energy-efficient wireless telemonitoring of noninvasive fetal ECG via block sparse bayesian learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-P</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Makeig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="300" to="309" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Video compressive sensing reconstruction via reweighted residual sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1182" to="1195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Nonconvex lp nuclear norm based admm framework for compressed sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Compression Conference (DCC)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="161" to="170" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
