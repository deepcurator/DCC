<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 C:\Grobid\grobid-0.5.5\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.5" ident="GROBID" when="2019-09-05T11:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tucker</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Brain</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
							<email>amnih@google.com</email>
							<affiliation key="aff1">
								<orgName type="department">DeepMind</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">DeepMind</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieterich</forename><surname>Lawson</surname></persName>
							<email>dieterichl@google.com</email>
							<affiliation key="aff0">
								<orgName type="department">Google Brain</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
							<email>jaschasd@google.com</email>
							<affiliation key="aff0">
								<orgName type="department">Google Brain</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Learning in models with discrete latent variables is challenging due to high variance gradient estimators. Generally, approaches have relied on control variates to reduce the variance of the REINFORCE estimator. Recent work <ref type="bibr" target="#b4">(Jang et al., 2016;</ref><ref type="bibr" target="#b8">Maddison et al., 2016)</ref> has taken a different approach, introducing a continuous relaxation of discrete variables to produce low-variance, but biased, gradient estimates. In this work, we combine the two approaches through a novel control variate that produces low-variance, unbiased gradient estimates. Then, we introduce a modification to the continuous relaxation and show that the tightness of the relaxation can be adapted online, removing it as a hyperparameter. We show state-of-the-art variance reduction on several benchmark generative modeling tasks, generally leading to faster convergence to a better final log-likelihood.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>to significantly improve its effectiveness. We call this the REBAR gradient estimator, because it combines REINFORCE gradients with gradients of the Concrete relaxation. Next, we show that a modification to the Concrete relaxation connects REBAR to MuProp in the high temperature limit. Finally, because REBAR is unbiased for all temperatures, we show that the temperature can be optimized online to reduce variance further and relieve the burden of setting an additional hyperparameter.</p><p>In our experiments, we illustrate the potential problems inherent with biased gradient estimators on a toy problem. Then, we use REBAR to train generative sigmoid belief networks (SBNs) on the MNIST and Omniglot datasets and to train conditional generative models on MNIST. Across tasks, we show that REBAR has state-of-the-art variance reduction which translates to faster convergence and better final log-likelihoods. Although we focus on binary variables for simplicity, this work is equally applicable to categorical variables (Appendix C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>For clarity, we first consider a simplified scenario. Let b ⇠ Bernoulli (✓) be a vector of independent binary random variables parameterized by ✓. We wish to maximize</p><formula xml:id="formula_0">E p(b) [f (b, ✓)] ,</formula><p>where f (b, ✓) is differentiable with respect to b and ✓, and we suppress the dependence of p(b) on ✓ to reduce notational clutter. This covers a wide range of discrete latent variable problems; for example, in variational inference f (b, ✓) would be the stochastic variational lower bound.</p><p>Typically, this problem has been approached by gradient ascent, which requires efficiently estimating</p><formula xml:id="formula_1">d d✓ E p(b) [f (b, ✓)] = E p(b)  @f (b, ✓) @✓ + f (b, ✓) @ @✓ log p(b) .<label>(1)</label></formula><p>In practice, the first term can be estimated effectively with a single Monte Carlo sample, however, a naïve single sample estimator of the second term has high variance. Because the dependence of f (b, ✓) on ✓ is straightforward to account for, to simplify exposition we assume that f (b, ✓) = f (b) does not depend on ✓ and concentrate on the second term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Variance reduction through control variates</head><p>Paisley et al. <ref type="formula" target="#formula_1">(2012)</ref>; <ref type="bibr" target="#b15">Ranganath et al. (2014)</ref>; <ref type="bibr" target="#b9">Mnih &amp; Gregor (2014)</ref>; <ref type="bibr" target="#b3">Gu et al. (2015)</ref> show that carefully designed control variates can reduce the variance of the second term significantly. Control variates seek to reduce the variance of such estimators using closed form expectations for closely related terms. We can subtract any c (random or constant) as long as we can correct the bias (see Appendix A and <ref type="bibr" target="#b13">(Paisley et al., 2012)</ref> for a review of control variates in this context):</p><formula xml:id="formula_2">@ @✓ E p(b,c) [f (b)] = @ @✓ ✓ E p(b,c) [f (b) c] + E p(b,c) [c] ◆ = E p(b,c)  (f (b) c) @ @✓ log p(b) + @ @✓ E p(b,c) [c]</formula><p>For example, NVIL <ref type="bibr" target="#b9">(Mnih &amp; Gregor, 2014</ref>) learns a c that does not depend 2 on b and MuProp <ref type="bibr" target="#b3">(Gu et al., 2015)</ref> uses a linear Taylor expansion of f around E p(b|✓) <ref type="bibr">[b]</ref>. Unfortunately, even with a control variate, the term can still have high variance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Continuous relaxations for discrete variables</head><p>Alternatively, following <ref type="bibr" target="#b8">Maddison et al. (2016)</ref>, we can parameterize b as b = H(z), where H is the element-wise hard threshold function 3 and z is a vector of independent Logistic random variables defined by</p><formula xml:id="formula_3">z := g(u, ✓) := log ✓ 1 ✓ + log u 1 u , 2</formula><p>In this case, c depends on the implicit observation in variational inference. 3 H(z) = 1 if z 0 and H(z) = 0 if z &lt; 0.</p><p>where u ⇠ Uniform(0, 1). Notably, z is differentiably reparameterizable <ref type="bibr" target="#b6">(Kingma &amp; Welling, 2013;</ref><ref type="bibr" target="#b16">Rezende et al., 2014)</ref>, but the discontinuous hard threshold function prevents us from using the reparameterization trick directly. Replacing all occurrences of the hard threshold function with a continuous relaxation H(z) ⇡ (z) := z = 1 + exp z 1 however results in a reparameterizable computational graph. Thus, we can compute low-variance gradient estimates for the relaxed model that approximate the gradient for the discrete model. In summary,</p><formula xml:id="formula_4">@ @✓ E p(b) [f (b)] = @ @✓ E p(z) [f (H(z))] ⇡ @ @✓ E p(z) [f ( (z))] = E p(u)  @ @✓ f ( (g(u, ✓))) ,</formula><p>where &gt; 0 can be thought of as a temperature that controls the tightness of the relaxation (at low temperatures, the relaxation is nearly tight). This generally results in a low-variance, but biased Monte Carlo estimator for the discrete model. As ! 0, the approximation becomes exact, but the variance of the Monte Carlo estimator diverges. Thus, in practice, must be tuned to balance bias and variance. See Appendix C and Jang et al. <ref type="formula" target="#formula_1">(2016)</ref>; <ref type="bibr" target="#b8">Maddison et al. (2016)</ref> for the generalization to the categorical case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">REBAR</head><p>We seek a low-variance, unbiased gradient estimator. Inspired by the Concrete relaxation, our strategy will be to construct a control variate (see Appendix A for a review of control variates in this context) based on the difference between the REINFORCE gradient estimator for the relaxed model and the gradient estimator from the reparameterization trick. First, note that closely following Eq. 1</p><formula xml:id="formula_5">E p(b)  f (b) @ @✓ log p(b) = @ @✓ E p(b) [f (b)] = @ @✓ E p(z) [f (H(z))] = E p(z)  f (H(z)) @ @✓ log p(z) . (2)</formula><p>The similar form of the REINFORCE gradient estimator for the relaxed model</p><formula xml:id="formula_6">@ @✓ E p(z) [f ( (z))] = E p(z)  f ( (z)) @ @✓ log p(z)<label>(3)</label></formula><p>suggests it will be strongly correlated and thus be an effective control variate. Unfortunately, the Monte Carlo gradient estimator derived from the left hand side of Eq. 2 has much lower variance than the Monte Carlo gradient estimator derived from the right hand side. This is because the left hand side can be seen as analytically performing a conditional marginalization over z given b, which is noisily approximated by Monte Carlo samples on the right hand side (see Appendix B for details). Our key insight is that an analogous conditional marginalization can be performed for the control variate (Eq. 3),</p><formula xml:id="formula_7">E p(z)  f ( (z)) @ @✓ log p(z) = E p(b)  @ @✓ E p(z|b) [f ( (z))] + E p(b)  E p(z|b) [f ( (z))] @ @✓ log p(b) ,</formula><p>where the first term on the right-hand side can be efficiently estimated with the reparameterization trick (see Appendix C for the details)</p><formula xml:id="formula_8">E p(b)  @ @✓ E p(z|b) [f ( (z))] = E p(b)  E p(v)  @ @✓ f ( (z)) , where v ⇠ Uniform(0, 1) andz ⌘g(v, b, ✓) is the differentiable reparameterization for z|b (Ap- pendix C). Therefore, E p(z)  f ( (z)) @ @✓ log p(z) = E p(b)  E p(v)  @ @✓ f ( (z)) + E p(b)  E p(z|b) [f ( (z))] @ @✓ log p(b) .</formula><p>Using this to form the control variate and correcting with the reparameterization trick gradient, we arrive at</p><formula xml:id="formula_9">@ @✓ E p(b) [f (b)] = E p(u,v)  [f (H(z)) ⌘f ( (z))] @ @✓ log p(b) b=H(z) + ⌘ @ @✓ f ( (z)) ⌘ @ @✓ f ( (z)) ,<label>(4)</label></formula><p>where</p><formula xml:id="formula_10">u, v ⇠ Uniform(0, 1), z ⌘ g(u, ✓),z ⌘g(v, H(z), ✓)</formula><p>, and ⌘ is a scaling on the control variate. The REBAR estimator is the single sample Monte Carlo estimator of this expectation. To reduce computation and variance, we couple u and v using common random numbers (Appendix G, <ref type="bibr" target="#b12">(Owen, 2013)</ref>). We estimate ⌘ by minimizing the variance of the Monte Carlo estimator with SGD. In Appendix D, we present an alternative derivation of REBAR that is shorter, but less intuitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Rethinking the relaxation and a connection to MuProp</head><p>Because (z) ! 1 2 as ! 1, we consider an alternative relaxation</p><formula xml:id="formula_11">H(z) ⇡ ✓ 1 2 + + 1 + 1 log ✓ 1 ✓ + 1 log u 1 u ◆ = (z ),<label>(5)</label></formula><formula xml:id="formula_12">where z = 2 + +1 +1 log ✓ 1 ✓ + log u 1 u .</formula><p>As ! 1, the relaxation converges to the mean, ✓, and still as ! 0, the relaxation becomes exact. Furthermore, as ! 1, the REBAR estimator converges to MuProp without the linear term (see Appendix E). We refer to this estimator as SimpleMuProp in the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Optimizing temperature ( )</head><p>The REBAR gradient estimator is unbiased for any choice of &gt; 0, so we can optimize to minimize the variance of the estimator without affecting its unbiasedness (similar to optimizing the dispersion coefficients in Ruiz et al. <ref type="formula" target="#formula_1">(2016)</ref>). In particular, denoting the REBAR gradient estimator by r( ), then</p><formula xml:id="formula_13">@ @ Var(r( )) = @ @ ⇣ E ⇥ r( ) 2 ⇤ E [r( )] 2 ⌘ = E  2r( ) @r( ) @ because E[r( )]</formula><p>does not depend on . The resulting expectation can be estimated with a single sample Monte Carlo estimator. This allows the tightness of the relaxation to be adapted online jointly with the optimization of the parameters and relieves the burden of choosing ahead of time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multilayer stochastic networks</head><p>Suppose we have multiple layers of stochastic units (i.e., b = {b 1 , b 2 , . . . , b n }) where p(b) factorizes as</p><formula xml:id="formula_14">p(b 1:n ) = p(b 1 )p(b 2 |b 1 ) · · · p(b n |b n 1 )</formula><p>, and similarly for the underlying Logistic random variables p(z 1:n ) recalling that b i = H(z i ). We can define a relaxed distribution over z 1:n where we replace the hard threshold function H(z) with a continuous relaxation (z). We refer to the relaxed distribution as q(z 1:n ). We can take advantage of the structure of p, by using the fact that the high variance REINFORCE term of the gradient also decomposes</p><formula xml:id="formula_15">E p(b)  f (b) @ @✓ log p(b) = X i E p(b)  f (b) @ @✓ log p(b i |b i 1 ) .</formula><p>Focusing on the i th term, we have</p><formula xml:id="formula_16">E p(b)  f (b) @ @✓ log p(b i |b i 1 ) = E p(b1:i 1 )  E p(bi|bi 1 )  E p(bi+1:n|bi) [f (b)] @ @✓ log p(b i |b i 1 ) ,</formula><p>which suggests the following control variate</p><formula xml:id="formula_17">E p(zi|bi,bi 1 )  E q(zi+1:n|zi) [f (b 1:i 1 , (z i:n ))] @ @✓ log p(b i |b i 1 )</formula><p>for the middle expectation. Similarly to the single layer case, we can debias the control variate with terms that are reparameterizable. Note that due to the switch between sampling from p and sampling from q, this approach requires n passes through the network (one pass per layer). We discuss alternatives that do not require multiple passes through the network in Appendix F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Q-functions</head><p>Finally, we note that since the derivation of this control variate is independent of f , the REBAR control variate can be generalized by replacing f with a learned, differentiable Q-function. This suggests that the REBAR control variate is applicable to RL, where it would allow a "pseudo-action"-dependent baseline. In this case, the pseudo-action would be the relaxation of the discrete output from a policy network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related work</head><p>Most approaches to optimizing an expectation of a function w.r.t. a discrete distribution based on samples from the distribution can be seen as applications of the REINFORCE (Williams, 1992) gradient estimator, also known as the likelihood ratio <ref type="bibr" target="#b2">(Glynn, 1990)</ref> or score-function estimator <ref type="bibr" target="#b1">(Fu, 2006)</ref>. Following the notation from Section 2, the basic form of an estimator of this type</p><formula xml:id="formula_18">is (f (b) c) @ @✓ log p(b)</formula><p>where b is a sample from the discrete distribution and c is some quantity independent of b, known as a baseline. Such estimators are unbiased, but without a carefully chosen baseline their variance tends to be too high for the estimator to be useful and much work has gone into finding effective baselines.</p><p>In the context of training latent variable models, REINFORCE-like methods have been used to implement sampling-based variational inference with either fully factorized <ref type="bibr" target="#b22">(Wingate &amp; Weber, 2013;</ref><ref type="bibr" target="#b15">Ranganath et al., 2014)</ref> or structured <ref type="bibr" target="#b9">(Mnih &amp; Gregor, 2014;</ref><ref type="bibr" target="#b3">Gu et al., 2015)</ref> variational distributions. All of these involve learned baselines: from simple scalar baselines <ref type="bibr" target="#b22">(Wingate &amp; Weber, 2013;</ref><ref type="bibr" target="#b15">Ranganath et al., 2014)</ref> to nonlinear input-dependent baselines <ref type="bibr" target="#b9">(Mnih &amp; Gregor, 2014)</ref>. MuProp <ref type="bibr" target="#b3">(Gu et al., 2015)</ref> combines an input-dependent baseline with a first-order Taylor approximation to the function based on the corresponding mean-field network to achieve further variance reduction. REBAR is similar to MuProp in that it also uses gradient information from a proxy model to reduce the variance of a REINFORCE-like estimator. The main difference is that in our approach the proxy model is essentially the relaxed (but still stochastic) version of the model we are interested in, whereas MuProp uses the mean field version of the model as a proxy, which can behave very differently from the original model due to being completely deterministic. The relaxation we use was proposed by <ref type="bibr" target="#b8">(Maddison et al., 2016;</ref><ref type="bibr" target="#b4">Jang et al., 2016)</ref> as a way of making discrete latent variable models reparameterizable, resulting in a low-variance but biased gradient estimator for the original model. REBAR on the other hand, uses the relaxation in a control variate which results in an unbiased, low-variance estimator. Alternatively, Titsias &amp; Lázaro-Gredilla (2015) introduced local expectation gradients, a general purpose unbiased gradient estimator for models with continuous and discrete latent variables. However, it typically requires substantially more computation than other methods. Recently, a specialized REINFORCE-like method was proposed for the tighter multi-sample version of the variational bound <ref type="bibr" target="#b0">(Burda et al., 2015)</ref> which uses a leave-out-out technique to construct per-sample baselines <ref type="bibr" target="#b10">(Mnih &amp; Rezende, 2016)</ref>. This approach is orthogonal to ours, and we expect it to benefit from incorporating the REBAR control variate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>As our goal was variance reduction to improve optimization, we compared our method to the state-of-the-art unbiased single-sample gradient estimators, NVIL <ref type="bibr" target="#b9">(Mnih &amp; Gregor, 2014)</ref> and MuProp <ref type="bibr" target="#b3">(Gu et al., 2015)</ref>, and the state-of-the-art biased single-sample gradient estimator GumbelSoftmax/Concrete <ref type="bibr" target="#b4">(Jang et al., 2016;</ref><ref type="bibr" target="#b8">Maddison et al., 2016)</ref> by measuring their progress on the training objective and the variance of the unbiased gradient estimators 4 . We start with an illustrative problem and then follow the experimental setup established in <ref type="bibr" target="#b8">(Maddison et al., 2016)</ref> to evaluate the methods on generative modeling and structured prediction tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Toy problem</head><p>To illustrate the potential ill-effects of biased gradient estimators, we evaluated the methods on a simple toy problem. We wish to minimize</p><formula xml:id="formula_19">E p(b) [(b t) 2</formula><p>], where t 2 (0, 1) is a continuous target value, and we have a single parameter controlling the Bernoulli distribution. <ref type="figure" target="#fig_0">Figure 1</ref> shows the perils of biased gradient estimators. The optimal solution is deterministic (i.e., p(b = 1) 2 {0, 1}), whereas the Concrete estimator converges to a stochastic one. All of the unbiased estimators correctly converge to the optimal loss, whereas the biased estimator fails to. For this simple problem, it is sufficient to reduce temperature of the relaxation to achieve an acceptable solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Learning sigmoid belief networks (SBNs)</head><p>Next, we trained SBNs on several standard benchmark tasks. We follow the setup established in <ref type="bibr" target="#b8">(Maddison et al., 2016)</ref>. We used the statically binarized MNIST digits from <ref type="bibr" target="#b19">Salakhutdinov &amp; Murray (2008)</ref> and a fixed binarization of the Omniglot character dataset. We used the standard splits into training, validation, and test sets. The network used several layers of 200 stochastic binary units interleaved with deterministic nonlinearities. In our experiments, we used either a linear deterministic layer (denoted linear) or 2 layers of 200 tanh units (denoted nonlinear).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Generative modeling on MNIST and Omniglot</head><p>For generative modeling, we maximized a single-sample variational lower bound on the log-likelihood. We performed amortized inference <ref type="bibr" target="#b6">(Kingma &amp; Welling, 2013;</ref><ref type="bibr" target="#b16">Rezende et al., 2014)</ref> with an inference network with similar architecture in the reverse direction. In particular, denoting the image by x and the hidden layer stochastic activations by b ⇠ q(b|x, ✓), we have</p><formula xml:id="formula_20">log p(x|✓) E q(b|x,✓) [log p(x, b|✓) log q(b|x, ✓)] ,</formula><p>which has the required form for REBAR.</p><p>To measure the variance of the gradient estimators, we follow a single optimization trajectory and use the same random numbers for all methods. This significantly reduces the variance in our measurements. We plot the log variance of the unbiased gradient estimators in <ref type="figure" target="#fig_2">Figure 2</ref> for MNIST (Appendix <ref type="figure">Figure App.</ref>3 for Omniglot). REBAR produced the lowest variance across linear and nonlinear models for both tasks. The reduction in variance was especially large for the linear models. For the nonlinear model, REBAR (0.1) reduced variance at the beginning of training, but its performance degraded later in training. REBAR was able to adaptively change the temperature as optimization progressed and retained superior variance reduction. We also observed that SimpleMuProp was a surprisingly strong baseline that improved significantly over NVIL. It performed similarly to MuProp despite not explicitly using the gradient of f .</p><p>Generally, lower variance gradient estimates led to faster optimization of the objective and convergence to a better final value ( <ref type="figure" target="#fig_3">Figure 3</ref>, <ref type="table">Table 1</ref>   Although our primary focus was optimization, for completeness, we include results on the test set in Appendix <ref type="table">Table App.</ref>2 computed with a 100-sample lower bound <ref type="bibr" target="#b0">Burda et al. (2015)</ref>. Improvements on the training variational lower bound do not directly translate into improved test log-likelihood. Previous work <ref type="bibr" target="#b8">(Maddison et al., 2016)</ref> showed that regularizing the inference network alone was sufficient to prevent overfitting. This led us to hypothesize that the overfitting results was primarily due to overfitting in the inference network (q). To test this, we trained a separate inference network on the validation and test sets, taking care not to affect the model parameters. This reduced overfitting (Appendix <ref type="figure">Figure App</ref>.5), but did not completely resolve the issue, suggesting that the generative and inference networks jointly overfit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Structured prediction on MNIST</head><p>Structured prediction is a form of conditional density estimation that aims to model high dimensional observations given a context. We followed the structured prediction task described by <ref type="bibr" target="#b14">Raiko et al. (2014)</ref>, where we modeled the bottom half of an MNIST digit (x) conditional on the top half (c). The conditional generative network takes as input c and passes it through an SBN. We optimized a single sample lower bound on the log-likelihood</p><formula xml:id="formula_21">log p(x|c, ✓) E p(b|c,✓)</formula><p>[log p(x|b, ✓)] .</p><p>We measured the log variance of the gradient estimator ( <ref type="figure" target="#fig_4">Figure 4</ref>) and found that REBAR significantly reduced variance. In some configurations, MuProp excelled, especially with the single layer linear model where the first order expansion that MuProp uses is most accurate. Again, the training objective performance generally mirrored the reduction in variance of the gradient estimator ( <ref type="figure" target="#fig_5">Figure 5</ref>, <ref type="table">Table  1</ref>).</p><p>MNIST gen.  <ref type="table">Table 1</ref>: Mean training variational lower bound over 5 trials with different random initializations. The standard error of the mean is given in the Appendix. We bolded the best performing method (up to standard error) for each task. We report trials using the best performing learning rate for each task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NVIL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Inspired by the Concrete relaxation, we introduced REBAR, a novel control variate for REINFORCE, and demonstrated that it greatly reduces the variance of the gradient estimator. We also showed that with a modification to the relaxation, REBAR and MuProp are closely related in the high temperature limit. Moreover, we showed that we can adapt the temperature online and that it further reduces variance. <ref type="bibr" target="#b17">Roeder et al. (2017)</ref> show that the reparameterization gradient includes a score function term which can adversely affect the gradient variance. Because the reparameterization gradient only enters the REBAR estimator through differences of reparameterization gradients, we implicitly implement the recommendation from <ref type="bibr" target="#b17">(Roeder et al., 2017)</ref>.</p><p>When optimizing the relaxation temperature, we require the derivative with respect to of the gradient of the parameters. Empirically, the temperature changes slowly relative to the parameters, so we might be able to amortize the cost of this operation over several parameter updates. We leave exploring these ideas to future work.</p><p>It would be natural to explore the extension to the multi-sample case (e.g., VIMCO <ref type="bibr" target="#b10">(Mnih &amp; Rezende, 2016)</ref>), to leverage the layered structure in our models using Q-functions, and to apply this approach to reinforcement learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Log variance of the gradient estimator (left) and loss (right) for the toy problem with t = 0.45. Only the unbiased estimators converge to the correct answer. We indicate the temperature in parenthesis where relevant.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>, Appendix Figures App.2 and App.4). For the nonlinear model, the Concrete estimator underperformed optimizing the training objective in both tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Log variance of the gradient estimator for the two layer linear model (left) and single layer nonlinear model (right) on the MNIST generative modeling task. All of the estimators are unbiased, so their variance is directly comparable. We estimated moments from exponential moving averages (with decay=0.999; we found that the results were robust to the exact value). The temperature is shown in parenthesis where relevant.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Training variational lower bound for the two layer linear model (left) and single layer nonlinear model (right) on the MNIST generative modeling task. We plot 5 trials over different random initializations for each method with the median trial highlighted. The temperature is shown in parenthesis where relevant.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Log variance of the gradient estimator for the two layer linear model (left) and single layer nonlinear model (right) on the structured prediction task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Training variational lower bound for the two layer linear model (left) and single layer nonlinear model (right) on the structured prediction task. We plot 5 trials over different random initializations for each method with the median trial highlighted.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Both MuProp and REBAR require twice as much computation per step as NVIL and Concrete. To present comparable results with previous work, we plot our results in steps. However, to offer a fair comparison, NVIL should use two samples and thus reduce its variance by half (or log(2) ⇡ 0.69 in our plots).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Ben Poole and Eric Jang for helpful discussions and assistance replicating their results.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00519</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">Importance weighted autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Gradient estimation. Handbooks in operations research and management science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="575" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Likelihood ratio gradient estimation for stochastic systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Glynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="75" to="84" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05176</idno>
		<title level="m">Ilya Sutskever, and Andriy Mnih. Muprop: Unbiased backpropagation for stochastic neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<title level="m">Categorical reparameterization with gumbel-softmax</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">Minka</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">. A*</forename><surname>Sampling</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Chris J Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.00712</idno>
		<title level="m">The concrete distribution: A continuous relaxation of discrete random variables</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Neural variational inference and learning in belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 31st International Conference on Machine Learning</title>
		<meeting>The 31st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1791" to="1799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Variational inference for monte carlo objectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<meeting>The 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2188" to="2196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Recurrent models of visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2204" to="2212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Monte Carlo theory, methods and examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Art</forename><forename type="middle">B</forename><surname>Owen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Variational bayesian inference with stochastic search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Coference on International Conference on Machine Learning</title>
		<meeting>the 29th International Coference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1363" to="1370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapani</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.2989</idno>
		<title level="m">Techniques for learning binary stochastic feedforward neural networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Black box variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="814" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 31st International Conference on Machine Learning</title>
		<meeting>The 31st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Sticking the landing: An asymptotically zero-variance gradient estimator for variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Roeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.09194</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Overdispersed black-box variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Michalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Titsias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Thirty-Second Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="647" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On the quantitative analysis of deep belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="872" to="879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Local expectation gradients for black box variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Michalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Titsias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lázaro-Gredilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2638" to="2646" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Automated variational inference in probabilistic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wingate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theophane</forename><surname>Weber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.1299</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00521</idno>
		<title level="m">Reinforcement learning neural Turing machines</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">362</biblScope>
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
