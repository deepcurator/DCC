we propose to leverage the recently proposed gumbel-softmax (gs) approximation to the discrete distribution [18, 30] -specifically, a recurrent neural network (rnn) augmented with a sequence of gs samplers, which when coupled with the straight-through gradient estimator [2, 18] enables end-to-end differentiability.