the training of large-scale models with huge amounts of data are often carried on distributed systems [ [7] [8] [9] , where data parallelism is adopted to exploit the compute capability empowered by multiple workers [10] .