our work aims to achieve the best of both worlds -the practical usefulness of g and the strong performance of d -via knowledge transfer from d to g. our primary contribution is an end-to-end trainable generative visual dialog model, where g receives gradients from d as a perceptual (not adversarial) loss of the sequence sampled from g. we leverage the recently proposed gumbel-softmax (gs) approximation to the discrete distribution -specifically, a rnn augmented with a sequence of gs samplers, coupled with the straight-through gradient estimator to enable end-to-end differentiability.