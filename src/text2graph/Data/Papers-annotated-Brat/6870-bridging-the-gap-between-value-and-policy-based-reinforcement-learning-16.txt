in this paper, we exploit a relationship between policy optimization under entropy regularization and softmax value consistency to obtain a new form of stable off-policy learning.