however, long sequence learning with rnns remains a challenging problem for the following reasons: first, memorizing extremely long-term dependencies while maintaining mid-and short-term memory is difficult; second, training rnns using back-propagationthrough-time is impeded by vanishing and exploding gradients; and lastly, both forward-and back-propagation are performed in a sequential manner, which makes the training time-consuming.