it is important to develop models that are robust to adversarial perturbations for a variety of reasons: • so that machine learning can be used in situations where an attacker may attempt to interfere with the operation of the deployed system, • so that machine learning is more useful for modelbased optimization, • to gain a better understanding of how to provide performance guarantees for models under distribution shift, • to gain a better understanding of how to enforce smoothness assumptions, etc.