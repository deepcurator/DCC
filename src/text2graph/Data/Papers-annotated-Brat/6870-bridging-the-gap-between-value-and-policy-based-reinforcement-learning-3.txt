from this observation, we develop a new rl algorithm, path consistency learning (pcl), that minimizes a notion of soft consistency error along multi-step action sequences extracted from both on-and off-policy traces.