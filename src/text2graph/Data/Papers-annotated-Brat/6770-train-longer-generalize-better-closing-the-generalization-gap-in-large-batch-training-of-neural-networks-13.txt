the optimization method of choice for training highly complex and non-convex dnns, is typically stochastic gradient decent (sgd) or some variant of it.