our primary technical contribution is an end-to-end trainable generative visual dialog model, where the generator receives gradients from the discriminator loss of the sequence sampled from g. note that this is challenging because the output of g is a sequence of discrete symbols, which na√Øvely is not amenable to gradient-based training.