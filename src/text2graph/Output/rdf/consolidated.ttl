@prefix : <https://github.com/deepcurator/DCC/> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xml: <http://www.w3.org/XML/1998/namespace> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

: a owl:Ontology ;
    rdfs:label "DeepSciKG" ;
    rdfs:comment "The first iteration of the Siemens Ontology Schema to represent the multimodal curated elements from the DARPA ASKE Project." .

<https://github.com/deepcurator/DCC/1806.02311> a :Publication ;
    :conferenceSeries "NIPS" ;
    :hasEntity <https://github.com/deepcurator/DCC/1806.02311_algorithm>,
        <https://github.com/deepcurator/DCC/1806.02311_approach>,
        <https://github.com/deepcurator/DCC/1806.02311_approaches>,
        <https://github.com/deepcurator/DCC/1806.02311_attention_mechanisms>,
        <https://github.com/deepcurator/DCC/1806.02311_image>,
        <https://github.com/deepcurator/DCC/1806.02311_mappings>,
        <https://github.com/deepcurator/DCC/1806.02311_modeling>,
        <https://github.com/deepcurator/DCC/1806.02311_objects>,
        <https://github.com/deepcurator/DCC/1806.02311_regions>,
        <https://github.com/deepcurator/DCC/1806.02311_scene>,
        <https://github.com/deepcurator/DCC/1806.02311_supervision>,
        <https://github.com/deepcurator/DCC/1806.02311_tasks>,
        <https://github.com/deepcurator/DCC/1806.02311_techniques>,
        <https://github.com/deepcurator/DCC/1806.02311_that>,
        <https://github.com/deepcurator/DCC/1806.02311_this>,
        <https://github.com/deepcurator/DCC/1806.02311_those>,
        <https://github.com/deepcurator/DCC/1806.02311_time>,
        <https://github.com/deepcurator/DCC/1806.02311_way>,
        <https://github.com/deepcurator/DCC/1806.02311_we> ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs> a :Publication ;
    :conferenceSeries "NIPS" ;
    :hasEntity <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_algorithm>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_approaches>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_baselines>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_benchmarks>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_classification>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_data>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_embeddings>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_feature>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_features>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_framework>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_function>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_functions>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_graph>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_graphs>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_information>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_interactions>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_learn>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_local_neighborhood>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_node>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_nodes>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_prediction>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_sampling>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_tasks>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_text>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_that>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_these>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_training>,
        <https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_we> ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting> a :Publication ;
    :conferenceSeries "NIPS" ;
    :hasEntity <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_algorithm>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_algorithms>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_application>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_convergence>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_convex>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_deep_networks>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_functions>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_gradient>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_hyperparameters>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_learning_methods>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_methods>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_objective_function>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_one>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_optimization>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_procedure>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_results>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_state>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_stochastic_gradient_descent>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_that>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_these>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_this>,
        <https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_we> ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

<https://github.com/deepcurator/DCC/6953-bayesian-gan> a :Publication ;
    :conferenceSeries "NIPS" ;
    :hasEntity <https://github.com/deepcurator/DCC/6953-bayesian-gan_adversarial>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_approach>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_audio>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_benchmarks>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_candidate>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_cifar-10>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_data>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_ensembles>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_formulation>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_framework>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_gan>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_gans>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_gradient>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_images>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_interpretable>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_interventions>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_learn>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_model>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_networks>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_parameters>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_posterior>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_results>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_semi-supervised_learning>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_smoothing>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_state>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_svhn>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_this>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_we>,
        <https://github.com/deepcurator/DCC/6953-bayesian-gan_weights> ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations> a :Publication ;
    :conferenceSeries "NIPS" ;
    :hasEntity <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_adversarial>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_algorithm>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_baselines>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_complex>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_data>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_domain>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_factors>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_human_actions>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_imitation_learning>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_inputs>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_interpretable>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_learn>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_method>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_model>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_our_method>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_representations>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_reward>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_signal>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_structure>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_that>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_this>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_way>,
        <https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_we> ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction> a :Publication ;
    :conferenceSeries "NIPS" ;
    :hasEntity <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_approaches>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_architectures>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_complex>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_components>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_deep_learning>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_framework>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_global_context>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_graph>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_images>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_interactions>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_model>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_model_design>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_modeling>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_objects>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_prediction>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_prediction_model>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_principles>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_results>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_scene>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_scenes>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_state>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_structured>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_task>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_that>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_this>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_understanding>,
        <https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_we> ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper a :Publication ;
    :conferenceSeries "ECCV" ;
    :hasEntity :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_complex,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_convolutions,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_domains,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_faces,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_image,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_information,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_map,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_mappings,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_objects,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_scale,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_semantic_segmentation,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_shape,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_techniques,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_texture,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_that,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_they,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_this,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_two,
        :Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:AbstractText a owl:Class ;
    rdfs:subClassOf :Text .

:AdadeltaOptimizer a owl:Class ;
    rdfs:subClassOf :train .

:AdagradOptimizer a owl:Class ;
    rdfs:subClassOf :train .

:AdamOptimizer a owl:Class ;
    rdfs:subClassOf :train .

:Alperovich_Light_Field_Intrinsics_CVPR_2018_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :hasModality <https://github.com/deepcurator/DCC/:fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1> ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1_Comp0 a :InputBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1> .

:Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1_Comp1 a :NormBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1> .

:Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1_Comp2 a :ConvBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1> .

:Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1_Comp3 :partOf <https://github.com/deepcurator/DCC/:fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1> .

:Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1_Comp4 a :ActivationBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1> .

:Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1_Comp6 a :OutputBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1> .

:BodyText a owl:Class ;
    rdfs:subClassOf :Text .

:BytesList a owl:Class ;
    rdfs:subClassOf :train .

:Cao_HashGAN_Deep_Learning_CVPR_2018_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:CheckpoingManager a owl:Class ;
    rdfs:subClassOf :train .

:Checkpoint a owl:Class ;
    rdfs:subClassOf :train .

:CheckpointSaverHook a owl:Class ;
    rdfs:subClassOf :train .

:CheckpointSaverListener a owl:Class ;
    rdfs:subClassOf :train .

:Chen_Photographic_Image_Synthesis_ICCV_2017_paper a :Publication ;
    :conferenceSeries "ICCV" ;
    :hasEntity :Chen_Photographic_Image_Synthesis_ICCV_2017_paper_approach,
        :Chen_Photographic_Image_Synthesis_ICCV_2017_paper_images,
        :Chen_Photographic_Image_Synthesis_ICCV_2017_paper_scenes,
        :Chen_Photographic_Image_Synthesis_ICCV_2017_paper_semantic,
        :Chen_Photographic_Image_Synthesis_ICCV_2017_paper_that,
        :Chen_Photographic_Image_Synthesis_ICCV_2017_paper_training ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

:ChiefSessionCreator a owl:Class ;
    rdfs:subClassOf :train .

:ClusterDef a owl:Class ;
    rdfs:subClassOf :train .

:ClusterSpec a owl:Class ;
    rdfs:subClassOf :train .

:ConcatBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:Coordinator a owl:Class ;
    rdfs:subClassOf :train .

:DeconvBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:DenseBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper a :Publication ;
    :conferenceSeries "ECCV" ;
    :hasEntity :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_adversarial,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_adversarial_learning,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_approaches,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_architecture,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_baseline,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_classes,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_classification,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_datasets,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_deep_convolutional_networks,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_efficiency,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_framework,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_frameworks,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_image,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_network,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_robustness,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_state,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_tasks,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_that,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_these,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_this,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_two,
        :Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:DropoutBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:EmbedBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:Example a owl:Class ;
    rdfs:subClassOf :train .

:ExponentialMovingAverage a owl:Class ;
    rdfs:subClassOf :train .

:Feature a owl:Class ;
    rdfs:subClassOf :train .

:FeatureList a owl:Class ;
    rdfs:subClassOf :train .

:FeatureLists a owl:Class ;
    rdfs:subClassOf :train .

:Features a owl:Class ;
    rdfs:subClassOf :train .

:FeedFnHook a owl:Class ;
    rdfs:subClassOf :train .

:FinalOpsHook a owl:Class ;
    rdfs:subClassOf :train .

:FlattenBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:FloatList a owl:Class ;
    rdfs:subClassOf :train .

:FtrlOptimizer a owl:Class ;
    rdfs:subClassOf :train .

:GenericTerm a owl:Class ;
    rdfs:subClassOf :TextEntity .

:GlobalStepWaiterHook a owl:Class ;
    rdfs:subClassOf :train .

:GradientDescentOptimizer a owl:Class ;
    rdfs:subClassOf :train .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :hasEntity :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_algorithms,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_architecture,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_benchmarks,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_boundary_detection,
        <https://github.com/deepcurator/DCC/Hou_Deeply_Supervised_Salient_CVPR_2017_paper_convolutional_neural_networks_(cnns)>,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_development,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_edge,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_effectiveness,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_efficiency,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_fcn,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_fcns,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_feature,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_framework,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_fully_convolutional_neural_networks,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_image,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_improvement,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_maps,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_method,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_models,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_object_detection,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_per,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_problem,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_results,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_scale,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_segmentation,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_structure,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_structures,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_supervision,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_that,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_this,
        :Hou_Deeply_Supervised_Salient_CVPR_2017_paper_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

:Int64List a owl:Class ;
    rdfs:subClassOf :train .

:Jas_Image_Specificity_2015_CVPR_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :hasEntity :Jas_Image_Specificity_2015_CVPR_paper_application,
        :Jas_Image_Specificity_2015_CVPR_paper_descriptions,
        :Jas_Image_Specificity_2015_CVPR_paper_features,
        :Jas_Image_Specificity_2015_CVPR_paper_image,
        :Jas_Image_Specificity_2015_CVPR_paper_image_content,
        :Jas_Image_Specificity_2015_CVPR_paper_images,
        :Jas_Image_Specificity_2015_CVPR_paper_improvements,
        :Jas_Image_Specificity_2015_CVPR_paper_measure,
        :Jas_Image_Specificity_2015_CVPR_paper_mechanisms,
        :Jas_Image_Specificity_2015_CVPR_paper_modeling,
        :Jas_Image_Specificity_2015_CVPR_paper_models,
        :Jas_Image_Specificity_2015_CVPR_paper_ones,
        :Jas_Image_Specificity_2015_CVPR_paper_other,
        :Jas_Image_Specificity_2015_CVPR_paper_properties,
        :Jas_Image_Specificity_2015_CVPR_paper_retrieval,
        :Jas_Image_Specificity_2015_CVPR_paper_specificity,
        :Jas_Image_Specificity_2015_CVPR_paper_text,
        :Jas_Image_Specificity_2015_CVPR_paper_that,
        :Jas_Image_Specificity_2015_CVPR_paper_this,
        :Jas_Image_Specificity_2015_CVPR_paper_two,
        :Jas_Image_Specificity_2015_CVPR_paper_understanding,
        :Jas_Image_Specificity_2015_CVPR_paper_we,
        :Jas_Image_Specificity_2015_CVPR_paper_words ;
    :platform "tensorflow" ;
    :yearOfPublication 2015 .

:JobDef a owl:Class ;
    rdfs:subClassOf :train .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper a :Publication ;
    :conferenceSeries "ECCV" ;
    :hasEntity :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_activations,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_approach,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_compression,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_datasets,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_deep_learning,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_deep_networks,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_distributed,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_experiments,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_magnitude,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_memory,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_models,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_network,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_networks,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_ones,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_operations,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_pooling,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_representation,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_representations,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_state,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_statistical_analysis,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_strategy,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_techniques,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_that,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_them,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_this,
        :Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:Kendall_Geometric_Loss_Functions_CVPR_2017_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

:Khoreva_Simple_Does_It_CVPR_2017_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

:LSTMBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:LSTMSeqBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:Li_Convolutional_Sequence_to_CVPR_2018_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:Li_Towards_Faster_Training_CVPR_2018_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :hasEntity :Li_Towards_Faster_Training_CVPR_2018_paper_convolutional_neural_networks,
        :Li_Towards_Faster_Training_CVPR_2018_paper_covariance,
        :Li_Towards_Faster_Training_CVPR_2018_paper_improvement,
        :Li_Towards_Faster_Training_CVPR_2018_paper_pooling ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :hasEntity :Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_adversarial,
        :Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_gan,
        :Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_image,
        :Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_network,
        :Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_problem,
        :Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_that,
        :Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_this,
        :Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:Liu_Decoupled_Networks_CVPR_2018_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :hasEntity :Liu_Decoupled_Networks_CVPR_2018_paper_component,
        :Liu_Decoupled_Networks_CVPR_2018_paper_convolution,
        <https://github.com/deepcurator/DCC/Liu_Decoupled_Networks_CVPR_2018_paper_convolutional_neural_networks_(cnns)> ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :hasEntity :Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper_face_recognition ;
    :hasModality <https://github.com/deepcurator/DCC/:fig_Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1> ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

:Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1_Comp0 :partOf <https://github.com/deepcurator/DCC/:fig_Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1> .

:Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1_Comp1 a :ConvBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1> .

:Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1_Comp2 :partOf <https://github.com/deepcurator/DCC/:fig_Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1> .

:Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1_Comp3 a :LossBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1> .

:Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1_Comp4 :partOf <https://github.com/deepcurator/DCC/:fig_Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1> .

:Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1_Comp5 :partOf <https://github.com/deepcurator/DCC/:fig_Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1> .

:Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1_Comp6 :partOf <https://github.com/deepcurator/DCC/:fig_Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1> .

:Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1_Comp7 :partOf <https://github.com/deepcurator/DCC/:fig_Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1> .

:LoggingTensorHook a owl:Class ;
    rdfs:subClassOf :train .

:LooperThread a owl:Class ;
    rdfs:subClassOf :train .

:Masana_Domain-Adaptive_Deep_Network_ICCV_2017_paper a :Publication ;
    :conferenceSeries "ICCV" ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

:Metric a owl:Class ;
    rdfs:subClassOf :TextEntity .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :hasEntity :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_activations,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_approach,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_approaches,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_architectures,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_baseline_methods,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_categories,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_convolutional_networks,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_end-to-end,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_field,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_learn,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_method,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_network,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_networks,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_representations,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_task,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_tasks,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_that,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_this,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_training_examples,
        :Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2016 .

:MomentumOptimizer a owl:Class ;
    rdfs:subClassOf :train .

:MonitoredSession a owl:Class ;
    rdfs:subClassOf :train .

:NanLossDuringTrainingError a owl:Class ;
    rdfs:subClassOf :train .

:NanTensorHook a owl:Class ;
    rdfs:subClassOf :train .

:Optimizer a owl:Class ;
    rdfs:subClassOf :train .

:OtherScientificTerm a owl:Class ;
    rdfs:subClassOf :TextEntity .

:ProfilerHook a owl:Class ;
    rdfs:subClassOf :train .

:ProximalAdagradOptimizer a owl:Class ;
    rdfs:subClassOf :train .

:ProximalGradientDescentOptimizer a owl:Class ;
    rdfs:subClassOf :train .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :hasModality <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Comp0 a :InputBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Comp1 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Comp2 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Comp3 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Comp4 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Comp5 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Comp6 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Comp7 a :OutputBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text0 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text1 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text12 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text14 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text16 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text18 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text19 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text20 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text21 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text22 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text3 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text4 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text5 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text6 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text8 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1_Text9 :partOf <https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> .

:QueueRunner a owl:Class ;
    rdfs:subClassOf :train .

:RMSPropOptimizer a owl:Class ;
    rdfs:subClassOf :train .

:RNNBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:RNNSeqBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:Saver a owl:Class ;
    rdfs:subClassOf :train .

:SaverDef a owl:Class ;
    rdfs:subClassOf :train .

:Scaffold a owl:Class ;
    rdfs:subClassOf :train .

:SecondOrStepTimer a owl:Class ;
    rdfs:subClassOf :train .

:SequenceExample a owl:Class ;
    rdfs:subClassOf :train .

:Server a owl:Class ;
    rdfs:subClassOf :train .

:ServerDef a owl:Class ;
    rdfs:subClassOf :train .

:SessionCreator a owl:Class ;
    rdfs:subClassOf :train .

:SessionManager a owl:Class ;
    rdfs:subClassOf :train .

:SessionRunArgs a owl:Class ;
    rdfs:subClassOf :train .

:SessionRunContext a owl:Class ;
    rdfs:subClassOf :train .

:SessionRunHook a owl:Class ;
    rdfs:subClassOf :train .

:SessionRunValues a owl:Class ;
    rdfs:subClassOf :train .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :hasModality <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp0 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp1 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp10 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp11 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp12 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp13 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp14 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp15 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp16 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp17 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp18 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp19 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp2 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp20 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp21 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp22 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp23 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp24 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp25 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp26 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp27 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp28 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp29 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp3 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp30 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp31 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp32 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp33 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp34 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp5 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp6 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp7 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp8 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Comp9 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Text1 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Text3 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Text8 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1_Text9 :partOf <https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> .

:SingularMonitoredSession a owl:Class ;
    rdfs:subClassOf :train .

:SourceCodeFile a owl:Class .

:StepCounterHook a owl:Class ;
    rdfs:subClassOf :train .

:StopAtStepHook a owl:Class ;
    rdfs:subClassOf :train .

:SummarySaverHook a owl:Class ;
    rdfs:subClassOf :train .

:Supervisor a owl:Class ;
    rdfs:subClassOf :train .

:SyncReplicasOptimizer a owl:Class ;
    rdfs:subClassOf :train .

:Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :hasModality <https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1_Comp1 a :PoolingBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> .

:Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1_Comp2 :partOf <https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> .

:Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1_Comp3 :partOf <https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> .

:Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1_Comp4 :partOf <https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> .

:Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1_Comp5 :partOf <https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> .

:Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1_Comp6 a :UnpoolingBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> .

:Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1_Comp7 :partOf <https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> .

:Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1_Comp8 :partOf <https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> .

:Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1_Text0 :partOf <https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> .

:Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1_Text2 :partOf <https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> .

:Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1_Text3 :partOf <https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> .

:TitleText a owl:Class ;
    rdfs:subClassOf :Text .

:Tong_Image_Super-Resolution_Using_ICCV_2017_paper a :Publication ;
    :conferenceSeries "ICCV" ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

:UserDefined a owl:Class ;
    rdfs:subClassOf :CodeEntity .

:VocabInfo a owl:Class ;
    rdfs:subClassOf :train .

:WorkerSessionCreator a owl:Class ;
    rdfs:subClassOf :train .

:Xu_Scene_Graph_Generation_CVPR_2017_paper a :Publication ;
    :conferenceSeries "CVPR" ;
    :hasModality <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp0 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp1 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp10 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp11 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp12 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp13 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp2 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp3 a :PoolingBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp4 a :PoolingBlock ;
    :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp5 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp6 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp8 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Comp9 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Text3 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Text4 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Text5 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1_Text8 :partOf <https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper a :Publication ;
    :conferenceSeries "ECCV" ;
    :hasEntity :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_accuracy,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_alternative,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_bn,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_classification,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_computation,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_computer_vision_tasks,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_counterpart,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_counterparts,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_deep_learning,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_development,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_estimation,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_features,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_imagenet,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_memory,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_models,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_networks,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_object_detection,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_other,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_pre-training,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_problems,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_resnet-50,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_segmentation,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_sizes,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_statistics,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_tasks,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_technique,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_that,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_this,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_training,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_variance,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_video,
        :Yuxin_Wu_Group_Normalization_ECCV_2018_paper_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:and a owl:ObjectProperty .

:arxivId a owl:DatatypeProperty .

:author a owl:ObjectProperty .

:authorName a owl:DatatypeProperty .

:authorOf a owl:ObjectProperty ;
    rdfs:domain :PublicationAuthor ;
    rdfs:range :Publication .

:bojchevski18a a :Publication ;
    :conferenceSeries "ICML" ;
    :hasEntity :bojchevski18a_approach,
        :bojchevski18a_discrete,
        :bojchevski18a_first,
        :bojchevski18a_gan,
        :bojchevski18a_generalization,
        :bojchevski18a_generation,
        :bojchevski18a_generative_model,
        :bojchevski18a_graph,
        :bojchevski18a_graphs,
        :bojchevski18a_input,
        :bojchevski18a_model,
        :bojchevski18a_network,
        :bojchevski18a_neural_network,
        :bojchevski18a_pose,
        :bojchevski18a_prediction,
        :bojchevski18a_problem,
        :bojchevski18a_properties,
        :bojchevski18a_real-world_networks,
        :bojchevski18a_research,
        :bojchevski18a_task,
        :bojchevski18a_that,
        :bojchevski18a_them,
        :bojchevski18a_these,
        :bojchevski18a_this,
        :bojchevski18a_time ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:calls a owl:ObjectProperty ;
    rdfs:domain :Function ;
    rdfs:range :Function .

:cites a owl:ObjectProperty .

:compare a owl:ObjectProperty .

:conferenceSeries a owl:DatatypeProperty .

:conjunction a owl:ObjectProperty .

:feature-of a owl:ObjectProperty ;
    rdfs:subPropertyOf owl:topObjectProperty .

:featureOf a owl:ObjectProperty .

:followedBy a owl:ObjectProperty .

:franceschi18a a :Publication ;
    :conferenceSeries "ICML" ;
    :hasEntity :franceschi18a_approach,
        :franceschi18a_approaches,
        :franceschi18a_conditions,
        :franceschi18a_deep_learning,
        :franceschi18a_dynamics,
        :franceschi18a_experiments,
        :franceschi18a_few-shot_learning,
        :franceschi18a_framework,
        :franceschi18a_gradient,
        :franceschi18a_hyperparameter,
        :franceschi18a_hyperparameters,
        :franceschi18a_layers,
        :franceschi18a_learn,
        :franceschi18a_learner,
        :franceschi18a_optimization,
        :franceschi18a_parameters,
        :franceschi18a_problem,
        :franceschi18a_representation,
        :franceschi18a_results,
        :franceschi18a_solutions,
        :franceschi18a_supervised_learning,
        :franceschi18a_that,
        :franceschi18a_those,
        :franceschi18a_training,
        :franceschi18a_variables,
        :franceschi18a_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:gehring17a a :Publication ;
    :conferenceSeries "ICML" ;
    :hasEntity :gehring17a_accuracy,
        :gehring17a_approach,
        :gehring17a_architecture,
        :gehring17a_computations,
        :gehring17a_convolutional_neural_networks,
        :gehring17a_decoder,
        :gehring17a_french,
        :gehring17a_gradient,
        :gehring17a_hardware,
        :gehring17a_input,
        :gehring17a_lstm,
        :gehring17a_magnitude,
        :gehring17a_maps,
        :gehring17a_models,
        :gehring17a_module,
        :gehring17a_non-linearities,
        :gehring17a_optimization,
        :gehring17a_recurrent_neural_networks,
        :gehring17a_training,
        :gehring17a_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

:githubrepo a owl:DatatypeProperty .

:greydanus18a a :Publication ;
    :conferenceSeries "ICML" ;
    :hasEntity :greydanus18a_agents,
        :greydanus18a_decisions,
        :greydanus18a_deep_reinforcement_learning,
        :greydanus18a_deep_rl,
        :greydanus18a_environments,
        :greydanus18a_information,
        :greydanus18a_learns,
        :greydanus18a_maps,
        :greydanus18a_maximizing,
        :greydanus18a_method,
        :greydanus18a_our_method,
        :greydanus18a_policy,
        :greydanus18a_results,
        :greydanus18a_rewards,
        :greydanus18a_rl,
        :greydanus18a_strategies,
        :greydanus18a_that,
        :greydanus18a_these,
        :greydanus18a_they,
        :greydanus18a_this,
        :greydanus18a_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:hasCaptionText a owl:DatatypeProperty ;
    rdfs:domain :CaptionText ;
    rdfs:subPropertyOf :hasText .

:hasComponent a owl:ObjectProperty .

:hasDataFlow a owl:DatatypeProperty .

:hasEntity a owl:ObjectProperty ;
    rdfs:domain :Modality ;
    rdfs:range :TextEntity .

:hasFigureId a owl:DatatypeProperty ;
    rdfs:domain :ImageComponent .

:hasFile a owl:DatatypeProperty .

:hasFunction a owl:ObjectProperty ;
    rdfs:domain :app,
        :audio,
        :strings,
        :summary,
        :sysconfig,
        :tf ;
    rdfs:range :decode_wav,
        :encode_wav,
        :run .

:hasModality a owl:ObjectProperty ;
    rdfs:domain :Publication ;
    rdfs:range :Code,
        :Figure,
        :Modality,
        :Text .

:hasPublicationId a owl:DatatypeProperty ;
    rdfs:domain :Publication .

:hasRepository a owl:ObjectProperty ;
    rdfs:domain :Publication ;
    rdfs:range :Repository .

:hasTitle a owl:DatatypeProperty .

:isDeprecated a owl:DatatypeProperty .

:isExperimental a owl:DatatypeProperty .

:kim17b a :Publication ;
    :conferenceSeries "ICML" ;
    :hasEntity :kim17b_accuracies,
        :kim17b_cifar-100,
        :kim17b_computations,
        :kim17b_datasets,
        :kim17b_deep_networks,
        :kim17b_deep_neural_network,
        :kim17b_feature,
        :kim17b_features,
        :kim17b_image_classification,
        :kim17b_learns,
        :kim17b_matrices,
        :kim17b_model,
        :kim17b_models,
        :kim17b_network,
        :kim17b_networks,
        :kim17b_our_method,
        :kim17b_parameters,
        :kim17b_resnet,
        :kim17b_structured,
        :kim17b_that,
        :kim17b_time,
        :kim17b_two,
        :kim17b_validate,
        :kim17b_we,
        :kim17b_weights ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

:li18a a :Publication ;
    :conferenceSeries "ICML" ;
    :hasEntity :li18a_baseline,
        :li18a_bias,
        :li18a_convolutional_networks,
        :li18a_data,
        :li18a_features,
        :li18a_finetuning,
        :li18a_mechanism,
        :li18a_model,
        :li18a_penalty,
        :li18a_regularization,
        :li18a_schemes,
        :li18a_solution,
        :li18a_target,
        :li18a_task,
        :li18a_tasks,
        :li18a_that,
        :li18a_this,
        :li18a_training,
        :li18a_transfer_learning,
        :li18a_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:part-of a owl:ObjectProperty ;
    rdfs:subPropertyOf owl:topObjectProperty .

:partOf a owl:ObjectProperty .

:platform a owl:DatatypeProperty .

:sameAs a owl:ObjectProperty ;
    rdfs:subPropertyOf owl:topObjectProperty .

:sharchilev18a a :Publication ;
    :conferenceSeries "ICML" ;
    :hasEntity :sharchilev18a_approach,
        :sharchilev18a_approaches,
        :sharchilev18a_approximations,
        :sharchilev18a_baselines,
        :sharchilev18a_computational_complexity,
        :sharchilev18a_computational_efficiency,
        :sharchilev18a_decision_trees,
        :sharchilev18a_ensemble,
        :sharchilev18a_ensembles,
        :sharchilev18a_framework,
        :sharchilev18a_gradient,
        :sharchilev18a_model,
        :sharchilev18a_models,
        :sharchilev18a_one,
        :sharchilev18a_our_method,
        :sharchilev18a_parametric_models,
        :sharchilev18a_predictions,
        :sharchilev18a_problem,
        :sharchilev18a_quality,
        :sharchilev18a_scheme,
        :sharchilev18a_that,
        :sharchilev18a_this,
        :sharchilev18a_training,
        :sharchilev18a_tree,
        :sharchilev18a_tree_structures,
        :sharchilev18a_way,
        :sharchilev18a_ways,
        :sharchilev18a_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:shi18a a :Publication ;
    :conferenceSeries "ICML" ;
    :hasEntity :shi18a_applications,
        :shi18a_approach,
        :shi18a_bias,
        :shi18a_effectiveness,
        :shi18a_error_bound,
        :shi18a_estimates,
        :shi18a_extension,
        :shi18a_function,
        :shi18a_gradient,
        :shi18a_method,
        :shi18a_operators,
        :shi18a_our_method,
        :shi18a_pca,
        :shi18a_results,
        :shi18a_spectral_decomposition,
        :shi18a_that,
        :shi18a_this,
        :shi18a_variance,
        :shi18a_variational_inference,
        :shi18a_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:silver17a a :Publication ;
    :conferenceSeries "ICML" ;
    :hasEntity :silver17a_architecture,
        :silver17a_deep_neural_network_architectures,
        :silver17a_fully_model,
        :silver17a_function,
        :silver17a_learn,
        :silver17a_models,
        :silver17a_planning,
        :silver17a_predictions,
        :silver17a_reward,
        :silver17a_rewards,
        :silver17a_that,
        :silver17a_these,
        :silver17a_this,
        :silver17a_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

:sun18e a :Publication ;
    :conferenceSeries "ICML" ;
    :hasEntity :sun18e_architecture,
        :sun18e_automatic,
        :sun18e_compositional,
        :sun18e_end-to-end,
        :sun18e_family,
        :sun18e_generalization,
        :sun18e_kernels,
        :sun18e_network,
        :sun18e_neural_network,
        :sun18e_optimization,
        :sun18e_properties,
        :sun18e_rules,
        :sun18e_structure,
        :sun18e_structures,
        :sun18e_tasks,
        :sun18e_texture,
        :sun18e_that,
        :sun18e_this,
        :sun18e_those,
        :sun18e_time_series,
        :sun18e_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2018 .

:used-for a owl:ObjectProperty ;
    rdfs:subPropertyOf owl:topObjectProperty .

:usedFor a owl:ObjectProperty .

:venueOfPublication a owl:ObjectProperty .

:yearOfPublication a owl:DatatypeProperty .

:zenke17a a :Publication ;
    :conferenceSeries "ICML" ;
    :hasEntity :zenke17a_applications,
        :zenke17a_approach,
        :zenke17a_artificial_neural_networks,
        :zenke17a_classification_tasks,
        :zenke17a_complex,
        :zenke17a_computational_efficiency,
        :zenke17a_data,
        :zenke17a_deep_learning,
        :zenke17a_domains,
        :zenke17a_information,
        :zenke17a_neural_networks,
        :zenke17a_ones,
        :zenke17a_relevant_information,
        :zenke17a_task,
        :zenke17a_tasks,
        :zenke17a_that,
        :zenke17a_this,
        :zenke17a_time,
        :zenke17a_we ;
    :platform "tensorflow" ;
    :yearOfPublication 2017 .

<https://github.com/deepcurator/DCC/1806.02311_algorithm> a :Generic ;
    :hasText "algorithm" .

<https://github.com/deepcurator/DCC/1806.02311_approach> a :Generic ;
    :hasText "approach" .

<https://github.com/deepcurator/DCC/1806.02311_approaches> a :Generic ;
    :hasText "approaches" .

<https://github.com/deepcurator/DCC/1806.02311_attention_mechanisms> a :Method ;
    :hasText "attention_mechanisms" .

<https://github.com/deepcurator/DCC/1806.02311_image> a :Material ;
    :hasText "image" .

<https://github.com/deepcurator/DCC/1806.02311_mappings> a :Other ;
    :hasText "mappings" .

<https://github.com/deepcurator/DCC/1806.02311_modeling> a :Task ;
    :hasText "modeling" .

<https://github.com/deepcurator/DCC/1806.02311_objects> a :Generic ;
    :hasText "objects" .

<https://github.com/deepcurator/DCC/1806.02311_regions> a :Generic ;
    :hasText "regions" .

<https://github.com/deepcurator/DCC/1806.02311_scene> a :Generic ;
    :hasText "scene" .

<https://github.com/deepcurator/DCC/1806.02311_supervision> a :Other ;
    :hasText "supervision" .

<https://github.com/deepcurator/DCC/1806.02311_tasks> a :Generic ;
    :hasText "tasks" .

<https://github.com/deepcurator/DCC/1806.02311_techniques> a :Generic ;
    :hasText "techniques" .

<https://github.com/deepcurator/DCC/1806.02311_that> a :Generic ;
    :hasText "that" .

<https://github.com/deepcurator/DCC/1806.02311_this> a :Generic ;
    :hasText "this" .

<https://github.com/deepcurator/DCC/1806.02311_those> a :Generic ;
    :hasText "those" .

<https://github.com/deepcurator/DCC/1806.02311_time> a :Generic ;
    :hasText "time" .

<https://github.com/deepcurator/DCC/1806.02311_way> a :Generic ;
    :hasText "way" .

<https://github.com/deepcurator/DCC/1806.02311_we> a :Generic ;
    :hasText "we" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_algorithm> a :Generic ;
    :hasText "algorithm" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_approaches> a :Generic ;
    :hasText "approaches" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_baselines> a :Generic ;
    :hasText "baselines" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_benchmarks> a :Material ;
    :hasText "benchmarks" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_classification> a :Task ;
    :hasText "classification" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_data> a :Generic ;
    :hasText "data" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_embeddings> a :Generic ;
    :hasText "embeddings" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_feature> a :Other ;
    :hasText "feature" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_features> a :Generic ;
    :hasText "features" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_framework> a :Generic ;
    :hasText "framework" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_function> a :Generic ;
    :hasText "function" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_functions> a :Generic ;
    :hasText "functions" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_graph> a :Other ;
    :hasText "graph" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_graphs> a :Other ;
    :hasText "graphs" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_information> a :Generic ;
    :hasText "information" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_interactions> a :Generic ;
    :hasText "interactions" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_learn> a :Task ;
    :hasText "learn" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_local_neighborhood> a :Generic ;
    :hasText "local_neighborhood" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_node> a :Other ;
    :hasText "node" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_nodes> a :Other ;
    :hasText "nodes" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_prediction> a :Task ;
    :hasText "prediction" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_sampling> a :Method ;
    :hasText "sampling" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_tasks> a :Generic ;
    :hasText "tasks" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_text> a :Material ;
    :hasText "text" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_that> a :Generic ;
    :hasText "that" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_these> a :Generic ;
    :hasText "these" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_training> a :Task ;
    :hasText "training" .

<https://github.com/deepcurator/DCC/6703-inductive-representation-learning-on-large-graphs_we> a :Generic ;
    :hasText "we" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_algorithm> a :Generic ;
    :hasText "algorithm" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_algorithms> a :Generic ;
    :hasText "algorithms" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_application> a :Generic ;
    :hasText "application" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_convergence> a :Generic ;
    :hasText "convergence" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_convex> a :Other ;
    :hasText "convex" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_deep_networks> a :Method ;
    :hasText "deep_networks" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_functions> a :Generic ;
    :hasText "functions" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_gradient> a :Other ;
    :hasText "gradient" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_hyperparameters> a :Generic ;
    :hasText "hyperparameters" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_learning_methods> a :Method ;
    :hasText "learning_methods" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_methods> a :Generic ;
    :hasText "methods" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_objective_function> a :Other ;
    :hasText "objective_function" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_one> a :Generic ;
    :hasText "one" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_optimization> a :Task ;
    :hasText "optimization" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_procedure> a :Generic ;
    :hasText "procedure" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_results> a :Generic ;
    :hasText "results" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_state> a :Generic ;
    :hasText "state" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_stochastic_gradient_descent> a :Method ;
    :hasText "stochastic_gradient_descent" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_that> a :Generic ;
    :hasText "that" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_these> a :Generic ;
    :hasText "these" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_this> a :Generic ;
    :hasText "this" .

<https://github.com/deepcurator/DCC/6811-training-deep-networks-without-learning-rates-through-coin-betting_we> a :Generic ;
    :hasText "we" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_adversarial> a :Generic ;
    :hasText "adversarial" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_approach> a :Generic ;
    :hasText "approach" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_audio> a :Material ;
    :hasText "audio" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_benchmarks> a :Material ;
    :hasText "benchmarks" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_candidate> a :Generic ;
    :hasText "candidate" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_cifar-10> a :Material ;
    :hasText "cifar-10" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_data> a :Generic ;
    :hasText "data" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_ensembles> a :Task ;
    :hasText "ensembles" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_formulation> a :Generic ;
    :hasText "formulation" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_framework> a :Generic ;
    :hasText "framework" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_gan> a :Method ;
    :hasText "gan" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_gans> a :Method ;
    :hasText "gans" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_gradient> a :Other ;
    :hasText "gradient" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_images> a :Material ;
    :hasText "images" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_interpretable> a :Generic ;
    :hasText "interpretable" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_interventions> a :Other ;
    :hasText "interventions" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_learn> a :Task ;
    :hasText "learn" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_model> a :Generic ;
    :hasText "model" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_networks> a :Generic ;
    :hasText "networks" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_parameters> a :Generic ;
    :hasText "parameters" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_posterior> a :Generic ;
    :hasText "posterior" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_results> a :Generic ;
    :hasText "results" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_semi-supervised_learning> a :Task ;
    :hasText "semi-supervised_learning" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_smoothing> a :Method ;
    :hasText "smoothing" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_state> a :Generic ;
    :hasText "state" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_svhn> a :Material ;
    :hasText "svhn" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_this> a :Generic ;
    :hasText "this" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_we> a :Generic ;
    :hasText "we" .

<https://github.com/deepcurator/DCC/6953-bayesian-gan_weights> a :Generic ;
    :hasText "weights" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_adversarial> a :Generic ;
    :hasText "adversarial" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_algorithm> a :Generic ;
    :hasText "algorithm" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_baselines> a :Generic ;
    :hasText "baselines" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_complex> a :Method ;
    :hasText "complex" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_data> a :Generic ;
    :hasText "data" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_domain> a :Generic ;
    :hasText "domain" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_factors> a :Generic ;
    :hasText "factors" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_human_actions> a :Other ;
    :hasText "human_actions" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_imitation_learning> a :Method ;
    :hasText "imitation_learning" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_inputs> a :Generic ;
    :hasText "inputs" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_interpretable> a :Generic ;
    :hasText "interpretable" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_learn> a :Task ;
    :hasText "learn" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_method> a :Generic ;
    :hasText "method" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_model> a :Generic ;
    :hasText "model" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_our_method> a :Other ;
    :hasText "our_method" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_representations> a :Generic ;
    :hasText "representations" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_reward> a :Eval ;
    :hasText "reward" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_signal> a :Generic ;
    :hasText "signal" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_structure> a :Generic ;
    :hasText "structure" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_that> a :Generic ;
    :hasText "that" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_this> a :Generic ;
    :hasText "this" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_way> a :Generic ;
    :hasText "way" .

<https://github.com/deepcurator/DCC/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations_we> a :Generic ;
    :hasText "we" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_approaches> a :Generic ;
    :hasText "approaches" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_architectures> a :Generic ;
    :hasText "architectures" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_complex> a :Method ;
    :hasText "complex" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_components> a :Generic ;
    :hasText "components" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_deep_learning> a :Generic ;
    :hasText "deep_learning" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_framework> a :Generic ;
    :hasText "framework" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_global_context> a :Other ;
    :hasText "global_context" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_graph> a :Other ;
    :hasText "graph" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_images> a :Material ;
    :hasText "images" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_interactions> a :Generic ;
    :hasText "interactions" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_model> a :Generic ;
    :hasText "model" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_model_design> a :Generic ;
    :hasText "model_design" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_modeling> a :Task ;
    :hasText "modeling" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_objects> a :Generic ;
    :hasText "objects" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_prediction> a :Task ;
    :hasText "prediction" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_prediction_model> a :Method ;
    :hasText "prediction_model" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_principles> a :Generic ;
    :hasText "principles" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_results> a :Generic ;
    :hasText "results" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_scene> a :Generic ;
    :hasText "scene" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_scenes> a :Generic ;
    :hasText "scenes" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_state> a :Generic ;
    :hasText "state" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_structured> a :Generic ;
    :hasText "structured" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_task> a :Generic ;
    :hasText "task" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_that> a :Generic ;
    :hasText "that" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_this> a :Generic ;
    :hasText "this" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_understanding> a :Task ;
    :hasText "understanding" .

<https://github.com/deepcurator/DCC/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction_we> a :Generic ;
    :hasText "we" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_complex a :Method ;
    :hasText "complex" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_convolutions a :Method ;
    :hasText "convolutions" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_domains a :Generic ;
    :hasText "domains" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_faces a :Other ;
    :hasText "faces" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_image a :Material ;
    :hasText "image" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_information a :Generic ;
    :hasText "information" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_map a :Eval ;
    :hasText "map" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_mappings a :Other ;
    :hasText "mappings" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_objects a :Generic ;
    :hasText "objects" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_scale a :Other ;
    :hasText "scale" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_semantic_segmentation a :Task ;
    :hasText "semantic_segmentation" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_shape a :Other ;
    :hasText "shape" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_techniques a :Generic ;
    :hasText "techniques" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_texture a :Other ;
    :hasText "texture" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_that a :Generic ;
    :hasText "that" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_they a :Generic ;
    :hasText "they" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_this a :Generic ;
    :hasText "this" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_two a :Generic ;
    :hasText "two" .

:Aaron_Gokaslan_Improving_Shape_Deformation_ECCV_2018_paper_we a :Generic ;
    :hasText "we" .

:ActivationBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:BasicLSTMCell a owl:Class ;
    rdfs:subClassOf :rnn_cell .

:BasicRNNCell a owl:Class ;
    rdfs:subClassOf :rnn_cell .

:CaptionText a owl:Class ;
    rdfs:subClassOf :Text .

:Chen_Photographic_Image_Synthesis_ICCV_2017_paper_approach a :Generic ;
    :hasText "approach" .

:Chen_Photographic_Image_Synthesis_ICCV_2017_paper_images a :Material ;
    :hasText "images" .

:Chen_Photographic_Image_Synthesis_ICCV_2017_paper_scenes a :Generic ;
    :hasText "scenes" .

:Chen_Photographic_Image_Synthesis_ICCV_2017_paper_semantic a :Other ;
    :hasText "semantic" .

:Chen_Photographic_Image_Synthesis_ICCV_2017_paper_that a :Generic ;
    :hasText "that" .

:Chen_Photographic_Image_Synthesis_ICCV_2017_paper_training a :Task ;
    :hasText "training" .

:Code a owl:Class ;
    rdfs:subClassOf :Modality .

:DeviceWrapper a owl:Class ;
    rdfs:subClassOf :rnn_cell .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_adversarial a :Generic ;
    :hasText "adversarial" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_adversarial_learning a :Method ;
    :hasText "adversarial_learning" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_approaches a :Generic ;
    :hasText "approaches" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_architecture a :Generic ;
    :hasText "architecture" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_baseline a :Generic ;
    :hasText "baseline" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_classes a :Generic ;
    :hasText "classes" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_classification a :Task ;
    :hasText "classification" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_datasets a :Material ;
    :hasText "datasets" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_deep_convolutional_networks a :Method ;
    :hasText "deep_convolutional_networks" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_efficiency a :Eval ;
    :hasText "efficiency" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_framework a :Generic ;
    :hasText "framework" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_frameworks a :Generic ;
    :hasText "frameworks" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_image a :Material ;
    :hasText "image" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_network a :Generic ;
    :hasText "network" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_robustness a :Eval ;
    :hasText "robustness" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_state a :Generic ;
    :hasText "state" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_tasks a :Generic ;
    :hasText "tasks" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_that a :Generic ;
    :hasText "that" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_these a :Generic ;
    :hasText "these" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_this a :Generic ;
    :hasText "this" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_two a :Generic ;
    :hasText "two" .

:Diana_Sungatullina_Image_Manipulation_with_ECCV_2018_paper_we a :Generic ;
    :hasText "we" .

:DropoutWrapper a owl:Class ;
    rdfs:subClassOf :rnn_cell .

:GRUCell a owl:Class ;
    rdfs:subClassOf :rnn_cell .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_algorithms a :Generic ;
    :hasText "algorithms" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_architecture a :Generic ;
    :hasText "architecture" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_benchmarks a :Material ;
    :hasText "benchmarks" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_boundary_detection a :Method ;
    :hasText "boundary_detection" .

<https://github.com/deepcurator/DCC/Hou_Deeply_Supervised_Salient_CVPR_2017_paper_convolutional_neural_networks_(cnns)> a :Method ;
    :hasText "convolutional_neural_networks_(cnns)" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_development a :Material ;
    :hasText "development" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_edge a :Other ;
    :hasText "edge" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_effectiveness a :Eval ;
    :hasText "effectiveness" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_efficiency a :Eval ;
    :hasText "efficiency" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_fcn a :Method ;
    :hasText "fcn" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_fcns a :Method ;
    :hasText "fcns" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_feature a :Other ;
    :hasText "feature" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_framework a :Generic ;
    :hasText "framework" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_fully_convolutional_neural_networks a :Method ;
    :hasText "fully_convolutional_neural_networks" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_image a :Material ;
    :hasText "image" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_improvement a :Eval ;
    :hasText "improvement" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_maps a :Eval ;
    :hasText "maps" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_method a :Generic ;
    :hasText "method" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_models a :Generic ;
    :hasText "models" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_object_detection a :Task ;
    :hasText "object_detection" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_per a :Eval ;
    :hasText "per" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_problem a :Generic ;
    :hasText "problem" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_results a :Generic ;
    :hasText "results" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_scale a :Other ;
    :hasText "scale" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_segmentation a :Task ;
    :hasText "segmentation" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_structure a :Generic ;
    :hasText "structure" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_structures a :Generic ;
    :hasText "structures" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_supervision a :Other ;
    :hasText "supervision" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_that a :Generic ;
    :hasText "that" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_this a :Generic ;
    :hasText "this" .

:Hou_Deeply_Supervised_Salient_CVPR_2017_paper_we a :Generic ;
    :hasText "we" .

:ImageComponent a owl:Class .

:Jas_Image_Specificity_2015_CVPR_paper_application a :Generic ;
    :hasText "application" .

:Jas_Image_Specificity_2015_CVPR_paper_descriptions a :Generic ;
    :hasText "descriptions" .

:Jas_Image_Specificity_2015_CVPR_paper_features a :Generic ;
    :hasText "features" .

:Jas_Image_Specificity_2015_CVPR_paper_image a :Material ;
    :hasText "image" .

:Jas_Image_Specificity_2015_CVPR_paper_image_content a :Other ;
    :hasText "image_content" .

:Jas_Image_Specificity_2015_CVPR_paper_images a :Material ;
    :hasText "images" .

:Jas_Image_Specificity_2015_CVPR_paper_improvements a :Eval ;
    :hasText "improvements" .

:Jas_Image_Specificity_2015_CVPR_paper_measure a :Generic ;
    :hasText "measure" .

:Jas_Image_Specificity_2015_CVPR_paper_mechanisms a :Generic ;
    :hasText "mechanisms" .

:Jas_Image_Specificity_2015_CVPR_paper_modeling a :Task ;
    :hasText "modeling" .

:Jas_Image_Specificity_2015_CVPR_paper_models a :Generic ;
    :hasText "models" .

:Jas_Image_Specificity_2015_CVPR_paper_ones a :Generic ;
    :hasText "ones" .

:Jas_Image_Specificity_2015_CVPR_paper_other a :Generic ;
    :hasText "other" .

:Jas_Image_Specificity_2015_CVPR_paper_properties a :Generic ;
    :hasText "properties" .

:Jas_Image_Specificity_2015_CVPR_paper_retrieval a :Task ;
    :hasText "retrieval" .

:Jas_Image_Specificity_2015_CVPR_paper_specificity a :Eval ;
    :hasText "specificity" .

:Jas_Image_Specificity_2015_CVPR_paper_text a :Material ;
    :hasText "text" .

:Jas_Image_Specificity_2015_CVPR_paper_that a :Generic ;
    :hasText "that" .

:Jas_Image_Specificity_2015_CVPR_paper_this a :Generic ;
    :hasText "this" .

:Jas_Image_Specificity_2015_CVPR_paper_two a :Generic ;
    :hasText "two" .

:Jas_Image_Specificity_2015_CVPR_paper_understanding a :Task ;
    :hasText "understanding" .

:Jas_Image_Specificity_2015_CVPR_paper_we a :Generic ;
    :hasText "we" .

:Jas_Image_Specificity_2015_CVPR_paper_words a :Generic ;
    :hasText "words" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_activations a :Other ;
    :hasText "activations" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_approach a :Generic ;
    :hasText "approach" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_compression a :Task ;
    :hasText "compression" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_datasets a :Material ;
    :hasText "datasets" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_deep_learning a :Generic ;
    :hasText "deep_learning" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_deep_networks a :Method ;
    :hasText "deep_networks" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_distributed a :Generic ;
    :hasText "distributed" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_experiments a :Generic ;
    :hasText "experiments" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_magnitude a :Other ;
    :hasText "magnitude" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_memory a :Other ;
    :hasText "memory" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_models a :Generic ;
    :hasText "models" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_network a :Generic ;
    :hasText "network" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_networks a :Generic ;
    :hasText "networks" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_ones a :Generic ;
    :hasText "ones" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_operations a :Generic ;
    :hasText "operations" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_pooling a :Method ;
    :hasText "pooling" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_representation a :Generic ;
    :hasText "representation" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_representations a :Generic ;
    :hasText "representations" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_state a :Generic ;
    :hasText "state" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_statistical_analysis a :Method ;
    :hasText "statistical_analysis" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_strategy a :Generic ;
    :hasText "strategy" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_techniques a :Generic ;
    :hasText "techniques" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_that a :Generic ;
    :hasText "that" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_them a :Generic ;
    :hasText "them" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_this a :Generic ;
    :hasText "this" .

:Kaicheng_Yu_Statistically-motivated_Second-order_Pooling_ECCV_2018_paper_we a :Generic ;
    :hasText "we" .

:LSTMCell a owl:Class ;
    rdfs:subClassOf :rnn_cell .

:LSTMStateTuple a owl:Class ;
    rdfs:subClassOf :rnn_cell .

:Li_Towards_Faster_Training_CVPR_2018_paper_convolutional_neural_networks a :Method ;
    :hasText "convolutional_neural_networks" .

:Li_Towards_Faster_Training_CVPR_2018_paper_covariance a :Other ;
    :hasText "covariance" .

:Li_Towards_Faster_Training_CVPR_2018_paper_improvement a :Eval ;
    :hasText "improvement" .

:Li_Towards_Faster_Training_CVPR_2018_paper_pooling a :Method ;
    :hasText "pooling" .

:Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_adversarial a :Generic ;
    :hasText "adversarial" .

:Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_gan a :Method ;
    :hasText "gan" .

:Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_image a :Material ;
    :hasText "image" .

:Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_network a :Generic ;
    :hasText "network" .

:Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_problem a :Generic ;
    :hasText "problem" .

:Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_that a :Generic ;
    :hasText "that" .

:Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_this a :Generic ;
    :hasText "this" .

:Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper_we a :Generic ;
    :hasText "we" .

:Liu_Decoupled_Networks_CVPR_2018_paper_component a :Generic ;
    :hasText "component" .

:Liu_Decoupled_Networks_CVPR_2018_paper_convolution a :Method ;
    :hasText "convolution" .

<https://github.com/deepcurator/DCC/Liu_Decoupled_Networks_CVPR_2018_paper_convolutional_neural_networks_(cnns)> a :Method ;
    :hasText "convolutional_neural_networks_(cnns)" .

:Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper_face_recognition a :Task ;
    :hasText "face_recognition" .

:LossBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_activations a :Other ;
    :hasText "activations" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_approach a :Generic ;
    :hasText "approach" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_approaches a :Generic ;
    :hasText "approaches" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_architectures a :Generic ;
    :hasText "architectures" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_baseline_methods a :Generic ;
    :hasText "baseline_methods" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_categories a :Generic ;
    :hasText "categories" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_convolutional_networks a :Method ;
    :hasText "convolutional_networks" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_end-to-end a :Generic ;
    :hasText "end-to-end" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_field a :Generic ;
    :hasText "field" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_learn a :Task ;
    :hasText "learn" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_method a :Generic ;
    :hasText "method" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_network a :Generic ;
    :hasText "network" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_networks a :Generic ;
    :hasText "networks" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_representations a :Generic ;
    :hasText "representations" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_task a :Generic ;
    :hasText "task" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_tasks a :Generic ;
    :hasText "tasks" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_that a :Generic ;
    :hasText "that" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_this a :Generic ;
    :hasText "this" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_training_examples a :Material ;
    :hasText "training_examples" .

:Misra_Cross-Stitch_Networks_for_CVPR_2016_paper_we a :Generic ;
    :hasText "we" .

:MultiRNNCell a owl:Class ;
    rdfs:subClassOf :rnn_cell .

:NormBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:PublicationAuthor a owl:Class .

:RNNCell a owl:Class ;
    rdfs:subClassOf :rnn_cell .

:Repository a owl:Class .

:ResidualWrapper a owl:Class ;
    rdfs:subClassOf :rnn_cell .

:UnpoolingBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_accuracy a :Eval ;
    :hasText "accuracy" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_alternative a :Generic ;
    :hasText "alternative" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_bn a :Method ;
    :hasText "bn" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_classification a :Task ;
    :hasText "classification" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_computation a :Other ;
    :hasText "computation" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_computer_vision_tasks a :Task ;
    :hasText "computer_vision_tasks" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_counterpart a :Generic ;
    :hasText "counterpart" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_counterparts a :Generic ;
    :hasText "counterparts" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_deep_learning a :Generic ;
    :hasText "deep_learning" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_development a :Material ;
    :hasText "development" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_estimation a :Generic ;
    :hasText "estimation" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_features a :Generic ;
    :hasText "features" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_imagenet a :Material ;
    :hasText "imagenet" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_memory a :Other ;
    :hasText "memory" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_models a :Generic ;
    :hasText "models" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_networks a :Generic ;
    :hasText "networks" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_object_detection a :Task ;
    :hasText "object_detection" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_other a :Generic ;
    :hasText "other" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_pre-training a :Method ;
    :hasText "pre-training" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_problems a :Generic ;
    :hasText "problems" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_resnet-50 a :Other ;
    :hasText "resnet-50" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_segmentation a :Task ;
    :hasText "segmentation" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_sizes a :Other ;
    :hasText "sizes" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_statistics a :Method ;
    :hasText "statistics" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_tasks a :Generic ;
    :hasText "tasks" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_technique a :Generic ;
    :hasText "technique" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_that a :Generic ;
    :hasText "that" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_this a :Generic ;
    :hasText "this" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_training a :Task ;
    :hasText "training" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_variance a :Generic ;
    :hasText "variance" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_video a :Material ;
    :hasText "video" .

:Yuxin_Wu_Group_Normalization_ECCV_2018_paper_we a :Generic ;
    :hasText "we" .

:all_candidate_sampler a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:atrous_conv2d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:atrous_conv2d_transpose a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:autograph a owl:Class ;
    rdfs:subClassOf :Module .

:avg_pool a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:avg_pool1d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:avg_pool2d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:avg_pool3d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:avg_pool_v2 a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:batch_norm_with_global_normalization a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:batch_normalization a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:bias_add a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:bidirectional_dynamic_rnn a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:bitwise a owl:Class ;
    rdfs:subClassOf :Module .

:bojchevski18a_approach a :Generic ;
    :hasText "approach" .

:bojchevski18a_discrete a :Generic ;
    :hasText "discrete" .

:bojchevski18a_first a :Generic ;
    :hasText "first" .

:bojchevski18a_gan a :Method ;
    :hasText "gan" .

:bojchevski18a_generalization a :Generic ;
    :hasText "generalization" .

:bojchevski18a_generation a :Task ;
    :hasText "generation" .

:bojchevski18a_generative_model a :Method ;
    :hasText "generative_model" .

:bojchevski18a_graph a :Other ;
    :hasText "graph" .

:bojchevski18a_graphs a :Other ;
    :hasText "graphs" .

:bojchevski18a_input a :Generic ;
    :hasText "input" .

:bojchevski18a_model a :Generic ;
    :hasText "model" .

:bojchevski18a_network a :Generic ;
    :hasText "network" .

:bojchevski18a_neural_network a :Method ;
    :hasText "neural_network" .

:bojchevski18a_pose a :Other ;
    :hasText "pose" .

:bojchevski18a_prediction a :Task ;
    :hasText "prediction" .

:bojchevski18a_problem a :Generic ;
    :hasText "problem" .

:bojchevski18a_properties a :Generic ;
    :hasText "properties" .

:bojchevski18a_real-world_networks a :Generic ;
    :hasText "real-world_networks" .

:bojchevski18a_research a :Generic ;
    :hasText "research" .

:bojchevski18a_task a :Generic ;
    :hasText "task" .

:bojchevski18a_that a :Generic ;
    :hasText "that" .

:bojchevski18a_them a :Generic ;
    :hasText "them" .

:bojchevski18a_these a :Generic ;
    :hasText "these" .

:bojchevski18a_this a :Generic ;
    :hasText "this" .

:bojchevski18a_time a :Generic ;
    :hasText "time" .

:collapse_repeated a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:compat a owl:Class ;
    rdfs:subClassOf :Module .

:compute_accidental_hits a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:config a owl:Class ;
    rdfs:subClassOf :Module .

:contrib a owl:Class ;
    rdfs:subClassOf :Module .

:conv1d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:conv1d_transpose a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:conv2d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:conv2d_backprop_filter a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:conv2d_backprop_input a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:conv2d_transpose a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:conv3d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:conv3d_backprop_filter_v2 a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:conv3d_transpose a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:conv_transpose a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:convolution a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:crelu a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:ctc_beam_search_decoder a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:ctc_beam_search_decoder_v2 a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:ctc_greedy_decoder a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:ctc_loss a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:ctc_loss_v2 a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:ctc_unique_labels a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:data a owl:Class ;
    rdfs:subClassOf :Module .

:debugging a owl:Class ;
    rdfs:subClassOf :Module .

:depth_to_space a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:depthwise_conv2d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:depthwise_conv2d_backprop_filter a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:depthwise_conv2d_backprop_input a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:depthwise_conv2d_native a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:depthwise_conv2d_native_backprop_filter a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:depthwise_conv2d_native_backprop_input a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:dilation2d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:distribute a owl:Class ;
    rdfs:subClassOf :Module .

:distributions a owl:Class ;
    rdfs:subClassOf :Module .

:dropout a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:dtypes a owl:Class ;
    rdfs:subClassOf :Module .

:dynamic_rnn a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:elu a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:embedding_lookup a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:embedding_lookup_sparse a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:erosion2d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:errors a owl:Class ;
    rdfs:subClassOf :Module .

:estimator a owl:Class ;
    rdfs:subClassOf :Module .

:experimental a owl:Class ;
    rdfs:subClassOf :Module .

:feature_column a owl:Class ;
    rdfs:subClassOf :Module .

:fixed_unigram_candidate_sampler a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:fractional_avg_pool a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:fractional_max_pool a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:franceschi18a_approach a :Generic ;
    :hasText "approach" .

:franceschi18a_approaches a :Generic ;
    :hasText "approaches" .

:franceschi18a_conditions a :Generic ;
    :hasText "conditions" .

:franceschi18a_deep_learning a :Generic ;
    :hasText "deep_learning" .

:franceschi18a_dynamics a :Generic ;
    :hasText "dynamics" .

:franceschi18a_experiments a :Generic ;
    :hasText "experiments" .

:franceschi18a_few-shot_learning a :Task ;
    :hasText "few-shot_learning" .

:franceschi18a_framework a :Generic ;
    :hasText "framework" .

:franceschi18a_gradient a :Other ;
    :hasText "gradient" .

:franceschi18a_hyperparameter a :Generic ;
    :hasText "hyperparameter" .

:franceschi18a_hyperparameters a :Generic ;
    :hasText "hyperparameters" .

:franceschi18a_layers a :Other ;
    :hasText "layers" .

:franceschi18a_learn a :Task ;
    :hasText "learn" .

:franceschi18a_learner a :Generic ;
    :hasText "learner" .

:franceschi18a_optimization a :Task ;
    :hasText "optimization" .

:franceschi18a_parameters a :Generic ;
    :hasText "parameters" .

:franceschi18a_problem a :Generic ;
    :hasText "problem" .

:franceschi18a_representation a :Generic ;
    :hasText "representation" .

:franceschi18a_results a :Generic ;
    :hasText "results" .

:franceschi18a_solutions a :Generic ;
    :hasText "solutions" .

:franceschi18a_supervised_learning a :Method ;
    :hasText "supervised_learning" .

:franceschi18a_that a :Generic ;
    :hasText "that" .

:franceschi18a_those a :Generic ;
    :hasText "those" .

:franceschi18a_training a :Task ;
    :hasText "training" .

:franceschi18a_variables a :Other ;
    :hasText "variables" .

:franceschi18a_we a :Generic ;
    :hasText "we" .

:fused_batch_norm a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:gehring17a_accuracy a :Eval ;
    :hasText "accuracy" .

:gehring17a_approach a :Generic ;
    :hasText "approach" .

:gehring17a_architecture a :Generic ;
    :hasText "architecture" .

:gehring17a_computations a :Generic ;
    :hasText "computations" .

:gehring17a_convolutional_neural_networks a :Method ;
    :hasText "convolutional_neural_networks" .

:gehring17a_decoder a :Method ;
    :hasText "decoder" .

:gehring17a_french a :Material ;
    :hasText "french" .

:gehring17a_gradient a :Other ;
    :hasText "gradient" .

:gehring17a_hardware a :Generic ;
    :hasText "hardware" .

:gehring17a_input a :Generic ;
    :hasText "input" .

:gehring17a_lstm a :Method ;
    :hasText "lstm" .

:gehring17a_magnitude a :Other ;
    :hasText "magnitude" .

:gehring17a_maps a :Eval ;
    :hasText "maps" .

:gehring17a_models a :Generic ;
    :hasText "models" .

:gehring17a_module a :Generic ;
    :hasText "module" .

:gehring17a_non-linearities a :Other ;
    :hasText "non-linearities" .

:gehring17a_optimization a :Task ;
    :hasText "optimization" .

:gehring17a_recurrent_neural_networks a :Method ;
    :hasText "recurrent_neural_networks" .

:gehring17a_training a :Task ;
    :hasText "training" .

:gehring17a_we a :Generic ;
    :hasText "we" .

:gfile a owl:Class ;
    rdfs:subClassOf :Module .

:graph_util a owl:Class ;
    rdfs:subClassOf :Module .

:greydanus18a_agents a :Generic ;
    :hasText "agents" .

:greydanus18a_decisions a :Generic ;
    :hasText "decisions" .

:greydanus18a_deep_reinforcement_learning a :Method ;
    :hasText "deep_reinforcement_learning" .

:greydanus18a_deep_rl a :Method ;
    :hasText "deep_rl" .

:greydanus18a_environments a :Generic ;
    :hasText "environments" .

:greydanus18a_information a :Generic ;
    :hasText "information" .

:greydanus18a_learns a :Task ;
    :hasText "learns" .

:greydanus18a_maps a :Eval ;
    :hasText "maps" .

:greydanus18a_maximizing a :Task ;
    :hasText "maximizing" .

:greydanus18a_method a :Generic ;
    :hasText "method" .

:greydanus18a_our_method a :Other ;
    :hasText "our_method" .

:greydanus18a_policy a :Other ;
    :hasText "policy" .

:greydanus18a_results a :Generic ;
    :hasText "results" .

:greydanus18a_rewards a :Eval ;
    :hasText "rewards" .

:greydanus18a_rl a :Task ;
    :hasText "rl" .

:greydanus18a_strategies a :Generic ;
    :hasText "strategies" .

:greydanus18a_that a :Generic ;
    :hasText "that" .

:greydanus18a_these a :Generic ;
    :hasText "these" .

:greydanus18a_they a :Generic ;
    :hasText "they" .

:greydanus18a_this a :Generic ;
    :hasText "this" .

:greydanus18a_we a :Generic ;
    :hasText "we" .

:hasText a owl:DatatypeProperty ;
    rdfs:domain :Text .

:image a owl:Class ;
    rdfs:subClassOf :Module .

:in_top_k a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:initializers a owl:Class ;
    rdfs:subClassOf :Module .

:io a owl:Class ;
    rdfs:subClassOf :Module .

:keras a owl:Class ;
    rdfs:subClassOf :Module .

:kim17b_accuracies a :Eval ;
    :hasText "accuracies" .

:kim17b_cifar-100 a :Material ;
    :hasText "cifar-100" .

:kim17b_computations a :Generic ;
    :hasText "computations" .

:kim17b_datasets a :Material ;
    :hasText "datasets" .

:kim17b_deep_networks a :Method ;
    :hasText "deep_networks" .

:kim17b_deep_neural_network a :Method ;
    :hasText "deep_neural_network" .

:kim17b_feature a :Other ;
    :hasText "feature" .

:kim17b_features a :Generic ;
    :hasText "features" .

:kim17b_image_classification a :Task ;
    :hasText "image_classification" .

:kim17b_learns a :Task ;
    :hasText "learns" .

:kim17b_matrices a :Generic ;
    :hasText "matrices" .

:kim17b_model a :Generic ;
    :hasText "model" .

:kim17b_models a :Generic ;
    :hasText "models" .

:kim17b_network a :Generic ;
    :hasText "network" .

:kim17b_networks a :Generic ;
    :hasText "networks" .

:kim17b_our_method a :Other ;
    :hasText "our_method" .

:kim17b_parameters a :Generic ;
    :hasText "parameters" .

:kim17b_resnet a :Method ;
    :hasText "resnet" .

:kim17b_structured a :Generic ;
    :hasText "structured" .

:kim17b_that a :Generic ;
    :hasText "that" .

:kim17b_time a :Generic ;
    :hasText "time" .

:kim17b_two a :Generic ;
    :hasText "two" .

:kim17b_validate a :Task ;
    :hasText "validate" .

:kim17b_we a :Generic ;
    :hasText "we" .

:kim17b_weights a :Generic ;
    :hasText "weights" .

:l2_loss a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:l2_normalize a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:layers a owl:Class ;
    rdfs:subClassOf :Module .

:leaky_relu a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:learned_unigram_candidate_sampler a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:li18a_baseline a :Generic ;
    :hasText "baseline" .

:li18a_bias a :Method ;
    :hasText "bias" .

:li18a_convolutional_networks a :Method ;
    :hasText "convolutional_networks" .

:li18a_data a :Generic ;
    :hasText "data" .

:li18a_features a :Generic ;
    :hasText "features" .

:li18a_finetuning a :Generic ;
    :hasText "finetuning" .

:li18a_mechanism a :Generic ;
    :hasText "mechanism" .

:li18a_model a :Generic ;
    :hasText "model" .

:li18a_penalty a :Eval ;
    :hasText "penalty" .

:li18a_regularization a :Other ;
    :hasText "regularization" .

:li18a_schemes a :Generic ;
    :hasText "schemes" .

:li18a_solution a :Generic ;
    :hasText "solution" .

:li18a_target a :Generic ;
    :hasText "target" .

:li18a_task a :Generic ;
    :hasText "task" .

:li18a_tasks a :Generic ;
    :hasText "tasks" .

:li18a_that a :Generic ;
    :hasText "that" .

:li18a_this a :Generic ;
    :hasText "this" .

:li18a_training a :Task ;
    :hasText "training" .

:li18a_transfer_learning a :Method ;
    :hasText "transfer_learning" .

:li18a_we a :Generic ;
    :hasText "we" .

:linalg a owl:Class ;
    rdfs:subClassOf :Module .

:lite a owl:Class ;
    rdfs:subClassOf :Module .

:local_response_normalization a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:log_poisson_loss a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:log_softmax a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:log_uniform_candidate_sampler a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:logging a owl:Class ;
    rdfs:subClassOf :Module .

:lookup a owl:Class ;
    rdfs:subClassOf :Module .

:losses a owl:Class ;
    rdfs:subClassOf :Module .

:lrn a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:manip a owl:Class ;
    rdfs:subClassOf :Module .

:math a owl:Class ;
    rdfs:subClassOf :Module .

:max_pool a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:max_pool1d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:max_pool2d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:max_pool3d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:max_pool_with_argmax a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:max_poolv2 a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:metrics a owl:Class ;
    rdfs:subClassOf :Module .

:moments a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:nce_loss a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:nest a owl:Class ;
    rdfs:subClassOf :Module .

:normalize_moments a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:pool a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:profiler a owl:Class ;
    rdfs:subClassOf :Module .

:python_io a owl:Class ;
    rdfs:subClassOf :Module .

:quantization a owl:Class ;
    rdfs:subClassOf :Module .

:quantized_avg_pool a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:quantized_conv2d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:quantized_max_pool a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:quantized_relu_x a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:queue a owl:Class ;
    rdfs:subClassOf :Module .

:ragged a owl:Class ;
    rdfs:subClassOf :Module .

:random a owl:Class ;
    rdfs:subClassOf :Module .

:raw_ops a owl:Class ;
    rdfs:subClassOf :Module .

:raw_rnn a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:relu a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:relu6 a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:relu_layer a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:resource_loader a owl:Class ;
    rdfs:subClassOf :Module .

:safe_embedding_lookup_sparse a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:sampled_softmax_loss a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:saved_model a owl:Class ;
    rdfs:subClassOf :Module .

:selu a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:separable_conv2d a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:sets a owl:Class ;
    rdfs:subClassOf :Module .

:sharchilev18a_approach a :Generic ;
    :hasText "approach" .

:sharchilev18a_approaches a :Generic ;
    :hasText "approaches" .

:sharchilev18a_approximations a :Generic ;
    :hasText "approximations" .

:sharchilev18a_baselines a :Generic ;
    :hasText "baselines" .

:sharchilev18a_computational_complexity a :Eval ;
    :hasText "computational_complexity" .

:sharchilev18a_computational_efficiency a :Eval ;
    :hasText "computational_efficiency" .

:sharchilev18a_decision_trees a :Method ;
    :hasText "decision_trees" .

:sharchilev18a_ensemble a :Task ;
    :hasText "ensemble" .

:sharchilev18a_ensembles a :Task ;
    :hasText "ensembles" .

:sharchilev18a_framework a :Generic ;
    :hasText "framework" .

:sharchilev18a_gradient a :Other ;
    :hasText "gradient" .

:sharchilev18a_model a :Generic ;
    :hasText "model" .

:sharchilev18a_models a :Generic ;
    :hasText "models" .

:sharchilev18a_one a :Generic ;
    :hasText "one" .

:sharchilev18a_our_method a :Other ;
    :hasText "our_method" .

:sharchilev18a_parametric_models a :Method ;
    :hasText "parametric_models" .

:sharchilev18a_predictions a :Task ;
    :hasText "predictions" .

:sharchilev18a_problem a :Generic ;
    :hasText "problem" .

:sharchilev18a_quality a :Eval ;
    :hasText "quality" .

:sharchilev18a_scheme a :Generic ;
    :hasText "scheme" .

:sharchilev18a_that a :Generic ;
    :hasText "that" .

:sharchilev18a_this a :Generic ;
    :hasText "this" .

:sharchilev18a_training a :Task ;
    :hasText "training" .

:sharchilev18a_tree a :Other ;
    :hasText "tree" .

:sharchilev18a_tree_structures a :Other ;
    :hasText "tree_structures" .

:sharchilev18a_way a :Generic ;
    :hasText "way" .

:sharchilev18a_ways a :Generic ;
    :hasText "ways" .

:sharchilev18a_we a :Generic ;
    :hasText "we" .

:shi18a_applications a :Generic ;
    :hasText "applications" .

:shi18a_approach a :Generic ;
    :hasText "approach" .

:shi18a_bias a :Method ;
    :hasText "bias" .

:shi18a_effectiveness a :Eval ;
    :hasText "effectiveness" .

:shi18a_error_bound a :Other ;
    :hasText "error_bound" .

:shi18a_estimates a :Generic ;
    :hasText "estimates" .

:shi18a_extension a :Generic ;
    :hasText "extension" .

:shi18a_function a :Generic ;
    :hasText "function" .

:shi18a_gradient a :Other ;
    :hasText "gradient" .

:shi18a_method a :Generic ;
    :hasText "method" .

:shi18a_operators a :Generic ;
    :hasText "operators" .

:shi18a_our_method a :Other ;
    :hasText "our_method" .

:shi18a_pca a :Method ;
    :hasText "pca" .

:shi18a_results a :Generic ;
    :hasText "results" .

:shi18a_spectral_decomposition a :Method ;
    :hasText "spectral_decomposition" .

:shi18a_that a :Generic ;
    :hasText "that" .

:shi18a_this a :Generic ;
    :hasText "this" .

:shi18a_variance a :Generic ;
    :hasText "variance" .

:shi18a_variational_inference a :Method ;
    :hasText "variational_inference" .

:shi18a_we a :Generic ;
    :hasText "we" .

:sigmoid a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:sigmoid_cross_entropy_with_logits a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:signal a owl:Class ;
    rdfs:subClassOf :Module .

:silver17a_architecture a :Generic ;
    :hasText "architecture" .

:silver17a_deep_neural_network_architectures a :Method ;
    :hasText "deep_neural_network_architectures" .

:silver17a_fully_model a :Method ;
    :hasText "fully_model" .

:silver17a_function a :Generic ;
    :hasText "function" .

:silver17a_learn a :Task ;
    :hasText "learn" .

:silver17a_models a :Generic ;
    :hasText "models" .

:silver17a_planning a :Other ;
    :hasText "planning" .

:silver17a_predictions a :Task ;
    :hasText "predictions" .

:silver17a_reward a :Eval ;
    :hasText "reward" .

:silver17a_rewards a :Eval ;
    :hasText "rewards" .

:silver17a_that a :Generic ;
    :hasText "that" .

:silver17a_these a :Generic ;
    :hasText "these" .

:silver17a_this a :Generic ;
    :hasText "this" .

:silver17a_we a :Generic ;
    :hasText "we" .

:softmax a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:softmax_cross_entropy_with_logits a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:softmax_cross_entropy_with_logits_v2 a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:softplus a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:softsign a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:space_to_batch a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:space_to_depth a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:sparse a owl:Class ;
    rdfs:subClassOf :Module .

:sparse_softmax_cross_entropy_with_logits a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:spectral a owl:Class ;
    rdfs:subClassOf :Module .

:static_bidirectional_rnn a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:static_rnn a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:static_state_saving_rnn a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:sufficient_statistics a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:sun18e_architecture a :Generic ;
    :hasText "architecture" .

:sun18e_automatic a :Task ;
    :hasText "automatic" .

:sun18e_compositional a :Other ;
    :hasText "compositional" .

:sun18e_end-to-end a :Generic ;
    :hasText "end-to-end" .

:sun18e_family a :Generic ;
    :hasText "family" .

:sun18e_generalization a :Generic ;
    :hasText "generalization" .

:sun18e_kernels a :Method ;
    :hasText "kernels" .

:sun18e_network a :Generic ;
    :hasText "network" .

:sun18e_neural_network a :Method ;
    :hasText "neural_network" .

:sun18e_optimization a :Task ;
    :hasText "optimization" .

:sun18e_properties a :Generic ;
    :hasText "properties" .

:sun18e_rules a :Other ;
    :hasText "rules" .

:sun18e_structure a :Generic ;
    :hasText "structure" .

:sun18e_structures a :Generic ;
    :hasText "structures" .

:sun18e_tasks a :Generic ;
    :hasText "tasks" .

:sun18e_texture a :Other ;
    :hasText "texture" .

:sun18e_that a :Generic ;
    :hasText "that" .

:sun18e_this a :Generic ;
    :hasText "this" .

:sun18e_those a :Generic ;
    :hasText "those" .

:sun18e_time_series a :Generic ;
    :hasText "time_series" .

:sun18e_we a :Generic ;
    :hasText "we" .

:tanh a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:test a owl:Class ;
    rdfs:subClassOf :Module .

:top_k a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:tpu a owl:Class ;
    rdfs:subClassOf :Module .

:uniform_candidate_sampler a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:user_ops a owl:Class ;
    rdfs:subClassOf :Module .

:version a owl:Class ;
    rdfs:subClassOf :Module .

:weighted_cross_entropy_with_logits a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:weighted_moments a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:with_space_to_batch a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:xla a owl:Class ;
    rdfs:subClassOf :Module .

:xw_plus_b a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:zenke17a_applications a :Generic ;
    :hasText "applications" .

:zenke17a_approach a :Generic ;
    :hasText "approach" .

:zenke17a_artificial_neural_networks a :Method ;
    :hasText "artificial_neural_networks" .

:zenke17a_classification_tasks a :Method ;
    :hasText "classification_tasks" .

:zenke17a_complex a :Method ;
    :hasText "complex" .

:zenke17a_computational_efficiency a :Eval ;
    :hasText "computational_efficiency" .

:zenke17a_data a :Generic ;
    :hasText "data" .

:zenke17a_deep_learning a :Generic ;
    :hasText "deep_learning" .

:zenke17a_domains a :Generic ;
    :hasText "domains" .

:zenke17a_information a :Generic ;
    :hasText "information" .

:zenke17a_neural_networks a :Method ;
    :hasText "neural_networks" .

:zenke17a_ones a :Generic ;
    :hasText "ones" .

:zenke17a_relevant_information a :Generic ;
    :hasText "relevant_information" .

:zenke17a_task a :Generic ;
    :hasText "task" .

:zenke17a_tasks a :Generic ;
    :hasText "tasks" .

:zenke17a_that a :Generic ;
    :hasText "that" .

:zenke17a_this a :Generic ;
    :hasText "this" .

:zenke17a_time a :Generic ;
    :hasText "time" .

:zenke17a_we a :Generic ;
    :hasText "we" .

:zero_fraction a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:CodeEntity a owl:Class .

:ConvBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:Function a owl:Class .

:InputBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:OutputBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:app a owl:Class ;
    rdfs:subClassOf :Module .

:audio a owl:Class ;
    rdfs:subClassOf :Module .

:decode_wav a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:encode_wav a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:nn a owl:Class ;
    rdfs:subClassOf :Module .

:run a owl:Class ;
    rdfs:subClassOf :TensorFlowDefined .

:strings a owl:Class ;
    rdfs:subClassOf :Module .

:summary a owl:Class ;
    rdfs:subClassOf :Module .

:sysconfig a owl:Class ;
    rdfs:subClassOf :Module .

:PoolingBlock a owl:Class ;
    rdfs:subClassOf :FigureComponent .

:tf a owl:Class .

:Modality a owl:Class .

:Text a owl:Class ;
    rdfs:subClassOf :Modality .

<https://github.com/deepcurator/DCC/:fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1> a :Figure .

:Figure a owl:Class ;
    rdfs:subClassOf :Modality .

:TextEntity a owl:Class .

<https://github.com/deepcurator/DCC/:fig_Liu_SphereFace_Deep_Hypersphere_CVPR_2017_paper-Figure4-1> a :Figure .

:rnn_cell a owl:Class ;
    rdfs:subClassOf :nn .

<https://github.com/deepcurator/DCC/:fig_Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper-Figure5-1> a :Figure .

<https://github.com/deepcurator/DCC/:fig_Xu_Scene_Graph_Generation_CVPR_2017_paper-Figure3-1> a :Figure .

:FigureComponent a owl:Class .

<https://github.com/deepcurator/DCC/:fig_Qi_PointNet_Deep_Learning_CVPR_2017_paper-Figure2-1> a :Figure .

:Material a owl:Class ;
    rdfs:subClassOf :TextEntity .

<https://github.com/deepcurator/DCC/:fig_Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper-Figure6-1> a :Figure .

:Publication a owl:Class .

:Task a owl:Class ;
    rdfs:subClassOf :TextEntity .

:Module a owl:Class ;
    rdfs:subClassOf :tf .

:train a owl:Class ;
    rdfs:subClassOf :Module .

:Method a owl:Class ;
    rdfs:subClassOf :TextEntity .

:TensorFlowDefined a owl:Class ;
    rdfs:subClassOf :CodeEntity .

[] a owl:AllDisjointClasses ;
    owl:members ( :BasicLSTMCell :BasicRNNCell :DeviceWrapper :DropoutWrapper :GRUCell :LSTMCell :LSTMStateTuple :MultiRNNCell :RNNCell :ResidualWrapper ) .

[] a owl:AllDisjointClasses ;
    owl:members ( :Modality :TextEntity :tf ) .

[] a owl:AllDisjointClasses ;
    owl:members ( :all_candidate_sampler :atrous_conv2d :atrous_conv2d_transpose :avg_pool :avg_pool1d :avg_pool2d :avg_pool3d :avg_pool_v2 :batch_norm_with_global_normalization :batch_normalization :bias_add :bidirectional_dynamic_rnn :collapse_repeated :compute_accidental_hits :conv1d :conv1d_transpose :conv2d :conv2d_backprop_filter :conv2d_backprop_input :conv2d_transpose :conv3d :conv3d_backprop_filter_v2 :conv3d_transpose :conv_transpose :convolution :crelu :ctc_beam_search_decoder :ctc_beam_search_decoder_v2 :ctc_greedy_decoder :ctc_loss :ctc_loss_v2 :ctc_unique_labels :decode_wav :depth_to_space :depthwise_conv2d :depthwise_conv2d_backprop_filter :depthwise_conv2d_backprop_input :depthwise_conv2d_native :depthwise_conv2d_native_backprop_filter :depthwise_conv2d_native_backprop_input :dilation2d :dropout :dynamic_rnn :elu :embedding_lookup :embedding_lookup_sparse :encode_wav :erosion2d :fixed_unigram_candidate_sampler :fractional_avg_pool :fractional_max_pool :fused_batch_norm :in_top_k :l2_loss :l2_normalize :leaky_relu :learned_unigram_candidate_sampler :local_response_normalization :log_poisson_loss :log_softmax :log_uniform_candidate_sampler :lrn :max_pool :max_pool1d :max_pool2d :max_pool3d :max_pool_with_argmax :max_poolv2 :moments :nce_loss :normalize_moments :pool :quantized_avg_pool :quantized_conv2d :quantized_max_pool :quantized_relu_x :raw_rnn :relu :relu6 :relu_layer :run :safe_embedding_lookup_sparse :sampled_softmax_loss :selu :separable_conv2d :sigmoid :sigmoid_cross_entropy_with_logits :softmax :softmax_cross_entropy_with_logits :softmax_cross_entropy_with_logits_v2 :softplus :softsign :space_to_batch :space_to_depth :sparse_softmax_cross_entropy_with_logits :static_bidirectional_rnn :static_rnn :static_state_saving_rnn :sufficient_statistics :tanh :top_k :uniform_candidate_sampler :weighted_cross_entropy_with_logits :weighted_moments :with_space_to_batch :xw_plus_b :zero_fraction ) .

[] a owl:AllDisjointClasses ;
    owl:members ( :app :audio :autograph :bitwise :compat :config :contrib :data :debugging :distribute :distributions :dtypes :errors :estimator :experimental :feature_column :gfile :graph_util :image :initializers :io :keras :layers :linalg :lite :logging :lookup :losses :manip :math :metrics :nest :nn :profiler :python_io :quantization :queue :ragged :random :raw_ops :resource_loader :saved_model :sets :signal :sparse :spectral :strings :summary :sysconfig :test :tpu :train :user_ops :version :xla ) .

