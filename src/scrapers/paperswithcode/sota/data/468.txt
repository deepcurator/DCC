The fundamental role of hypernymy in NLP has motivated the development of
many methods for the automatic identification of this relation, most of which
rely on word distribution. We investigate an extensive number of such
unsupervised measures, using several distributional semantic models that differ
by context type and feature weighting. We analyze the performance of the
different methods based on their linguistic motivation. Comparison to the
state-of-the-art supervised methods shows that while supervised methods
generally outperform the unsupervised ones, the former are sensitive to the
distribution of training instances, hurting their reliability. Being based on
general linguistic hypotheses and independent from training data, unsupervised
measures are more robust, and therefore are still useful artillery for
hypernymy detection.