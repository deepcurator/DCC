Large pose variations remain to be a challenge that confronts real-word face
detection. We propose a new cascaded Convolutional Neural Network, dubbed the
name Supervised Transformer Network, to address this challenge. The first stage
is a multi-task Region Proposal Network (RPN), which simultaneously predicts
candidate face regions along with associated facial landmarks. The candidate
regions are then warped by mapping the detected facial landmarks to their
canonical positions to better normalize the face patterns. The second stage,
which is a RCNN, then verifies if the warped candidate regions are valid faces
or not. We conduct end-to-end learning of the cascaded network, including
optimizing the canonical positions of the facial landmarks. This supervised
learning of the transformations automatically selects the best scale to
differentiate face/non-face patterns. By combining feature maps from both
stages of the network, we achieve state-of-the-art detection accuracies on
several public benchmarks. For real-time performance, we run the cascaded
network only on regions of interests produced from a boosting cascade face
detector. Our detector runs at 30 FPS on a single CPU core for a VGA-resolution
image.