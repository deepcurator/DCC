In this paper, we present the Lipschitz regularization theory and algorithms
for a novel Loss-Sensitive Generative Adversarial Network (LS-GAN).
Specifically, it trains a loss function to distinguish between real and fake
samples by designated margins, while learning a generator alternately to
produce realistic samples by minimizing their losses. The LS-GAN further
regularizes its loss function with a Lipschitz regularity condition on the
density of real data, yielding a regularized model that can better generalize
to produce new data from a reasonable number of training examples than the
classic GAN. We will further present a Generalized LS-GAN (GLS-GAN) and show it
contains a large family of regularized GAN models, including both LS-GAN and
Wasserstein GAN, as its special cases. Compared with the other GAN models, we
will conduct experiments to show both LS-GAN and GLS-GAN exhibit competitive
ability in generating new images in terms of the Minimum Reconstruction Error
(MRE) assessed on a separate test set. We further extend the LS-GAN to a
conditional form for supervised and semi-supervised learning problems, and
demonstrate its outstanding performance on image classification tasks.