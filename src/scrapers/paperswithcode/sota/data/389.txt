Limited labeled data are available for the research of estimating facial
expression intensities. For instance, the ability to train deep networks for
automated pain assessment is limited by small datasets with labels of
patient-reported pain intensities. Fortunately, fine-tuning from a
data-extensive pre-trained domain, such as face verification, can alleviate
this problem. In this paper, we propose a network that fine-tunes a
state-of-the-art face verification network using a regularized regression loss
and additional data with expression labels. In this way, the expression
intensity regression task can benefit from the rich feature representations
trained on a huge amount of data for face verification. The proposed
regularized deep regressor is applied to estimate the pain expression intensity
and verified on the widely-used UNBC-McMaster Shoulder-Pain dataset, achieving
the state-of-the-art performance. A weighted evaluation metric is also proposed
to address the imbalance issue of different pain intensities.