The combination of global and partial features has been an essential solution
to improve discriminative performances in person re-identification (Re-ID)
tasks. Previous part-based methods mainly focus on locating regions with
specific pre-defined semantics to learn local representations, which increases
learning difficulty but not efficient or robust to scenarios with large
variances. In this paper, we propose an end-to-end feature learning strategy
integrating discriminative information with various granularities. We carefully
design the Multiple Granularity Network (MGN), a multi-branch deep network
architecture consisting of one branch for global feature representations and
two branches for local feature representations. Instead of learning on semantic
regions, we uniformly partition the images into several stripes, and vary the
number of parts in different local branches to obtain local feature
representations with multiple granularities. Comprehensive experiments
implemented on the mainstream evaluation datasets including Market-1501,
DukeMTMC-reid and CUHK03 indicate that our method has robustly achieved
state-of-the-art performances and outperformed any existing approaches by a
large margin. For example, on Market-1501 dataset in single query mode, we
achieve a state-of-the-art result of Rank-1/mAP=96.6%/94.2% after re-ranking.