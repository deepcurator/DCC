Conversational question answering (CQA) is a novel QA task that requires
understanding of dialogue context. Different from traditional single-turn
machine reading comprehension (MRC) tasks, CQA includes passage comprehension,
coreference resolution, and contextual understanding. In this paper, we propose
an innovated contextualized attention-based deep neural network, SDNet, to fuse
context into traditional MRC models. Our model leverages both inter-attention
and self-attention to comprehend conversation context and extract relevant
information from passage. Furthermore, we demonstrated a novel method to
integrate the latest BERT contextual model. Empirical results show the
effectiveness of our model, which sets the new state of the art result in CoQA
leaderboard, outperforming the previous best model by 1.6% F1. Our ensemble
model further improves the result by 2.7% F1.