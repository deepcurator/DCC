This paper presents a method for face detection in the wild, which integrates
a ConvNet and a 3D mean face model in an end-to-end multi-task discriminative
learning framework. The 3D mean face model is predefined and fixed (e.g., we
used the one provided in the AFLW dataset). The ConvNet consists of two
components: (i) The face pro- posal component computes face bounding box
proposals via estimating facial key-points and the 3D transformation (rotation
and translation) parameters for each predicted key-point w.r.t. the 3D mean
face model. (ii) The face verification component computes detection results by
prun- ing and refining proposals based on facial key-points based configuration
pooling. The proposed method addresses two issues in adapting state- of-the-art
generic object detection ConvNets (e.g., faster R-CNN) for face detection: (i)
One is to eliminate the heuristic design of prede- fined anchor boxes in the
region proposals network (RPN) by exploit- ing a 3D mean face model. (ii) The
other is to replace the generic RoI (Region-of-Interest) pooling layer with a
configuration pooling layer to respect underlying object structures. The
multi-task loss consists of three terms: the classification Softmax loss and
the location smooth l1 -losses [14] of both the facial key-points and the face
bounding boxes. In ex- periments, our ConvNet is trained on the AFLW dataset
only and tested on the FDDB benchmark with fine-tuning and on the AFW benchmark
without fine-tuning. The proposed method obtains very competitive
state-of-the-art performance in the two benchmarks.