This work introduces a novel convolutional network architecture for the task
of human pose estimation. Features are processed across all scales and
consolidated to best capture the various spatial relationships associated with
the body. We show how repeated bottom-up, top-down processing used in
conjunction with intermediate supervision is critical to improving the
performance of the network. We refer to the architecture as a "stacked
hourglass" network based on the successive steps of pooling and upsampling that
are done to produce a final set of predictions. State-of-the-art results are
achieved on the FLIC and MPII benchmarks outcompeting all recent methods.