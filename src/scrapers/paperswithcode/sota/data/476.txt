Training large-scale question answering systems is complicated because
training sources usually cover a small portion of the range of possible
questions. This paper studies the impact of multitask and transfer learning for
simple question answering; a setting for which the reasoning required to answer
is quite easy, as long as one can retrieve the correct evidence given a
question, which can be difficult in large-scale conditions. To this end, we
introduce a new dataset of 100k questions that we use in conjunction with
existing benchmarks. We conduct our study within the framework of Memory
Networks (Weston et al., 2015) because this perspective allows us to eventually
scale up to more complex reasoning, and show that Memory Networks can be
successfully trained to achieve excellent performance.