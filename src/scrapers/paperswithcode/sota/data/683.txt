Background: Given the importance of relation or event extraction from
biomedical research publications to support knowledge capture and synthesis,
and the strong dependency of approaches to this information extraction task on
syntactic information, it is valuable to understand which approaches to
syntactic processing of biomedical text have the highest performance. Results:
We perform an empirical study comparing state-of-the-art traditional
feature-based and neural network-based models for two core natural language
processing tasks of part-of-speech (POS) tagging and dependency parsing on two
benchmark biomedical corpora, GENIA and CRAFT. To the best of our knowledge,
there is no recent work making such comparisons in the biomedical context;
specifically no detailed analysis of neural models on this data is available.
Experimental results show that in general, the neural models outperform the
feature-based models on two benchmark biomedical corpora GENIA and CRAFT. We
also perform a task-oriented evaluation to investigate the influences of these
models in a downstream application on biomedical event extraction, and show
that better intrinsic parsing performance does not always imply better
extrinsic event extraction performance. Conclusion: We have presented a
detailed empirical study comparing traditional feature-based and neural
network-based models for POS tagging and dependency parsing in the biomedical
context, and also investigated the influence of parser selection for a
biomedical event extraction downstream task. Availability of data and material:
We make the retrained models available at
this https URL