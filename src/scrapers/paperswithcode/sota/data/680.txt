We present a simple and effective scheme for dependency parsing which is
based on bidirectional-LSTMs (BiLSTMs). Each sentence token is associated with
a BiLSTM vector representing the token in its sentential context, and feature
vectors are constructed by concatenating a few BiLSTM vectors. The BiLSTM is
trained jointly with the parser objective, resulting in very effective feature
extractors for parsing. We demonstrate the effectiveness of the approach by
applying it to a greedy transition-based parser as well as to a globally
optimized graph-based parser. The resulting parsers have very simple
architectures, and match or surpass the state-of-the-art accuracies on English
and Chinese.