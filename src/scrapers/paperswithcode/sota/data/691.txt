Neural network models have been demonstrated to be capable of achieving
remarkable performance in sentence and document modeling. Convolutional neural
network (CNN) and recurrent neural network (RNN) are two mainstream
architectures for such modeling tasks, which adopt totally different ways of
understanding natural languages. In this work, we combine the strengths of both
architectures and propose a novel and unified model called C-LSTM for sentence
representation and text classification. C-LSTM utilizes CNN to extract a
sequence of higher-level phrase representations, and are fed into a long
short-term memory recurrent neural network (LSTM) to obtain the sentence
representation. C-LSTM is able to capture both local features of phrases as
well as global and temporal sentence semantics. We evaluate the proposed
architecture on sentiment classification and question classification tasks. The
experimental results show that the C-LSTM outperforms both CNN and LSTM and can
achieve excellent performance on these tasks.