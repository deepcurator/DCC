:fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1 isA Figure 
:fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1 foundIn Light Field Intrinsics With a Deep Encoder-Decoder Network 
:fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1 hasCaption Figure 3. A single residual block of the network. After batch normalization, a first path leads through a (possibly strided) convolution layer and a leaky ReLU. A second path either keeps the input, or passes it through a strided convolution in case it needs to be resampled. Both paths are added together to produce the final output. The idea is that it is much easier for such blocks to learn the identiy transformation, or perform only small modifications to the input [10], which helps the encoder-decoder paths to gradually add details. 
:Comp0 partOf :fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1 
:Comp0 hasPos (13, 13, 480, 19) 
:Comp0 isType input 
:Comp0 hasDescription ['input '] 
:Comp1 partOf :fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1 
:Comp1 hasPos (13, 43, 480, 19) 
:Comp1 isType norm 
:Comp1 hasDescription ['batch +', 'normalization hit'] 
:Comp2 partOf :fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1 
:Comp2 hasPos (13, 96, 193, 19) 
:Comp2 isType conv 
:Comp2 hasDescription ['convolution '] 
:Comp3 partOf :fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1 
:Comp3 hasPos (301, 97, 192, 18) 
:Comp3 hasDescription ['lonvolutiol '] 
:Comp4 partOf :fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1 
:Comp4 hasPos (13, 126, 193, 20) 
:Comp4 isType activation 
:Comp4 hasDescription ['1 leaky ', 'relu + '] 
:Comp6 partOf :fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1 
:Comp6 hasPos (13, 201, 480, 20) 
:Comp6 isType output 
:Comp6 hasDescription ['Output '] 
:fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1 hasFlow top-to-bottom
