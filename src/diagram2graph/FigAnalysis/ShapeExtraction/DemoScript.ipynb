{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from ShapeDetect import ShapeDetect as sd\n",
    "from ArrowDetect import ArrowDetect as ad\n",
    "from TextDetect_OPENCV import TextDetectAll as tda\n",
    "from Diag2Graph_v2 import Diag2Graph as tgv2\n",
    "import pytesseract\n",
    "from ParseJSON import ParseJSON as pj\n",
    "\n",
    "# Comment below line for LINUX - Update below path for WINDOWS\n",
    "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessImage(image_path, resize):\n",
    "    \n",
    "    # load the image from disk and then preprocess it\n",
    "    image = cv2.imread(image_path)\n",
    "    # add white border in the original image        \n",
    "    image = cv2.copyMakeBorder(image,10,10,10,10,cv2.BORDER_CONSTANT,value=[255, 255, 255]) \n",
    "    if resize == 1:\n",
    "        newX, newY = image.shape[1]*1.5, image.shape[0]*1.5\n",
    "    else:\n",
    "        newX, newY = image.shape[1], image.shape[0]\n",
    "            \n",
    "    image_resize = cv2.resize(image,(int(newX),int(newY)))\n",
    "        \n",
    "    imgPIL = Image.open(image_path)\n",
    "    imgPIL = ImageOps.expand(imgPIL, border = 10, fill = 'white')\n",
    "    imgPIL = imgPIL.resize((int(newX),int(newY)), Image.ANTIALIAS)        \n",
    "    imgPIL = ImageEnhance.Color(imgPIL)\n",
    "    imgPIL = imgPIL.enhance(0)\n",
    "    gray_im = imgPIL.convert('L') \n",
    "\n",
    "    gray_imcv = np.array(gray_im, dtype=np.uint8)    \n",
    "    _, thresh_im = cv2.threshold(gray_imcv, 240, 255, cv2.THRESH_BINARY_INV)    \n",
    "        \n",
    "    return image_resize, thresh_im, gray_imcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdir_path = \"Input\"\n",
    "op_dir = \"Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images ...\n",
      "Input\\fig_1802.06006v2-Figure2-1.png\n",
      "4\n",
      "4\n",
      "Input\\fig_1802.06006v2-Figure2-1.png\n",
      "Input\\fig_1807.03039v2-Figure2-1.png\n",
      "11\n",
      "11\n",
      "Input\\fig_1807.03039v2-Figure2-1.png\n",
      "Input\\fig_7237-modulating-early-visual-processing-by-language-Figure1-1.png\n",
      "13\n",
      "13\n",
      "Input\\fig_7237-modulating-early-visual-processing-by-language-Figure1-1.png\n",
      "Input\\fig_7272-real-time-image-saliency-for-black-box-classifiers-Figure4-1.png\n",
      "16\n",
      "16\n",
      "Input\\fig_7272-real-time-image-saliency-for-black-box-classifiers-Figure4-1.png\n",
      "Input\\fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1.png\n",
      "7\n",
      "7\n",
      "Input\\fig_Alperovich_Light_Field_Intrinsics_CVPR_2018_paper-Figure3-1.png\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images ...\")\n",
    "    \n",
    "for filename in glob.glob(os.path.join(imdir_path, '*png')):\n",
    "    print(filename)\n",
    "    im, thresh_im, gray_imcv = preprocessImage(filename, 0)\n",
    "    \n",
    "    parsejson = pj()\n",
    "    paper_title, paper_file_name, paper_conf, paper_year, fig_caption, fig_text = parsejson.getCaption(filename)\n",
    "    if not os.path.isdir(os.path.join(op_dir, paper_file_name)):\n",
    "        os.mkdir(os.path.join(op_dir, paper_file_name))\n",
    "        os.mkdir(os.path.join(op_dir, paper_file_name, \"diag2graph\"))\n",
    "        os.mkdir(os.path.join(op_dir, paper_file_name, \"Figures\"))\n",
    "\n",
    "    cv2.imwrite(os.path.join(op_dir, paper_file_name+ \"/Figures/\" + os.path.basename(filename)), im)\n",
    "    \n",
    "    shapedetector = sd()\n",
    "    component, flow_dir = shapedetector.find_component(filename, op_dir, im, thresh_im, gray_imcv)\n",
    "               \n",
    "    textdetector = tda()\n",
    "    text_list = textdetector.combinedTextDetect(filename, im, component, fig_text)\n",
    "        \n",
    "    arrowdetector = ad()            \n",
    "    line_connect = arrowdetector.detectLines(im, thresh_im, gray_imcv, component, text_list)\n",
    "    \n",
    "    graphcreator = tgv2()\n",
    "    graphcreator.createDiag2Graph(op_dir, filename, im, thresh_im, component, flow_dir, text_list, line_connect, paper_title, paper_file_name, paper_conf, paper_year, fig_caption)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
