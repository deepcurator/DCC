[{
  "renderDpi": 150,
  "name": "1",
  "page": 5,
  "figType": "Table",
  "regionBoundary": {
    "x1": 108.0,
    "y1": 89.75999999999999,
    "x2": 502.08,
    "y2": 211.2
  },
  "caption": "Table 1: VQA accuracies trained with train set and evaluated on test-dev.",
  "imageText": ["44", "8", "MRN", "[14]", "with", "ResNet-50", "80.20%", "37.73%", "49.53%", "60.84%", "MRN", "[14]", "with", "ResNet-152", "80.95%", "38.39%", "50.59%", "61.73%", "MUTAN+MLB", "[2]", "82.29%", "37.27%", "48.23%", "61.02%", "MCB", "+", "Attention", "[9]", "with", "ResNet-50", "60.46%", "38.29%", "48.68%", "60.46%", "MCB", "+", "Attention", "[9]", "with", "ResNet-152", "-", "-", "-", "62.50%", "MODERN", "81.38%", "36.06%", "51.64%", "62.16%", "MODERN", "+", "MRN", "[14]", "82.17%", "38.06%", "52.29%", "63.01%", "44", "8x", "Ft", "Stage", "4", "78.37%", "34.27%", "43.72%", "56.91%", "Ft", "BN", "80.18%", "35.98%", "46.07%", "58.98%", "MODERN", "81.17%", "37.79%", "48.66%", "60.82%", "22", "4", "Baseline", "79.45%", "36.63%", "44.62%", "58.05%", "22", "4x", "Answer", "type", "Yes/No", "Number", "Other", "Overall"],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7237-modulating-early-visual-processing-by-language-Table1-1.png",
  "captionBoundary": {
    "x1": 160.56199645996094,
    "y1": 80.6075210571289,
    "x2": 451.13116455078125,
    "y2": 86.6099853515625
  }
}, {
  "renderDpi": 150,
  "name": "2",
  "page": 5,
  "figType": "Table",
  "regionBoundary": {
    "x1": 121.92,
    "y1": 256.8,
    "x2": 458.4,
    "y2": 339.36
  },
  "caption": "Table 2: Ablation study to investigate the impact of leaving out the lower stages of ResNet.",
  "imageText": ["CBN", "applied", "to", "Test", "error", "?", "29.92%", "Stage", "4", "26.42%", "Stages", "3?", "4", "25.24%", "Stages", "2?", "4", "25.31%", "All", "25.06%", "(b)", "GuessWhat?!,", "lower", "is", "better", "CBN", "applied", "to", "Val.", "accuracy", "?", "56.12%", "Stage", "4", "57.68%", "Stages", "3?", "4", "58.29%", "Stages", "2?", "4", "58.32%", "All", "58.56%", "(a)", "VQA,", "higher", "is", "better"],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7237-modulating-early-visual-processing-by-language-Table2-1.png",
  "captionBoundary": {
    "x1": 124.39299774169922,
    "y1": 239.75851440429688,
    "x2": 487.3006286621094,
    "y2": 245.760986328125
  }
}, {
  "renderDpi": 150,
  "name": "1",
  "page": 1,
  "figType": "Figure",
  "regionBoundary": {
    "x1": 156.96,
    "y1": 72.0,
    "x2": 455.03999999999996,
    "y2": 218.4
  },
  "caption": "Figure 1: An overview of the classic VQA pipeline (left) vs ours (right). While language and vision modalities are independently processed in the classic pipeline, we propose to directly modulate ResNet processing by language.",
  "imageText": [],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7237-modulating-early-visual-processing-by-language-Figure1-1.png",
  "captionBoundary": {
    "x1": 108.0,
    "y1": 226.17654418945312,
    "x2": 503.99761962890625,
    "y2": 253.99700927734375
  }
}, {
  "renderDpi": 150,
  "name": "3",
  "page": 6,
  "figType": "Table",
  "regionBoundary": {
    "x1": 108.0,
    "y1": 89.75999999999999,
    "x2": 504.0,
    "y2": 135.35999999999999
  },
  "caption": "Table 3: GuessWhat?! test errors for the Oracle model with different embeddings. Lower is better.",
  "imageText": ["Crop", "29.92%", "27.48%", "27.94%", "25.06%", "Crop", "+", "Spatial", "+", "Category", "22.55%", "22.68%", "22.42%", "19.52%", "Spatial", "+", "Category", "21.5%", "Raw", "features", "ft", "stage4", "Ft", "BN", "CBN"],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7237-modulating-early-visual-processing-by-language-Table3-1.png",
  "captionBoundary": {
    "x1": 109.98699951171875,
    "y1": 80.6075210571289,
    "x2": 501.7065124511719,
    "y2": 86.6099853515625
  }
}, {
  "renderDpi": 150,
  "name": "4",
  "page": 7,
  "figType": "Figure",
  "regionBoundary": {
    "x1": 108.0,
    "y1": 72.0,
    "x2": 501.12,
    "y2": 181.44
  },
  "caption": "Figure 4: t-SNE projection of feature maps (before attention mechanism) of ResNet and MODERN. Points are colored according to the answer type of VQA. Whilst there are no clusters with raw features, MODERN successfully modulates the image feature towards specific answer types.",
  "imageText": ["(a)", "Feature", "map", "projection", "from", "raw", "ResNet", "(b)", "Feature", "map", "projection", "from", "MODERN"],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7237-modulating-early-visual-processing-by-language-Figure4-1.png",
  "captionBoundary": {
    "x1": 108.0,
    "y1": 191.58450317382812,
    "x2": 505.7433166503906,
    "y2": 219.406005859375
  }
}, {
  "renderDpi": 150,
  "name": "2",
  "page": 3,
  "figType": "Figure",
  "regionBoundary": {
    "x1": 126.72,
    "y1": 70.56,
    "x2": 485.28,
    "y2": 210.23999999999998
  },
  "caption": "Figure 2: An overview of the computation graph of batch normalization (left) and conditional batch normalization (right). Best viewed in color.",
  "imageText": [],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7237-modulating-early-visual-processing-by-language-Figure2-1.png",
  "captionBoundary": {
    "x1": 108.0,
    "y1": 218.57351684570312,
    "x2": 503.9971618652344,
    "y2": 235.4849853515625
  }
}, {
  "renderDpi": 150,
  "name": "3",
  "page": 4,
  "figType": "Figure",
  "regionBoundary": {
    "x1": 156.96,
    "y1": 70.56,
    "x2": 455.03999999999996,
    "y2": 244.32
  },
  "caption": "Figure 3: An overview of the MODERN architecture conditioned on the language embedding. MODERN modulates the batch norm parameters in all residual blocks.",
  "imageText": [],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7237-modulating-early-visual-processing-by-language-Figure3-1.png",
  "captionBoundary": {
    "x1": 108.0,
    "y1": 252.01651000976562,
    "x2": 505.74517822265625,
    "y2": 268.927978515625
  }
}]