[{
  "renderDpi": 150,
  "name": "1",
  "page": 1,
  "figType": "Figure",
  "regionBoundary": {
    "x1": 109.92,
    "y1": 72.0,
    "x2": 502.08,
    "y2": 278.88
  },
  "caption": "Figure 1: An example of explanations produced by our model. The top row shows the explanation for the \"Egyptian cat\" while the bottom row shows the explanation for the \"Beagle\". Note that produced explanations can precisely both highlight and remove the selected object from the image.",
  "imageText": ["(a)", "Input", "Image", "(b)", "Generated", "saliency", "map", "(c)", "Image", "multiplied", "by", "the", "mask", "(d)", "Image", "multiplied", "by", "inverted", "mask"],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7272-real-time-image-saliency-for-black-box-classifiers-Figure1-1.png",
  "captionBoundary": {
    "x1": 108.0,
    "y1": 287.3587951660156,
    "x2": 504.0011291503906,
    "y2": 311.9679870605469
  }
}, {
  "renderDpi": 150,
  "name": "5",
  "page": 6,
  "figType": "Figure",
  "regionBoundary": {
    "x1": 108.96,
    "y1": 70.56,
    "x2": 503.03999999999996,
    "y2": 342.24
  },
  "caption": "Figure 5: Saliency maps generated by different methods for the ground truth class. The ground truth classes, starting from the first row are: Scottish terrier, chocolate syrup, standard schnauzer and sorrel. Columns b, c, d show the masks generated by our masking models, each trained on a different black box classifier (from left to right: AlexNet, GoogleNet, ResNet-50). Last two columns e, f show saliency maps for GoogleNet generated respectively by gradient [11] and the recently introduced iterative mask optimisation approach [2].",
  "imageText": ["(a)", "Input", "Image", "(b)", "Model", "&", "AlexNet", "(c)", "Model", "&", "GoogleNet", "(d)", "Model", "&", "ResNet-50", "(e)", "Grad", "[11]", "(f)", "Mask", "[2]"],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7272-real-time-image-saliency-for-black-box-classifiers-Figure5-1.png",
  "captionBoundary": {
    "x1": 108.0,
    "y1": 350.80780029296875,
    "x2": 505.1168518066406,
    "y2": 394.34600830078125
  }
}, {
  "renderDpi": 150,
  "name": "3",
  "page": 2,
  "figType": "Figure",
  "regionBoundary": {
    "x1": 168.95999999999998,
    "y1": 582.72,
    "x2": 443.03999999999996,
    "y2": 676.3199999999999
  },
  "caption": "Figure 3: The adversarial mask introduces very small perturbations, but can completely alter the classifier’s predictions. From left to right: an image which is correctly recognised by the classifier with a high confidence as a \"tabby cat\"; a generated adversarial mask; an original image after application of the mask that is no longer recognised as a \"tabby cat\".",
  "imageText": [],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7272-real-time-image-saliency-for-black-box-classifiers-Figure3-1.png",
  "captionBoundary": {
    "x1": 108.0,
    "y1": 683.0867309570312,
    "x2": 504.15655517578125,
    "y2": 717.1610107421875
  }
}, {
  "renderDpi": 150,
  "name": "2",
  "page": 2,
  "figType": "Figure",
  "regionBoundary": {
    "x1": 168.95999999999998,
    "y1": 188.64,
    "x2": 443.03999999999996,
    "y2": 280.32
  },
  "caption": "Figure 2: From left to right: the input image; smallest sufficient region (SSR); smallest destroying region (SDR). Regions were found using the mask optimisation procedure from [2].",
  "imageText": [],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7272-real-time-image-saliency-for-black-box-classifiers-Figure2-1.png",
  "captionBoundary": {
    "x1": 108.0,
    "y1": 287.18878173828125,
    "x2": 505.57196044921875,
    "y2": 302.3340148925781
  }
}, {
  "renderDpi": 150,
  "name": "1",
  "page": 7,
  "figType": "Table",
  "regionBoundary": {
    "x1": 156.96,
    "y1": 71.52,
    "x2": 453.12,
    "y2": 104.16
  },
  "caption": "Table 1: Weakly supervised bounding box localisation error on ImageNet validation set for our masking models trained with different black box classifiers.",
  "imageText": ["Alexnet", "[5]", "GoogleNet", "[14]", "ResNet-50", "[3]", "Localisation", "Err", "(%)", "39.8", "36.9", "36.7"],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7272-real-time-image-saliency-for-black-box-classifiers-Table1-1.png",
  "captionBoundary": {
    "x1": 107.72200012207031,
    "y1": 110.43880462646484,
    "x2": 504.0000915527344,
    "y2": 125.5830078125
  }
}, {
  "renderDpi": 150,
  "name": "2",
  "page": 7,
  "figType": "Table",
  "regionBoundary": {
    "x1": 109.92,
    "y1": 231.84,
    "x2": 499.2,
    "y2": 264.0
  },
  "caption": "Table 2: Localisation errors(%) on ImageNet validation set for popular weakly supervised methods. Error rates were taken from [2] which recalculated originally reported results using few different mask thresholding techniques and achieved slightly lower error rates. For a fair comparison, all the methods follow the same evaluation protocol of [1] and produce saliency maps for GoogleNet classifier [14].",
  "imageText": ["Center", "Grad", "[11]", "Guid", "[12]", "CAM", "[18]", "Exc", "[16]", "Feed", "[1]", "Mask", "[2]", "This", "Work", "46.3", "41.7", "42.0", "48.1", "39.0", "38.7", "43.1", "36.9"],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7272-real-time-image-saliency-for-black-box-classifiers-Table2-1.png",
  "captionBoundary": {
    "x1": 107.72200012207031,
    "y1": 270.7857971191406,
    "x2": 504.15283203125,
    "y2": 304.8590087890625
  }
}, {
  "renderDpi": 150,
  "name": "3",
  "page": 7,
  "figType": "Table",
  "regionBoundary": {
    "x1": 153.6,
    "y1": 476.64,
    "x2": 455.03999999999996,
    "y2": 566.4
  },
  "caption": "Table 3: ImageNet localisation error and the saliency metric for GoogleNet.",
  "imageText": ["Localisation", "Err", "(%)", "Saliency", "Metric", "Ground", "truth", "boxes", "(baseline)", "0.00", "0.284", "Max", "box", "(baseline)", "59.7", "1.366", "Center", "box", "(baseline)", "46.3", "0.645", "Grad", "[11]", "41.7", "0.451", "Exc", "[16]", "39.0", "0.415", "Masking", "model", "(this", "work)", "36.9", "0.318"],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7272-real-time-image-saliency-for-black-box-classifiers-Table3-1.png",
  "captionBoundary": {
    "x1": 169.93699645996094,
    "y1": 572.478759765625,
    "x2": 441.7892150878906,
    "y2": 578.1589965820312
  }
}, {
  "renderDpi": 150,
  "name": "6",
  "page": 8,
  "figType": "Figure",
  "regionBoundary": {
    "x1": 116.64,
    "y1": 70.56,
    "x2": 495.35999999999996,
    "y2": 154.07999999999998
  },
  "caption": "Figure 6: Saliency maps generated by our model for images from CIFAR-10 validation set.",
  "imageText": [],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7272-real-time-image-saliency-for-black-box-classifiers-Figure6-1.png",
  "captionBoundary": {
    "x1": 142.625,
    "y1": 161.90174865722656,
    "x2": 469.3784484863281,
    "y2": 167.58197021484375
  }
}, {
  "renderDpi": 150,
  "name": "4",
  "page": 4,
  "figType": "Figure",
  "regionBoundary": {
    "x1": 156.0,
    "y1": 404.64,
    "x2": 456.47999999999996,
    "y2": 575.04
  },
  "caption": "Figure 4: Architecture diagram of the masking model.",
  "imageText": [],
  "renderURL": "C:/Aditi/ProjectWork/DARPA_ASKE/DATASET/pwc_edited_plt_withImage/NIPS/image/fig_7272-real-time-image-saliency-for-black-box-classifiers-Figure4-1.png",
  "captionBoundary": {
    "x1": 208.85899353027344,
    "y1": 582.8587646484375,
    "x2": 403.14288330078125,
    "y2": 588.5390014648438
  }
}]