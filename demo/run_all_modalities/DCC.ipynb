{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Code Curator\n",
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check our [readme](./) for the requirements file and other prerequisites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Necessary modules have been successfully imported!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('../../src'))\n",
    "\n",
    "import text2graph\n",
    "import diagram2graph\n",
    "import code2graph\n",
    "import pytesseract\n",
    "import IPython\n",
    "\n",
    "from visualize import get_vis, get_nx_vis\n",
    "from rdflib import Graph, URIRef\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Necessary modules have been successfully imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Input /Output Folders and Required Dependencies\n",
    "<a id=\"input\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- INPUT ---------\n",
    "# Path to the folder which contains the input pdf file(s)\n",
    "### We included two sample papers in the demo_input folder\n",
    "inputFolder = 'demo_input'\n",
    "\n",
    "# Path to the folder which contains the code repositories of the papers in the inputFolder\n",
    "### For the sample papers we provided, you can download the project codes \n",
    "### as a zip from the below links\n",
    "### https://github.com/ShichenLiu/CondenseNet and extract to the folder demo_code\n",
    "### https://github.com/mikacuy/pointnetvlad and extract to the folder demo_code\n",
    "codeFolder = \"demo_code\"\n",
    "\n",
    "# CSV file that maps the pdf file name in the inputFolder to the code repository name in the codeFolder\n",
    "# A sample CSV file is provided for the sample papers above\n",
    "inputCSV = 'input.csv'\n",
    "\n",
    "# --------- OUTPUT ---------\n",
    "# Path to the folder to which the output from all three modalities will be placed\n",
    "outputFolder = 'demo_output'\n",
    "\n",
    "# --------- DEPENDENCIES ---------\n",
    "# The dependencies that you have downloaded following the instructions from README\n",
    "ontology_file = \"DeepSciKG.nt\"\n",
    "text2graph_models_dir = \"text2graph_models\"\n",
    "image2graph_models_dir = \"image2graph_models\"\n",
    "grobid_client = \"grobid-client-python\"\n",
    "\n",
    "# Comment below line for LINUX - Update below path for WINDOWS\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Text2Graph!\n",
    "Reminders: Make sure that Grobid Server is running! (cd into the grobid-0.5.5 folder and run `gradle run`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Extracting XML from PDF's...\n",
      "[Info] Extracting abstracts from XML's...\n",
      "[Info] Extracting entities/relationships and generating RDF's...\n",
      "Completed processing file CondenseNet.txt\n",
      "Saving rdf file demo_output/text2graph/CondenseNet_text2graph.ttl\n",
      "Completed processing file PointNetVLAD.txt\n",
      "Saving rdf file demo_output/text2graph/PointNetVLAD_text2graph.ttl\n",
      "[Info] Completed text2graph pipeline!\n"
     ]
    }
   ],
   "source": [
    "from text2graph import t2graph\n",
    "\n",
    "# Uncomment below two lines if you have a proxy in your network\n",
    "# os.environ['http_proxy'] = \"\"\n",
    "# os.environ['https_proxy'] = \"\"\n",
    "\n",
    "t2graph.run(inputFolder, outputFolder, ontology_file, text2graph_models_dir, grobid_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have seen the message \"[Info] Completed text2graph pipeline!\", this means you can now explore the output of the text2graph module in the outputFolder you specified. The file `text2graph.ttl` contains the output graph for each paper!\n",
    "\n",
    "Below, we visualize the results as a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"text2graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x27d114d2dd8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse(outputFolder + \"/text2graph/PointNetVLAD_text2graph.ttl\", format=\"ttl\")\n",
    "g_vis = get_vis(g, \"Text\")\n",
    "g_vis.show(\"text2graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Image2Graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading trained models ...\n",
      "Loaded binary classifier model from disk\n",
      "Loaded multiclass classifier model from disk\n",
      "[INFO] Loading and analyzing images ...\n",
      "[INFO] Creating RDF graph ...\n",
      "Processing paper: CondenseNet.pdf\n",
      "demo_output/image2graph/CondenseNet/diag2graph\n",
      "[]\n",
      "Processing paper: PointNetVLAD.pdf\n",
      "demo_output/image2graph/PointNetVLAD/diag2graph\n",
      "['demo_output/image2graph/PointNetVLAD/diag2graph\\\\PointNetVLAD-Figure2-1.txt']\n",
      "[Info] Completed image2graph pipeline!\n"
     ]
    }
   ],
   "source": [
    "from diagram2graph.FigAnalysis.ShapeExtraction import i2graph\n",
    "\n",
    "i2graph.run(inputFolder, outputFolder, ontology_file, image2graph_models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have seen the message \"[Info] Completed image2graph pipeline!\", this means you can now explore the output of the image2graph module in the outputFolder you specified. The file `image2graph.ttl` contains the output graph for each paper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"image2graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x27d12d784e0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse(outputFolder + \"/image2graph/PointNetVLAD/image2graph.ttl\", format=\"ttl\")\n",
    "g_vis = get_vis(g, \"Image\")\n",
    "g_vis.show(\"image2graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Code2Graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master\\\\cifar10.py'...\n",
      "Listing 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master\\\\data'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master\\\\data\\\\generate_cifar10_tfrecords.py'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master\\\\experiment.py'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master\\\\main.py'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master\\\\model.py'...\n",
      "Reading cached tf types file\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\cifar10.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\experiment.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\main.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\model.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\data\\generate_cifar10_tfrecords.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\cifar10.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\experiment.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\main.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\model.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\data\\generate_cifar10_tfrecords.py\n",
      "Start from root: <Node module:generate_cifar10_tfrecords>\n",
      "Start from root: <Node module:main>\n",
      "dump info with option 3: dump_rdf_graphs\n",
      "[Info] Completed code2graph pipeline for condensenet-tensorflow-master!\n",
      "Listing 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\evaluate.py'...\n",
      "Listing 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\generating_queries'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\generating_queries\\\\generate_test_sets.py'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\generating_queries\\\\generate_training_tuples_baseline.py'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\generating_queries\\\\generate_training_tuples_refine.py'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\loading_pointclouds.py'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\loupe.py'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\pointnetvlad_cls.py'...\n",
      "Listing 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\submap_generation'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\tf_util.py'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\train_pointnetvlad.py'...\n",
      "Compiling 'C:\\\\aske-2\\\\demo\\\\new\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\transform_nets.py'...\n",
      "Reading cached tf types file\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\evaluate.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\loading_pointclouds.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\loupe.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\pointnetvlad_cls.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\tf_util.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\train_pointnetvlad.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\transform_nets.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\generating_queries\\generate_test_sets.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\generating_queries\\generate_training_tuples_baseline.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\generating_queries\\generate_training_tuples_refine.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\evaluate.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\loading_pointclouds.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\loupe.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\pointnetvlad_cls.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\tf_util.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\train_pointnetvlad.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\transform_nets.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\generating_queries\\generate_test_sets.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\generating_queries\\generate_training_tuples_baseline.py\n",
      "C:\\aske-2\\demo\\new\\DCC\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\generating_queries\\generate_training_tuples_refine.py\n",
      "Start from root: <Node function:pointnetvlad_cls.lazy_quadruplet_loss_sm>\n",
      "Start from root: <Node module:generate_training_tuples_refine>\n",
      "Start from root: <Node module:generate_test_sets>\n",
      "Start from root: <Node module:train_pointnetvlad>\n",
      "Start from root: <Node namespace:tf_util.dropout.lambda>\n",
      "Start from root: <Node module:evaluate>\n",
      "Start from root: <Node module:generate_training_tuples_baseline>\n",
      "Start from root: <Node function:loading_pointclouds.get_jittered_tuple>\n",
      "Start from root: <Node function:pointnetvlad_cls.quadruplet_loss_sm>\n",
      "Start from root: <Node function:pointnetvlad_cls.quadruplet_loss>\n",
      "Start from root: <Node function:loading_pointclouds.get_rotated_tuple>\n",
      "dump info with option 3: dump_rdf_graphs\n",
      "[Info] Completed code2graph pipeline for pointnetvlad-master!\n",
      "[Info] Completed code2graph pipeline for all repositories!\n"
     ]
    }
   ],
   "source": [
    "from code2graph import c2graph\n",
    "\n",
    "# Uncomment below two lines if you have a proxy in your network\n",
    "# Update the ip address and the port number with your proxy information\n",
    "# os.environ['http_proxy'] = \"194.138.0.9:9400\" \n",
    "# os.environ['https_proxy'] = \"194.138.0.9:9400\" \n",
    "\n",
    "c2graph.run(codeFolder, outputFolder, ontology_file, inputCSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have seen the message \"[Info] Completed code2graph pipeline for all repositories!\", this means you can now explore the output of the code2graph module in the outputFolder you specified. The file `code2graph.ttl` contains the output graph for each paper!\n",
    "\n",
    "There is a graph visualization created for each of the input python files from the repository. Change the filename in the below cell to display different graph visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002ftnu\\AppData\\Local\\Continuum\\anaconda3\\envs\\all4\\lib\\site-packages\\IPython\\core\\display.py:694: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=demo_output/code2graph/pointnetvlad-master/pointnetvlad_clsquadruplet_loss.html width=100% height=350></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize code2graph results\n",
    "# You may change the below file name to display graphs for other python files\n",
    "vis_file_to_display = outputFolder + \"/code2graph/pointnetvlad-master/pointnetvlad_clsquadruplet_loss.html\"\n",
    "iframe = '<iframe src=' + vis_file_to_display + ' width=100% height=350></iframe>'\n",
    "IPython.display.HTML(iframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all4",
   "language": "python",
   "name": "all4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
