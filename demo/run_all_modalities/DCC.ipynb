{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Code Curator\n",
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check our [readme](./) for the requirements file and other prerequisites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Necessary modules have been successfully imported!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('../../src'))\n",
    "\n",
    "import text2graph\n",
    "import diagram2graph\n",
    "import code2graph\n",
    "import pytesseract\n",
    "import IPython\n",
    "\n",
    "from visualize import get_vis\n",
    "from rdflib import Graph, URIRef\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Necessary modules have been successfully imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Input /Output Folders and Required Dependencies\n",
    "<a id=\"input\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- INPUT ---------\n",
    "# Path to the folder which contains the input pdf file(s)\n",
    "### We included two sample papers in the demo_input folder\n",
    "inputFolder = 'demo_input'\n",
    "\n",
    "# Path to the folder which contains the code repositories of the papers in the inputFolder\n",
    "### For the sample papers we provided, you can download the project codes \n",
    "### as a zip from the below links\n",
    "### https://github.com/ShichenLiu/CondenseNet and extract to the folder demo_code\n",
    "### https://github.com/mikacuy/pointnetvlad and extract to the folder demo_code\n",
    "codeFolder = \"demo_code\"\n",
    "\n",
    "# CSV file that maps the pdf file name in the inputFolder to the code repository name in the codeFolder\n",
    "# A sample CSV file is provided for the sample papers above\n",
    "inputCSV = 'input.csv'\n",
    "\n",
    "# --------- OUTPUT ---------\n",
    "# Path to the folder to which the output from all three modalities will be placed\n",
    "outputFolder = 'demo_output'\n",
    "\n",
    "# --------- DEPENDENCIES ---------\n",
    "# The dependencies that you have downloaded following the instructions from README\n",
    "ontology_file = \"DeepSciKG.nt\"\n",
    "text2graph_models_dir = \"text2graph_models\"\n",
    "image2graph_models_dir = \"image2graph_models\"\n",
    "grobid_client = \"grobid-client-python\"\n",
    "\n",
    "# Comment below line for LINUX - Update below path for WINDOWS\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Text2Graph!\n",
    "Reminders: Make sure that Grobid Server is running! (cd into the grobid-0.5.5 folder and run `gradle run`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Extracting XML from PDF's...\n",
      "[Info] Extracting abstracts from XML's...\n",
      "[Info] Extracting entities/relationships and generating RDF's...\n",
      "Done with file input_paper\n",
      "Saving rdf file demo_output/text2graph/input_paper_text2graph.ttl\n",
      "[Info] Completed text2graph pipeline!\n"
     ]
    }
   ],
   "source": [
    "from text2graph import text2rdfgraph\n",
    "\n",
    "# Uncomment below two lines if you have a proxy in your network\n",
    "os.environ['http_proxy'] = \"\"\n",
    "os.environ['https_proxy'] = \"\"\n",
    "\n",
    "text2rdfgraph.run_demo(inputFolder, outputFolder, ontology_file, text2graph_models_dir, grobid_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have seen the message \"[Info] Completed text2graph pipeline!\", this means you can now explore the output of the text2graph module in the outputFolder you specified. The file `text2graph.ttl` contains the output graph for each paper!\n",
    "\n",
    "Below, we visualize the results as a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Backup-Restored\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_output\\\\text2graph\\\\Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper_text2graph.ttl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-1ea6f9c07e18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputFolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/text2graph/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper_text2graph.ttl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ttl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mg_vis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_vis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mg_vis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text2graph.html\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\z002ftnu\\AppData\\Local\\Continuum\\anaconda3\\envs\\all4\\lib\\site-packages\\rdflib\\graph.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, source, publicID, format, location, file, data, **args)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         source = create_input_source(source=source, publicID=publicID,\n\u001b[0;32m   1033\u001b[0m                                      \u001b[0mlocation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m                                      data=data, format=format)\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\z002ftnu\\AppData\\Local\\Continuum\\anaconda3\\envs\\all4\\lib\\site-packages\\rdflib\\parser.py\u001b[0m in \u001b[0;36mcreate_input_source\u001b[1;34m(source, publicID, location, file, data, format)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mabsolute_location\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"file:///\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl2pathname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabsolute_location\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"file:///\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0minput_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mURLInputSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabsolute_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Backup-Restored\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_output\\\\text2graph\\\\Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper_text2graph.ttl'"
     ]
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse(outputFolder + \"/text2graph/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper_text2graph.ttl\", format=\"ttl\")\n",
    "g_vis = get_vis(g, \"Text\")\n",
    "g_vis.show(\"text2graph.html\")\n",
    "\n",
    "# g_image = Graph()\n",
    "# g_image.parse(outputFolder + \"/image2graph/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper/image2graph.ttl\", format=\"ttl\")\n",
    "# g_image_vis = get_vis(g_image, \"Image\")\n",
    "# g_image_vis.show(\"image2graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Image2Graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading trained models ...\n",
      "Loaded binary classifier model from disk\n",
      "Loaded multiclass classifier model from disk\n",
      "[INFO] Loading and analyzing images ...\n",
      "[INFO] Creating RDF graph ...\n",
      "Processing paper: input_paper.pdf\n",
      "demo_output\\image2graph\\input_paper\\image2graph.ttl\n",
      "[Info] Completed image2graph pipeline!\n"
     ]
    }
   ],
   "source": [
    "from diagram2graph.FigAnalysis.ShapeExtraction import i2graph\n",
    "\n",
    "i2graph.run(inputFolder, outputFolder, ontology_file, image2graph_models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have seen the message \"[Info] Completed image2graph pipeline!\", this means you can now explore the output of the image2graph module in the outputFolder you specified. The file `image2graph.ttl` contains the output graph for each paper!\n",
    "\n",
    "Below, we visualize the results as a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"image2graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1f10a5c75f8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse(outputFolder + \"/image2graph/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper/image2graph.ttl\", format=\"ttl\")\n",
    "g_vis = get_vis(g, \"Image\")\n",
    "g_vis.show(\"image2graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Code2Graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python script_lightweight.py -ip demo_code/condensenet-tensorflow-master -opt 3 -ont DeepSciKG.nt -pid CondenseNet.pdf --arg --url\n",
      "Listing 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master\\\\cifar10.py'...\n",
      "Listing 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master\\\\data'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master\\\\data\\\\generate_cifar10_tfrecords.py'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master\\\\experiment.py'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master\\\\main.py'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\condensenet-tensorflow-master\\\\model.py'...\n",
      "Reading cached tf types file\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\cifar10.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\experiment.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\main.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\model.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\data\\generate_cifar10_tfrecords.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\cifar10.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\experiment.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\main.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\model.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\condensenet-tensorflow-master\\data\\generate_cifar10_tfrecords.py\n",
      "Start from root: <Node module:main>\n",
      "Start from root: <Node module:generate_cifar10_tfrecords>\n",
      "dump info with option 3: dump_rdf_graphs\n",
      "[Info] Completed code2graph pipeline for condensenet-tensorflow-master!\n",
      "python script_lightweight.py -ip demo_code/pointnetvlad-master -opt 3 -ont DeepSciKG.nt -pid Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper.pdf --arg --url\n",
      "Listing 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\evaluate.py'...\n",
      "Listing 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\generating_queries'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\generating_queries\\\\generate_test_sets.py'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\generating_queries\\\\generate_training_tuples_baseline.py'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\generating_queries\\\\generate_training_tuples_refine.py'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\loading_pointclouds.py'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\loupe.py'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\pointnetvlad_cls.py'...\n",
      "Listing 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\submap_generation'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\tf_util.py'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\train_pointnetvlad.py'...\n",
      "Compiling 'C:\\\\home\\\\projects\\\\DARPA ASKE\\\\DCC-dev\\\\demo\\\\run_all_modalities\\\\demo_code\\\\pointnetvlad-master\\\\transform_nets.py'...\n",
      "Reading cached tf types file\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\evaluate.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\loading_pointclouds.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\loupe.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\pointnetvlad_cls.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\tf_util.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\train_pointnetvlad.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\transform_nets.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\generating_queries\\generate_test_sets.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\generating_queries\\generate_training_tuples_baseline.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\generating_queries\\generate_training_tuples_refine.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\evaluate.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\loading_pointclouds.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\loupe.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\pointnetvlad_cls.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\tf_util.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\train_pointnetvlad.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\transform_nets.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\generating_queries\\generate_test_sets.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\generating_queries\\generate_training_tuples_baseline.py\n",
      "C:\\home\\projects\\DARPA ASKE\\DCC-dev\\demo\\run_all_modalities\\demo_code\\pointnetvlad-master\\generating_queries\\generate_training_tuples_refine.py\n",
      "Start from root: <Node function:loading_pointclouds.get_jittered_tuple>\n",
      "Start from root: <Node module:train_pointnetvlad>\n",
      "Start from root: <Node namespace:tf_util.dropout.lambda>\n",
      "Start from root: <Node function:pointnetvlad_cls.quadruplet_loss_sm>\n",
      "Start from root: <Node module:evaluate>\n",
      "Start from root: <Node function:loading_pointclouds.get_rotated_tuple>\n",
      "Start from root: <Node module:generate_test_sets>\n",
      "Start from root: <Node module:generate_training_tuples_refine>\n",
      "Start from root: <Node function:pointnetvlad_cls.lazy_quadruplet_loss_sm>\n",
      "Start from root: <Node function:pointnetvlad_cls.quadruplet_loss>\n",
      "Start from root: <Node module:generate_training_tuples_baseline>\n",
      "dump info with option 3: dump_rdf_graphs\n",
      "[Info] Completed code2graph pipeline for pointnetvlad-master!\n",
      "[Info] Completed code2graph pipeline for all repositories!\n"
     ]
    }
   ],
   "source": [
    "from code2graph import c2graph\n",
    "\n",
    "# Uncomment below two lines if you have a proxy in your network\n",
    "# Update the ip address and the port number with your proxy information\n",
    "# os.environ['http_proxy'] = \"194.138.0.9:9400\" \n",
    "# os.environ['https_proxy'] = \"194.138.0.9:9400\" \n",
    "\n",
    "c2graph.run(codeFolder, outputFolder, ontology_file, inputCSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have seen the message \"[Info] Completed code2graph pipeline for all repositories!\", this means you can now explore the output of the code2graph module in the outputFolder you specified. The file `code2graph.ttl` contains the output graph for each paper!\n",
    "\n",
    "There is a graph visualization created for each of the input python files from the repository. Change the filename in the below cell to display different graph visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=demo_output/code2graph/pointnetvlad-master/pointnetvlad_clsquadruplet_loss.html width=100% height=350></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize code2graph results\n",
    "# You may change the below file name to display graphs for other python files\n",
    "vis_file_to_display = outputFolder + \"/code2graph/pointnetvlad-master/pointnetvlad_clsquadruplet_loss.html\"\n",
    "iframe = '<iframe src=' + vis_file_to_display + ' width=100% height=350></iframe>'\n",
    "IPython.display.HTML(iframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
