{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Code Curator\n",
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check our [readme](./) for the requirements file and other prerequisites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary modules have been successfully imported!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('../../src'))\n",
    "\n",
    "import text2graph\n",
    "import diagram2graph\n",
    "import code2graph\n",
    "import pytesseract\n",
    "import IPython\n",
    "\n",
    "from visualize import get_vis\n",
    "from rdflib import Graph, URIRef\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Necessary modules have been successfully imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Input /Output Folders and Required Dependencies\n",
    "<a id=\"input\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- INPUT ---------\n",
    "# Path to the folder which contains the input pdf file(s)\n",
    "### We included two sample papers in the demo_input folder\n",
    "inputFolder = 'demo_input_Copy'\n",
    "\n",
    "# Path to the folder which contains the code repositories of the papers in the inputFolder\n",
    "### For the sample papers we provided, you can download the project codes \n",
    "### as a zip from the below links\n",
    "### https://github.com/ShichenLiu/CondenseNet and extract to the folder demo_code\n",
    "### https://github.com/mikacuy/pointnetvlad and extract to the folder demo_code\n",
    "codeFolder = \"demo_code_Copy\"\n",
    "\n",
    "# CSV file that maps the pdf file name in the inputFolder to the code repository name in the codeFolder\n",
    "# A sample CSV file is provided for the sample papers above\n",
    "inputCSV = 'input_Copy.csv'\n",
    "\n",
    "# --------- OUTPUT ---------\n",
    "# Path to the folder to which the output from all three modalities will be placed\n",
    "outputFolder = 'demo_output_Copy'\n",
    "\n",
    "# --------- DEPENDENCIES ---------\n",
    "# The dependencies that you have downloaded following the instructions from README\n",
    "ontology_file = \"DeepSciKG.nt\"\n",
    "text2graph_models_dir = \"text2graph_models\"\n",
    "image2graph_models_dir = \"image2graph_models\"\n",
    "grobid_client = \"grobid-client-python\"\n",
    "\n",
    "# Comment below line for LINUX - Update below path for WINDOWS\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Text2Graph!\n",
    "Reminders: Make sure that Grobid Server is running! (cd into the grobid-0.5.5 folder and run `gradle run`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Extracting XML from PDF's...\n",
      "[Info] Extracting abstracts from XML's...\n",
      "[Info] Extracting entities/relationships and generating RDF's...\n",
      "Completed processing file CondenseNet.txt\n",
      "Saving rdf file demo_output_Copy/text2graph/CondenseNet_text2graph.ttl\n",
      "Completed processing file input_paper.txt\n",
      "Saving rdf file demo_output_Copy/text2graph/input_paper_text2graph.ttl\n",
      "Completed processing file Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper.txt\n",
      "Saving rdf file demo_output_Copy/text2graph/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper_text2graph.ttl\n",
      "[Info] Completed text2graph pipeline!\n"
     ]
    }
   ],
   "source": [
    "from text2graph import t2graph\n",
    "\n",
    "# Uncomment below two lines if you have a proxy in your network\n",
    "os.environ['http_proxy'] = \"\"\n",
    "os.environ['https_proxy'] = \"\"\n",
    "\n",
    "t2graph.run(inputFolder, outputFolder, ontology_file, text2graph_models_dir, grobid_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have seen the message \"[Info] Completed text2graph pipeline!\", this means you can now explore the output of the text2graph module in the outputFolder you specified. The file `text2graph.ttl` contains the output graph for each paper!\n",
    "\n",
    "Below, we visualize the results as a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"text2graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x26a117e7e48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse(outputFolder + \"/text2graph/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper_text2graph.ttl\", format=\"ttl\")\n",
    "g_vis = get_vis(g, \"Text\")\n",
    "g_vis.show(\"text2graph.html\")\n",
    "\n",
    "# g_image = Graph()\n",
    "# g_image.parse(outputFolder + \"/image2graph/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper/image2graph.ttl\", format=\"ttl\")\n",
    "# g_image_vis = get_vis(g_image, \"Image\")\n",
    "# g_image_vis.show(\"image2graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Image2Graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\z002ftnu\\AppData\\Local\\Continuum\\anaconda3\\envs\\dcc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\z002ftnu\\AppData\\Local\\Continuum\\anaconda3\\envs\\dcc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\z002ftnu\\AppData\\Local\\Continuum\\anaconda3\\envs\\dcc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\z002ftnu\\AppData\\Local\\Continuum\\anaconda3\\envs\\dcc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\z002ftnu\\AppData\\Local\\Continuum\\anaconda3\\envs\\dcc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\z002ftnu\\AppData\\Local\\Continuum\\anaconda3\\envs\\dcc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading trained models ...\n",
      "WARNING:tensorflow:From C:\\Users\\z002ftnu\\AppData\\Local\\Continuum\\anaconda3\\envs\\dcc\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\z002ftnu\\AppData\\Local\\Continuum\\anaconda3\\envs\\dcc\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Loaded binary classifier model from disk\n",
      "Loaded multiclass classifier model from disk\n",
      "[INFO] Loading and analyzing images ...\n",
      "[INFO] Creating RDF graph ...\n",
      "Processing paper: CondenseNet.pdf\n",
      "demo_output_Copy/image2graph/CondenseNet/diag2graph\n",
      "[]\n",
      "Processing paper: input_paper.pdf\n",
      "demo_output_Copy/image2graph/input_paper/diag2graph\n",
      "['demo_output_Copy/image2graph/input_paper/diag2graph\\\\input_paper-Figure2-1.txt', 'demo_output_Copy/image2graph/input_paper/diag2graph\\\\input_paper-Figure4-1.txt']\n",
      "Processing paper: Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper.pdf\n",
      "demo_output_Copy/image2graph/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper/diag2graph\n",
      "['demo_output_Copy/image2graph/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper/diag2graph\\\\Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper-Figure2-1.txt']\n",
      "[Info] Completed image2graph pipeline!\n"
     ]
    }
   ],
   "source": [
    "from diagram2graph.FigAnalysis.ShapeExtraction import i2graph\n",
    "\n",
    "i2graph.run(inputFolder, outputFolder, ontology_file, image2graph_models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have seen the message \"[Info] Completed image2graph pipeline!\", this means you can now explore the output of the image2graph module in the outputFolder you specified. The file `image2graph.ttl` contains the output graph for each paper!\n",
    "\n",
    "Below, we visualize the results as a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"image2graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x26a7bf6b438>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse(outputFolder + \"/image2graph/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper/image2graph.ttl\", format=\"ttl\")\n",
    "g_vis = get_vis(g, \"Image\")\n",
    "g_vis.show(\"image2graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Code2Graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python script_lightweight.py -ip demo_code_Copy/condensenet-tensorflow-master -opt 3 -ont DeepSciKG.nt -pid CondenseNet.pdf --arg --url\n",
      "Listing 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\condensenet-tensorflow-master'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\condensenet-tensorflow-master\\\\cifar10.py'...\n",
      "Listing 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\condensenet-tensorflow-master\\\\data'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\condensenet-tensorflow-master\\\\data\\\\generate_cifar10_tfrecords.py'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\condensenet-tensorflow-master\\\\experiment.py'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\condensenet-tensorflow-master\\\\main.py'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\condensenet-tensorflow-master\\\\model.py'...\n",
      "Reading cached tf types file\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\condensenet-tensorflow-master\\cifar10.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\condensenet-tensorflow-master\\experiment.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\condensenet-tensorflow-master\\main.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\condensenet-tensorflow-master\\model.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\condensenet-tensorflow-master\\data\\generate_cifar10_tfrecords.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\condensenet-tensorflow-master\\cifar10.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\condensenet-tensorflow-master\\experiment.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\condensenet-tensorflow-master\\main.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\condensenet-tensorflow-master\\model.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\condensenet-tensorflow-master\\data\\generate_cifar10_tfrecords.py\n",
      "Start from root: <Node module:main>\n",
      "Start from root: <Node module:generate_cifar10_tfrecords>\n",
      "dump info with option 3: dump_rdf_graphs\n",
      "[Info] Completed code2graph pipeline for condensenet-tensorflow-master!\n",
      "python script_lightweight.py -ip demo_code_Copy/pointnetvlad-master -opt 3 -ont DeepSciKG.nt -pid Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper.pdf --arg --url\n",
      "Listing 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master\\\\evaluate.py'...\n",
      "Listing 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master\\\\generating_queries'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master\\\\generating_queries\\\\generate_test_sets.py'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master\\\\generating_queries\\\\generate_training_tuples_baseline.py'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master\\\\generating_queries\\\\generate_training_tuples_refine.py'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master\\\\loading_pointclouds.py'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master\\\\loupe.py'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master\\\\pointnetvlad_cls.py'...\n",
      "Listing 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master\\\\submap_generation'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master\\\\tf_util.py'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master\\\\train_pointnetvlad.py'...\n",
      "Compiling 'C:\\\\DCC\\\\DCC\\\\demo\\\\run_all_modalities\\\\demo_code_Copy\\\\pointnetvlad-master\\\\transform_nets.py'...\n",
      "Reading cached tf types file\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\evaluate.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\loading_pointclouds.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\loupe.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\pointnetvlad_cls.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\tf_util.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\train_pointnetvlad.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\transform_nets.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\generating_queries\\generate_test_sets.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\generating_queries\\generate_training_tuples_baseline.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\generating_queries\\generate_training_tuples_refine.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\evaluate.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\loading_pointclouds.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\loupe.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\pointnetvlad_cls.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\tf_util.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\train_pointnetvlad.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\transform_nets.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\generating_queries\\generate_test_sets.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\generating_queries\\generate_training_tuples_baseline.py\n",
      "C:\\DCC\\DCC\\demo\\run_all_modalities\\demo_code_Copy\\pointnetvlad-master\\generating_queries\\generate_training_tuples_refine.py\n",
      "Start from root: <Node function:loading_pointclouds.get_rotated_tuple>\n",
      "Start from root: <Node module:train_pointnetvlad>\n",
      "Start from root: <Node function:pointnetvlad_cls.quadruplet_loss>\n",
      "Start from root: <Node module:generate_test_sets>\n",
      "Start from root: <Node module:evaluate>\n",
      "Start from root: <Node module:generate_training_tuples_refine>\n",
      "Start from root: <Node function:pointnetvlad_cls.lazy_quadruplet_loss_sm>\n",
      "Start from root: <Node module:generate_training_tuples_baseline>\n",
      "Start from root: <Node function:loading_pointclouds.get_jittered_tuple>\n",
      "Start from root: <Node namespace:tf_util.dropout.lambda>\n",
      "Start from root: <Node function:pointnetvlad_cls.quadruplet_loss_sm>\n",
      "dump info with option 3: dump_rdf_graphs\n",
      "[Info] Completed code2graph pipeline for pointnetvlad-master!\n",
      "[Info] Completed code2graph pipeline for all repositories!\n"
     ]
    }
   ],
   "source": [
    "from code2graph import c2graph\n",
    "\n",
    "# Uncomment below two lines if you have a proxy in your network\n",
    "# Update the ip address and the port number with your proxy information\n",
    "# os.environ['http_proxy'] = \"194.138.0.9:9400\" \n",
    "# os.environ['https_proxy'] = \"194.138.0.9:9400\" \n",
    "\n",
    "c2graph.run(codeFolder, outputFolder, ontology_file, inputCSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have seen the message \"[Info] Completed code2graph pipeline for all repositories!\", this means you can now explore the output of the code2graph module in the outputFolder you specified. The file `code2graph.ttl` contains the output graph for each paper!\n",
    "\n",
    "There is a graph visualization created for each of the input python files from the repository. Change the filename in the below cell to display different graph visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\z002ftnu\\AppData\\Local\\Continuum\\anaconda3\\envs\\dcc\\lib\\site-packages\\IPython\\core\\display.py:694: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src=demo_output_Copy/code2graph/pointnetvlad-master/pointnetvlad_clsquadruplet_loss.html width=100% height=350></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize code2graph results\n",
    "# You may change the below file name to display graphs for other python files\n",
    "vis_file_to_display = outputFolder + \"/code2graph/pointnetvlad-master/pointnetvlad_clsquadruplet_loss.html\"\n",
    "iframe = '<iframe src=' + vis_file_to_display + ' width=100% height=350></iframe>'\n",
    "IPython.display.HTML(iframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
